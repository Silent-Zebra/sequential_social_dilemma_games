srun: job 1101900 queued and waiting for resources
srun: job 1101900 has been allocated resources
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-07-15_17-27-51_25792/logs.
Waiting for redis server at 127.0.0.1:51379 to respond...
Waiting for redis server at 127.0.0.1:52749 to respond...
Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
Starting the Plasma object store with 20.0 GB memory using /dev/shm.

======================================================================
View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=e92522ede590e035f60b47380ccdb41a22e74a9470ca6774
======================================================================

Commencing experiment harvest_A3C
{'monitor': False, 'log_level': 'INFO', 'callbacks': {'on_episode_start': <ray.tune.suggest.variant_generator.function object at 0x7fc982ef9668>, 'on_episode_end': <ray.tune.suggest.variant_generator.function object at 0x7fc982ef95c0>}, 'model': {'custom_model': 'conv_to_fc_net', 'use_lstm': True, 'lstm_cell_size': 128}, 'optimizer': {}, 'gamma': 0.99, 'horizon': 1000, 'env_config': {'func_create': <ray.tune.suggest.variant_generator.function object at 0x7fc9818e5da0>, 'env_name': 'harvest_env', 'run': 'A3C'}, 'env': None, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'num_workers': 2, 'num_gpus': 0, 'num_cpus_per_worker': 0.5, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'num_envs_per_worker': 1, 'sample_batch_size': 10, 'train_batch_size': 30000, 'batch_mode': 'truncate_episodes', 'sample_async': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_evaluator_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'input': 'sampler', 'input_evaluation': None, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policy_graphs': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_pytorch': False, 'lambda': 1.0, 'grad_clip': 40.0, 'lr': 0.0001, 'lr_schedule': [[0, 0.00136], [20000000, 2.8e-05]], 'vf_loss_coeff': 0.5, 'entropy_coeff': -0.000687, 'min_iter_time_s': 5}
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB

Created LogSyncer for /h/zhaostep/ray_results/harvest_A3C/A3C_harvest_env_0_2020-07-15_17-27-521s8hh6zk -> 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 24.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING

/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-15 17:28:04,709	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
2020-07-15 17:28:04.710175: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-15 17:28:16,674	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
2020-07-15 17:28:16.675442: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-07-15 17:28:17,151	INFO policy_evaluator.py:262 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
2020-07-15 17:28:17.153798: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
From /h/zhaostep/.conda/envs/causal/lib/python3.6/site-packages/ray/rllib/models/lstm.py:59: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-28-28
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.442
    dispatch_time_ms: 10.343
    learner:
      cur_lr: 0.0013599999947473407
      grad_gnorm: 39.99999237060547
      policy_entropy: 63.75481414794922
      policy_loss: -2235.9130859375
      var_gnorm: 18.661136627197266
      vf_explained_var: -0.001030564308166504
      vf_loss: 31883.3984375
    num_steps_sampled: 5000
    num_steps_trained: 5000
    wait_time_ms: 76.318
  iterations_since_restore: 1
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 22.82659935951233
  time_this_iter_s: 22.82659935951233
  time_total_s: 22.82659935951233
  timestamp: 1594848508
  timesteps_since_restore: 5000
  timesteps_this_iter: 5000
  timesteps_total: 5000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 22 s, 1 iter, 5000 ts, nan rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -9137.625491587238
agent-2: -8878.625491587238
agent-3: -9670.62549158724
agent-4: -9034.625491587236
agent-5: -9182.625491587234
Extrinsic Rewards:
-992
-733
-1525
-889
-1037
Sum Reward: -5176
Avg Reward: -1035.2
Min Reward: -1525
Max Reward: -733
Gini Coefficient: -0.1338485316846986
20:20 Ratio: 0.48065573770491804
Max-min Ratio: 0.48065573770491804
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-28-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -45904.12745793646
  episode_reward_mean: -45904.12745793646
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 1
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 10.243
    learner:
      cur_lr: 0.0013596670469269156
      grad_gnorm: 39.999961853027344
      policy_entropy: 49.62348556518555
      policy_loss: -681.5404052734375
      var_gnorm: 19.1874942779541
      vf_explained_var: -0.012122511863708496
      vf_loss: 6870.6298828125
    num_steps_sampled: 10000
    num_steps_trained: 10000
    wait_time_ms: 78.19
  iterations_since_restore: 2
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 31.625195503234863
  time_this_iter_s: 8.798596143722534
  time_total_s: 31.625195503234863
  timestamp: 1594848517
  timesteps_since_restore: 10000
  timesteps_this_iter: 5000
  timesteps_total: 10000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 25.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 31 s, 2 iter, 10000 ts, -4.59e+04 rew

[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
agent-1: -8137.080774191373
agent-2: -7827.080774191374
agent-3: -8464.080774191378
agent-4: -8330.08077419138
agent-5: -8318.080774191378
Extrinsic Rewards:
-842
-532
-1169
-1035
-1023
Sum Reward: -4601
Avg Reward: -920.2
Min Reward: -1169
Max Reward: -532
Gini Coefficient: -0.12753749184959792
20:20 Ratio: 0.4550898203592814
Max-min Ratio: 0.4550898203592814
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-28-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -41076.40387095732
  episode_reward_mean: -43490.265664446895
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 2
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.566
    dispatch_time_ms: 9.118
    learner:
      cur_lr: 0.0013593339826911688
      grad_gnorm: 39.999977111816406
      policy_entropy: 72.35618591308594
      policy_loss: 132.7970733642578
      var_gnorm: 20.44381332397461
      vf_explained_var: -0.005871772766113281
      vf_loss: 97.40776062011719
    num_steps_sampled: 15000
    num_steps_trained: 15000
    wait_time_ms: 74.566
  iterations_since_restore: 3
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 40.17757868766785
  time_this_iter_s: 8.552383184432983
  time_total_s: 40.17757868766785
  timestamp: 1594848526
  timesteps_since_restore: 15000
  timesteps_this_iter: 5000
  timesteps_total: 15000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 40 s, 3 iter, 15000 ts, -4.35e+04 rew

agent-1: -461.3084221960791
agent-2: -416.3084221960791
agent-3: -457.30842219607916
agent-4: -596.3084221960793
agent-5: -423.30842219607916
Extrinsic Rewards:
-42
3
-38
-177
-4
Sum Reward: -258
Avg Reward: -51.6
Min Reward: -177
Max Reward: 3
Gini Coefficient: -0.6170542635658914
20:20 Ratio: -0.01694915254237288
Max-min Ratio: -0.01694915254237288
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-28-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2354.542110980375
  episode_reward_mean: -29778.357813291386
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 3
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.265
    dispatch_time_ms: 11.108
    learner:
      cur_lr: 0.0013590010348707438
      grad_gnorm: 39.99998092651367
      policy_entropy: 75.9474868774414
      policy_loss: 63.56661605834961
      var_gnorm: 20.938304901123047
      vf_explained_var: -0.0027654170989990234
      vf_loss: 32.48453903198242
    num_steps_sampled: 20000
    num_steps_trained: 20000
    wait_time_ms: 71.344
  iterations_since_restore: 4
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 48.680346965789795
  time_this_iter_s: 8.502768278121948
  time_total_s: 48.680346965789795
  timestamp: 1594848534
  timesteps_since_restore: 20000
  timesteps_this_iter: 5000
  timesteps_total: 20000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 48 s, 4 iter, 20000 ts, -2.98e+04 rew

agent-1: -910.6009127046303
agent-2: -900.600912704631
agent-3: -950.6009127046308
agent-4: -937.6009127046301
agent-5: -853.6009127046309
Extrinsic Rewards:
-101
-91
-141
-128
-44
Sum Reward: -505
Avg Reward: -101.0
Min Reward: -141
Max Reward: -44
Gini Coefficient: -0.18297029702970297
20:20 Ratio: 0.3120567375886525
Max-min Ratio: 0.3120567375886525
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-29-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2354.542110980375
  episode_reward_mean: -23472.019500849332
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 4
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.934
    dispatch_time_ms: 8.682
    learner:
      cur_lr: 0.0013586679706349969
      grad_gnorm: 40.0
      policy_entropy: 71.84381103515625
      policy_loss: 63.82258987426758
      var_gnorm: 21.002248764038086
      vf_explained_var: 0.04384005069732666
      vf_loss: 25.316524505615234
    num_steps_sampled: 25000
    num_steps_trained: 25000
    wait_time_ms: 77.296
  iterations_since_restore: 5
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 57.37520098686218
  time_this_iter_s: 8.694854021072388
  time_total_s: 57.37520098686218
  timestamp: 1594848543
  timesteps_since_restore: 25000
  timesteps_this_iter: 5000
  timesteps_total: 25000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 57 s, 5 iter, 25000 ts, -2.35e+04 rew

agent-1: -593.0428692585451
agent-2: -451.0428692585449
agent-3: -494.0428692585449
agent-4: -496.0428692585449
agent-5: -503.04286925854495
Extrinsic Rewards:
-142
0
-43
-45
-52
Sum Reward: -282
Avg Reward: -56.4
Min Reward: -142
Max Reward: 0
Gini Coefficient: -0.4156028368794326
20:20 Ratio: -0.0
Max-min Ratio: -0.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-29-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2354.542110980375
  episode_reward_mean: -19285.05846993802
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 5
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.371
    dispatch_time_ms: 7.875
    learner:
      cur_lr: 0.0013583350228145719
      grad_gnorm: 40.0
      policy_entropy: 64.65535736083984
      policy_loss: 30.134944915771484
      var_gnorm: 20.965103149414062
      vf_explained_var: 0.044367074966430664
      vf_loss: 10.208227157592773
    num_steps_sampled: 30000
    num_steps_trained: 30000
    wait_time_ms: 76.19
  iterations_since_restore: 6
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 66.13702464103699
  time_this_iter_s: 8.761823654174805
  time_total_s: 66.13702464103699
  timestamp: 1594848552
  timesteps_since_restore: 30000
  timesteps_this_iter: 5000
  timesteps_total: 30000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 66 s, 6 iter, 30000 ts, -1.93e+04 rew

agent-1: -1087.3999329543176
agent-2: -1180.3999329543176
agent-3: -1130.3999329543178
agent-4: -1039.3999329543174
agent-5: -1133.3999329543174
Extrinsic Rewards:
-97
-190
-140
-49
-143
Sum Reward: -619
Avg Reward: -123.8
Min Reward: -190
Max Reward: -49
Gini Coefficient: -0.21195476575121164
20:20 Ratio: 0.2578947368421053
Max-min Ratio: 0.2578947368421053
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-29-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -2354.542110980375
  episode_reward_mean: -16999.382002410282
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 6
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.315
    dispatch_time_ms: 8.527
    learner:
      cur_lr: 0.001358001958578825
      grad_gnorm: 40.000003814697266
      policy_entropy: 74.25007629394531
      policy_loss: -17.060609817504883
      var_gnorm: 20.977970123291016
      vf_explained_var: 7.510185241699219e-06
      vf_loss: 1.832158088684082
    num_steps_sampled: 35000
    num_steps_trained: 35000
    wait_time_ms: 74.452
  iterations_since_restore: 7
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 74.86515355110168
  time_this_iter_s: 8.728128910064697
  time_total_s: 74.86515355110168
  timestamp: 1594848561
  timesteps_since_restore: 35000
  timesteps_this_iter: 5000
  timesteps_total: 35000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 74 s, 7 iter, 35000 ts, -1.7e+04 rew

agent-1: -136.58878826775634
agent-2: -137.58878826775634
agent-3: -182.58878826775623
agent-4: -135.58878826775634
agent-5: -181.5887882677563
Extrinsic Rewards:
1
0
-45
2
-44
Sum Reward: -86
Avg Reward: -17.2
Min Reward: -45
Max Reward: 2
Gini Coefficient: -0.6465116279069767
20:20 Ratio: -0.044444444444444446
Max-min Ratio: -0.044444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-29-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -773.9439413387736
  episode_reward_mean: -14681.46227940007
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 7
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.068
    dispatch_time_ms: 7.795
    learner:
      cur_lr: 0.0013576690107584
      grad_gnorm: 39.999996185302734
      policy_entropy: 66.25369262695312
      policy_loss: 123.07430267333984
      var_gnorm: 20.982234954833984
      vf_explained_var: -1.6450881958007812e-05
      vf_loss: 135.91558837890625
    num_steps_sampled: 40000
    num_steps_trained: 40000
    wait_time_ms: 74.063
  iterations_since_restore: 8
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 83.68145394325256
  time_this_iter_s: 8.816300392150879
  time_total_s: 83.68145394325256
  timestamp: 1594848569
  timesteps_since_restore: 40000
  timesteps_this_iter: 5000
  timesteps_total: 40000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 83 s, 8 iter, 40000 ts, -1.47e+04 rew

agent-1: -203.5758034073315
agent-2: -251.5758034073315
agent-3: -206.57580340733156
agent-4: -251.57580340733145
agent-5: -255.5758034073315
Extrinsic Rewards:
4
-44
1
-44
-48
Sum Reward: -131
Avg Reward: -26.2
Min Reward: -48
Max Reward: 4
Gini Coefficient: -0.4549618320610687
20:20 Ratio: -0.08333333333333333
Max-min Ratio: -0.08333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-29-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -773.9439413387736
  episode_reward_mean: -12992.389371604642
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 8
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 8.104
    learner:
      cur_lr: 0.001357335946522653
      grad_gnorm: 4.659061908721924
      policy_entropy: 45.82505416870117
      policy_loss: -1.290176510810852
      var_gnorm: 21.245588302612305
      vf_explained_var: 0.807197093963623
      vf_loss: 0.02964690886437893
    num_steps_sampled: 45000
    num_steps_trained: 45000
    wait_time_ms: 79.346
  iterations_since_restore: 9
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 92.38305020332336
  time_this_iter_s: 8.7015962600708
  time_total_s: 92.38305020332336
  timestamp: 1594848578
  timesteps_since_restore: 45000
  timesteps_this_iter: 5000
  timesteps_total: 45000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 92 s, 9 iter, 45000 ts, -1.3e+04 rew

agent-1: -17.71997722559834
agent-2: -69.71997722559821
agent-3: -27.719977225598218
agent-4: -25.71997722559823
agent-5: -26.719977225598225
Extrinsic Rewards:
12
-40
2
4
3
Sum Reward: -19
Avg Reward: -3.8
Min Reward: -40
Max Reward: 12
Gini Coefficient: -2.231578947368421
20:20 Ratio: -0.3
Max-min Ratio: -0.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-29-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: -167.5998861279893
  episode_reward_mean: -11567.412762107237
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 9
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.666
    dispatch_time_ms: 12.778
    learner:
      cur_lr: 0.001357002998702228
      grad_gnorm: 39.652122497558594
      policy_entropy: 65.06015014648438
      policy_loss: 11.82048225402832
      var_gnorm: 21.290679931640625
      vf_explained_var: 0.32772690057754517
      vf_loss: 1.1179263591766357
    num_steps_sampled: 50000
    num_steps_trained: 50000
    wait_time_ms: 72.845
  iterations_since_restore: 10
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 101.17036962509155
  time_this_iter_s: 8.787319421768188
  time_total_s: 101.17036962509155
  timestamp: 1594848587
  timesteps_since_restore: 50000
  timesteps_this_iter: 5000
  timesteps_total: 50000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 26.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 101 s, 10 iter, 50000 ts, -1.16e+04 rew

agent-1: 53.19999999296426
agent-2: 61.199999992964266
agent-3: 56.19999999296426
agent-4: 62.19999999296426
agent-5: 55.19999999296426
Extrinsic Rewards:
2
10
5
11
4
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.3
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-29-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 287.999999964822
  episode_reward_mean: -10381.871485900032
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 10
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 7.668
    learner:
      cur_lr: 0.001356670050881803
      grad_gnorm: 3.1866230964660645
      policy_entropy: 68.18338775634766
      policy_loss: -0.997660756111145
      var_gnorm: 21.3089656829834
      vf_explained_var: -3.5762786865234375e-05
      vf_loss: 0.0068627879954874516
    num_steps_sampled: 55000
    num_steps_trained: 55000
    wait_time_ms: 79.95
  iterations_since_restore: 11
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 110.0290322303772
  time_this_iter_s: 8.858662605285645
  time_total_s: 110.0290322303772
  timestamp: 1594848596
  timesteps_since_restore: 55000
  timesteps_this_iter: 5000
  timesteps_total: 55000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 110 s, 11 iter, 55000 ts, -1.04e+04 rew

agent-1: -31.18729639905086
agent-2: -33.18729639905088
agent-3: -78.18729639905084
agent-4: -34.18729639905088
agent-5: -38.187296399050915
Extrinsic Rewards:
7
5
-40
4
0
Sum Reward: -24
Avg Reward: -4.8
Min Reward: -40
Max Reward: 7
Gini Coefficient: -1.65
20:20 Ratio: -0.175
Max-min Ratio: -0.175
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-30-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 287.999999964822
  episode_reward_mean: -9457.604667363234
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 11
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.344
    dispatch_time_ms: 10.182
    learner:
      cur_lr: 0.0013563369866460562
      grad_gnorm: 20.259815216064453
      policy_entropy: 75.95314025878906
      policy_loss: 7.7679219245910645
      var_gnorm: 21.31609344482422
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.2785305678844452
    num_steps_sampled: 60000
    num_steps_trained: 60000
    wait_time_ms: 74.225
  iterations_since_restore: 12
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 118.73653936386108
  time_this_iter_s: 8.707507133483887
  time_total_s: 118.73653936386108
  timestamp: 1594848605
  timesteps_since_restore: 60000
  timesteps_this_iter: 5000
  timesteps_total: 60000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 118 s, 12 iter, 60000 ts, -9.46e+03 rew

agent-1: 53.6035828854776
agent-2: 55.6035828854776
agent-3: 63.60358288547754
agent-4: 51.603582885477614
agent-5: 54.6035828854776
Extrinsic Rewards:
4
6
14
2
5
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.33548387096774196
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-30-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 287.999999964822
  episode_reward_mean: -8646.219452214016
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 12
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.81
    dispatch_time_ms: 12.136
    learner:
      cur_lr: 0.0013560040388256311
      grad_gnorm: 3.586733818054199
      policy_entropy: 65.46391296386719
      policy_loss: -1.427056074142456
      var_gnorm: 21.31806182861328
      vf_explained_var: -3.6954879760742188e-06
      vf_loss: 0.009197389706969261
    num_steps_sampled: 65000
    num_steps_trained: 65000
    wait_time_ms: 73.13
  iterations_since_restore: 13
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 127.48686599731445
  time_this_iter_s: 8.75032663345337
  time_total_s: 127.48686599731445
  timestamp: 1594848613
  timesteps_since_restore: 65000
  timesteps_this_iter: 5000
  timesteps_total: 65000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 127 s, 13 iter, 65000 ts, -8.65e+03 rew

agent-1: 29.99999999966418
agent-2: 23.99999999966418
agent-3: 24.99999999966418
agent-4: 29.99999999966418
agent-5: 25.99999999966418
Extrinsic Rewards:
6
0
1
6
2
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.4533333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-30-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 287.999999964822
  episode_reward_mean: -7970.741032813066
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 13
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.232
    dispatch_time_ms: 9.58
    learner:
      cur_lr: 0.0013556709745898843
      grad_gnorm: 6.0956196784973145
      policy_entropy: 20.6190242767334
      policy_loss: 0.7121079564094543
      var_gnorm: 21.32422637939453
      vf_explained_var: -2.5033950805664062e-06
      vf_loss: 0.027417026460170746
    num_steps_sampled: 70000
    num_steps_trained: 70000
    wait_time_ms: 69.562
  iterations_since_restore: 14
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 136.0681607723236
  time_this_iter_s: 8.581294775009155
  time_total_s: 136.0681607723236
  timestamp: 1594848622
  timesteps_since_restore: 70000
  timesteps_this_iter: 5000
  timesteps_total: 70000
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 136 s, 14 iter, 70000 ts, -7.97e+03 rew

agent-1: -11.197402290528375
agent-2: -74.19740229052826
agent-3: -24.19740229052844
agent-4: -20.197402290528448
agent-5: -23.19740229052844
Extrinsic Rewards:
16
-47
3
7
4
Sum Reward: -17
Avg Reward: -3.4
Min Reward: -47
Max Reward: 16
Gini Coefficient: -3.0588235294117645
20:20 Ratio: -0.3404255319148936
Max-min Ratio: -0.3404255319148936
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-30-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 287.999999964822
  episode_reward_mean: -7412.3300312873225
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 14
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.061
    dispatch_time_ms: 9.739
    learner:
      cur_lr: 0.0013553380267694592
      grad_gnorm: 40.00000762939453
      policy_entropy: 66.87445831298828
      policy_loss: -36.1031379699707
      var_gnorm: 21.35118293762207
      vf_explained_var: 0.0
      vf_loss: 6.0599284172058105
    num_steps_sampled: 75000
    num_steps_trained: 75000
    wait_time_ms: 77.449
  iterations_since_restore: 15
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 144.54366874694824
  time_this_iter_s: 8.475507974624634
  time_total_s: 144.54366874694824
  timestamp: 1594848631
  timesteps_since_restore: 75000
  timesteps_this_iter: 5000
  timesteps_total: 75000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 144 s, 15 iter, 75000 ts, -7.41e+03 rew

agent-1: 78.3999852731708
agent-2: 86.3999852731708
agent-3: 101.39998527317076
agent-4: 89.39998527317078
agent-5: 85.3999852731708
Extrinsic Rewards:
0
8
23
11
7
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 0
Max Reward: 23
Gini Coefficient: 0.40816326530612246
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-30-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 440.99992636585176
  episode_reward_mean: -6888.77470077711
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 15
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.573
    dispatch_time_ms: 10.213
    learner:
      cur_lr: 0.0013550049625337124
      grad_gnorm: 1.0864613056182861
      policy_entropy: 10.678284645080566
      policy_loss: -0.43552863597869873
      var_gnorm: 21.328086853027344
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00043171990546397865
    num_steps_sampled: 80000
    num_steps_trained: 80000
    wait_time_ms: 74.522
  iterations_since_restore: 16
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 153.395446062088
  time_this_iter_s: 8.85177731513977
  time_total_s: 153.395446062088
  timestamp: 1594848639
  timesteps_since_restore: 80000
  timesteps_this_iter: 5000
  timesteps_total: 80000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 27.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 153 s, 16 iter, 80000 ts, -6.89e+03 rew

agent-1: 68.79999946262384
agent-2: 70.79999946262386
agent-3: 69.79999946262387
agent-4: 69.79999946262387
agent-5: 62.79999946262394
Extrinsic Rewards:
8
10
9
9
2
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.17894736842105263
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-30-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 440.99992636585176
  episode_reward_mean: -6436.85128214647
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 16
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.604
    dispatch_time_ms: 9.198
    learner:
      cur_lr: 0.0013546720147132874
      grad_gnorm: 40.000003814697266
      policy_entropy: 10.31894588470459
      policy_loss: 0.7316539883613586
      var_gnorm: 21.331472396850586
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.7380521297454834
    num_steps_sampled: 85000
    num_steps_trained: 85000
    wait_time_ms: 72.421
  iterations_since_restore: 17
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 161.8418197631836
  time_this_iter_s: 8.446373701095581
  time_total_s: 161.8418197631836
  timestamp: 1594848648
  timesteps_since_restore: 85000
  timesteps_this_iter: 5000
  timesteps_total: 85000
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 161 s, 17 iter, 85000 ts, -6.44e+03 rew

agent-1: 118.2129972172651
agent-2: 136.2129972172651
agent-3: 112.2129972172651
agent-4: 120.2129972172651
agent-5: 123.2129972172651
Extrinsic Rewards:
10
28
4
12
15
Sum Reward: 69
Avg Reward: 13.8
Min Reward: 4
Max Reward: 28
Gini Coefficient: 0.3072463768115942
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-30-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 610.0649860863232
  episode_reward_mean: -6022.326795779835
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 17
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 9.787
    learner:
      cur_lr: 0.0013543389504775405
      grad_gnorm: 40.0
      policy_entropy: 43.394527435302734
      policy_loss: 52.167884826660156
      var_gnorm: 21.37372398376465
      vf_explained_var: 0.0
      vf_loss: 53.0955696105957
    num_steps_sampled: 90000
    num_steps_trained: 90000
    wait_time_ms: 75.274
  iterations_since_restore: 18
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 170.41336846351624
  time_this_iter_s: 8.571548700332642
  time_total_s: 170.41336846351624
  timestamp: 1594848656
  timesteps_since_restore: 90000
  timesteps_this_iter: 5000
  timesteps_total: 90000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 170 s, 18 iter, 90000 ts, -6.02e+03 rew

agent-1: 118.29685852045205
agent-2: 106.29685852045208
agent-3: 113.2968585204521
agent-4: 112.29685852045209
agent-5: 116.29685852045208
Extrinsic Rewards:
18
6
13
12
16
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 6
Max Reward: 18
Gini Coefficient: 0.1723076923076923
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-31-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 610.0649860863232
  episode_reward_mean: -5656.281735314164
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 18
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.641
    dispatch_time_ms: 8.897
    learner:
      cur_lr: 0.0013540060026571155
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.229957580566406
      policy_loss: -15.467024803161621
      var_gnorm: 21.36183738708496
      vf_explained_var: 0.0
      vf_loss: 7.95352029800415
    num_steps_sampled: 95000
    num_steps_trained: 95000
    wait_time_ms: 75.052
  iterations_since_restore: 19
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 179.14777278900146
  time_this_iter_s: 8.73440432548523
  time_total_s: 179.14777278900146
  timestamp: 1594848665
  timesteps_since_restore: 95000
  timesteps_this_iter: 5000
  timesteps_total: 95000
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 179 s, 19 iter, 95000 ts, -5.66e+03 rew

agent-1: 28.599999999626085
agent-2: 28.599999999626082
agent-3: 31.599999999626085
agent-4: 29.599999999626085
agent-5: 25.59999999962609
Extrinsic Rewards:
3
3
6
4
0
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.325
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-31-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 610.0649860863232
  episode_reward_mean: -5351.0037492450965
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 19
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.639
    dispatch_time_ms: 8.198
    learner:
      cur_lr: 0.0013536730548366904
      grad_gnorm: 40.0
      policy_entropy: 10.580543518066406
      policy_loss: 2.774360418319702
      var_gnorm: 21.331878662109375
      vf_explained_var: 0.0
      vf_loss: 49.453224182128906
    num_steps_sampled: 100000
    num_steps_trained: 100000
    wait_time_ms: 79.177
  iterations_since_restore: 20
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 188.04084515571594
  time_this_iter_s: 8.893072366714478
  time_total_s: 188.04084515571594
  timestamp: 1594848674
  timesteps_since_restore: 100000
  timesteps_this_iter: 5000
  timesteps_total: 100000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 188 s, 20 iter, 100000 ts, -5.35e+03 rew

agent-1: 104.19999986834902
agent-2: 96.199999868349
agent-3: 102.199999868349
agent-4: 103.199999868349
agent-5: 107.199999868349
Extrinsic Rewards:
13
5
11
12
16
Sum Reward: 57
Avg Reward: 11.4
Min Reward: 5
Max Reward: 16
Gini Coefficient: 0.16842105263157894
20:20 Ratio: 3.2
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-31-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 610.0649860863232
  episode_reward_mean: -5057.803561815754
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 20
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 5.784
    learner:
      cur_lr: 0.0013533399906009436
      grad_gnorm: 40.0
      policy_entropy: 35.01145935058594
      policy_loss: -14.282672882080078
      var_gnorm: 21.36138153076172
      vf_explained_var: 0.0
      vf_loss: 5.138764381408691
    num_steps_sampled: 105000
    num_steps_trained: 105000
    wait_time_ms: 79.607
  iterations_since_restore: 21
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 196.48191618919373
  time_this_iter_s: 8.441071033477783
  time_total_s: 196.48191618919373
  timestamp: 1594848683
  timesteps_since_restore: 105000
  timesteps_this_iter: 5000
  timesteps_total: 105000
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 196 s, 21 iter, 105000 ts, -5.06e+03 rew

agent-1: 88.19999697931343
agent-2: 87.19999697931344
agent-3: 81.19999697931347
agent-4: 82.19999697931345
agent-5: 84.19999697931345
Extrinsic Rewards:
13
12
6
7
9
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 6
Max Reward: 13
Gini Coefficient: 0.16170212765957448
20:20 Ratio: 2.1666666666666665
Max-min Ratio: 2.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-31-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 610.0649860863232
  episode_reward_mean: -4796.812916734215
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 21
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.526
    dispatch_time_ms: 7.861
    learner:
      cur_lr: 0.0013530070427805185
      grad_gnorm: 2.1988790035247803
      policy_entropy: 21.39389991760254
      policy_loss: -0.40083029866218567
      var_gnorm: 21.330934524536133
      vf_explained_var: -1.9073486328125e-06
      vf_loss: 0.003387040924280882
    num_steps_sampled: 110000
    num_steps_trained: 110000
    wait_time_ms: 72.211
  iterations_since_restore: 22
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 205.17668867111206
  time_this_iter_s: 8.694772481918335
  time_total_s: 205.17668867111206
  timestamp: 1594848691
  timesteps_since_restore: 110000
  timesteps_this_iter: 5000
  timesteps_total: 110000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 28.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 205 s, 22 iter, 110000 ts, -4.8e+03 rew

agent-1: 84.59999866961482
agent-2: 83.59999866961482
agent-3: 78.5999986696148
agent-4: 81.59999866961479
agent-5: 85.59999866961482
Extrinsic Rewards:
11
10
5
8
12
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 5
Max Reward: 12
Gini Coefficient: 0.14782608695652175
20:20 Ratio: 2.4
Max-min Ratio: 2.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-31-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 610.0649860863232
  episode_reward_mean: -4559.957784457747
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 22
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 6.949
    learner:
      cur_lr: 0.0013526739785447717
      grad_gnorm: 40.0
      policy_entropy: 15.166373252868652
      policy_loss: 17.167566299438477
      var_gnorm: 21.364398956298828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 19.62449073791504
    num_steps_sampled: 115000
    num_steps_trained: 115000
    wait_time_ms: 78.081
  iterations_since_restore: 23
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 213.66538262367249
  time_this_iter_s: 8.488693952560425
  time_total_s: 213.66538262367249
  timestamp: 1594848700
  timesteps_since_restore: 115000
  timesteps_this_iter: 5000
  timesteps_total: 115000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 213 s, 23 iter, 115000 ts, -4.56e+03 rew

agent-1: 173.38229780633654
agent-2: 181.38229780633654
agent-3: 166.38229780633645
agent-4: 161.38229780633642
agent-5: 163.3822978063364
Extrinsic Rewards:
23
31
16
11
13
Sum Reward: 94
Avg Reward: 18.8
Min Reward: 11
Max Reward: 31
Gini Coefficient: 0.2127659574468085
20:20 Ratio: 2.8181818181818183
Max-min Ratio: 2.8181818181818183
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-31-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -4324.919989958207
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 23
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.629
    dispatch_time_ms: 7.714
    learner:
      cur_lr: 0.0013523410307243466
      grad_gnorm: 40.0
      policy_entropy: 18.34039878845215
      policy_loss: -15.645934104919434
      var_gnorm: 21.38392448425293
      vf_explained_var: 0.0
      vf_loss: 12.221745491027832
    num_steps_sampled: 120000
    num_steps_trained: 120000
    wait_time_ms: 76.247
  iterations_since_restore: 24
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 222.21153855323792
  time_this_iter_s: 8.54615592956543
  time_total_s: 222.21153855323792
  timestamp: 1594848708
  timesteps_since_restore: 120000
  timesteps_this_iter: 5000
  timesteps_total: 120000
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 222 s, 24 iter, 120000 ts, -4.32e+03 rew

agent-1: 168.19017361679497
agent-2: 164.1901736167949
agent-3: 162.1901736167949
agent-4: 170.190173616795
agent-5: 163.19017361679494
Extrinsic Rewards:
21
17
15
23
16
Sum Reward: 92
Avg Reward: 18.4
Min Reward: 15
Max Reward: 23
Gini Coefficient: 0.09130434782608696
20:20 Ratio: 1.5333333333333334
Max-min Ratio: 1.5333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-31-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -4110.217037539783
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 24
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.841
    dispatch_time_ms: 9.365
    learner:
      cur_lr: 0.0013520079664885998
      grad_gnorm: 40.0
      policy_entropy: 17.197324752807617
      policy_loss: -6.160655975341797
      var_gnorm: 21.356632232666016
      vf_explained_var: 0.0
      vf_loss: 5.747822284698486
    num_steps_sampled: 125000
    num_steps_trained: 125000
    wait_time_ms: 77.09
  iterations_since_restore: 25
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 230.88896322250366
  time_this_iter_s: 8.677424669265747
  time_total_s: 230.88896322250366
  timestamp: 1594848717
  timesteps_since_restore: 125000
  timesteps_this_iter: 5000
  timesteps_total: 125000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 230 s, 25 iter, 125000 ts, -4.11e+03 rew

agent-1: 49.79999999513427
agent-2: 48.799999995134264
agent-3: 53.79999999513427
agent-4: 52.79999999513426
agent-5: 46.79999999513427
Extrinsic Rewards:
5
4
9
8
2
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2571428571428571
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-32-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -3935.7283560391643
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 25
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.792
    dispatch_time_ms: 9.014
    learner:
      cur_lr: 0.0013516750186681747
      grad_gnorm: 40.0
      policy_entropy: 23.301471710205078
      policy_loss: 22.863201141357422
      var_gnorm: 21.332204818725586
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 44.623695373535156
    num_steps_sampled: 130000
    num_steps_trained: 130000
    wait_time_ms: 73.127
  iterations_since_restore: 26
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 239.50931406021118
  time_this_iter_s: 8.62035083770752
  time_total_s: 239.50931406021118
  timestamp: 1594848726
  timesteps_since_restore: 130000
  timesteps_this_iter: 5000
  timesteps_total: 130000
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 239 s, 26 iter, 130000 ts, -3.94e+03 rew

agent-1: 54.99999999244936
agent-2: 59.999999992449354
agent-3: 49.99999999244936
agent-4: 51.99999999244936
agent-5: 52.99999999244937
Extrinsic Rewards:
7
12
2
4
5
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.30666666666666664
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-32-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -3773.9695731160336
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 26
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.842
    dispatch_time_ms: 9.643
    learner:
      cur_lr: 0.0013513419544324279
      grad_gnorm: 3.81062388420105
      policy_entropy: 23.654813766479492
      policy_loss: -0.5226297378540039
      var_gnorm: 21.332117080688477
      vf_explained_var: 0.0
      vf_loss: 0.010742850601673126
    num_steps_sampled: 135000
    num_steps_trained: 135000
    wait_time_ms: 74.716
  iterations_since_restore: 27
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 248.14838933944702
  time_this_iter_s: 8.63907527923584
  time_total_s: 248.14838933944702
  timestamp: 1594848735
  timesteps_since_restore: 135000
  timesteps_this_iter: 5000
  timesteps_total: 135000
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 248 s, 27 iter, 135000 ts, -3.77e+03 rew

agent-1: 27.999999999542865
agent-2: 24.99999999954287
agent-3: 23.99999999954287
agent-4: 27.999999999542872
agent-5: 29.999999999542872
Extrinsic Rewards:
4
1
0
4
6
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-32-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -3629.1929222599683
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 27
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.638
    dispatch_time_ms: 9.427
    learner:
      cur_lr: 0.0013510090066120028
      grad_gnorm: 0.11129093170166016
      policy_entropy: 26.88787078857422
      policy_loss: 0.004967875313013792
      var_gnorm: 21.331745147705078
      vf_explained_var: 8.094310760498047e-05
      vf_loss: 3.127374270661676e-07
    num_steps_sampled: 140000
    num_steps_trained: 140000
    wait_time_ms: 73.992
  iterations_since_restore: 28
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 256.76960611343384
  time_this_iter_s: 8.621216773986816
  time_total_s: 256.76960611343384
  timestamp: 1594848743
  timesteps_since_restore: 140000
  timesteps_this_iter: 5000
  timesteps_total: 140000
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 256 s, 28 iter, 140000 ts, -3.63e+03 rew

agent-1: 38.39999999918436
agent-2: 30.399999999184327
agent-3: 32.39999999918439
agent-4: 37.39999999918436
agent-5: 32.39999999918439
Extrinsic Rewards:
8
0
2
7
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4421052631578947
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-32-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -3493.4717464651153
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 28
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.496
    dispatch_time_ms: 8.898
    learner:
      cur_lr: 0.001350675942376256
      grad_gnorm: 6.888190746307373
      policy_entropy: 22.788002014160156
      policy_loss: -1.1669840812683105
      var_gnorm: 21.333328247070312
      vf_explained_var: -8.344650268554688e-07
      vf_loss: 0.034184038639068604
    num_steps_sampled: 145000
    num_steps_trained: 145000
    wait_time_ms: 73.578
  iterations_since_restore: 29
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 265.35396337509155
  time_this_iter_s: 8.584357261657715
  time_total_s: 265.35396337509155
  timestamp: 1594848752
  timesteps_since_restore: 145000
  timesteps_this_iter: 5000
  timesteps_total: 145000
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 265 s, 29 iter, 145000 ts, -3.49e+03 rew

agent-1: 59.19999999002127
agent-2: 59.199999990021276
agent-3: 54.19999999002129
agent-4: 53.19999999002129
agent-5: 62.19999999002127
Extrinsic Rewards:
8
8
3
2
11
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.2875
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-32-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -3363.076169002521
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 29
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.371
    dispatch_time_ms: 8.09
    learner:
      cur_lr: 0.001350342994555831
      grad_gnorm: 0.09516765922307968
      policy_entropy: 30.843843460083008
      policy_loss: 0.006818131543695927
      var_gnorm: 21.333084106445312
      vf_explained_var: 0.00025981664657592773
      vf_loss: 6.998297976679169e-07
    num_steps_sampled: 150000
    num_steps_trained: 150000
    wait_time_ms: 75.695
  iterations_since_restore: 30
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 274.1025323867798
  time_this_iter_s: 8.748569011688232
  time_total_s: 274.1025323867798
  timestamp: 1594848761
  timesteps_since_restore: 150000
  timesteps_this_iter: 5000
  timesteps_total: 150000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 274 s, 30 iter, 150000 ts, -3.36e+03 rew

agent-1: 32.9999999995227
agent-2: 23.999999999522778
agent-3: 25.99999999952278
agent-4: 24.99999999952278
agent-5: 26.999999999522778
Extrinsic Rewards:
9
0
2
1
3
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-32-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -3246.47363003585
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 30
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.869
    dispatch_time_ms: 6.356
    learner:
      cur_lr: 0.001350010046735406
      grad_gnorm: 30.56058120727539
      policy_entropy: 17.36565399169922
      policy_loss: -3.4452054500579834
      var_gnorm: 21.336454391479492
      vf_explained_var: 0.0
      vf_loss: 0.6749752163887024
    num_steps_sampled: 155000
    num_steps_trained: 155000
    wait_time_ms: 82.153
  iterations_since_restore: 31
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 282.8828058242798
  time_this_iter_s: 8.7802734375
  time_total_s: 282.8828058242798
  timestamp: 1594848769
  timesteps_since_restore: 155000
  timesteps_this_iter: 5000
  timesteps_total: 155000
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 29.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 282 s, 31 iter, 155000 ts, -3.25e+03 rew

agent-1: 38.59999999918511
agent-2: 35.59999999918513
agent-3: 36.59999999918513
agent-4: 38.59999999918511
agent-5: 39.59999999918511
Extrinsic Rewards:
5
2
3
5
6
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.19047619047619047
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-32-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -3135.651900034825
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 31
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 9.193
    learner:
      cur_lr: 0.001349676982499659
      grad_gnorm: 0.12746216356754303
      policy_entropy: 30.72382926940918
      policy_loss: -0.0072771599516272545
      var_gnorm: 21.331480026245117
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.077873088841443e-06
    num_steps_sampled: 160000
    num_steps_trained: 160000
    wait_time_ms: 80.488
  iterations_since_restore: 32
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 291.64081168174744
  time_this_iter_s: 8.758005857467651
  time_total_s: 291.64081168174744
  timestamp: 1594848778
  timesteps_since_restore: 160000
  timesteps_this_iter: 5000
  timesteps_total: 160000
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 291 s, 32 iter, 160000 ts, -3.14e+03 rew

agent-1: 98.39999961196675
agent-2: 113.39999961196672
agent-3: 97.39999961196676
agent-4: 106.39999961196675
agent-5: 115.39999961196672
Extrinsic Rewards:
4
19
3
12
21
Sum Reward: 59
Avg Reward: 11.8
Min Reward: 3
Max Reward: 21
Gini Coefficient: 0.34576271186440677
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-33-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -3021.0690282193677
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 32
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 8.453
    learner:
      cur_lr: 0.001349344034679234
      grad_gnorm: 5.101273059844971
      policy_entropy: 22.550220489501953
      policy_loss: -0.7720885872840881
      var_gnorm: 21.333120346069336
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.019274435937404633
    num_steps_sampled: 165000
    num_steps_trained: 165000
    wait_time_ms: 75.203
  iterations_since_restore: 33
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 300.2814476490021
  time_this_iter_s: 8.640635967254639
  time_total_s: 300.2814476490021
  timestamp: 1594848787
  timesteps_since_restore: 165000
  timesteps_this_iter: 5000
  timesteps_total: 165000
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 300 s, 33 iter, 165000 ts, -3.02e+03 rew

agent-1: 44.39999999836273
agent-2: 38.399999998362766
agent-3: 40.399999998362766
agent-4: 42.39999999836275
agent-5: 50.399999998362745
Extrinsic Rewards:
6
0
2
4
12
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.4666666666666667
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-33-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -2922.9760273644833
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 33
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.28
    dispatch_time_ms: 10.33
    learner:
      cur_lr: 0.0013490109704434872
      grad_gnorm: 0.1084989458322525
      policy_entropy: 25.30620574951172
      policy_loss: 0.0040542325004935265
      var_gnorm: 21.332788467407227
      vf_explained_var: 0.0
      vf_loss: 3.87180705274659e-07
    num_steps_sampled: 170000
    num_steps_trained: 170000
    wait_time_ms: 72.9
  iterations_since_restore: 34
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 308.89991068840027
  time_this_iter_s: 8.618463039398193
  time_total_s: 308.89991068840027
  timestamp: 1594848795
  timesteps_since_restore: 170000
  timesteps_this_iter: 5000
  timesteps_total: 170000
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 308 s, 34 iter, 170000 ts, -2.92e+03 rew

agent-1: 37.19999999787807
agent-2: 42.19999999787806
agent-3: 38.199999997878066
agent-4: 39.199999997878066
agent-5: 41.199999997878066
Extrinsic Rewards:
2
7
3
4
6
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.23636363636363636
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-33-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -2831.1826147952515
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 34
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.037
    dispatch_time_ms: 9.548
    learner:
      cur_lr: 0.0013486780226230621
      grad_gnorm: 7.621273517608643
      policy_entropy: 31.80175018310547
      policy_loss: -1.3084051609039307
      var_gnorm: 21.33453369140625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.04249473288655281
    num_steps_sampled: 175000
    num_steps_trained: 175000
    wait_time_ms: 73.233
  iterations_since_restore: 35
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 317.50734305381775
  time_this_iter_s: 8.60743236541748
  time_total_s: 317.50734305381775
  timestamp: 1594848804
  timesteps_since_restore: 175000
  timesteps_this_iter: 5000
  timesteps_total: 175000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 30.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 317 s, 35 iter, 175000 ts, -2.83e+03 rew

agent-1: 37.199999993333904
agent-2: 36.1999999933339
agent-3: 39.199999993333904
agent-4: 44.1999999933339
agent-5: 41.1999999933339
Extrinsic Rewards:
2
1
4
9
6
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.36363636363636365
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-33-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -2744.6345400877685
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 35
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 11.169
    learner:
      cur_lr: 0.0013483449583873153
      grad_gnorm: 0.09119592607021332
      policy_entropy: 26.80168342590332
      policy_loss: 0.0023644031025469303
      var_gnorm: 21.334716796875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.8720992872877105e-07
    num_steps_sampled: 180000
    num_steps_trained: 180000
    wait_time_ms: 71.004
  iterations_since_restore: 36
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 326.0822322368622
  time_this_iter_s: 8.574889183044434
  time_total_s: 326.0822322368622
  timestamp: 1594848813
  timesteps_since_restore: 180000
  timesteps_this_iter: 5000
  timesteps_total: 180000
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 326 s, 36 iter, 180000 ts, -2.74e+03 rew

agent-1: 35.99999999644036
agent-2: 32.99999999644036
agent-3: 39.99999999644037
agent-4: 35.99999999644035
agent-5: 34.999999996440366
Extrinsic Rewards:
4
1
8
4
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.3
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-33-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -2663.3946917524913
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 36
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.111
    dispatch_time_ms: 8.733
    learner:
      cur_lr: 0.0013480120105668902
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.154484748840332
      policy_loss: -2.460421323776245
      var_gnorm: 21.348379135131836
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 2.9415903091430664
    num_steps_sampled: 185000
    num_steps_trained: 185000
    wait_time_ms: 76.65
  iterations_since_restore: 37
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 334.68961787223816
  time_this_iter_s: 8.607385635375977
  time_total_s: 334.68961787223816
  timestamp: 1594848821
  timesteps_since_restore: 185000
  timesteps_this_iter: 5000
  timesteps_total: 185000
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 334 s, 37 iter, 185000 ts, -2.66e+03 rew

agent-1: 71.79999972677423
agent-2: 73.79999972677423
agent-3: 70.79999972677423
agent-4: 63.79999972677422
agent-5: 61.7999997267742
Extrinsic Rewards:
11
13
10
3
1
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.3368421052631579
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-33-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -2582.1678082285357
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 37
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.985
    dispatch_time_ms: 9.149
    learner:
      cur_lr: 0.0013476789463311434
      grad_gnorm: 0.2266625016927719
      policy_entropy: 12.768802642822266
      policy_loss: 0.023618659004569054
      var_gnorm: 21.33694076538086
      vf_explained_var: 0.0
      vf_loss: 1.919414717121981e-05
    num_steps_sampled: 190000
    num_steps_trained: 190000
    wait_time_ms: 74.821
  iterations_since_restore: 38
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 343.4051537513733
  time_this_iter_s: 8.715535879135132
  time_total_s: 343.4051537513733
  timestamp: 1594848830
  timesteps_since_restore: 190000
  timesteps_this_iter: 5000
  timesteps_total: 190000
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 343 s, 38 iter, 190000 ts, -2.58e+03 rew

agent-1: 61.199999941471965
agent-2: 62.19999994147197
agent-3: 71.1999999414719
agent-4: 65.19999994147193
agent-5: 73.19999994147193
Extrinsic Rewards:
2
3
12
6
14
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.3567567567567568
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-33-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -2505.452865914433
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 38
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.773
    dispatch_time_ms: 10.022
    learner:
      cur_lr: 0.0013473459985107183
      grad_gnorm: 40.0
      policy_entropy: 26.333736419677734
      policy_loss: -6.219372272491455
      var_gnorm: 21.3752384185791
      vf_explained_var: 0.0
      vf_loss: 3.345082998275757
    num_steps_sampled: 195000
    num_steps_trained: 195000
    wait_time_ms: 75.799
  iterations_since_restore: 39
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 351.97432136535645
  time_this_iter_s: 8.569167613983154
  time_total_s: 351.97432136535645
  timestamp: 1594848839
  timesteps_since_restore: 195000
  timesteps_this_iter: 5000
  timesteps_total: 195000
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 351 s, 39 iter, 195000 ts, -2.51e+03 rew

agent-1: 97.19999132831639
agent-2: 100.1999913283164
agent-3: 93.19999132831641
agent-4: 91.19999132831641
agent-5: 86.19999132831646
Extrinsic Rewards:
14
17
10
8
3
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 3
Max Reward: 17
Gini Coefficient: 0.26153846153846155
20:20 Ratio: 5.666666666666667
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-34-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -2429.210485848894
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 39
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 10.14
    learner:
      cur_lr: 0.0013470130506902933
      grad_gnorm: 2.2240183353424072
      policy_entropy: 20.73387908935547
      policy_loss: -0.3052110970020294
      var_gnorm: 21.34967613220215
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0030317455530166626
    num_steps_sampled: 200000
    num_steps_trained: 200000
    wait_time_ms: 73.165
  iterations_since_restore: 40
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 360.5720317363739
  time_this_iter_s: 8.597710371017456
  time_total_s: 360.5720317363739
  timestamp: 1594848847
  timesteps_since_restore: 200000
  timesteps_this_iter: 5000
  timesteps_total: 200000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 360 s, 40 iter, 200000 ts, -2.43e+03 rew

agent-1: 163.3968211009366
agent-2: 159.3968211009366
agent-3: 162.39682110093665
agent-4: 157.39682110093653
agent-5: 158.39682110093653
Extrinsic Rewards:
21
17
20
15
16
Sum Reward: 89
Avg Reward: 17.8
Min Reward: 15
Max Reward: 21
Gini Coefficient: 0.07191011235955057
20:20 Ratio: 1.4
Max-min Ratio: 1.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-34-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -2348.4556210650544
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 40
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.35
    dispatch_time_ms: 9.727
    learner:
      cur_lr: 0.0013466799864545465
      grad_gnorm: 40.0
      policy_entropy: 29.1842098236084
      policy_loss: -6.662177085876465
      var_gnorm: 21.343284606933594
      vf_explained_var: 0.0
      vf_loss: 1.3700450658798218
    num_steps_sampled: 205000
    num_steps_trained: 205000
    wait_time_ms: 76.416
  iterations_since_restore: 41
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 369.2843313217163
  time_this_iter_s: 8.712299585342407
  time_total_s: 369.2843313217163
  timestamp: 1594848856
  timesteps_since_restore: 205000
  timesteps_this_iter: 5000
  timesteps_total: 205000
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 369 s, 41 iter, 205000 ts, -2.35e+03 rew

agent-1: 42.399999991810624
agent-2: 43.399999991810624
agent-3: 43.399999991810624
agent-4: 48.399999991810624
agent-5: 38.399999991810624
Extrinsic Rewards:
4
5
5
10
0
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.35
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-34-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -2285.9079229912963
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 41
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.599
    dispatch_time_ms: 9.013
    learner:
      cur_lr: 0.0013463470386341214
      grad_gnorm: 40.0
      policy_entropy: 50.476715087890625
      policy_loss: 80.4527587890625
      var_gnorm: 21.33773422241211
      vf_explained_var: 0.0
      vf_loss: 82.81173706054688
    num_steps_sampled: 210000
    num_steps_trained: 210000
    wait_time_ms: 74.552
  iterations_since_restore: 42
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 378.05378007888794
  time_this_iter_s: 8.76944875717163
  time_total_s: 378.05378007888794
  timestamp: 1594848865
  timesteps_since_restore: 210000
  timesteps_this_iter: 5000
  timesteps_total: 210000
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 378 s, 42 iter, 210000 ts, -2.29e+03 rew

agent-1: 55.599999984335525
agent-2: 56.599999984335525
agent-3: 61.59999998433551
agent-4: 52.59999998433551
agent-5: 52.59999998433551
Extrinsic Rewards:
6
7
12
3
3
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.2838709677419355
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-34-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -2224.8386867314634
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 42
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.235
    dispatch_time_ms: 10.358
    learner:
      cur_lr: 0.0013460139743983746
      grad_gnorm: 40.000003814697266
      policy_entropy: 24.65465545654297
      policy_loss: -8.341986656188965
      var_gnorm: 21.350797653198242
      vf_explained_var: 0.0
      vf_loss: 1.7806988954544067
    num_steps_sampled: 215000
    num_steps_trained: 215000
    wait_time_ms: 72.828
  iterations_since_restore: 43
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 386.71742510795593
  time_this_iter_s: 8.663645029067993
  time_total_s: 386.71742510795593
  timestamp: 1594848874
  timesteps_since_restore: 215000
  timesteps_this_iter: 5000
  timesteps_total: 215000
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 386 s, 43 iter, 215000 ts, -2.22e+03 rew

agent-1: 90.19999950400249
agent-2: 92.1999995040025
agent-3: 90.1999995040025
agent-4: 101.19999950400255
agent-5: 94.1999995040025
Extrinsic Rewards:
7
9
7
18
11
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 7
Max Reward: 18
Gini Coefficient: 0.2
20:20 Ratio: 2.5714285714285716
Max-min Ratio: 2.5714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-34-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -2162.2145312837547
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 43
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.021
    dispatch_time_ms: 9.912
    learner:
      cur_lr: 0.0013456810265779495
      grad_gnorm: 40.0
      policy_entropy: 3.5669538974761963
      policy_loss: 29.328081130981445
      var_gnorm: 21.348894119262695
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 106.0428237915039
    num_steps_sampled: 220000
    num_steps_trained: 220000
    wait_time_ms: 74.459
  iterations_since_restore: 44
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 395.5474169254303
  time_this_iter_s: 8.829991817474365
  time_total_s: 395.5474169254303
  timestamp: 1594848882
  timesteps_since_restore: 220000
  timesteps_this_iter: 5000
  timesteps_total: 220000
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 31.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 395 s, 44 iter, 220000 ts, -2.16e+03 rew

agent-1: 67.19999998931806
agent-2: 67.19999998931804
agent-3: 68.19999998931804
agent-4: 65.19999998931799
agent-5: 65.19999998931799
Extrinsic Rewards:
8
8
9
6
6
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 6
Max Reward: 9
Gini Coefficient: 0.08648648648648649
20:20 Ratio: 1.5
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-34-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -2105.505110119429
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 44
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.354
    dispatch_time_ms: 10.202
    learner:
      cur_lr: 0.0013453479623422027
      grad_gnorm: 40.0
      policy_entropy: 36.417457580566406
      policy_loss: 27.71013069152832
      var_gnorm: 21.36896324157715
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 14.163488388061523
    num_steps_sampled: 225000
    num_steps_trained: 225000
    wait_time_ms: 77.207
  iterations_since_restore: 45
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 404.0738546848297
  time_this_iter_s: 8.526437759399414
  time_total_s: 404.0738546848297
  timestamp: 1594848891
  timesteps_since_restore: 225000
  timesteps_this_iter: 5000
  timesteps_total: 225000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 404 s, 45 iter, 225000 ts, -2.11e+03 rew

agent-1: 84.19991426539224
agent-2: 85.19991426539224
agent-3: 85.19991426539225
agent-4: 81.19991426539221
agent-5: 87.19991426539228
Extrinsic Rewards:
9
10
10
6
12
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 6
Max Reward: 12
Gini Coefficient: 0.11063829787234042
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-35-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -2049.3161171983975
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 45
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.228
    dispatch_time_ms: 11.428
    learner:
      cur_lr: 0.0013450150145217776
      grad_gnorm: 40.0
      policy_entropy: 10.054442405700684
      policy_loss: 12.589943885803223
      var_gnorm: 21.34735870361328
      vf_explained_var: -0.03465771675109863
      vf_loss: 65.1384048461914
    num_steps_sampled: 230000
    num_steps_trained: 230000
    wait_time_ms: 71.654
  iterations_since_restore: 46
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 412.945104598999
  time_this_iter_s: 8.871249914169312
  time_total_s: 412.945104598999
  timestamp: 1594848900
  timesteps_since_restore: 230000
  timesteps_this_iter: 5000
  timesteps_total: 230000
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 412 s, 46 iter, 230000 ts, -2.05e+03 rew

agent-1: 93.39997574069238
agent-2: 89.39997574069237
agent-3: 84.39997574069243
agent-4: 90.3999757406924
agent-5: 83.39997574069243
Extrinsic Rewards:
15
11
6
12
5
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 5
Max Reward: 15
Gini Coefficient: 0.21224489795918366
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-35-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9114890316815
  episode_reward_mean: -1995.1788129396616
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 46
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.756
    dispatch_time_ms: 10.321
    learner:
      cur_lr: 0.0013446819502860308
      grad_gnorm: 40.0
      policy_entropy: 26.356220245361328
      policy_loss: 18.37483787536621
      var_gnorm: 21.38918685913086
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 32.390869140625
    num_steps_sampled: 235000
    num_steps_trained: 235000
    wait_time_ms: 74.212
  iterations_since_restore: 47
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 421.48607063293457
  time_this_iter_s: 8.540966033935547
  time_total_s: 421.48607063293457
  timestamp: 1594848909
  timesteps_since_restore: 235000
  timesteps_this_iter: 5000
  timesteps_total: 235000
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 421 s, 47 iter, 235000 ts, -2e+03 rew

agent-1: 197.56193166646514
agent-2: 212.56193166646503
agent-3: 199.56193166646509
agent-4: 199.56193166646506
agent-5: 189.5619316664651
Extrinsic Rewards:
20
35
22
22
12
Sum Reward: 111
Avg Reward: 22.2
Min Reward: 12
Max Reward: 35
Gini Coefficient: 0.17297297297297298
20:20 Ratio: 2.9166666666666665
Max-min Ratio: 2.9166666666666665
agent-1: 141.19901966262344
agent-2: 156.19901966262347
agent-3: 142.1990196626234
agent-4: 155.19901966262344
agent-5: 143.19901966262344
Extrinsic Rewards:
10
25
11
24
12
Sum Reward: 82
Avg Reward: 16.4
Min Reward: 10
Max Reward: 25
Gini Coefficient: 0.2097560975609756
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-35-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1875.8629299703953
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 2
  episodes_total: 48
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.386
    dispatch_time_ms: 9.817
    learner:
      cur_lr: 0.0013443490024656057
      grad_gnorm: 40.0
      policy_entropy: 42.62715148925781
      policy_loss: -417.5654602050781
      var_gnorm: 21.389455795288086
      vf_explained_var: -0.002832174301147461
      vf_loss: 3142.4560546875
    num_steps_sampled: 240000
    num_steps_trained: 240000
    wait_time_ms: 78.514
  iterations_since_restore: 48
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 430.2139108181
  time_this_iter_s: 8.727840185165405
  time_total_s: 430.2139108181
  timestamp: 1594848917
  timesteps_since_restore: 240000
  timesteps_this_iter: 5000
  timesteps_total: 240000
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 430 s, 48 iter, 240000 ts, -1.88e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-35-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1875.8629299703955
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 0
  episodes_total: 48
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.963
    dispatch_time_ms: 11.475
    learner:
      cur_lr: 0.0013440160546451807
      grad_gnorm: 40.0
      policy_entropy: 38.98310089111328
      policy_loss: -25.64928436279297
      var_gnorm: 21.390947341918945
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 11.840510368347168
    num_steps_sampled: 245000
    num_steps_trained: 245000
    wait_time_ms: 72.808
  iterations_since_restore: 49
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 438.8830885887146
  time_this_iter_s: 8.669177770614624
  time_total_s: 438.8830885887146
  timestamp: 1594848926
  timesteps_since_restore: 245000
  timesteps_this_iter: 5000
  timesteps_total: 245000
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 438 s, 49 iter, 245000 ts, -1.88e+03 rew

agent-1: 73.79999991808874
agent-2: 78.79999991808876
agent-3: 83.79999991808879
agent-4: 77.79999991808874
agent-5: 72.79999991808874
Extrinsic Rewards:
5
10
15
9
4
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 4
Max Reward: 15
Gini Coefficient: 0.25116279069767444
20:20 Ratio: 3.75
Max-min Ratio: 3.75
agent-1: 80.39999991966899
agent-2: 84.399999919669
agent-3: 102.39999991966897
agent-4: 91.39999991966899
agent-5: 82.39999991966901
Extrinsic Rewards:
2
6
24
13
4
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 2
Max Reward: 24
Gini Coefficient: 0.4326530612244898
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-35-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1784.2684127878042
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 2
  episodes_total: 50
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.6
    dispatch_time_ms: 9.335
    learner:
      cur_lr: 0.0013436829904094338
      grad_gnorm: 8.394014358520508
      policy_entropy: 23.3908634185791
      policy_loss: -1.2233848571777344
      var_gnorm: 21.34458351135254
      vf_explained_var: 0.33492857217788696
      vf_loss: 0.05240098014473915
    num_steps_sampled: 250000
    num_steps_trained: 250000
    wait_time_ms: 71.863
  iterations_since_restore: 50
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 447.4919948577881
  time_this_iter_s: 8.608906269073486
  time_total_s: 447.4919948577881
  timestamp: 1594848935
  timesteps_since_restore: 250000
  timesteps_this_iter: 5000
  timesteps_total: 250000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 447 s, 50 iter, 250000 ts, -1.78e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-35-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1784.2684127878042
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 0
  episodes_total: 50
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 9.684
    learner:
      cur_lr: 0.0013433500425890088
      grad_gnorm: 15.345893859863281
      policy_entropy: 41.523704528808594
      policy_loss: -3.1932461261749268
      var_gnorm: 21.345905303955078
      vf_explained_var: 0.0
      vf_loss: 0.17440848052501678
    num_steps_sampled: 255000
    num_steps_trained: 255000
    wait_time_ms: 76.274
  iterations_since_restore: 51
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 456.14850783348083
  time_this_iter_s: 8.656512975692749
  time_total_s: 456.14850783348083
  timestamp: 1594848943
  timesteps_since_restore: 255000
  timesteps_this_iter: 5000
  timesteps_total: 255000
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 32.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 456 s, 51 iter, 255000 ts, -1.78e+03 rew

agent-1: 41.59999999353276
agent-2: 37.59999999353277
agent-3: 35.599999993532776
agent-4: 35.59999999353278
agent-5: 38.599999993532776
Extrinsic Rewards:
8
4
2
2
5
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2857142857142857
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-35-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1745.576875282795
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 51
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 7.248
    learner:
      cur_lr: 0.001343016978353262
      grad_gnorm: 40.0
      policy_entropy: 17.478893280029297
      policy_loss: 33.03654479980469
      var_gnorm: 21.346830368041992
      vf_explained_var: 0.004455268383026123
      vf_loss: 64.44535827636719
    num_steps_sampled: 260000
    num_steps_trained: 260000
    wait_time_ms: 73.695
  iterations_since_restore: 52
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 464.95094108581543
  time_this_iter_s: 8.802433252334595
  time_total_s: 464.95094108581543
  timestamp: 1594848952
  timesteps_since_restore: 260000
  timesteps_this_iter: 5000
  timesteps_total: 260000
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 464 s, 52 iter, 260000 ts, -1.75e+03 rew

agent-1: 50.7999999898533
agent-2: 54.7999999898533
agent-3: 48.79999998985331
agent-4: 45.799999989853305
agent-5: 51.79999998985329
Extrinsic Rewards:
6
10
4
1
7
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.3
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-36-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1707.1619353744863
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 52
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.85
    dispatch_time_ms: 7.576
    learner:
      cur_lr: 0.001342684030532837
      grad_gnorm: 39.999996185302734
      policy_entropy: 27.79847526550293
      policy_loss: 24.885562896728516
      var_gnorm: 21.370040893554688
      vf_explained_var: 0.0
      vf_loss: 23.950729370117188
    num_steps_sampled: 265000
    num_steps_trained: 265000
    wait_time_ms: 73.977
  iterations_since_restore: 53
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 473.4730749130249
  time_this_iter_s: 8.522133827209473
  time_total_s: 473.4730749130249
  timestamp: 1594848961
  timesteps_since_restore: 265000
  timesteps_this_iter: 5000
  timesteps_total: 265000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 473 s, 53 iter, 265000 ts, -1.71e+03 rew

agent-1: 90.199917508616
agent-2: 91.19991750861601
agent-3: 81.19991750861594
agent-4: 81.19991750861593
agent-5: 79.19991750861591
Extrinsic Rewards:
15
16
6
6
4
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 4
Max Reward: 16
Gini Coefficient: 0.28085106382978725
20:20 Ratio: 4.0
Max-min Ratio: 4.0
agent-1: 150.19492236899498
agent-2: 159.1949223689951
agent-3: 160.19492236899507
agent-4: 161.19492236899512
agent-5: 152.19492236899504
Extrinsic Rewards:
11
20
21
22
13
Sum Reward: 87
Avg Reward: 17.4
Min Reward: 11
Max Reward: 22
Gini Coefficient: 0.13793103448275862
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-36-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1621.6008600015784
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 2
  episodes_total: 54
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 10.055
    learner:
      cur_lr: 0.00134235096629709
      grad_gnorm: 40.0
      policy_entropy: 14.753240585327148
      policy_loss: -109.95684051513672
      var_gnorm: 21.362873077392578
      vf_explained_var: -0.00034928321838378906
      vf_loss: 1069.356201171875
    num_steps_sampled: 270000
    num_steps_trained: 270000
    wait_time_ms: 75.57
  iterations_since_restore: 54
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 482.1640863418579
  time_this_iter_s: 8.691011428833008
  time_total_s: 482.1640863418579
  timestamp: 1594848969
  timesteps_since_restore: 270000
  timesteps_this_iter: 5000
  timesteps_total: 270000
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 482 s, 54 iter, 270000 ts, -1.62e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-36-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1621.600860001578
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 0
  episodes_total: 54
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.882
    dispatch_time_ms: 10.567
    learner:
      cur_lr: 0.001342018018476665
      grad_gnorm: 7.225396156311035
      policy_entropy: 38.04599380493164
      policy_loss: 1.8624603748321533
      var_gnorm: 21.38457679748535
      vf_explained_var: 0.0
      vf_loss: 0.05503455176949501
    num_steps_sampled: 275000
    num_steps_trained: 275000
    wait_time_ms: 75.981
  iterations_since_restore: 55
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 490.5651681423187
  time_this_iter_s: 8.401081800460815
  time_total_s: 490.5651681423187
  timestamp: 1594848978
  timesteps_since_restore: 275000
  timesteps_this_iter: 5000
  timesteps_total: 275000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 490 s, 55 iter, 275000 ts, -1.62e+03 rew

agent-1: 79.79997965890723
agent-2: 92.7999796589072
agent-3: 87.79997965890723
agent-4: 81.79997965890723
agent-5: 89.7999796589072
Extrinsic Rewards:
3
16
11
5
13
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 3
Max Reward: 16
Gini Coefficient: 0.2833333333333333
20:20 Ratio: 5.333333333333333
Max-min Ratio: 5.333333333333333
agent-1: 87.59998762405415
agent-2: 79.59998762405412
agent-3: 82.59998762405412
agent-4: 85.59998762405412
agent-5: 78.59998762405415
Extrinsic Rewards:
14
6
9
12
5
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 5
Max Reward: 14
Gini Coefficient: 0.20869565217391303
20:20 Ratio: 2.8
Max-min Ratio: 2.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-36-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1548.5794036369714
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 2
  episodes_total: 56
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 9.597
    learner:
      cur_lr: 0.0013416849542409182
      grad_gnorm: 40.0
      policy_entropy: 14.952670097351074
      policy_loss: -36.50920867919922
      var_gnorm: 21.350351333618164
      vf_explained_var: -0.04639232158660889
      vf_loss: 69.70729064941406
    num_steps_sampled: 280000
    num_steps_trained: 280000
    wait_time_ms: 76.413
  iterations_since_restore: 56
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 499.3371932506561
  time_this_iter_s: 8.772025108337402
  time_total_s: 499.3371932506561
  timestamp: 1594848987
  timesteps_since_restore: 280000
  timesteps_this_iter: 5000
  timesteps_total: 280000
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 499 s, 56 iter, 280000 ts, -1.55e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-36-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1548.5794036369714
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 0
  episodes_total: 56
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.312
    dispatch_time_ms: 10.939
    learner:
      cur_lr: 0.0013413520064204931
      grad_gnorm: 38.33576965332031
      policy_entropy: 24.13846206665039
      policy_loss: -4.736181735992432
      var_gnorm: 21.35498809814453
      vf_explained_var: 0.0
      vf_loss: 1.0721509456634521
    num_steps_sampled: 285000
    num_steps_trained: 285000
    wait_time_ms: 75.551
  iterations_since_restore: 57
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 508.0432698726654
  time_this_iter_s: 8.706076622009277
  time_total_s: 508.0432698726654
  timestamp: 1594848995
  timesteps_since_restore: 285000
  timesteps_this_iter: 5000
  timesteps_total: 285000
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 508 s, 57 iter, 285000 ts, -1.55e+03 rew

agent-1: 77.39999998470739
agent-2: 81.39999998470739
agent-3: 74.39999998470739
agent-4: 80.39999998470739
agent-5: 82.39999998470739
Extrinsic Rewards:
7
11
4
10
12
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.18181818181818182
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-36-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1514.4639755043308
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 57
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.725
    dispatch_time_ms: 5.624
    learner:
      cur_lr: 0.0013410189421847463
      grad_gnorm: 40.0
      policy_entropy: 30.275455474853516
      policy_loss: 54.49896240234375
      var_gnorm: 21.351171493530273
      vf_explained_var: 0.010597705841064453
      vf_loss: 185.10806274414062
    num_steps_sampled: 290000
    num_steps_trained: 290000
    wait_time_ms: 80.311
  iterations_since_restore: 58
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 516.8470375537872
  time_this_iter_s: 8.803767681121826
  time_total_s: 516.8470375537872
  timestamp: 1594849004
  timesteps_since_restore: 290000
  timesteps_this_iter: 5000
  timesteps_total: 290000
  training_iteration: 58
  
agent-1: 69.19999994704267
agent-2: 81.19999994704268
agent-3: 78.19999994704266
agent-4: 77.19999994704266
agent-5: 72.19999994704268
Extrinsic Rewards:
2
14
11
10
5
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.2857142857142857
20:20 Ratio: 7.0
Max-min Ratio: 7.0
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 516 s, 58 iter, 290000 ts, -1.51e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-36-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1481.8352862760628
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 58
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.144
    dispatch_time_ms: 7.965
    learner:
      cur_lr: 0.0013406859943643212
      grad_gnorm: 5.388701438903809
      policy_entropy: 22.864927291870117
      policy_loss: -0.9970929026603699
      var_gnorm: 21.35273551940918
      vf_explained_var: 1.430511474609375e-06
      vf_loss: 0.020562345162034035
    num_steps_sampled: 295000
    num_steps_trained: 295000
    wait_time_ms: 77.22
  iterations_since_restore: 59
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 525.6410474777222
  time_this_iter_s: 8.794009923934937
  time_total_s: 525.6410474777222
  timestamp: 1594849013
  timesteps_since_restore: 295000
  timesteps_this_iter: 5000
  timesteps_total: 295000
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 525 s, 59 iter, 295000 ts, -1.48e+03 rew

agent-1: 30.3999999994383
agent-2: 34.39999999943838
agent-3: 34.39999999943838
agent-4: 40.399999999438386
agent-5: 31.3999999994383
Extrinsic Rewards:
0
4
4
10
1
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.4842105263157895
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 45.999999998096165
agent-2: 49.999999998096165
agent-3: 45.999999998096165
agent-4: 42.99999999809616
agent-5: 39.999999998096165
Extrinsic Rewards:
6
10
6
3
0
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.368
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-37-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1425.8407767337328
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 2
  episodes_total: 60
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.915
    dispatch_time_ms: 11.183
    learner:
      cur_lr: 0.0013403530465438962
      grad_gnorm: 39.999996185302734
      policy_entropy: 25.013275146484375
      policy_loss: 65.56330871582031
      var_gnorm: 21.352439880371094
      vf_explained_var: 0.01163405179977417
      vf_loss: 221.1492919921875
    num_steps_sampled: 300000
    num_steps_trained: 300000
    wait_time_ms: 75.032
  iterations_since_restore: 60
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 534.4284999370575
  time_this_iter_s: 8.787452459335327
  time_total_s: 534.4284999370575
  timestamp: 1594849022
  timesteps_since_restore: 300000
  timesteps_this_iter: 5000
  timesteps_total: 300000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 33.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 534 s, 60 iter, 300000 ts, -1.43e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-37-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1425.8407767337328
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 0
  episodes_total: 60
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.589
    dispatch_time_ms: 6.195
    learner:
      cur_lr: 0.0013400199823081493
      grad_gnorm: 5.920530319213867
      policy_entropy: 21.02669334411621
      policy_loss: -0.6775963306427002
      var_gnorm: 21.35220718383789
      vf_explained_var: 0.0
      vf_loss: 0.025903500616550446
    num_steps_sampled: 305000
    num_steps_trained: 305000
    wait_time_ms: 74.328
  iterations_since_restore: 61
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 543.085401058197
  time_this_iter_s: 8.656901121139526
  time_total_s: 543.085401058197
  timestamp: 1594849031
  timesteps_since_restore: 305000
  timesteps_this_iter: 5000
  timesteps_total: 305000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 543 s, 61 iter, 305000 ts, -1.43e+03 rew

agent-1: 40.99999999900603
agent-2: 43.99999999900602
agent-3: 48.999999999006015
agent-4: 43.99999999900602
agent-5: 46.999999999006015
Extrinsic Rewards:
1
4
9
4
7
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.304
20:20 Ratio: 9.0
Max-min Ratio: 9.0
agent-1: 60.19999999703859
agent-2: 52.199999997038574
agent-3: 58.19999999703859
agent-4: 55.19999999703859
agent-5: 62.199999997038574
Extrinsic Rewards:
9
1
7
4
11
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.3125
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-37-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1371.5717194200604
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 2
  episodes_total: 62
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 8.791
    learner:
      cur_lr: 0.0013396870344877243
      grad_gnorm: 40.0
      policy_entropy: 28.93212127685547
      policy_loss: 48.33619689941406
      var_gnorm: 21.351524353027344
      vf_explained_var: 0.01820385456085205
      vf_loss: 55.198020935058594
    num_steps_sampled: 310000
    num_steps_trained: 310000
    wait_time_ms: 77.023
  iterations_since_restore: 62
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 551.8792052268982
  time_this_iter_s: 8.793804168701172
  time_total_s: 551.8792052268982
  timestamp: 1594849039
  timesteps_since_restore: 310000
  timesteps_this_iter: 5000
  timesteps_total: 310000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 551 s, 62 iter, 310000 ts, -1.37e+03 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-37-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1371.5717194200606
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 0
  episodes_total: 62
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 9.656
    learner:
      cur_lr: 0.0013393539702519774
      grad_gnorm: 40.0
      policy_entropy: 18.452838897705078
      policy_loss: -5.293266296386719
      var_gnorm: 21.35999298095703
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.4250872135162354
    num_steps_sampled: 315000
    num_steps_trained: 315000
    wait_time_ms: 76.36
  iterations_since_restore: 63
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 560.618670463562
  time_this_iter_s: 8.739465236663818
  time_total_s: 560.618670463562
  timestamp: 1594849048
  timesteps_since_restore: 315000
  timesteps_this_iter: 5000
  timesteps_total: 315000
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 560 s, 63 iter, 315000 ts, -1.37e+03 rew

agent-1: 76.19999996726108
agent-2: 74.19999996726108
agent-3: 79.19999996726109
agent-4: 73.19999996726106
agent-5: 75.19999996726109
Extrinsic Rewards:
9
7
12
6
8
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 6
Max Reward: 12
Gini Coefficient: 0.13333333333333333
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-37-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1343.8007397493247
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 63
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.284
    dispatch_time_ms: 10.622
    learner:
      cur_lr: 0.0013390210224315524
      grad_gnorm: 0.29005342721939087
      policy_entropy: 5.748325347900391
      policy_loss: 0.0023979877587407827
      var_gnorm: 21.35516357421875
      vf_explained_var: 0.0
      vf_loss: 6.239429785637185e-05
    num_steps_sampled: 320000
    num_steps_trained: 320000
    wait_time_ms: 74.054
  iterations_since_restore: 64
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 569.3807954788208
  time_this_iter_s: 8.762125015258789
  time_total_s: 569.3807954788208
  timestamp: 1594849057
  timesteps_since_restore: 320000
  timesteps_this_iter: 5000
  timesteps_total: 320000
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 569 s, 64 iter, 320000 ts, -1.34e+03 rew

agent-1: 95.19999992154364
agent-2: 88.19999992154361
agent-3: 91.19999992154362
agent-4: 95.19999992154364
agent-5: 98.19999992154362
Extrinsic Rewards:
12
5
8
12
15
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 5
Max Reward: 15
Gini Coefficient: 0.18461538461538463
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-37-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1315.491353196871
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 64
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.997
    dispatch_time_ms: 8.03
    learner:
      cur_lr: 0.0013386879581958055
      grad_gnorm: 29.795015335083008
      policy_entropy: 21.58768081665039
      policy_loss: -5.158280372619629
      var_gnorm: 21.379119873046875
      vf_explained_var: 0.0
      vf_loss: 1.427612066268921
    num_steps_sampled: 325000
    num_steps_trained: 325000
    wait_time_ms: 77.847
  iterations_since_restore: 65
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 577.9992632865906
  time_this_iter_s: 8.618467807769775
  time_total_s: 577.9992632865906
  timestamp: 1594849066
  timesteps_since_restore: 325000
  timesteps_this_iter: 5000
  timesteps_total: 325000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 577 s, 65 iter, 325000 ts, -1.32e+03 rew

agent-1: 114.99999273949366
agent-2: 117.99999273949366
agent-3: 112.99999273949366
agent-4: 115.99999273949366
agent-5: 122.99999273949372
Extrinsic Rewards:
11
14
9
12
19
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 9
Max Reward: 19
Gini Coefficient: 0.14153846153846153
20:20 Ratio: 2.111111111111111
Max-min Ratio: 2.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-37-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1286.2530252446502
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 65
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.757
    dispatch_time_ms: 6.081
    learner:
      cur_lr: 0.0013383550103753805
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.40436363220215
      policy_loss: 9.322032928466797
      var_gnorm: 21.354963302612305
      vf_explained_var: 0.05086761713027954
      vf_loss: 10.882404327392578
    num_steps_sampled: 330000
    num_steps_trained: 330000
    wait_time_ms: 80.629
  iterations_since_restore: 66
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 586.8156526088715
  time_this_iter_s: 8.816389322280884
  time_total_s: 586.8156526088715
  timestamp: 1594849074
  timesteps_since_restore: 330000
  timesteps_this_iter: 5000
  timesteps_total: 330000
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 586 s, 66 iter, 330000 ts, -1.29e+03 rew

agent-1: 69.19999977737416
agent-2: 78.19999977737413
agent-3: 76.19999977737413
agent-4: 76.19999977737415
agent-5: 78.19999977737413
Extrinsic Rewards:
2
11
9
9
11
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.19047619047619047
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-38-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1261.0370703335668
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 66
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.114
    dispatch_time_ms: 11.463
    learner:
      cur_lr: 0.0013380219461396337
      grad_gnorm: 16.539518356323242
      policy_entropy: 34.85799026489258
      policy_loss: -2.745242118835449
      var_gnorm: 21.35917854309082
      vf_explained_var: 0.0
      vf_loss: 0.16781985759735107
    num_steps_sampled: 335000
    num_steps_trained: 335000
    wait_time_ms: 73.868
  iterations_since_restore: 67
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 595.4664978981018
  time_this_iter_s: 8.650845289230347
  time_total_s: 595.4664978981018
  timestamp: 1594849083
  timesteps_since_restore: 335000
  timesteps_this_iter: 5000
  timesteps_total: 335000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 34.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 595 s, 67 iter, 335000 ts, -1.26e+03 rew

agent-1: 60.39999999404843
agent-2: 62.39999999404843
agent-3: 59.39999999404843
agent-4: 62.399999994048414
agent-5: 61.39999999404843
Extrinsic Rewards:
6
8
5
8
7
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 5
Max Reward: 8
Gini Coefficient: 0.09411764705882353
20:20 Ratio: 1.6
Max-min Ratio: 1.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-38-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1237.6484573439577
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 67
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.823
    dispatch_time_ms: 12.348
    learner:
      cur_lr: 0.0013376889983192086
      grad_gnorm: 0.06774664670228958
      policy_entropy: 36.04421615600586
      policy_loss: 0.026155689731240273
      var_gnorm: 21.35818862915039
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.297125658718869e-06
    num_steps_sampled: 340000
    num_steps_trained: 340000
    wait_time_ms: 71.47
  iterations_since_restore: 68
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 604.1756691932678
  time_this_iter_s: 8.709171295166016
  time_total_s: 604.1756691932678
  timestamp: 1594849092
  timesteps_since_restore: 340000
  timesteps_this_iter: 5000
  timesteps_total: 340000
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 604 s, 68 iter, 340000 ts, -1.24e+03 rew

agent-1: 76.39999999103027
agent-2: 68.39999999103028
agent-3: 67.39999999103031
agent-4: 65.39999999103026
agent-5: 73.3999999910303
Extrinsic Rewards:
14
6
5
3
11
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.28717948717948716
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-38-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1214.2859800307356
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 68
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.174
    dispatch_time_ms: 10.645
    learner:
      cur_lr: 0.0013373560504987836
      grad_gnorm: 4.449857234954834
      policy_entropy: 32.44401550292969
      policy_loss: -0.722709059715271
      var_gnorm: 21.356473922729492
      vf_explained_var: 4.291534423828125e-06
      vf_loss: 0.014282365329563618
    num_steps_sampled: 345000
    num_steps_trained: 345000
    wait_time_ms: 74.664
  iterations_since_restore: 69
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 612.8871641159058
  time_this_iter_s: 8.71149492263794
  time_total_s: 612.8871641159058
  timestamp: 1594849101
  timesteps_since_restore: 345000
  timesteps_this_iter: 5000
  timesteps_total: 345000
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 612 s, 69 iter, 345000 ts, -1.21e+03 rew

agent-1: 39.99999999885931
agent-2: 44.999999998859295
agent-3: 45.999999998859295
agent-4: 46.999999998859295
agent-5: 46.999999998859295
Extrinsic Rewards:
0
5
6
7
7
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.256
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-38-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1193.4267629289234
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 69
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.524
    dispatch_time_ms: 10.427
    learner:
      cur_lr: 0.0013370229862630367
      grad_gnorm: 40.0
      policy_entropy: 29.767738342285156
      policy_loss: 40.85090637207031
      var_gnorm: 21.356203079223633
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 57.79907989501953
    num_steps_sampled: 350000
    num_steps_trained: 350000
    wait_time_ms: 74.169
  iterations_since_restore: 70
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 621.5780448913574
  time_this_iter_s: 8.69088077545166
  time_total_s: 621.5780448913574
  timestamp: 1594849109
  timesteps_since_restore: 350000
  timesteps_this_iter: 5000
  timesteps_total: 350000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 621 s, 70 iter, 350000 ts, -1.19e+03 rew

agent-1: 39.19999999837781
agent-2: 35.19999999837783
agent-3: 46.19999999837782
agent-4: 41.19999999837782
agent-5: 36.19999999837781
Extrinsic Rewards:
4
0
11
6
1
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.4909090909090909
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-38-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1173.5492377443404
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 70
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.012
    dispatch_time_ms: 9.036
    learner:
      cur_lr: 0.0013366900384426117
      grad_gnorm: 33.020347595214844
      policy_entropy: 5.120431900024414
      policy_loss: -1.595544695854187
      var_gnorm: 21.360050201416016
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.8057907819747925
    num_steps_sampled: 355000
    num_steps_trained: 355000
    wait_time_ms: 78.286
  iterations_since_restore: 71
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 630.2510018348694
  time_this_iter_s: 8.672956943511963
  time_total_s: 630.2510018348694
  timestamp: 1594849118
  timesteps_since_restore: 355000
  timesteps_this_iter: 5000
  timesteps_total: 355000
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 630 s, 71 iter, 355000 ts, -1.17e+03 rew

agent-1: 99.59999963640185
agent-2: 99.59999963640185
agent-3: 112.59999963640185
agent-4: 94.59999963640185
agent-5: 97.59999963640185
Extrinsic Rewards:
10
10
23
5
8
Sum Reward: 56
Avg Reward: 11.2
Min Reward: 5
Max Reward: 23
Gini Coefficient: 0.2714285714285714
20:20 Ratio: 4.6
Max-min Ratio: 4.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-38-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1149.9217837172087
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 71
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 11.639
    learner:
      cur_lr: 0.0013363569742068648
      grad_gnorm: 40.00000762939453
      policy_entropy: 1.0559154748916626
      policy_loss: 0.04308101907372475
      var_gnorm: 21.36029052734375
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 2.8439908027648926
    num_steps_sampled: 360000
    num_steps_trained: 360000
    wait_time_ms: 72.601
  iterations_since_restore: 72
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 639.0361275672913
  time_this_iter_s: 8.785125732421875
  time_total_s: 639.0361275672913
  timestamp: 1594849127
  timesteps_since_restore: 360000
  timesteps_this_iter: 5000
  timesteps_total: 360000
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 639 s, 72 iter, 360000 ts, -1.15e+03 rew

agent-1: 30.199999998727243
agent-2: 29.199999998727243
agent-3: 34.199999998727236
agent-4: 29.199999998727236
agent-5: 30.199999998727243
Extrinsic Rewards:
3
2
7
2
3
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.25882352941176473
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-38-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1131.8256478323358
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 72
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.079
    dispatch_time_ms: 8.422
    learner:
      cur_lr: 0.0013360240263864398
      grad_gnorm: 20.996049880981445
      policy_entropy: 4.080946445465088
      policy_loss: -0.0705215334892273
      var_gnorm: 21.362947463989258
      vf_explained_var: 0.0
      vf_loss: 0.3192179501056671
    num_steps_sampled: 365000
    num_steps_trained: 365000
    wait_time_ms: 72.641
  iterations_since_restore: 73
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 647.4881970882416
  time_this_iter_s: 8.452069520950317
  time_total_s: 647.4881970882416
  timestamp: 1594849135
  timesteps_since_restore: 365000
  timesteps_this_iter: 5000
  timesteps_total: 365000
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 647 s, 73 iter, 365000 ts, -1.13e+03 rew

agent-1: 109.77488291407998
agent-2: 108.77488291407998
agent-3: 109.77488291407998
agent-4: 98.77488291408001
agent-5: 100.77488291407998
Extrinsic Rewards:
16
15
16
5
7
Sum Reward: 59
Avg Reward: 11.8
Min Reward: 5
Max Reward: 16
Gini Coefficient: 0.21016949152542372
20:20 Ratio: 3.2
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-39-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1109.0900305391478
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 73
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.536
    dispatch_time_ms: 6.212
    learner:
      cur_lr: 0.001335690962150693
      grad_gnorm: 40.0
      policy_entropy: 14.054651260375977
      policy_loss: -5.825351238250732
      var_gnorm: 21.39097785949707
      vf_explained_var: 0.0
      vf_loss: 9.123676300048828
    num_steps_sampled: 370000
    num_steps_trained: 370000
    wait_time_ms: 80.833
  iterations_since_restore: 74
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 656.1001744270325
  time_this_iter_s: 8.611977338790894
  time_total_s: 656.1001744270325
  timestamp: 1594849144
  timesteps_since_restore: 370000
  timesteps_this_iter: 5000
  timesteps_total: 370000
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 35.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 656 s, 74 iter, 370000 ts, -1.11e+03 rew

agent-1: 102.56927298286146
agent-2: 98.56927298286145
agent-3: 101.56927298286145
agent-4: 104.56927298286145
agent-5: 96.56927298286146
Extrinsic Rewards:
13
9
12
15
7
Sum Reward: 56
Avg Reward: 11.2
Min Reward: 7
Max Reward: 15
Gini Coefficient: 0.14285714285714285
20:20 Ratio: 2.142857142857143
Max-min Ratio: 2.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-39-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1087.2935927627498
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 74
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.852
    dispatch_time_ms: 8.213
    learner:
      cur_lr: 0.001335358014330268
      grad_gnorm: 40.0
      policy_entropy: 10.555910110473633
      policy_loss: -4.143861770629883
      var_gnorm: 21.421342849731445
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 15.270133972167969
    num_steps_sampled: 375000
    num_steps_trained: 375000
    wait_time_ms: 78.468
  iterations_since_restore: 75
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 664.7842674255371
  time_this_iter_s: 8.684092998504639
  time_total_s: 664.7842674255371
  timestamp: 1594849153
  timesteps_since_restore: 375000
  timesteps_this_iter: 5000
  timesteps_total: 375000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 664 s, 75 iter, 375000 ts, -1.09e+03 rew

agent-1: 87.19999982604034
agent-2: 79.19999982604034
agent-3: 88.19999982604034
agent-4: 82.19999982604034
agent-5: 86.19999982604037
Extrinsic Rewards:
12
4
13
7
11
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 4
Max Reward: 13
Gini Coefficient: 0.19574468085106383
20:20 Ratio: 3.25
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-39-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1067.1563448708437
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 75
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.502
    dispatch_time_ms: 8.221
    learner:
      cur_lr: 0.001335024950094521
      grad_gnorm: 13.281783103942871
      policy_entropy: 4.823951244354248
      policy_loss: -2.5365612506866455
      var_gnorm: 21.35809898376465
      vf_explained_var: 0.0
      vf_loss: 0.1198735460639
    num_steps_sampled: 380000
    num_steps_trained: 380000
    wait_time_ms: 76.84
  iterations_since_restore: 76
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 673.6448857784271
  time_this_iter_s: 8.860618352890015
  time_total_s: 673.6448857784271
  timestamp: 1594849162
  timesteps_since_restore: 380000
  timesteps_this_iter: 5000
  timesteps_total: 380000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 673 s, 76 iter, 380000 ts, -1.07e+03 rew

agent-1: 98.99999959250367
agent-2: 96.9999995925037
agent-3: 93.99999959250367
agent-4: 109.99999959250376
agent-5: 94.99999959250367
Extrinsic Rewards:
11
9
6
22
7
Sum Reward: 55
Avg Reward: 11.0
Min Reward: 6
Max Reward: 22
Gini Coefficient: 0.26181818181818184
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-39-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1046.601656149352
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 76
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.074
    dispatch_time_ms: 9.467
    learner:
      cur_lr: 0.001334692002274096
      grad_gnorm: 39.999996185302734
      policy_entropy: 46.90533447265625
      policy_loss: 49.274593353271484
      var_gnorm: 21.400157928466797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 27.471107482910156
    num_steps_sampled: 385000
    num_steps_trained: 385000
    wait_time_ms: 73.509
  iterations_since_restore: 77
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 682.1125028133392
  time_this_iter_s: 8.46761703491211
  time_total_s: 682.1125028133392
  timestamp: 1594849170
  timesteps_since_restore: 385000
  timesteps_this_iter: 5000
  timesteps_total: 385000
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 682 s, 77 iter, 385000 ts, -1.05e+03 rew

agent-1: 150.5995653438865
agent-2: 153.59956534388655
agent-3: 157.59956534388655
agent-4: 148.59956534388658
agent-5: 163.59956534388655
Extrinsic Rewards:
13
16
20
11
26
Sum Reward: 86
Avg Reward: 17.2
Min Reward: 11
Max Reward: 26
Gini Coefficient: 0.17209302325581396
20:20 Ratio: 2.3636363636363638
Max-min Ratio: 2.3636363636363638
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-39-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1022.9575070211864
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 77
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.468
    dispatch_time_ms: 6.771
    learner:
      cur_lr: 0.001334359054453671
      grad_gnorm: 40.0
      policy_entropy: 1.1867344379425049
      policy_loss: -0.045284539461135864
      var_gnorm: 21.392215728759766
      vf_explained_var: 0.0
      vf_loss: 2.1655099391937256
    num_steps_sampled: 390000
    num_steps_trained: 390000
    wait_time_ms: 76.945
  iterations_since_restore: 78
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 690.7871613502502
  time_this_iter_s: 8.67465853691101
  time_total_s: 690.7871613502502
  timestamp: 1594849179
  timesteps_since_restore: 390000
  timesteps_this_iter: 5000
  timesteps_total: 390000
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 690 s, 78 iter, 390000 ts, -1.02e+03 rew

agent-1: 115.79996077421296
agent-2: 114.799960774213
agent-3: 111.79996077421299
agent-4: 109.79996077421299
agent-5: 114.79996077421296
Extrinsic Rewards:
15
14
11
9
14
Sum Reward: 63
Avg Reward: 12.6
Min Reward: 9
Max Reward: 15
Gini Coefficient: 0.09523809523809523
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-39-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -1002.573438932824
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 78
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.636
    dispatch_time_ms: 9.704
    learner:
      cur_lr: 0.0013340259902179241
      grad_gnorm: 26.981531143188477
      policy_entropy: 1.0542819499969482
      policy_loss: 0.019813336431980133
      var_gnorm: 21.38393211364746
      vf_explained_var: 0.0
      vf_loss: 0.5538604855537415
    num_steps_sampled: 395000
    num_steps_trained: 395000
    wait_time_ms: 68.067
  iterations_since_restore: 79
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 699.1395947933197
  time_this_iter_s: 8.352433443069458
  time_total_s: 699.1395947933197
  timestamp: 1594849187
  timesteps_since_restore: 395000
  timesteps_this_iter: 5000
  timesteps_total: 395000
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 699 s, 79 iter, 395000 ts, -1e+03 rew

agent-1: 10.50363126434021
agent-2: 12.5036312643402
agent-3: 10.50363126434021
agent-4: 14.503631264340209
agent-5: 12.50363126434021
Extrinsic Rewards:
0
2
0
4
2
Sum Reward: 8
Avg Reward: 1.6
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.5
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-39-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -989.1165832966908
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 79
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 11.699
    learner:
      cur_lr: 0.001333693042397499
      grad_gnorm: 40.0
      policy_entropy: 1.6022460460662842
      policy_loss: 14.62601089477539
      var_gnorm: 21.381383895874023
      vf_explained_var: 0.0
      vf_loss: 30.56863021850586
    num_steps_sampled: 400000
    num_steps_trained: 400000
    wait_time_ms: 67.433
  iterations_since_restore: 80
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 707.456873178482
  time_this_iter_s: 8.317278385162354
  time_total_s: 707.456873178482
  timestamp: 1594849196
  timesteps_since_restore: 400000
  timesteps_this_iter: 5000
  timesteps_total: 400000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 707 s, 80 iter, 400000 ts, -989 rew

agent-1: 13.81952509697649
agent-2: 13.819525096976493
agent-3: 15.819525096976486
agent-4: 11.819525096976493
agent-5: 13.81952509697649
Extrinsic Rewards:
2
2
4
0
2
Sum Reward: 10
Avg Reward: 2.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.32
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-40-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -975.8889056869214
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 80
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.022
    dispatch_time_ms: 9.119
    learner:
      cur_lr: 0.0013333599781617522
      grad_gnorm: 40.0
      policy_entropy: 24.07065773010254
      policy_loss: 23.521339416503906
      var_gnorm: 21.373720169067383
      vf_explained_var: 0.0
      vf_loss: 29.314495086669922
    num_steps_sampled: 405000
    num_steps_trained: 405000
    wait_time_ms: 71.258
  iterations_since_restore: 81
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 715.7809629440308
  time_this_iter_s: 8.324089765548706
  time_total_s: 715.7809629440308
  timestamp: 1594849204
  timesteps_since_restore: 405000
  timesteps_this_iter: 5000
  timesteps_total: 405000
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 36.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 715 s, 81 iter, 405000 ts, -976 rew

agent-1: 53.99935427939067
agent-2: 56.99935427939066
agent-3: 51.99935427939066
agent-4: 53.99935427939066
agent-5: 52.99935427939067
Extrinsic Rewards:
6
9
4
6
5
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.14666666666666667
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-40-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -960.5076010315651
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 81
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.539
    dispatch_time_ms: 11.918
    learner:
      cur_lr: 0.0013330270303413272
      grad_gnorm: 29.670446395874023
      policy_entropy: 13.131690979003906
      policy_loss: -2.2987492084503174
      var_gnorm: 21.37353515625
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.6522430777549744
    num_steps_sampled: 410000
    num_steps_trained: 410000
    wait_time_ms: 71.085
  iterations_since_restore: 82
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 724.3485696315765
  time_this_iter_s: 8.567606687545776
  time_total_s: 724.3485696315765
  timestamp: 1594849213
  timesteps_since_restore: 410000
  timesteps_this_iter: 5000
  timesteps_total: 410000
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 724 s, 82 iter, 410000 ts, -961 rew

agent-1: 91.79911101813165
agent-2: 97.79911101813161
agent-3: 90.79911101813165
agent-4: 101.7991110181316
agent-5: 94.79911101813163
Extrinsic Rewards:
7
13
6
17
10
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 6
Max Reward: 17
Gini Coefficient: 0.21132075471698114
20:20 Ratio: 2.8333333333333335
Max-min Ratio: 2.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-40-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -942.9770747373916
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 82
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.014
    dispatch_time_ms: 8.228
    learner:
      cur_lr: 0.0013326939661055803
      grad_gnorm: 16.523422241210938
      policy_entropy: 50.65454864501953
      policy_loss: -1.9358198642730713
      var_gnorm: 21.39438247680664
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.18213443458080292
    num_steps_sampled: 415000
    num_steps_trained: 415000
    wait_time_ms: 74.279
  iterations_since_restore: 83
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 732.7868394851685
  time_this_iter_s: 8.438269853591919
  time_total_s: 732.7868394851685
  timestamp: 1594849221
  timesteps_since_restore: 415000
  timesteps_this_iter: 5000
  timesteps_total: 415000
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 732 s, 83 iter, 415000 ts, -943 rew

agent-1: 93.99998883139008
agent-2: 94.99998883139008
agent-3: 96.99998883139004
agent-4: 104.99998883139007
agent-5: 103.99998883139007
Extrinsic Rewards:
6
7
9
17
16
Sum Reward: 55
Avg Reward: 11.0
Min Reward: 6
Max Reward: 17
Gini Coefficient: 0.22545454545454546
20:20 Ratio: 2.8333333333333335
Max-min Ratio: 2.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-40-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -925.6520504133631
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 83
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.159
    dispatch_time_ms: 8.769
    learner:
      cur_lr: 0.0013323610182851553
      grad_gnorm: 5.61301326751709
      policy_entropy: 13.076333999633789
      policy_loss: -0.6168001890182495
      var_gnorm: 21.365015029907227
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.02290860190987587
    num_steps_sampled: 420000
    num_steps_trained: 420000
    wait_time_ms: 73.674
  iterations_since_restore: 84
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 741.3904097080231
  time_this_iter_s: 8.603570222854614
  time_total_s: 741.3904097080231
  timestamp: 1594849230
  timesteps_since_restore: 420000
  timesteps_this_iter: 5000
  timesteps_total: 420000
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 741 s, 84 iter, 420000 ts, -926 rew

agent-1: 85.1999958681108
agent-2: 80.1999958681108
agent-3: 81.1999958681108
agent-4: 88.1999958681108
agent-5: 88.19999586811078
Extrinsic Rewards:
10
5
6
13
13
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 5
Max Reward: 13
Gini Coefficient: 0.19574468085106383
20:20 Ratio: 2.6
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-40-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -909.596669106769
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 84
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.551
    dispatch_time_ms: 7.81
    learner:
      cur_lr: 0.0013320279540494084
      grad_gnorm: 11.73786735534668
      policy_entropy: 21.18435287475586
      policy_loss: -1.915441870689392
      var_gnorm: 21.36463165283203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.09172078967094421
    num_steps_sampled: 425000
    num_steps_trained: 425000
    wait_time_ms: 73.538
  iterations_since_restore: 85
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 750.0203335285187
  time_this_iter_s: 8.629923820495605
  time_total_s: 750.0203335285187
  timestamp: 1594849238
  timesteps_since_restore: 425000
  timesteps_this_iter: 5000
  timesteps_total: 425000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 750 s, 85 iter, 425000 ts, -910 rew

agent-1: 52.39999999746907
agent-2: 49.39999999746907
agent-3: 57.39999999746907
agent-4: 52.39999999746906
agent-5: 49.39999999746907
Extrinsic Rewards:
6
3
11
6
3
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.2620689655172414
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-40-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -895.8249435880147
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 85
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.832
    dispatch_time_ms: 10.513
    learner:
      cur_lr: 0.0013316950062289834
      grad_gnorm: 0.07870722562074661
      policy_entropy: 6.037187099456787
      policy_loss: 0.006908287759870291
      var_gnorm: 21.366085052490234
      vf_explained_var: 0.0
      vf_loss: 3.3581793559278594e-06
    num_steps_sampled: 430000
    num_steps_trained: 430000
    wait_time_ms: 71.007
  iterations_since_restore: 86
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 758.460794210434
  time_this_iter_s: 8.440460681915283
  time_total_s: 758.460794210434
  timestamp: 1594849247
  timesteps_since_restore: 430000
  timesteps_this_iter: 5000
  timesteps_total: 430000
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 758 s, 86 iter, 430000 ts, -896 rew

agent-1: 67.79999999290813
agent-2: 63.79999999290803
agent-3: 65.79999999290814
agent-4: 73.79999999290816
agent-5: 70.79999999290817
Extrinsic Rewards:
7
3
5
13
10
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.2631578947368421
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-40-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -881.4316302908918
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 86
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.291
    dispatch_time_ms: 10.726
    learner:
      cur_lr: 0.0013313619419932365
      grad_gnorm: 11.424616813659668
      policy_entropy: 36.968345642089844
      policy_loss: -1.5035475492477417
      var_gnorm: 21.383695602416992
      vf_explained_var: 0.0
      vf_loss: 0.08665166050195694
    num_steps_sampled: 435000
    num_steps_trained: 435000
    wait_time_ms: 71.064
  iterations_since_restore: 87
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 766.77188372612
  time_this_iter_s: 8.311089515686035
  time_total_s: 766.77188372612
  timestamp: 1594849255
  timesteps_since_restore: 435000
  timesteps_this_iter: 5000
  timesteps_total: 435000
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 37.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 766 s, 87 iter, 435000 ts, -881 rew

agent-1: 133.99009409937136
agent-2: 132.99009409937142
agent-3: 136.99009409937136
agent-4: 129.9900940993714
agent-5: 140.99009409937136
Extrinsic Rewards:
14
13
17
10
21
Sum Reward: 75
Avg Reward: 15.0
Min Reward: 10
Max Reward: 21
Gini Coefficient: 0.13866666666666666
20:20 Ratio: 2.1
Max-min Ratio: 2.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-41-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -863.5421808565499
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 87
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.172
    dispatch_time_ms: 8.38
    learner:
      cur_lr: 0.0013310289941728115
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.58150291442871
      policy_loss: 17.094572067260742
      var_gnorm: 21.370229721069336
      vf_explained_var: 0.0
      vf_loss: 10.486384391784668
    num_steps_sampled: 440000
    num_steps_trained: 440000
    wait_time_ms: 75.765
  iterations_since_restore: 88
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 775.5348320007324
  time_this_iter_s: 8.762948274612427
  time_total_s: 775.5348320007324
  timestamp: 1594849264
  timesteps_since_restore: 440000
  timesteps_this_iter: 5000
  timesteps_total: 440000
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 775 s, 88 iter, 440000 ts, -864 rew

agent-1: 74.19999432564452
agent-2: 73.1999943256445
agent-3: 81.19999432564458
agent-4: 77.19999432564458
agent-5: 72.1999943256445
Extrinsic Rewards:
7
6
14
10
5
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 5
Max Reward: 14
Gini Coefficient: 0.20952380952380953
20:20 Ratio: 2.8
Max-min Ratio: 2.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-41-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -849.4337473055867
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 88
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.745
    dispatch_time_ms: 7.359
    learner:
      cur_lr: 0.0013306960463523865
      grad_gnorm: 10.173727035522461
      policy_entropy: 17.463289260864258
      policy_loss: -1.3721989393234253
      var_gnorm: 21.364246368408203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.07646389305591583
    num_steps_sampled: 445000
    num_steps_trained: 445000
    wait_time_ms: 80.809
  iterations_since_restore: 89
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 784.2497329711914
  time_this_iter_s: 8.714900970458984
  time_total_s: 784.2497329711914
  timestamp: 1594849273
  timesteps_since_restore: 445000
  timesteps_this_iter: 5000
  timesteps_total: 445000
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 784 s, 89 iter, 445000 ts, -849 rew

agent-1: 29.199999999380754
agent-2: 30.199999999380754
agent-3: 27.199999999380754
agent-4: 32.19999999938079
agent-5: 34.1999999993808
Extrinsic Rewards:
2
3
0
5
7
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 58.9999999967248
agent-2: 49.9999999967248
agent-3: 50.9999999967248
agent-4: 53.99999999672482
agent-5: 55.9999999967248
Extrinsic Rewards:
11
2
3
6
8
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.30666666666666664
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-41-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -825.8574418101233
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 2
  episodes_total: 90
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 6.766
    learner:
      cur_lr: 0.0013303629821166396
      grad_gnorm: 1.156067132949829
      policy_entropy: 16.828096389770508
      policy_loss: 0.1481683999300003
      var_gnorm: 21.363719940185547
      vf_explained_var: -0.583267092704773
      vf_loss: 0.0007288897759281099
    num_steps_sampled: 450000
    num_steps_trained: 450000
    wait_time_ms: 76.157
  iterations_since_restore: 90
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 793.0764129161835
  time_this_iter_s: 8.826679944992065
  time_total_s: 793.0764129161835
  timestamp: 1594849282
  timesteps_since_restore: 450000
  timesteps_this_iter: 5000
  timesteps_total: 450000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 793 s, 90 iter, 450000 ts, -826 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-41-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -825.8574418101232
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 0
  episodes_total: 90
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.297
    dispatch_time_ms: 9.867
    learner:
      cur_lr: 0.0013300300342962146
      grad_gnorm: 5.563840389251709
      policy_entropy: 38.73151397705078
      policy_loss: -1.8129197359085083
      var_gnorm: 21.363370895385742
      vf_explained_var: 0.0
      vf_loss: 0.02262028120458126
    num_steps_sampled: 455000
    num_steps_trained: 455000
    wait_time_ms: 74.887
  iterations_since_restore: 91
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 801.7519860267639
  time_this_iter_s: 8.675573110580444
  time_total_s: 801.7519860267639
  timestamp: 1594849290
  timesteps_since_restore: 455000
  timesteps_this_iter: 5000
  timesteps_total: 455000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 801 s, 91 iter, 455000 ts, -826 rew

agent-1: 34.599999997449
agent-2: 34.599999997449
agent-3: 42.599999997448975
agent-4: 37.599999997448975
agent-5: 39.59999999744897
Extrinsic Rewards:
1
1
9
4
6
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: 9.0
Max-min Ratio: 9.0
agent-1: 43.399999998708395
agent-2: 44.399999998708395
agent-3: 40.39999999870839
agent-4: 41.39999999870839
agent-5: 46.399999998708395
Extrinsic Rewards:
5
6
2
3
8
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.25
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-41-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -803.5018452492426
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 2
  episodes_total: 92
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.447
    dispatch_time_ms: 10.408
    learner:
      cur_lr: 0.0013296969700604677
      grad_gnorm: 0.48345527052879333
      policy_entropy: 38.368770599365234
      policy_loss: 0.08123764395713806
      var_gnorm: 21.363300323486328
      vf_explained_var: -1.0
      vf_loss: 0.0001362473558401689
    num_steps_sampled: 460000
    num_steps_trained: 460000
    wait_time_ms: 74.296
  iterations_since_restore: 92
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 810.5032420158386
  time_this_iter_s: 8.751255989074707
  time_total_s: 810.5032420158386
  timestamp: 1594849299
  timesteps_since_restore: 460000
  timesteps_this_iter: 5000
  timesteps_total: 460000
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 810 s, 92 iter, 460000 ts, -804 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-41-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -803.5018452492425
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 0
  episodes_total: 92
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.201
    dispatch_time_ms: 10.276
    learner:
      cur_lr: 0.0013293640222400427
      grad_gnorm: 2.578179359436035
      policy_entropy: 13.390512466430664
      policy_loss: -0.38326945900917053
      var_gnorm: 21.36487579345703
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.004852807614952326
    num_steps_sampled: 465000
    num_steps_trained: 465000
    wait_time_ms: 76.47
  iterations_since_restore: 93
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 819.2275350093842
  time_this_iter_s: 8.724292993545532
  time_total_s: 819.2275350093842
  timestamp: 1594849308
  timesteps_since_restore: 465000
  timesteps_this_iter: 5000
  timesteps_total: 465000
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 819 s, 93 iter, 465000 ts, -804 rew

agent-1: 39.19999999919744
agent-2: 43.19999999919744
agent-3: 41.19999999919743
agent-4: 37.199999999197445
agent-5: 37.199999999197445
Extrinsic Rewards:
4
8
6
2
2
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2909090909090909
20:20 Ratio: 4.0
Max-min Ratio: 4.0
agent-1: 36.19999999907839
agent-2: 41.19999999907841
agent-3: 41.19999999907841
agent-4: 37.19999999907839
agent-5: 42.19999999907839
Extrinsic Rewards:
1
6
6
2
7
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.2909090909090909
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-41-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -792.7330082035951
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 93
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.882
    dispatch_time_ms: 8.738
    learner:
      cur_lr: 0.0013290309580042958
      grad_gnorm: 40.0
      policy_entropy: 16.914783477783203
      policy_loss: 8.202461242675781
      var_gnorm: 21.364591598510742
      vf_explained_var: 0.054124295711517334
      vf_loss: 10.855452537536621
    num_steps_sampled: 470000
    num_steps_trained: 470000
    wait_time_ms: 76.439
  iterations_since_restore: 94
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 828.1087844371796
  time_this_iter_s: 8.88124942779541
  time_total_s: 828.1087844371796
  timestamp: 1594849317
  timesteps_since_restore: 470000
  timesteps_this_iter: 5000
  timesteps_total: 470000
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 828 s, 94 iter, 470000 ts, -793 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-42-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -782.1932953504142
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 1
  episodes_total: 94
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.516
    dispatch_time_ms: 5.921
    learner:
      cur_lr: 0.0013286980101838708
      grad_gnorm: 40.0
      policy_entropy: 33.53260040283203
      policy_loss: 7.545021057128906
      var_gnorm: 21.374492645263672
      vf_explained_var: 0.0
      vf_loss: 1.4522488117218018
    num_steps_sampled: 475000
    num_steps_trained: 475000
    wait_time_ms: 81.814
  iterations_since_restore: 95
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 836.7593936920166
  time_this_iter_s: 8.650609254837036
  time_total_s: 836.7593936920166
  timestamp: 1594849325
  timesteps_since_restore: 475000
  timesteps_this_iter: 5000
  timesteps_total: 475000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 836 s, 95 iter, 475000 ts, -782 rew

agent-1: 167.79998671445674
agent-2: 166.79998671445676
agent-3: 165.79998671445676
agent-4: 170.7999867144568
agent-5: 165.7999867144567
Extrinsic Rewards:
19
18
17
22
17
Sum Reward: 93
Avg Reward: 18.6
Min Reward: 17
Max Reward: 22
Gini Coefficient: 0.05161290322580645
20:20 Ratio: 1.2941176470588236
Max-min Ratio: 1.2941176470588236
agent-1: 34.5999999988766
agent-2: 34.5999999988766
agent-3: 37.59999999887662
agent-4: 39.599999998876626
agent-5: 42.5999999988766
Extrinsic Rewards:
1
1
4
6
9
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-42-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -755.2101023892943
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 2
  episodes_total: 96
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.22
    dispatch_time_ms: 9.455
    learner:
      cur_lr: 0.001328364945948124
      grad_gnorm: 40.0
      policy_entropy: 29.642009735107422
      policy_loss: 20.531963348388672
      var_gnorm: 21.367996215820312
      vf_explained_var: 0.036041200160980225
      vf_loss: 40.51433181762695
    num_steps_sampled: 480000
    num_steps_trained: 480000
    wait_time_ms: 74.289
  iterations_since_restore: 96
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 845.5611312389374
  time_this_iter_s: 8.801737546920776
  time_total_s: 845.5611312389374
  timestamp: 1594849334
  timesteps_since_restore: 480000
  timesteps_this_iter: 5000
  timesteps_total: 480000
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 845 s, 96 iter, 480000 ts, -755 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-42-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -755.2101023892943
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 0
  episodes_total: 96
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.639
    dispatch_time_ms: 10.173
    learner:
      cur_lr: 0.001328031998127699
      grad_gnorm: 40.0
      policy_entropy: 8.588637351989746
      policy_loss: 4.650607585906982
      var_gnorm: 21.393348693847656
      vf_explained_var: 0.0
      vf_loss: 5.065464496612549
    num_steps_sampled: 485000
    num_steps_trained: 485000
    wait_time_ms: 73.838
  iterations_since_restore: 97
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 854.2500519752502
  time_this_iter_s: 8.688920736312866
  time_total_s: 854.2500519752502
  timestamp: 1594849343
  timesteps_since_restore: 485000
  timesteps_this_iter: 5000
  timesteps_total: 485000
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 854 s, 97 iter, 485000 ts, -755 rew

agent-1: 157.3369197167083
agent-2: 153.3369197167083
agent-3: 155.33691971670825
agent-4: 163.33691971670825
agent-5: 171.33691971670825
Extrinsic Rewards:
15
11
13
21
29
Sum Reward: 89
Avg Reward: 17.8
Min Reward: 11
Max Reward: 29
Gini Coefficient: 0.19775280898876405
20:20 Ratio: 2.6363636363636362
Max-min Ratio: 2.6363636363636362
agent-1: 75.59999987339698
agent-2: 89.59999987339701
agent-3: 85.59999987339704
agent-4: 81.59999987339701
agent-5: 81.59999987339701
Extrinsic Rewards:
2
16
12
8
8
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.2782608695652174
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-42-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -727.4029105247115
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 2
  episodes_total: 98
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.808
    dispatch_time_ms: 7.4
    learner:
      cur_lr: 0.0013276990503072739
      grad_gnorm: 40.000003814697266
      policy_entropy: 36.72383117675781
      policy_loss: -160.11778259277344
      var_gnorm: 21.371793746948242
      vf_explained_var: 1.0
      vf_loss: 208.61624145507812
    num_steps_sampled: 490000
    num_steps_trained: 490000
    wait_time_ms: 80.246
  iterations_since_restore: 98
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 863.0178589820862
  time_this_iter_s: 8.767807006835938
  time_total_s: 863.0178589820862
  timestamp: 1594849352
  timesteps_since_restore: 490000
  timesteps_this_iter: 5000
  timesteps_total: 490000
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 863 s, 98 iter, 490000 ts, -727 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-42-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -727.4029105247115
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 0
  episodes_total: 98
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.426
    dispatch_time_ms: 10.032
    learner:
      cur_lr: 0.001327365986071527
      grad_gnorm: 17.77819061279297
      policy_entropy: 65.46232604980469
      policy_loss: -6.731658935546875
      var_gnorm: 21.37554168701172
      vf_explained_var: 0.0
      vf_loss: 0.17618390917778015
    num_steps_sampled: 495000
    num_steps_trained: 495000
    wait_time_ms: 75.134
  iterations_since_restore: 99
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 871.729097366333
  time_this_iter_s: 8.711238384246826
  time_total_s: 871.729097366333
  timestamp: 1594849361
  timesteps_since_restore: 495000
  timesteps_this_iter: 5000
  timesteps_total: 495000
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 871 s, 99 iter, 495000 ts, -727 rew

agent-1: 51.39999999660229
agent-2: 55.39999999660229
agent-3: 54.39999999660228
agent-4: 52.39999999660229
agent-5: 47.39999999660227
Extrinsic Rewards:
5
9
8
6
1
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.2620689655172414
20:20 Ratio: 9.0
Max-min Ratio: 9.0
agent-1: 47.39999999453284
agent-2: 53.39999999453284
agent-3: 51.39999999453284
agent-4: 54.39999999453284
agent-5: 54.39999999453284
Extrinsic Rewards:
1
7
5
8
8
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.23448275862068965
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-42-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -707.6348523146605
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 2
  episodes_total: 100
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.946
    dispatch_time_ms: 11.883
    learner:
      cur_lr: 0.001327033038251102
      grad_gnorm: 39.99999237060547
      policy_entropy: 61.46297073364258
      policy_loss: 87.04866027832031
      var_gnorm: 21.38063621520996
      vf_explained_var: 0.009021520614624023
      vf_loss: 80.6618881225586
    num_steps_sampled: 500000
    num_steps_trained: 500000
    wait_time_ms: 72.986
  iterations_since_restore: 100
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 880.4834747314453
  time_this_iter_s: 8.754377365112305
  time_total_s: 880.4834747314453
  timestamp: 1594849369
  timesteps_since_restore: 500000
  timesteps_this_iter: 5000
  timesteps_total: 500000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 880 s, 100 iter, 500000 ts, -708 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-42-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -707.6348523146604
  episode_reward_min: -45904.12745793646
  episodes_this_iter: 0
  episodes_total: 100
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.161
    dispatch_time_ms: 7.573
    learner:
      cur_lr: 0.0013266999740153551
      grad_gnorm: 40.0
      policy_entropy: 32.660911560058594
      policy_loss: 68.41400909423828
      var_gnorm: 21.391586303710938
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 105.88623809814453
    num_steps_sampled: 505000
    num_steps_trained: 505000
    wait_time_ms: 77.561
  iterations_since_restore: 101
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 889.1231775283813
  time_this_iter_s: 8.639702796936035
  time_total_s: 889.1231775283813
  timestamp: 1594849378
  timesteps_since_restore: 505000
  timesteps_this_iter: 5000
  timesteps_total: 505000
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 889 s, 101 iter, 505000 ts, -708 rew

agent-1: 159.59862634185964
agent-2: 160.59862634185967
agent-3: 164.59862634185964
agent-4: 148.59862634185967
agent-5: 140.59862634185967
Extrinsic Rewards:
22
23
27
11
3
Sum Reward: 86
Avg Reward: 17.2
Min Reward: 3
Max Reward: 27
Gini Coefficient: 0.27906976744186046
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-43-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: -240.85364641820286
  episode_reward_min: -41076.40387095732
  episodes_this_iter: 1
  episodes_total: 101
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.493
    dispatch_time_ms: 10.593
    learner:
      cur_lr: 0.00132636702619493
      grad_gnorm: 5.5347981452941895
      policy_entropy: 48.55193328857422
      policy_loss: -1.1217663288116455
      var_gnorm: 21.380338668823242
      vf_explained_var: 0.0
      vf_loss: 0.018125005066394806
    num_steps_sampled: 510000
    num_steps_trained: 510000
    wait_time_ms: 72.399
  iterations_since_restore: 102
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 897.7905750274658
  time_this_iter_s: 8.667397499084473
  time_total_s: 897.7905750274658
  timestamp: 1594849387
  timesteps_since_restore: 510000
  timesteps_this_iter: 5000
  timesteps_total: 510000
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 897 s, 102 iter, 510000 ts, -241 rew

agent-1: 38.39999999923304
agent-2: 34.39999999923303
agent-3: 32.399999999233
agent-4: 34.39999999923303
agent-5: 31.399999999233106
Extrinsic Rewards:
8
4
2
4
1
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.3368421052631579
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-43-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 171.6203922913321
  episode_reward_min: -5570.999664771621
  episodes_this_iter: 1
  episodes_total: 102
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.304
    dispatch_time_ms: 11.136
    learner:
      cur_lr: 0.0013260339619591832
      grad_gnorm: 18.400989532470703
      policy_entropy: 44.4273567199707
      policy_loss: -4.7576704025268555
      var_gnorm: 21.3834228515625
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.24845939874649048
    num_steps_sampled: 515000
    num_steps_trained: 515000
    wait_time_ms: 73.465
  iterations_since_restore: 103
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 906.5564613342285
  time_this_iter_s: 8.765886306762695
  time_total_s: 906.5564613342285
  timestamp: 1594849396
  timesteps_since_restore: 515000
  timesteps_this_iter: 5000
  timesteps_total: 515000
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 906 s, 103 iter, 515000 ts, 172 rew

agent-1: 49.999999997241574
agent-2: 51.999999997241574
agent-3: 56.999999997241574
agent-4: 51.999999997241574
agent-5: 58.999999997241574
Extrinsic Rewards:
2
4
9
4
11
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.30666666666666664
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-43-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 197.8658134009979
  episode_reward_min: -5570.999664771621
  episodes_this_iter: 1
  episodes_total: 103
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 7.489
    learner:
      cur_lr: 0.0013257010141387582
      grad_gnorm: 0.10436466336250305
      policy_entropy: 40.21010971069336
      policy_loss: 0.029933638870716095
      var_gnorm: 21.38262176513672
      vf_explained_var: 0.0
      vf_loss: 7.680702765355818e-06
    num_steps_sampled: 520000
    num_steps_trained: 520000
    wait_time_ms: 75.888
  iterations_since_restore: 104
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 915.2558958530426
  time_this_iter_s: 8.699434518814087
  time_total_s: 915.2558958530426
  timestamp: 1594849404
  timesteps_since_restore: 520000
  timesteps_this_iter: 5000
  timesteps_total: 520000
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 915 s, 104 iter, 520000 ts, 198 rew

agent-1: 83.79999997142203
agent-2: 69.79999997142203
agent-3: 78.799999971422
agent-4: 69.79999997142203
agent-5: 84.79999997142203
Extrinsic Rewards:
15
1
10
1
16
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 1
Max Reward: 16
Gini Coefficient: 0.40930232558139534
20:20 Ratio: 16.0
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-43-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 247.26585903480088
  episode_reward_min: -5570.999664771621
  episodes_this_iter: 1
  episodes_total: 104
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.875
    dispatch_time_ms: 11.044
    learner:
      cur_lr: 0.0013253679499030113
      grad_gnorm: 6.838367462158203
      policy_entropy: 26.261783599853516
      policy_loss: -1.909447193145752
      var_gnorm: 21.383460998535156
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.02828085608780384
    num_steps_sampled: 525000
    num_steps_trained: 525000
    wait_time_ms: 75.274
  iterations_since_restore: 105
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 923.9468817710876
  time_this_iter_s: 8.690985918045044
  time_total_s: 923.9468817710876
  timestamp: 1594849413
  timesteps_since_restore: 525000
  timesteps_this_iter: 5000
  timesteps_total: 525000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 923 s, 105 iter, 525000 ts, 247 rew

agent-1: 31.399999998597348
agent-2: 37.399999998597416
agent-3: 34.399999998597416
agent-4: 34.39999999859742
agent-5: 33.39999999859743
Extrinsic Rewards:
1
7
4
4
3
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.2736842105263158
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-43-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 274.3480024976583
  episode_reward_min: -5570.999664771621
  episodes_this_iter: 1
  episodes_total: 105
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.833
    dispatch_time_ms: 7.477
    learner:
      cur_lr: 0.0013250350020825863
      grad_gnorm: 0.10888860374689102
      policy_entropy: 27.995391845703125
      policy_loss: 0.005177555605769157
      var_gnorm: 21.383068084716797
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.2913462771612103e-07
    num_steps_sampled: 530000
    num_steps_trained: 530000
    wait_time_ms: 80.719
  iterations_since_restore: 106
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 932.6731758117676
  time_this_iter_s: 8.726294040679932
  time_total_s: 932.6731758117676
  timestamp: 1594849422
  timesteps_since_restore: 530000
  timesteps_this_iter: 5000
  timesteps_total: 530000
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 932 s, 106 iter, 530000 ts, 274 rew

agent-1: 59.99999999673654
agent-2: 48.99999999673653
agent-3: 54.99999999673654
agent-4: 56.99999999673654
agent-5: 48.99999999673653
Extrinsic Rewards:
12
1
7
9
1
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.4
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-43-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 332.7579991452114
  episode_reward_min: -1168.8790170366572
  episodes_this_iter: 1
  episodes_total: 106
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.899
    dispatch_time_ms: 9.256
    learner:
      cur_lr: 0.0013247020542621613
      grad_gnorm: 12.776077270507812
      policy_entropy: 40.640804290771484
      policy_loss: -3.0095057487487793
      var_gnorm: 21.38333511352539
      vf_explained_var: 0.0
      vf_loss: 0.11583361029624939
    num_steps_sampled: 535000
    num_steps_trained: 535000
    wait_time_ms: 76.078
  iterations_since_restore: 107
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 941.2880346775055
  time_this_iter_s: 8.614858865737915
  time_total_s: 941.2880346775055
  timestamp: 1594849430
  timesteps_since_restore: 535000
  timesteps_this_iter: 5000
  timesteps_total: 535000
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 941 s, 107 iter, 535000 ts, 333 rew

agent-1: 36.39999998895919
agent-2: 34.39999998895917
agent-3: 34.39999998895917
agent-4: 30.399999988959184
agent-5: 35.39999998895917
Extrinsic Rewards:
6
4
4
0
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.2736842105263158
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-43-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 342.207438558047
  episode_reward_min: -1168.8790170366572
  episodes_this_iter: 1
  episodes_total: 107
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.83
    dispatch_time_ms: 10.034
    learner:
      cur_lr: 0.0013243689900264144
      grad_gnorm: 0.0994710922241211
      policy_entropy: 38.608333587646484
      policy_loss: 0.016331955790519714
      var_gnorm: 21.383195877075195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.014565552599379e-06
    num_steps_sampled: 540000
    num_steps_trained: 540000
    wait_time_ms: 73.327
  iterations_since_restore: 108
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 949.9382665157318
  time_this_iter_s: 8.650231838226318
  time_total_s: 949.9382665157318
  timestamp: 1594849439
  timesteps_since_restore: 540000
  timesteps_this_iter: 5000
  timesteps_total: 540000
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 949 s, 108 iter, 540000 ts, 342 rew

agent-1: 40.39999999361571
agent-2: 44.39999999361572
agent-3: 39.399999993615715
agent-4: 42.39999999361572
agent-5: 49.39999999361571
Extrinsic Rewards:
2
6
1
4
11
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.4
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-44-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 356.05622872809437
  episode_reward_min: -214.9364819952554
  episodes_this_iter: 1
  episodes_total: 108
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.282
    dispatch_time_ms: 6.781
    learner:
      cur_lr: 0.0013240360422059894
      grad_gnorm: 40.0
      policy_entropy: 36.428855895996094
      policy_loss: 42.846038818359375
      var_gnorm: 21.402446746826172
      vf_explained_var: 0.0
      vf_loss: 39.89653396606445
    num_steps_sampled: 545000
    num_steps_trained: 545000
    wait_time_ms: 69.147
  iterations_since_restore: 109
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 958.3515932559967
  time_this_iter_s: 8.413326740264893
  time_total_s: 958.3515932559967
  timestamp: 1594849448
  timesteps_since_restore: 545000
  timesteps_this_iter: 5000
  timesteps_total: 545000
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 958 s, 109 iter, 545000 ts, 356 rew

agent-1: 165.5995531581328
agent-2: 149.59955315813298
agent-3: 158.59955315813284
agent-4: 150.59955315813292
agent-5: 149.59955315813295
Extrinsic Rewards:
28
12
21
13
12
Sum Reward: 86
Avg Reward: 17.2
Min Reward: 12
Max Reward: 28
Gini Coefficient: 0.19069767441860466
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-44-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 365.472205247281
  episode_reward_min: -214.9364819952554
  episodes_this_iter: 1
  episodes_total: 109
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.431
    dispatch_time_ms: 11.054
    learner:
      cur_lr: 0.0013237029779702425
      grad_gnorm: 40.000003814697266
      policy_entropy: 41.64934158325195
      policy_loss: 45.40210723876953
      var_gnorm: 21.389366149902344
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 30.481483459472656
    num_steps_sampled: 550000
    num_steps_trained: 550000
    wait_time_ms: 72.299
  iterations_since_restore: 110
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 967.1031415462494
  time_this_iter_s: 8.751548290252686
  time_total_s: 967.1031415462494
  timestamp: 1594849456
  timesteps_since_restore: 550000
  timesteps_this_iter: 5000
  timesteps_total: 550000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 967 s, 110 iter, 550000 ts, 365 rew

agent-1: 104.7996531454596
agent-2: 91.79965314545966
agent-3: 96.79965314545966
agent-4: 89.79965314545967
agent-5: 93.79965314545967
Extrinsic Rewards:
20
7
12
5
9
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 5
Max Reward: 20
Gini Coefficient: 0.2641509433962264
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-44-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 367.36218790490574
  episode_reward_min: -214.9364819952554
  episodes_this_iter: 1
  episodes_total: 110
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.218
    dispatch_time_ms: 8.946
    learner:
      cur_lr: 0.0013233700301498175
      grad_gnorm: 39.999996185302734
      policy_entropy: 51.56459426879883
      policy_loss: -14.411739349365234
      var_gnorm: 21.395492553710938
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.2843246459960938
    num_steps_sampled: 555000
    num_steps_trained: 555000
    wait_time_ms: 74.049
  iterations_since_restore: 111
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 975.6877081394196
  time_this_iter_s: 8.584566593170166
  time_total_s: 975.6877081394196
  timestamp: 1594849465
  timesteps_since_restore: 555000
  timesteps_this_iter: 5000
  timesteps_total: 555000
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 975 s, 111 iter, 555000 ts, 367 rew

agent-1: 49.59999998201821
agent-2: 57.59999998201823
agent-3: 58.59999998201822
agent-4: 54.59999998201822
agent-5: 58.59999998201823
Extrinsic Rewards:
0
8
9
5
9
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.2838709677419355
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 59.99999993264598
agent-2: 69.99999993264609
agent-3: 57.99999993264598
agent-4: 59.99999993264596
agent-5: 66.99999993264608
Extrinsic Rewards:
4
14
2
4
11
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.35428571428571426
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-44-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 372.3015527239593
  episode_reward_min: -152.9870114526401
  episodes_this_iter: 1
  episodes_total: 111
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.769
    dispatch_time_ms: 14.587
    learner:
      cur_lr: 0.0013230369659140706
      grad_gnorm: 0.08079729229211807
      policy_entropy: 12.277127265930176
      policy_loss: -0.0024158835876733065
      var_gnorm: 21.387001037597656
      vf_explained_var: 0.0
      vf_loss: 1.6736877341827494e-06
    num_steps_sampled: 560000
    num_steps_trained: 560000
    wait_time_ms: 53.86
  iterations_since_restore: 112
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 986.3032178878784
  time_this_iter_s: 10.615509748458862
  time_total_s: 986.3032178878784
  timestamp: 1594849476
  timesteps_since_restore: 560000
  timesteps_this_iter: 5000
  timesteps_total: 560000
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 986 s, 112 iter, 560000 ts, 372 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-44-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 372.66137357631754
  episode_reward_min: -152.9870114526401
  episodes_this_iter: 1
  episodes_total: 112
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.931
    dispatch_time_ms: 11.482
    learner:
      cur_lr: 0.0013227040180936456
      grad_gnorm: 40.000003814697266
      policy_entropy: 33.95852279663086
      policy_loss: 25.18255615234375
      var_gnorm: 21.40963363647461
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 23.959672927856445
    num_steps_sampled: 565000
    num_steps_trained: 565000
    wait_time_ms: 76.42
  iterations_since_restore: 113
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 994.5683343410492
  time_this_iter_s: 8.265116453170776
  time_total_s: 994.5683343410492
  timestamp: 1594849484
  timesteps_since_restore: 565000
  timesteps_this_iter: 5000
  timesteps_total: 565000
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 994 s, 113 iter, 565000 ts, 373 rew

agent-1: 102.99996675600073
agent-2: 107.99996675600073
agent-3: 110.99996675600073
agent-4: 110.99996675600073
agent-5: 106.99996675600076
Extrinsic Rewards:
7
12
15
15
11
Sum Reward: 60
Avg Reward: 12.0
Min Reward: 7
Max Reward: 15
Gini Coefficient: 0.13333333333333333
20:20 Ratio: 2.142857142857143
Max-min Ratio: 2.142857142857143
agent-1: 72.1999997719819
agent-2: 66.19999977198187
agent-3: 67.19999977198187
agent-4: 61.19999977198189
agent-5: 66.1999997719819
Extrinsic Rewards:
13
7
8
2
7
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.24864864864864866
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-44-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 381.57124201725986
  episode_reward_min: 60.518156321701646
  episodes_this_iter: 2
  episodes_total: 114
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.397
    dispatch_time_ms: 13.012
    learner:
      cur_lr: 0.0013223709538578987
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.389582633972168
      policy_loss: -4.062355041503906
      var_gnorm: 21.386577606201172
      vf_explained_var: -0.47171199321746826
      vf_loss: 1.4583940505981445
    num_steps_sampled: 570000
    num_steps_trained: 570000
    wait_time_ms: 72.23
  iterations_since_restore: 114
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1003.5498163700104
  time_this_iter_s: 8.981482028961182
  time_total_s: 1003.5498163700104
  timestamp: 1594849493
  timesteps_since_restore: 570000
  timesteps_this_iter: 5000
  timesteps_total: 570000
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1003 s, 114 iter, 570000 ts, 382 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-45-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 381.57124201725986
  episode_reward_min: 60.518156321701646
  episodes_this_iter: 0
  episodes_total: 114
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.986
    dispatch_time_ms: 13.655
    learner:
      cur_lr: 0.0013220380060374737
      grad_gnorm: 40.0
      policy_entropy: 39.42960739135742
      policy_loss: 17.47565269470215
      var_gnorm: 21.410236358642578
      vf_explained_var: 0.0
      vf_loss: 5.557525157928467
    num_steps_sampled: 575000
    num_steps_trained: 575000
    wait_time_ms: 72.052
  iterations_since_restore: 115
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1011.9060089588165
  time_this_iter_s: 8.356192588806152
  time_total_s: 1011.9060089588165
  timestamp: 1594849502
  timesteps_since_restore: 575000
  timesteps_this_iter: 5000
  timesteps_total: 575000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1011 s, 115 iter, 575000 ts, 382 rew

agent-1: 96.7993514228851
agent-2: 88.7993514228851
agent-3: 90.79935142288505
agent-4: 100.79935142288498
agent-5: 99.79935142288501
Extrinsic Rewards:
12
4
6
16
15
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 4
Max Reward: 16
Gini Coefficient: 0.2490566037735849
20:20 Ratio: 4.0
Max-min Ratio: 4.0
agent-1: 75.79991393380234
agent-2: 69.79991393380242
agent-3: 81.79991393380233
agent-4: 77.79991393380234
agent-5: 81.79991393380234
Extrinsic Rewards:
7
1
13
9
13
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.27906976744186046
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-45-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 382.38120604830453
  episode_reward_min: 60.518156321701646
  episodes_this_iter: 2
  episodes_total: 116
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 10.013
    learner:
      cur_lr: 0.0013217049418017268
      grad_gnorm: 40.0
      policy_entropy: 38.55168914794922
      policy_loss: -165.7468719482422
      var_gnorm: 21.399431228637695
      vf_explained_var: 0.007127165794372559
      vf_loss: 474.3138732910156
    num_steps_sampled: 580000
    num_steps_trained: 580000
    wait_time_ms: 78.295
  iterations_since_restore: 116
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1020.8325145244598
  time_this_iter_s: 8.92650556564331
  time_total_s: 1020.8325145244598
  timestamp: 1594849511
  timesteps_since_restore: 580000
  timesteps_this_iter: 5000
  timesteps_total: 580000
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1020 s, 116 iter, 580000 ts, 382 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-45-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 382.38120604830465
  episode_reward_min: 60.518156321701646
  episodes_this_iter: 0
  episodes_total: 116
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.931
    dispatch_time_ms: 10.761
    learner:
      cur_lr: 0.0013213719939813018
      grad_gnorm: 31.236915588378906
      policy_entropy: 23.202560424804688
      policy_loss: 4.445628643035889
      var_gnorm: 21.405803680419922
      vf_explained_var: 0.0
      vf_loss: 4.238468170166016
    num_steps_sampled: 585000
    num_steps_trained: 585000
    wait_time_ms: 70.732
  iterations_since_restore: 117
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1029.4035387039185
  time_this_iter_s: 8.571024179458618
  time_total_s: 1029.4035387039185
  timestamp: 1594849519
  timesteps_since_restore: 585000
  timesteps_this_iter: 5000
  timesteps_total: 585000
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1029 s, 117 iter, 585000 ts, 382 rew

agent-1: 60.30077424254341
agent-2: 63.30077424254344
agent-3: 61.30077424254344
agent-4: 62.300774242543426
agent-5: 60.300774242543426
Extrinsic Rewards:
6
9
7
8
6
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 6
Max Reward: 9
Gini Coefficient: 0.08888888888888889
20:20 Ratio: 1.5
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-45-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 379.3555948995686
  episode_reward_min: 60.518156321701646
  episodes_this_iter: 1
  episodes_total: 117
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.87
    dispatch_time_ms: 16.766
    learner:
      cur_lr: 0.0013210390461608768
      grad_gnorm: 40.0
      policy_entropy: 24.796714782714844
      policy_loss: 8.230626106262207
      var_gnorm: 21.409963607788086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.7332839965820312
    num_steps_sampled: 590000
    num_steps_trained: 590000
    wait_time_ms: 69.843
  iterations_since_restore: 118
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1037.422604084015
  time_this_iter_s: 8.019065380096436
  time_total_s: 1037.422604084015
  timestamp: 1594849529
  timesteps_since_restore: 590000
  timesteps_this_iter: 5000
  timesteps_total: 590000
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1037 s, 118 iter, 590000 ts, 379 rew

agent-1: 49.76792475414479
agent-2: 48.767924754144794
agent-3: 50.767924754144794
agent-4: 51.76792475414481
agent-5: 44.767924754144794
Extrinsic Rewards:
7
6
8
9
2
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-45-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 376.1491482112532
  episode_reward_min: 60.518156321701646
  episodes_this_iter: 1
  episodes_total: 118
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 12.674
    learner:
      cur_lr: 0.0013207059819251299
      grad_gnorm: 39.999996185302734
      policy_entropy: 48.940059661865234
      policy_loss: -24.09014129638672
      var_gnorm: 21.43824577331543
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 8.269073486328125
    num_steps_sampled: 595000
    num_steps_trained: 595000
    wait_time_ms: 69.124
  iterations_since_restore: 119
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1046.2239379882812
  time_this_iter_s: 8.801333904266357
  time_total_s: 1046.2239379882812
  timestamp: 1594849537
  timesteps_since_restore: 595000
  timesteps_this_iter: 5000
  timesteps_total: 595000
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1046 s, 119 iter, 595000 ts, 376 rew

agent-1: 66.19999884359868
agent-2: 65.19999884359868
agent-3: 67.19999884359865
agent-4: 63.19999884359886
agent-5: 71.1999988435986
Extrinsic Rewards:
7
6
8
4
12
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.1945945945945946
20:20 Ratio: 3.0
Max-min Ratio: 3.0
agent-1: 97.79999837211572
agent-2: 94.79999837211572
agent-3: 89.79999837211575
agent-4: 90.79999837211572
agent-5: 103.79999837211571
Extrinsic Rewards:
13
10
5
6
19
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 5
Max Reward: 19
Gini Coefficient: 0.2641509433962264
20:20 Ratio: 3.8
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-45-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 377.67914807864014
  episode_reward_min: 60.518156321701646
  episodes_this_iter: 2
  episodes_total: 120
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.96
    dispatch_time_ms: 14.055
    learner:
      cur_lr: 0.0013203730341047049
      grad_gnorm: 40.0
      policy_entropy: 2.0584888458251953
      policy_loss: -0.17779581248760223
      var_gnorm: 21.409412384033203
      vf_explained_var: -0.11298084259033203
      vf_loss: 9.04305362701416
    num_steps_sampled: 600000
    num_steps_trained: 600000
    wait_time_ms: 74.959
  iterations_since_restore: 120
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1055.2577373981476
  time_this_iter_s: 9.033799409866333
  time_total_s: 1055.2577373981476
  timestamp: 1594849546
  timesteps_since_restore: 600000
  timesteps_this_iter: 5000
  timesteps_total: 600000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1055 s, 120 iter, 600000 ts, 378 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-45-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 377.67914807864014
  episode_reward_min: 60.518156321701646
  episodes_this_iter: 0
  episodes_total: 120
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.502
    dispatch_time_ms: 13.211
    learner:
      cur_lr: 0.001320039969868958
      grad_gnorm: 2.546543598175049
      policy_entropy: 2.566635847091675
      policy_loss: -0.003219952341169119
      var_gnorm: 21.409122467041016
      vf_explained_var: 0.0
      vf_loss: 0.004417295567691326
    num_steps_sampled: 605000
    num_steps_trained: 605000
    wait_time_ms: 75.159
  iterations_since_restore: 121
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1063.597352027893
  time_this_iter_s: 8.339614629745483
  time_total_s: 1063.597352027893
  timestamp: 1594849555
  timesteps_since_restore: 605000
  timesteps_this_iter: 5000
  timesteps_total: 605000
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1063 s, 121 iter, 605000 ts, 378 rew

agent-1: 63.12461997960969
agent-2: 73.12461997960972
agent-3: 58.12461997960964
agent-4: 62.124619979609676
agent-5: 60.12461997960967
Extrinsic Rewards:
8
18
3
7
5
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 3
Max Reward: 18
Gini Coefficient: 0.32195121951219513
20:20 Ratio: 6.0
Max-min Ratio: 6.0
agent-1: 52.62981643166293
agent-2: 48.62981643166292
agent-3: 57.629816431662945
agent-4: 50.62981643166294
agent-5: 54.62981643166298
Extrinsic Rewards:
6
2
11
4
8
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.2838709677419355
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-46-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 375.11687011675735
  episode_reward_min: 60.518156321701646
  episodes_this_iter: 2
  episodes_total: 122
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.737
    dispatch_time_ms: 25.11
    learner:
      cur_lr: 0.001319707022048533
      grad_gnorm: 40.0
      policy_entropy: 16.809127807617188
      policy_loss: -81.6889877319336
      var_gnorm: 21.41547393798828
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 692.371337890625
    num_steps_sampled: 610000
    num_steps_trained: 610000
    wait_time_ms: 65.586
  iterations_since_restore: 122
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1078.170396566391
  time_this_iter_s: 14.573044538497925
  time_total_s: 1078.170396566391
  timestamp: 1594849570
  timesteps_since_restore: 610000
  timesteps_this_iter: 5000
  timesteps_total: 610000
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1078 s, 122 iter, 610000 ts, 375 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-46-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 375.1168701167573
  episode_reward_min: 60.518156321701646
  episodes_this_iter: 0
  episodes_total: 122
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.569
    dispatch_time_ms: 36.594
    learner:
      cur_lr: 0.001319373957812786
      grad_gnorm: 40.0
      policy_entropy: 39.783321380615234
      policy_loss: -21.217636108398438
      var_gnorm: 21.43706703186035
      vf_explained_var: 0.0
      vf_loss: 8.390563011169434
    num_steps_sampled: 615000
    num_steps_trained: 615000
    wait_time_ms: 54.173
  iterations_since_restore: 123
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1087.161792755127
  time_this_iter_s: 8.991396188735962
  time_total_s: 1087.161792755127
  timestamp: 1594849579
  timesteps_since_restore: 615000
  timesteps_this_iter: 5000
  timesteps_total: 615000
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1087 s, 123 iter, 615000 ts, 375 rew

agent-1: 68.39999998556978
agent-2: 69.3999999855698
agent-3: 68.39999998556978
agent-4: 72.3999999855698
agent-5: 72.3999999855698
Extrinsic Rewards:
6
7
6
10
10
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 6
Max Reward: 10
Gini Coefficient: 0.12307692307692308
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
agent-1: 106.59999911518752
agent-2: 113.59999911518746
agent-3: 106.59999911518752
agent-4: 115.59999911518749
agent-5: 106.59999911518752
Extrinsic Rewards:
9
16
9
18
9
Sum Reward: 61
Avg Reward: 12.2
Min Reward: 9
Max Reward: 18
Gini Coefficient: 0.16393442622950818
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-46-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 367.3782465006387
  episode_reward_min: 60.518156321701646
  episodes_this_iter: 2
  episodes_total: 124
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.812
    dispatch_time_ms: 22.092
    learner:
      cur_lr: 0.001319041009992361
      grad_gnorm: 5.717776775360107
      policy_entropy: 1.1443828344345093
      policy_loss: -0.009642145596444607
      var_gnorm: 21.412343978881836
      vf_explained_var: -1.0
      vf_loss: 0.03347349166870117
    num_steps_sampled: 620000
    num_steps_trained: 620000
    wait_time_ms: 59.887
  iterations_since_restore: 124
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1096.0896031856537
  time_this_iter_s: 8.927810430526733
  time_total_s: 1096.0896031856537
  timestamp: 1594849588
  timesteps_since_restore: 620000
  timesteps_this_iter: 5000
  timesteps_total: 620000
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1096 s, 124 iter, 620000 ts, 367 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-46-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 367.3782465006386
  episode_reward_min: 60.518156321701646
  episodes_this_iter: 0
  episodes_total: 124
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.224
    dispatch_time_ms: 34.265
    learner:
      cur_lr: 0.0013187079457566142
      grad_gnorm: 17.578840255737305
      policy_entropy: 1.6058844327926636
      policy_loss: -0.004297913052141666
      var_gnorm: 21.410816192626953
      vf_explained_var: 0.0
      vf_loss: 0.1841421276330948
    num_steps_sampled: 625000
    num_steps_trained: 625000
    wait_time_ms: 45.826
  iterations_since_restore: 125
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1104.4615700244904
  time_this_iter_s: 8.37196683883667
  time_total_s: 1104.4615700244904
  timestamp: 1594849596
  timesteps_since_restore: 625000
  timesteps_this_iter: 5000
  timesteps_total: 625000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1104 s, 125 iter, 625000 ts, 367 rew

agent-1: 13.000480248315984
agent-2: 12.000480248315982
agent-3: 14.000480248315979
agent-4: 11.000480248315979
agent-5: 10.00048024831598
Extrinsic Rewards:
3
2
4
1
0
Sum Reward: 10
Avg Reward: 2.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-46-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 365.4582705132977
  episode_reward_min: 60.00240124157989
  episodes_this_iter: 1
  episodes_total: 125
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 37.211
    learner:
      cur_lr: 0.0013183749979361892
      grad_gnorm: 40.0
      policy_entropy: 37.378753662109375
      policy_loss: 17.606168746948242
      var_gnorm: 21.412748336791992
      vf_explained_var: 0.0
      vf_loss: 10.4374361038208
    num_steps_sampled: 630000
    num_steps_trained: 630000
    wait_time_ms: 45.64
  iterations_since_restore: 126
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1113.081594467163
  time_this_iter_s: 8.62002444267273
  time_total_s: 1113.081594467163
  timestamp: 1594849605
  timesteps_since_restore: 630000
  timesteps_this_iter: 5000
  timesteps_total: 630000
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1113 s, 126 iter, 630000 ts, 365 rew

agent-1: 42.295047215145345
agent-2: 40.29504721514537
agent-3: 37.29504721514536
agent-4: 50.295047215145324
agent-5: 43.29504721514537
Extrinsic Rewards:
5
3
0
13
6
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.42962962962962964
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-46-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 364.8930228744325
  episode_reward_min: 60.00240124157989
  episodes_this_iter: 1
  episodes_total: 126
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.26
    dispatch_time_ms: 34.062
    learner:
      cur_lr: 0.0013180420501157641
      grad_gnorm: 25.695728302001953
      policy_entropy: 0.8271859288215637
      policy_loss: -0.02196570113301277
      var_gnorm: 21.423221588134766
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.489959716796875
    num_steps_sampled: 635000
    num_steps_trained: 635000
    wait_time_ms: 55.775
  iterations_since_restore: 127
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1122.08367395401
  time_this_iter_s: 9.002079486846924
  time_total_s: 1122.08367395401
  timestamp: 1594849614
  timesteps_since_restore: 635000
  timesteps_this_iter: 5000
  timesteps_total: 635000
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1122 s, 127 iter, 635000 ts, 365 rew

agent-1: 53.1999999932838
agent-2: 46.19999999328377
agent-3: 52.1999999932838
agent-4: 45.19999999328377
agent-5: 46.19999999328377
Extrinsic Rewards:
10
3
9
2
3
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.32592592592592595
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-47-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 365.97302287411964
  episode_reward_min: 60.00240124157989
  episodes_this_iter: 1
  episodes_total: 127
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.301
    dispatch_time_ms: 29.795
    learner:
      cur_lr: 0.0013177089858800173
      grad_gnorm: 0.6965645551681519
      policy_entropy: 0.7935324311256409
      policy_loss: 0.0013057014439255
      var_gnorm: 21.421287536621094
      vf_explained_var: 0.0
      vf_loss: 0.00036002323031425476
    num_steps_sampled: 640000
    num_steps_trained: 640000
    wait_time_ms: 56.565
  iterations_since_restore: 128
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1131.2456369400024
  time_this_iter_s: 9.161962985992432
  time_total_s: 1131.2456369400024
  timestamp: 1594849623
  timesteps_since_restore: 640000
  timesteps_this_iter: 5000
  timesteps_total: 640000
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1131 s, 128 iter, 640000 ts, 366 rew

agent-1: 30.59999999934121
agent-2: 31.59999999934121
agent-3: 27.59999999934121
agent-4: 25.599999999341208
agent-5: 28.599999999341208
Extrinsic Rewards:
5
6
2
0
3
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.375
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-47-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 365.7030228741275
  episode_reward_min: 60.00240124157989
  episodes_this_iter: 1
  episodes_total: 128
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 28.235
    learner:
      cur_lr: 0.0013173760380595922
      grad_gnorm: 2.378852605819702
      policy_entropy: 0.853243887424469
      policy_loss: -0.0016758148558437824
      var_gnorm: 21.42137336730957
      vf_explained_var: 0.0
      vf_loss: 0.0041991714388132095
    num_steps_sampled: 645000
    num_steps_trained: 645000
    wait_time_ms: 60.744
  iterations_since_restore: 129
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1140.1244769096375
  time_this_iter_s: 8.87883996963501
  time_total_s: 1140.1244769096375
  timestamp: 1594849632
  timesteps_since_restore: 645000
  timesteps_this_iter: 5000
  timesteps_total: 645000
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1140 s, 129 iter, 645000 ts, 366 rew

agent-1: 4.79999999994895
agent-2: 4.79999999994895
agent-3: 7.79999999994895
agent-4: 4.79999999994895
agent-5: 4.79999999994895
Extrinsic Rewards:
0
0
3
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-47-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 363.093022874624
  episode_reward_min: 26.99999999974511
  episodes_this_iter: 1
  episodes_total: 129
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.232
    dispatch_time_ms: 31.38
    learner:
      cur_lr: 0.0013170429738238454
      grad_gnorm: 13.737810134887695
      policy_entropy: 0.8797199726104736
      policy_loss: -0.00024007449974305928
      var_gnorm: 21.421329498291016
      vf_explained_var: 2.384185791015625e-06
      vf_loss: 0.11101236939430237
    num_steps_sampled: 650000
    num_steps_trained: 650000
    wait_time_ms: 58.937
  iterations_since_restore: 130
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1149.016544342041
  time_this_iter_s: 8.892067432403564
  time_total_s: 1149.016544342041
  timestamp: 1594849641
  timesteps_since_restore: 650000
  timesteps_this_iter: 5000
  timesteps_total: 650000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1149 s, 130 iter, 650000 ts, 363 rew

agent-1: 11.199999999880434
agent-2: 12.199999999880436
agent-3: 14.199999999880434
agent-4: 14.199999999880434
agent-5: 11.199999999880434
Extrinsic Rewards:
0
1
3
3
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5142857142857142
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-47-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 362.37302287464183
  episode_reward_min: 26.99999999974511
  episodes_this_iter: 1
  episodes_total: 130
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.911
    dispatch_time_ms: 23.807
    learner:
      cur_lr: 0.0013167100260034204
      grad_gnorm: 5.662489891052246
      policy_entropy: 0.9044358134269714
      policy_loss: -0.003600146621465683
      var_gnorm: 21.420486450195312
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.023794008418917656
    num_steps_sampled: 655000
    num_steps_trained: 655000
    wait_time_ms: 59.73
  iterations_since_restore: 131
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1157.7788071632385
  time_this_iter_s: 8.76226282119751
  time_total_s: 1157.7788071632385
  timestamp: 1594849650
  timesteps_since_restore: 655000
  timesteps_this_iter: 5000
  timesteps_total: 655000
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1157 s, 131 iter, 655000 ts, 362 rew

agent-1: 1.5999999999834102
agent-2: 2.5999999999834125
agent-3: 1.5999999999834102
agent-4: 1.5999999999834102
agent-5: 1.5999999999834102
Extrinsic Rewards:
0
1
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-47-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 360.5730228746817
  episode_reward_min: 8.999999999916996
  episodes_this_iter: 1
  episodes_total: 131
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 38.862
    learner:
      cur_lr: 0.0013163769617676735
      grad_gnorm: 3.8059933185577393
      policy_entropy: 1.5860569477081299
      policy_loss: -0.01134230475872755
      var_gnorm: 21.41988754272461
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.010737702250480652
    num_steps_sampled: 660000
    num_steps_trained: 660000
    wait_time_ms: 49.387
  iterations_since_restore: 132
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1166.6270537376404
  time_this_iter_s: 8.848246574401855
  time_total_s: 1166.6270537376404
  timestamp: 1594849659
  timesteps_since_restore: 660000
  timesteps_this_iter: 5000
  timesteps_total: 660000
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1166 s, 132 iter, 660000 ts, 361 rew

agent-1: 13.796567553779596
agent-2: 14.796567553779596
agent-3: 14.796567553779612
agent-4: 12.796567553779596
agent-5: 15.796567553779612
Extrinsic Rewards:
1
2
2
0
3
Sum Reward: 8
Avg Reward: 1.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.35
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-47-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 355.98285127177246
  episode_reward_min: 8.999999999916996
  episodes_this_iter: 1
  episodes_total: 132
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 17.004
    learner:
      cur_lr: 0.0013160440139472485
      grad_gnorm: 5.517651081085205
      policy_entropy: 2.6028010845184326
      policy_loss: -0.002543684095144272
      var_gnorm: 21.419816970825195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.022592321038246155
    num_steps_sampled: 665000
    num_steps_trained: 665000
    wait_time_ms: 72.723
  iterations_since_restore: 133
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1175.4410750865936
  time_this_iter_s: 8.814021348953247
  time_total_s: 1175.4410750865936
  timestamp: 1594849668
  timesteps_since_restore: 665000
  timesteps_this_iter: 5000
  timesteps_total: 665000
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1175 s, 133 iter, 665000 ts, 356 rew

agent-1: 1.558237677456533
agent-2: 1.558237677456533
agent-3: 2.5582376774565336
agent-4: 1.558237677456533
agent-5: 1.558237677456533
Extrinsic Rewards:
0
0
1
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-47-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 353.9107631557272
  episode_reward_min: 8.791188387282622
  episodes_this_iter: 1
  episodes_total: 133
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 32.313
    learner:
      cur_lr: 0.0013157109497115016
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.217586517333984
      policy_loss: 23.194055557250977
      var_gnorm: 21.42147445678711
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 20.129865646362305
    num_steps_sampled: 670000
    num_steps_trained: 670000
    wait_time_ms: 57.882
  iterations_since_restore: 134
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1184.157516002655
  time_this_iter_s: 8.716440916061401
  time_total_s: 1184.157516002655
  timestamp: 1594849677
  timesteps_since_restore: 670000
  timesteps_this_iter: 5000
  timesteps_total: 670000
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1184 s, 134 iter, 670000 ts, 354 rew

agent-1: 22.79917155991638
agent-2: 28.799171559916402
agent-3: 23.799171559916378
agent-4: 20.799171559916378
agent-5: 20.799171559916378
Extrinsic Rewards:
2
8
3
0
0
Sum Reward: 13
Avg Reward: 2.6
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.5846153846153846
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-48-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 353.10072173382906
  episode_reward_min: 8.791188387282622
  episodes_this_iter: 1
  episodes_total: 134
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.767
    dispatch_time_ms: 27.887
    learner:
      cur_lr: 0.0013153780018910766
      grad_gnorm: 9.781248092651367
      policy_entropy: 38.39586639404297
      policy_loss: -1.4825574159622192
      var_gnorm: 21.422765731811523
      vf_explained_var: 0.0
      vf_loss: 0.0670560896396637
    num_steps_sampled: 675000
    num_steps_trained: 675000
    wait_time_ms: 58.698
  iterations_since_restore: 135
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1192.85116481781
  time_this_iter_s: 8.69364881515503
  time_total_s: 1192.85116481781
  timestamp: 1594849685
  timesteps_since_restore: 675000
  timesteps_this_iter: 5000
  timesteps_total: 675000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1192 s, 135 iter, 675000 ts, 353 rew

agent-1: 100.08906100429755
agent-2: 100.08906100429755
agent-3: 95.0890610042976
agent-4: 97.08906100429755
agent-5: 94.08906100429758
Extrinsic Rewards:
15
15
10
12
9
Sum Reward: 61
Avg Reward: 12.2
Min Reward: 9
Max Reward: 15
Gini Coefficient: 0.11147540983606558
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-48-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 355.98517478437725
  episode_reward_min: 8.791188387282622
  episodes_this_iter: 1
  episodes_total: 135
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.964
    dispatch_time_ms: 26.912
    learner:
      cur_lr: 0.0013150450540706515
      grad_gnorm: 39.999996185302734
      policy_entropy: 29.456300735473633
      policy_loss: -6.404380798339844
      var_gnorm: 21.434329986572266
      vf_explained_var: 0.0
      vf_loss: 3.9061808586120605
    num_steps_sampled: 680000
    num_steps_trained: 680000
    wait_time_ms: 61.525
  iterations_since_restore: 136
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1201.5523200035095
  time_this_iter_s: 8.701155185699463
  time_total_s: 1201.5523200035095
  timestamp: 1594849694
  timesteps_since_restore: 680000
  timesteps_this_iter: 5000
  timesteps_total: 680000
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1201 s, 136 iter, 680000 ts, 356 rew

agent-1: 62.50841136814401
agent-2: 65.50841136814401
agent-3: 66.508411368144
agent-4: 66.50841136814401
agent-5: 62.508411368143996
Extrinsic Rewards:
5
8
9
9
5
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 5
Max Reward: 9
Gini Coefficient: 0.13333333333333333
20:20 Ratio: 1.8
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-48-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 357.42059535296244
  episode_reward_min: 8.791188387282622
  episodes_this_iter: 1
  episodes_total: 136
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.543
    dispatch_time_ms: 21.356
    learner:
      cur_lr: 0.0013147119898349047
      grad_gnorm: 39.999996185302734
      policy_entropy: 34.95499801635742
      policy_loss: -0.4785745143890381
      var_gnorm: 21.51470947265625
      vf_explained_var: 0.0
      vf_loss: 4.033392429351807
    num_steps_sampled: 685000
    num_steps_trained: 685000
    wait_time_ms: 71.264
  iterations_since_restore: 137
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1210.517079591751
  time_this_iter_s: 8.964759588241577
  time_total_s: 1210.517079591751
  timestamp: 1594849703
  timesteps_since_restore: 685000
  timesteps_this_iter: 5000
  timesteps_total: 685000
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 42.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1210 s, 137 iter, 685000 ts, 357 rew

agent-1: 133.39987659987503
agent-2: 140.39987659987494
agent-3: 129.3998765998751
agent-4: 130.39987659987514
agent-5: 132.39987659987503
Extrinsic Rewards:
15
22
11
12
14
Sum Reward: 74
Avg Reward: 14.8
Min Reward: 11
Max Reward: 22
Gini Coefficient: 0.13513513513513514
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-48-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 360.6605891966176
  episode_reward_min: 8.791188387282622
  episodes_this_iter: 1
  episodes_total: 137
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 36.627
    learner:
      cur_lr: 0.0013143790420144796
      grad_gnorm: 40.0
      policy_entropy: 0.2236790806055069
      policy_loss: -0.016589852049946785
      var_gnorm: 21.47001838684082
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 7.0510711669921875
    num_steps_sampled: 690000
    num_steps_trained: 690000
    wait_time_ms: 46.963
  iterations_since_restore: 138
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1219.2873380184174
  time_this_iter_s: 8.77025842666626
  time_total_s: 1219.2873380184174
  timestamp: 1594849712
  timesteps_since_restore: 690000
  timesteps_this_iter: 5000
  timesteps_total: 690000
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1219 s, 138 iter, 690000 ts, 361 rew

agent-1: 172.19770196164927
agent-2: 175.19770196164927
agent-3: 178.1977019616493
agent-4: 172.19770196164927
agent-5: 175.19770196164927
Extrinsic Rewards:
17
20
23
17
20
Sum Reward: 97
Avg Reward: 19.4
Min Reward: 17
Max Reward: 23
Gini Coefficient: 0.061855670103092786
20:20 Ratio: 1.3529411764705883
Max-min Ratio: 1.3529411764705883
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-48-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 366.0604742976265
  episode_reward_min: 8.791188387282622
  episodes_this_iter: 1
  episodes_total: 138
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 36.262
    learner:
      cur_lr: 0.0013140459777787328
      grad_gnorm: 2.2444591522216797
      policy_entropy: 0.2605067491531372
      policy_loss: -0.0004295450635254383
      var_gnorm: 21.442047119140625
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0034459710586816072
    num_steps_sampled: 695000
    num_steps_trained: 695000
    wait_time_ms: 43.332
  iterations_since_restore: 139
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1227.75572347641
  time_this_iter_s: 8.468385457992554
  time_total_s: 1227.75572347641
  timestamp: 1594849720
  timesteps_since_restore: 695000
  timesteps_this_iter: 5000
  timesteps_total: 695000
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1227 s, 139 iter, 695000 ts, 366 rew

agent-1: 1.5999994086832678
agent-2: 1.5999994086832678
agent-3: 2.599999408683267
agent-4: 1.5999994086832678
agent-5: 1.5999994086832678
Extrinsic Rewards:
0
0
1
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-48-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 353.4606336465979
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 140
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 29.613
    learner:
      cur_lr: 0.0013137130299583077
      grad_gnorm: 21.45353126525879
      policy_entropy: 0.3000849485397339
      policy_loss: -0.0037230828311294317
      var_gnorm: 21.441143035888672
      vf_explained_var: -1.0
      vf_loss: 0.27065521478652954
    num_steps_sampled: 700000
    num_steps_trained: 700000
    wait_time_ms: 65.658
  iterations_since_restore: 140
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1236.4178433418274
  time_this_iter_s: 8.66211986541748
  time_total_s: 1236.4178433418274
  timestamp: 1594849729
  timesteps_since_restore: 700000
  timesteps_this_iter: 5000
  timesteps_total: 700000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1236 s, 140 iter, 700000 ts, 353 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-48-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 353.4606336465979
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 140
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.86
    dispatch_time_ms: 31.779
    learner:
      cur_lr: 0.0013133799657225609
      grad_gnorm: 0.07823594659566879
      policy_entropy: 0.3036150336265564
      policy_loss: -2.60387132584583e-05
      var_gnorm: 21.44108772277832
      vf_explained_var: 0.0
      vf_loss: 4.539579549600603e-06
    num_steps_sampled: 705000
    num_steps_trained: 705000
    wait_time_ms: 46.111
  iterations_since_restore: 141
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1244.681333065033
  time_this_iter_s: 8.263489723205566
  time_total_s: 1244.681333065033
  timestamp: 1594849737
  timesteps_since_restore: 705000
  timesteps_this_iter: 5000
  timesteps_total: 705000
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1244 s, 141 iter, 705000 ts, 353 rew

agent-1: 4.544710872989794
agent-2: 2.544710872989795
agent-3: 2.544710872989795
agent-4: 2.544710872989795
agent-5: 2.544710872989795
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-49-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 348.6578691914401
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 142
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.451
    dispatch_time_ms: 18.99
    learner:
      cur_lr: 0.0013130470179021358
      grad_gnorm: 40.0
      policy_entropy: 0.4428902268409729
      policy_loss: -0.020509488880634308
      var_gnorm: 21.440288543701172
      vf_explained_var: -1.0
      vf_loss: 4.226905822753906
    num_steps_sampled: 710000
    num_steps_trained: 710000
    wait_time_ms: 79.118
  iterations_since_restore: 142
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1253.3228795528412
  time_this_iter_s: 8.641546487808228
  time_total_s: 1253.3228795528412
  timestamp: 1594849746
  timesteps_since_restore: 710000
  timesteps_this_iter: 5000
  timesteps_total: 710000
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1253 s, 142 iter, 710000 ts, 349 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-49-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 348.65786919144017
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 142
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 27.061
    learner:
      cur_lr: 0.001312713953666389
      grad_gnorm: 0.01095839124172926
      policy_entropy: 0.7352893352508545
      policy_loss: -0.000250922777922824
      var_gnorm: 21.439151763916016
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 4.785319106304087e-05
    num_steps_sampled: 715000
    num_steps_trained: 715000
    wait_time_ms: 62.929
  iterations_since_restore: 143
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1261.7466266155243
  time_this_iter_s: 8.423747062683105
  time_total_s: 1261.7466266155243
  timestamp: 1594849754
  timesteps_since_restore: 715000
  timesteps_this_iter: 5000
  timesteps_total: 715000
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1261 s, 143 iter, 715000 ts, 349 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-49-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 343.97786921624
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 143
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.921
    dispatch_time_ms: 30.449
    learner:
      cur_lr: 0.001312381005845964
      grad_gnorm: 2.6130053997039795
      policy_entropy: 0.9309090375900269
      policy_loss: -0.004859979264438152
      var_gnorm: 21.439098358154297
      vf_explained_var: -1.0
      vf_loss: 0.042795807123184204
    num_steps_sampled: 720000
    num_steps_trained: 720000
    wait_time_ms: 56.243
  iterations_since_restore: 144
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1270.2154886722565
  time_this_iter_s: 8.468862056732178
  time_total_s: 1270.2154886722565
  timestamp: 1594849763
  timesteps_since_restore: 720000
  timesteps_this_iter: 5000
  timesteps_total: 720000
  training_iteration: 144
  
agent-1: 1.3889257914639566
agent-2: 0.3889257914639571
agent-3: 0.3889257914639571
agent-4: 0.3889257914639571
agent-5: 0.3889257914639571
Extrinsic Rewards:
1
0
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1270 s, 144 iter, 720000 ts, 344 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-49-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 340.67731550634727
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 144
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.234
    dispatch_time_ms: 29.887
    learner:
      cur_lr: 0.001312048058025539
      grad_gnorm: 0.09579731523990631
      policy_entropy: 1.1626542806625366
      policy_loss: -0.00018384262511972338
      var_gnorm: 21.43843650817871
      vf_explained_var: 0.0
      vf_loss: 6.750941338395933e-06
    num_steps_sampled: 725000
    num_steps_trained: 725000
    wait_time_ms: 45.865
  iterations_since_restore: 145
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1278.6806046962738
  time_this_iter_s: 8.465116024017334
  time_total_s: 1278.6806046962738
  timestamp: 1594849772
  timesteps_since_restore: 725000
  timesteps_this_iter: 5000
  timesteps_total: 725000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1278 s, 145 iter, 725000 ts, 341 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-49-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 332.03732100604304
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 146
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.641
    dispatch_time_ms: 32.354
    learner:
      cur_lr: 0.001311714993789792
      grad_gnorm: 2.6056723594665527
      policy_entropy: 1.446710228919983
      policy_loss: -0.0075203911401331425
      var_gnorm: 21.43836784362793
      vf_explained_var: -1.0
      vf_loss: 0.04264368489384651
    num_steps_sampled: 730000
    num_steps_trained: 730000
    wait_time_ms: 56.214
  iterations_since_restore: 146
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1287.2892663478851
  time_this_iter_s: 8.608661651611328
  time_total_s: 1287.2892663478851
  timestamp: 1594849780
  timesteps_since_restore: 730000
  timesteps_this_iter: 5000
  timesteps_total: 730000
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1287 s, 146 iter, 730000 ts, 332 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-49-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 998.809658332323
  episode_reward_mean: 332.037321006043
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 146
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 52.868
    learner:
      cur_lr: 0.001311382045969367
      grad_gnorm: 0.00775340897962451
      policy_entropy: 1.2533974647521973
      policy_loss: 2.619237875478575e-07
      var_gnorm: 21.438283920288086
      vf_explained_var: 0.0
      vf_loss: 1.1734768712301502e-09
    num_steps_sampled: 735000
    num_steps_trained: 735000
    wait_time_ms: 50.864
  iterations_since_restore: 147
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1295.9628765583038
  time_this_iter_s: 8.673610210418701
  time_total_s: 1295.9628765583038
  timestamp: 1594849789
  timesteps_since_restore: 735000
  timesteps_this_iter: 5000
  timesteps_total: 735000
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1295 s, 147 iter, 735000 ts, 332 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-49-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 314.66927343958866
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 148
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 27.509
    learner:
      cur_lr: 0.0013110489817336202
      grad_gnorm: 0.007937252521514893
      policy_entropy: 1.3046832084655762
      policy_loss: 2.2147770550873247e-07
      var_gnorm: 21.438207626342773
      vf_explained_var: -1.0
      vf_loss: 3.130313369625881e-11
    num_steps_sampled: 740000
    num_steps_trained: 740000
    wait_time_ms: 57.43
  iterations_since_restore: 148
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1304.350082874298
  time_this_iter_s: 8.387206315994263
  time_total_s: 1304.350082874298
  timestamp: 1594849797
  timesteps_since_restore: 740000
  timesteps_this_iter: 5000
  timesteps_total: 740000
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 42.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1304 s, 148 iter, 740000 ts, 315 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-50-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 314.66927343958866
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 148
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.711
    dispatch_time_ms: 25.853
    learner:
      cur_lr: 0.0013107160339131951
      grad_gnorm: 27.1491756439209
      policy_entropy: 1.5042088031768799
      policy_loss: 0.03383158892393112
      var_gnorm: 21.437774658203125
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.5599560737609863
    num_steps_sampled: 745000
    num_steps_trained: 745000
    wait_time_ms: 56.924
  iterations_since_restore: 149
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1312.906314611435
  time_this_iter_s: 8.55623173713684
  time_total_s: 1312.906314611435
  timestamp: 1594849806
  timesteps_since_restore: 745000
  timesteps_this_iter: 5000
  timesteps_total: 745000
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1312 s, 149 iter, 745000 ts, 315 rew

agent-1: 35.76744636344115
agent-2: 36.76744636344114
agent-3: 27.767446363441174
agent-4: 29.76744636344118
agent-5: 29.76744636344118
Extrinsic Rewards:
8
9
0
2
2
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.45714285714285713
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 35.14455196930828
agent-2: 35.14455196930828
agent-3: 32.144551969308296
agent-4: 37.14455196930829
agent-5: 46.144551969308274
Extrinsic Rewards:
3
3
0
5
14
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.48
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-50-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 309.8448733643383
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 150
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.623
    dispatch_time_ms: 31.411
    learner:
      cur_lr: 0.0013103829696774483
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.746137619018555
      policy_loss: 17.176355361938477
      var_gnorm: 21.440202713012695
      vf_explained_var: 0.0
      vf_loss: 16.516658782958984
    num_steps_sampled: 750000
    num_steps_trained: 750000
    wait_time_ms: 42.208
  iterations_since_restore: 150
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1326.186329126358
  time_this_iter_s: 13.280014514923096
  time_total_s: 1326.186329126358
  timestamp: 1594849819
  timesteps_since_restore: 750000
  timesteps_this_iter: 5000
  timesteps_total: 750000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1326 s, 150 iter, 750000 ts, 310 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-50-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 309.8448733643383
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 150
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.535
    dispatch_time_ms: 29.983
    learner:
      cur_lr: 0.0013100500218570232
      grad_gnorm: 39.88064956665039
      policy_entropy: 0.06238178163766861
      policy_loss: -0.002406742423772812
      var_gnorm: 21.489084243774414
      vf_explained_var: 0.0
      vf_loss: 1.1801272630691528
    num_steps_sampled: 755000
    num_steps_trained: 755000
    wait_time_ms: 58.06
  iterations_since_restore: 151
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1334.9051775932312
  time_this_iter_s: 8.718848466873169
  time_total_s: 1334.9051775932312
  timestamp: 1594849828
  timesteps_since_restore: 755000
  timesteps_this_iter: 5000
  timesteps_total: 755000
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1334 s, 151 iter, 755000 ts, 310 rew

agent-1: 48.19999996903712
agent-2: 44.199999969037144
agent-3: 47.19999996903713
agent-4: 49.19999996903713
agent-5: 54.199999969037115
Extrinsic Rewards:
5
1
4
6
11
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.32592592592592595
20:20 Ratio: 11.0
Max-min Ratio: 11.0
agent-1: 28.199999998684895
agent-2: 29.199999998684895
agent-3: 30.199999998684888
agent-4: 36.19999999868487
agent-5: 29.199999998684895
Extrinsic Rewards:
1
2
3
9
2
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-50-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 309.39487336355506
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 152
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.479
    dispatch_time_ms: 16.853
    learner:
      cur_lr: 0.0013097169576212764
      grad_gnorm: 2.0150108337402344
      policy_entropy: 0.034436676651239395
      policy_loss: -3.3032370993169025e-05
      var_gnorm: 21.489917755126953
      vf_explained_var: 0.09301930665969849
      vf_loss: 0.0023876726627349854
    num_steps_sampled: 760000
    num_steps_trained: 760000
    wait_time_ms: 81.396
  iterations_since_restore: 152
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1344.0865058898926
  time_this_iter_s: 9.181328296661377
  time_total_s: 1344.0865058898926
  timestamp: 1594849837
  timesteps_since_restore: 760000
  timesteps_this_iter: 5000
  timesteps_total: 760000
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1344 s, 152 iter, 760000 ts, 309 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-50-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 309.39487336355506
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 152
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.045
    dispatch_time_ms: 25.683
    learner:
      cur_lr: 0.0013093840098008513
      grad_gnorm: 0.4973647892475128
      policy_entropy: 0.03379853442311287
      policy_loss: -8.31384659250034e-06
      var_gnorm: 21.490026473999023
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00018358274246565998
    num_steps_sampled: 765000
    num_steps_trained: 765000
    wait_time_ms: 39.001
  iterations_since_restore: 153
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1352.8417572975159
  time_this_iter_s: 8.755251407623291
  time_total_s: 1352.8417572975159
  timestamp: 1594849846
  timesteps_since_restore: 765000
  timesteps_this_iter: 5000
  timesteps_total: 765000
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1352 s, 153 iter, 765000 ts, 309 rew

agent-1: 4.79999999994895
agent-2: 4.79999999994895
agent-3: 4.79999999994895
agent-4: 7.79999999994895
agent-5: 4.79999999994895
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-50-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 297.60513136967194
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 154
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.599
    dispatch_time_ms: 28.833
    learner:
      cur_lr: 0.0013090509455651045
      grad_gnorm: 0.018095504492521286
      policy_entropy: 0.03383126109838486
      policy_loss: -6.035113386815283e-08
      var_gnorm: 21.490015029907227
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.9496378911298962e-07
    num_steps_sampled: 770000
    num_steps_trained: 770000
    wait_time_ms: 63.791
  iterations_since_restore: 154
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1361.7443664073944
  time_this_iter_s: 8.90260910987854
  time_total_s: 1361.7443664073944
  timestamp: 1594849855
  timesteps_since_restore: 770000
  timesteps_this_iter: 5000
  timesteps_total: 770000
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1361 s, 154 iter, 770000 ts, 298 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-51-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 297.605131369672
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 154
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 19.344
    learner:
      cur_lr: 0.0013087179977446795
      grad_gnorm: 0.19754090905189514
      policy_entropy: 0.03384348377585411
      policy_loss: 4.35817946708994e-06
      var_gnorm: 21.490005493164062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.896153455367312e-05
    num_steps_sampled: 775000
    num_steps_trained: 775000
    wait_time_ms: 52.748
  iterations_since_restore: 155
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1370.3619236946106
  time_this_iter_s: 8.617557287216187
  time_total_s: 1370.3619236946106
  timestamp: 1594849864
  timesteps_since_restore: 775000
  timesteps_this_iter: 5000
  timesteps_total: 775000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1370 s, 155 iter, 775000 ts, 298 rew

agent-1: 6.3999999999297055
agent-2: 10.39999999992971
agent-3: 6.3999999999297055
agent-4: 6.3999999999297055
agent-5: 6.3999999999297055
Extrinsic Rewards:
0
4
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-51-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 293.8251319884658
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 155
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.759
    dispatch_time_ms: 30.096
    learner:
      cur_lr: 0.0013083850499242544
      grad_gnorm: 0.016212286427617073
      policy_entropy: 0.03393029794096947
      policy_loss: -2.0312745618866757e-06
      var_gnorm: 21.4899959564209
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.9479240620512428e-07
    num_steps_sampled: 780000
    num_steps_trained: 780000
    wait_time_ms: 54.443
  iterations_since_restore: 156
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1379.2801640033722
  time_this_iter_s: 8.918240308761597
  time_total_s: 1379.2801640033722
  timestamp: 1594849873
  timesteps_since_restore: 780000
  timesteps_this_iter: 5000
  timesteps_total: 780000
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1379 s, 156 iter, 780000 ts, 294 rew

agent-1: 4.799999999948068
agent-2: 4.799999999948068
agent-3: 4.799999999948068
agent-4: 7.799999999948069
agent-5: 4.799999999948068
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-51-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 289.7751330055178
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 156
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.775
    dispatch_time_ms: 41.495
    learner:
      cur_lr: 0.0013080519856885076
      grad_gnorm: 0.1266336739063263
      policy_entropy: 0.033972837030887604
      policy_loss: 2.1168823423067806e-06
      var_gnorm: 21.489992141723633
      vf_explained_var: 0.0
      vf_loss: 1.2700531442533247e-05
    num_steps_sampled: 785000
    num_steps_trained: 785000
    wait_time_ms: 62.42
  iterations_since_restore: 157
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1388.2177639007568
  time_this_iter_s: 8.937599897384644
  time_total_s: 1388.2177639007568
  timestamp: 1594849882
  timesteps_since_restore: 785000
  timesteps_this_iter: 5000
  timesteps_total: 785000
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1388 s, 157 iter, 785000 ts, 290 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-51-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 285.8151330062824
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 157
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.179
    dispatch_time_ms: 49.888
    learner:
      cur_lr: 0.0013077190378680825
      grad_gnorm: 40.0
      policy_entropy: 0.034003544598817825
      policy_loss: 0.001979144522920251
      var_gnorm: 21.489994049072266
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.912017822265625
    num_steps_sampled: 790000
    num_steps_trained: 790000
    wait_time_ms: 40.245
  iterations_since_restore: 158
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1397.0357315540314
  time_this_iter_s: 8.817967653274536
  time_total_s: 1397.0357315540314
  timestamp: 1594849890
  timesteps_since_restore: 790000
  timesteps_this_iter: 5000
  timesteps_total: 790000
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1397 s, 158 iter, 790000 ts, 286 rew

agent-1: 4.79999999994895
agent-2: 4.79999999994895
agent-3: 4.79999999994895
agent-4: 7.79999999994895
agent-5: 4.79999999994895
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-51-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 282.3051330089278
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 158
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 24.328
    learner:
      cur_lr: 0.0013073859736323357
      grad_gnorm: 0.21416394412517548
      policy_entropy: 0.03401787579059601
      policy_loss: 5.143296561982424e-07
      var_gnorm: 21.489988327026367
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.4037446312140673e-05
    num_steps_sampled: 795000
    num_steps_trained: 795000
    wait_time_ms: 64.545
  iterations_since_restore: 159
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1405.8672256469727
  time_this_iter_s: 8.831494092941284
  time_total_s: 1405.8672256469727
  timestamp: 1594849899
  timesteps_since_restore: 795000
  timesteps_this_iter: 5000
  timesteps_total: 795000
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1405 s, 159 iter, 795000 ts, 282 rew

agent-1: 6.399999999931053
agent-2: 9.399999999931085
agent-3: 6.399999999931053
agent-4: 7.399999999931052
agent-5: 6.399999999931053
Extrinsic Rewards:
0
3
0
1
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-51-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 280.41513300901954
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 159
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.16
    dispatch_time_ms: 27.029
    learner:
      cur_lr: 0.0013070530258119106
      grad_gnorm: 0.0005704819341190159
      policy_entropy: 0.03406153619289398
      policy_loss: 2.0859602045675274e-08
      var_gnorm: 21.4899845123291
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.9722723454407287e-10
    num_steps_sampled: 800000
    num_steps_trained: 800000
    wait_time_ms: 53.829
  iterations_since_restore: 160
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1414.6221525669098
  time_this_iter_s: 8.754926919937134
  time_total_s: 1414.6221525669098
  timestamp: 1594849908
  timesteps_since_restore: 800000
  timesteps_this_iter: 5000
  timesteps_total: 800000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1414 s, 160 iter, 800000 ts, 280 rew

agent-1: 5.199999999966401
agent-2: 3.1999999999664004
agent-3: 3.1999999999664004
agent-4: 3.1999999999664004
agent-5: 3.1999999999664004
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-51-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 278.88513300904594
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 160
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.081
    dispatch_time_ms: 15.396
    learner:
      cur_lr: 0.0013067199615761638
      grad_gnorm: 0.1353835165500641
      policy_entropy: 0.13486872613430023
      policy_loss: -3.1565352401230484e-05
      var_gnorm: 21.916040420532227
      vf_explained_var: 0.0012892484664916992
      vf_loss: 1.4192270100465976e-05
    num_steps_sampled: 805000
    num_steps_trained: 805000
    wait_time_ms: 73.802
  iterations_since_restore: 161
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1423.474178314209
  time_this_iter_s: 8.852025747299194
  time_total_s: 1423.474178314209
  timestamp: 1594849917
  timesteps_since_restore: 805000
  timesteps_this_iter: 5000
  timesteps_total: 805000
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1423 s, 161 iter, 805000 ts, 279 rew

agent-1: 9.599999999897893
agent-2: 10.599999999897893
agent-3: 11.59999999989789
agent-4: 9.599999999897893
agent-5: 12.59999999989789
Extrinsic Rewards:
0
1
2
0
3
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 6.399999999932382
agent-2: 7.399999999932382
agent-3: 6.399999999932382
agent-4: 6.399999999932382
agent-5: 9.399999999932376
Extrinsic Rewards:
0
1
0
0
3
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-52-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 274.65513300923527
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 162
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.943
    dispatch_time_ms: 24.366
    learner:
      cur_lr: 0.0013063870137557387
      grad_gnorm: 0.023173339664936066
      policy_entropy: 0.13566148281097412
      policy_loss: 1.7331998378722346e-06
      var_gnorm: 21.916133880615234
      vf_explained_var: -1.0
      vf_loss: 3.333254312565259e-07
    num_steps_sampled: 810000
    num_steps_trained: 810000
    wait_time_ms: 54.703
  iterations_since_restore: 162
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1432.2004294395447
  time_this_iter_s: 8.726251125335693
  time_total_s: 1432.2004294395447
  timestamp: 1594849926
  timesteps_since_restore: 810000
  timesteps_this_iter: 5000
  timesteps_total: 810000
  training_iteration: 162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1432 s, 162 iter, 810000 ts, 275 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-52-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 274.6551330092352
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 162
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.725
    dispatch_time_ms: 24.234
    learner:
      cur_lr: 0.0013060539495199919
      grad_gnorm: 0.16066479682922363
      policy_entropy: 0.16807961463928223
      policy_loss: -3.543098137015477e-05
      var_gnorm: 21.916154861450195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.0619327187887393e-05
    num_steps_sampled: 815000
    num_steps_trained: 815000
    wait_time_ms: 60.648
  iterations_since_restore: 163
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1440.9878492355347
  time_this_iter_s: 8.78741979598999
  time_total_s: 1440.9878492355347
  timestamp: 1594849935
  timesteps_since_restore: 815000
  timesteps_this_iter: 5000
  timesteps_total: 815000
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1440 s, 163 iter, 815000 ts, 275 rew

agent-1: 10.39999999993108
agent-2: 6.399999999931052
agent-3: 6.399999999931052
agent-4: 6.399999999931052
agent-5: 6.399999999931052
Extrinsic Rewards:
4
0
0
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 7.999999999915366
agent-2: 7.999999999915366
agent-3: 7.999999999915366
agent-4: 10.99999999991536
agent-5: 9.999999999915364
Extrinsic Rewards:
0
0
0
3
2
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-52-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 267.0051330147873
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 164
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.06
    dispatch_time_ms: 44.108
    learner:
      cur_lr: 0.0013057210016995668
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.22026759386062622
      policy_loss: 0.036847010254859924
      var_gnorm: 21.91611671447754
      vf_explained_var: 0.019739151000976562
      vf_loss: 64.39881896972656
    num_steps_sampled: 820000
    num_steps_trained: 820000
    wait_time_ms: 46.358
  iterations_since_restore: 164
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1449.7838065624237
  time_this_iter_s: 8.795957326889038
  time_total_s: 1449.7838065624237
  timestamp: 1594849943
  timesteps_since_restore: 820000
  timesteps_this_iter: 5000
  timesteps_total: 820000
  training_iteration: 164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1449 s, 164 iter, 820000 ts, 267 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-52-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 267.0051330147873
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 164
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.632
    dispatch_time_ms: 38.702
    learner:
      cur_lr: 0.0013053880538791418
      grad_gnorm: 0.1509830802679062
      policy_entropy: 0.17168742418289185
      policy_loss: -0.0001341398456133902
      var_gnorm: 21.91608428955078
      vf_explained_var: 0.0
      vf_loss: 1.820571742428001e-05
    num_steps_sampled: 825000
    num_steps_trained: 825000
    wait_time_ms: 44.076
  iterations_since_restore: 165
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1458.5625975131989
  time_this_iter_s: 8.778790950775146
  time_total_s: 1458.5625975131989
  timestamp: 1594849952
  timesteps_since_restore: 825000
  timesteps_this_iter: 5000
  timesteps_total: 825000
  training_iteration: 165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1458 s, 165 iter, 825000 ts, 267 rew

agent-1: 7.9999999999127045
agent-2: 7.9999999999127045
agent-3: 10.99999999991271
agent-4: 9.99999999991271
agent-5: 7.9999999999127045
Extrinsic Rewards:
0
0
3
2
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 6.399999999932382
agent-2: 8.399999999932367
agent-3: 6.399999999932382
agent-4: 8.399999999932367
agent-5: 6.399999999932382
Extrinsic Rewards:
0
2
0
2
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-52-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 258.1851333889362
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 166
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.772
    dispatch_time_ms: 26.167
    learner:
      cur_lr: 0.001305054989643395
      grad_gnorm: 1.980834722518921
      policy_entropy: 0.2258797287940979
      policy_loss: -0.0008775623864494264
      var_gnorm: 21.917177200317383
      vf_explained_var: -1.0
      vf_loss: 0.026204539462924004
    num_steps_sampled: 830000
    num_steps_trained: 830000
    wait_time_ms: 59.156
  iterations_since_restore: 166
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1467.3508715629578
  time_this_iter_s: 8.788274049758911
  time_total_s: 1467.3508715629578
  timestamp: 1594849961
  timesteps_since_restore: 830000
  timesteps_this_iter: 5000
  timesteps_total: 830000
  training_iteration: 166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1467 s, 166 iter, 830000 ts, 258 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-52-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 258.18513338893615
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 166
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.349
    dispatch_time_ms: 26.486
    learner:
      cur_lr: 0.00130472204182297
      grad_gnorm: 0.059675101190805435
      policy_entropy: 0.1690877377986908
      policy_loss: -9.198141015076544e-06
      var_gnorm: 21.917312622070312
      vf_explained_var: 0.0
      vf_loss: 2.8442693746910663e-06
    num_steps_sampled: 835000
    num_steps_trained: 835000
    wait_time_ms: 58.528
  iterations_since_restore: 167
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1476.1488523483276
  time_this_iter_s: 8.797980785369873
  time_total_s: 1476.1488523483276
  timestamp: 1594849970
  timesteps_since_restore: 835000
  timesteps_this_iter: 5000
  timesteps_total: 835000
  training_iteration: 167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1476 s, 167 iter, 835000 ts, 258 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 4.79999999994895
agent-2: 4.79999999994895
agent-3: 4.79999999994895
agent-4: 7.79999999994895
agent-5: 4.79999999994895
Extrinsic Rewards:
0
0
0
3
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-52-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 255.12513338923375
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 167
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.172
    dispatch_time_ms: 23.822
    learner:
      cur_lr: 0.001304388977587223
      grad_gnorm: 39.999996185302734
      policy_entropy: 0.17030900716781616
      policy_loss: 0.011796262115240097
      var_gnorm: 21.917285919189453
      vf_explained_var: 0.0
      vf_loss: 12.37358570098877
    num_steps_sampled: 840000
    num_steps_trained: 840000
    wait_time_ms: 67.113
  iterations_since_restore: 168
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1485.028930425644
  time_this_iter_s: 8.880078077316284
  time_total_s: 1485.028930425644
  timestamp: 1594849979
  timesteps_since_restore: 840000
  timesteps_this_iter: 5000
  timesteps_total: 840000
  training_iteration: 168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1485 s, 168 iter, 840000 ts, 255 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-53-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 251.8851333896797
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 168
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.579
    dispatch_time_ms: 28.402
    learner:
      cur_lr: 0.001304056029766798
      grad_gnorm: 0.062066156417131424
      policy_entropy: 0.14428763091564178
      policy_loss: -2.8512564313132316e-05
      var_gnorm: 21.91800308227539
      vf_explained_var: 0.0
      vf_loss: 3.074772621403099e-06
    num_steps_sampled: 845000
    num_steps_trained: 845000
    wait_time_ms: 60.606
  iterations_since_restore: 169
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1493.7596685886383
  time_this_iter_s: 8.730738162994385
  time_total_s: 1493.7596685886383
  timestamp: 1594849988
  timesteps_since_restore: 845000
  timesteps_this_iter: 5000
  timesteps_total: 845000
  training_iteration: 169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1493 s, 169 iter, 845000 ts, 252 rew

agent-1: 6.3999999999297055
agent-2: 6.3999999999297055
agent-3: 10.39999999992971
agent-4: 6.3999999999297055
agent-5: 6.3999999999297055
Extrinsic Rewards:
0
0
4
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-53-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 249.9951333897332
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 169
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 20.617
    learner:
      cur_lr: 0.0013037229655310512
      grad_gnorm: 40.0
      policy_entropy: 0.14531230926513672
      policy_loss: 0.007564916275441647
      var_gnorm: 21.917985916137695
      vf_explained_var: 0.0
      vf_loss: 7.360665798187256
    num_steps_sampled: 850000
    num_steps_trained: 850000
    wait_time_ms: 59.215
  iterations_since_restore: 170
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1502.5605728626251
  time_this_iter_s: 8.800904273986816
  time_total_s: 1502.5605728626251
  timestamp: 1594849996
  timesteps_since_restore: 850000
  timesteps_this_iter: 5000
  timesteps_total: 850000
  training_iteration: 170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 42.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1502 s, 170 iter, 850000 ts, 250 rew

agent-1: 6.399999999931052
agent-2: 6.399999999931052
agent-3: 10.39999999993108
agent-4: 6.399999999931052
agent-5: 6.399999999931052
Extrinsic Rewards:
0
0
4
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-53-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 248.37513338981088
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 170
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.745
    dispatch_time_ms: 26.598
    learner:
      cur_lr: 0.0013033900177106261
      grad_gnorm: 0.4951782822608948
      policy_entropy: 0.11870652437210083
      policy_loss: -9.10436428966932e-05
      var_gnorm: 21.918869018554688
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.00019589607836678624
    num_steps_sampled: 855000
    num_steps_trained: 855000
    wait_time_ms: 63.727
  iterations_since_restore: 171
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1511.3293750286102
  time_this_iter_s: 8.768802165985107
  time_total_s: 1511.3293750286102
  timestamp: 1594850005
  timesteps_since_restore: 855000
  timesteps_this_iter: 5000
  timesteps_total: 855000
  training_iteration: 171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1511 s, 171 iter, 855000 ts, 248 rew

agent-1: 13.599870422683397
agent-2: 9.599870422683388
agent-3: 9.599870422683388
agent-4: 9.599870422683388
agent-5: 11.599870422683388
Extrinsic Rewards:
4
0
0
0
2
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-53-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 243.87512692912492
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 171
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 19.506
    learner:
      cur_lr: 0.0013030569534748793
      grad_gnorm: 40.000003814697266
      policy_entropy: 0.1188570186495781
      policy_loss: 0.013247549533843994
      var_gnorm: 21.918861389160156
      vf_explained_var: 0.0
      vf_loss: 36.89125442504883
    num_steps_sampled: 860000
    num_steps_trained: 860000
    wait_time_ms: 66.478
  iterations_since_restore: 172
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1520.014225244522
  time_this_iter_s: 8.684850215911865
  time_total_s: 1520.014225244522
  timestamp: 1594850014
  timesteps_since_restore: 860000
  timesteps_this_iter: 5000
  timesteps_total: 860000
  training_iteration: 172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1520 s, 172 iter, 860000 ts, 244 rew

agent-1: 14.199999999880038
agent-2: 14.199999999880038
agent-3: 11.199999999880033
agent-4: 11.199999999880033
agent-5: 12.199999999880033
Extrinsic Rewards:
3
3
0
0
1
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.5142857142857142
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-53-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 242.97512692918258
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 172
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.363
    dispatch_time_ms: 19.699
    learner:
      cur_lr: 0.0013027240056544542
      grad_gnorm: 0.24275276064872742
      policy_entropy: 0.11754478514194489
      policy_loss: -4.890958371106535e-05
      var_gnorm: 21.918926239013672
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.7077435738174245e-05
    num_steps_sampled: 865000
    num_steps_trained: 865000
    wait_time_ms: 62.978
  iterations_since_restore: 173
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1528.9091148376465
  time_this_iter_s: 8.89488959312439
  time_total_s: 1528.9091148376465
  timestamp: 1594850023
  timesteps_since_restore: 865000
  timesteps_this_iter: 5000
  timesteps_total: 865000
  training_iteration: 173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1528 s, 173 iter, 865000 ts, 243 rew

agent-1: 11.19999999987868
agent-2: 11.19999999987868
agent-3: 11.19999999987868
agent-4: 14.199999999878681
agent-5: 15.199999999878681
Extrinsic Rewards:
0
0
0
3
4
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-53-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 238.32638278347255
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 173
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.687
    dispatch_time_ms: 29.974
    learner:
      cur_lr: 0.0013023910578340292
      grad_gnorm: 0.0008703257772140205
      policy_entropy: 0.11836347728967667
      policy_loss: -1.7390574669207126e-07
      var_gnorm: 21.918888092041016
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.2237715008023287e-10
    num_steps_sampled: 870000
    num_steps_trained: 870000
    wait_time_ms: 55.203
  iterations_since_restore: 174
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1537.6614928245544
  time_this_iter_s: 8.752377986907959
  time_total_s: 1537.6614928245544
  timestamp: 1594850032
  timesteps_since_restore: 870000
  timesteps_this_iter: 5000
  timesteps_total: 870000
  training_iteration: 174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1537 s, 174 iter, 870000 ts, 238 rew

agent-1: 7.999999999914477
agent-2: 9.999999999914458
agent-3: 10.999999999914456
agent-4: 7.999999999914477
agent-5: 7.999999999914477
Extrinsic Rewards:
0
2
3
0
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-54-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 233.7379191343252
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 174
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.382
    dispatch_time_ms: 33.093
    learner:
      cur_lr: 0.0013020579935982823
      grad_gnorm: 9.986459732055664
      policy_entropy: 0.2344079166650772
      policy_loss: 5.3409581596497446e-05
      var_gnorm: 21.916162490844727
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.07229500263929367
    num_steps_sampled: 875000
    num_steps_trained: 875000
    wait_time_ms: 44.211
  iterations_since_restore: 175
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1546.5754177570343
  time_this_iter_s: 8.913924932479858
  time_total_s: 1546.5754177570343
  timestamp: 1594850041
  timesteps_since_restore: 875000
  timesteps_this_iter: 5000
  timesteps_total: 875000
  training_iteration: 175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 42.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1546 s, 175 iter, 875000 ts, 234 rew

agent-1: 3.199998457104561
agent-2: 3.199998457104561
agent-3: 3.199998457104561
agent-4: 5.199998457104572
agent-5: 3.199998457104561
Extrinsic Rewards:
0
0
0
2
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 9.599999999896122
agent-2: 9.599999999896122
agent-3: 13.599999999896122
agent-4: 11.599999999896118
agent-5: 9.599999999896122
Extrinsic Rewards:
0
0
4
2
0
Sum Reward: 6
Avg Reward: 1.2
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-54-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 229.68791906587842
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 175
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 30.543
    learner:
      cur_lr: 0.0013017250457778573
      grad_gnorm: 2.0561952590942383
      policy_entropy: 0.33624064922332764
      policy_loss: -0.0013506130781024694
      var_gnorm: 21.915538787841797
      vf_explained_var: -1.0
      vf_loss: 0.028520438820123672
    num_steps_sampled: 880000
    num_steps_trained: 880000
    wait_time_ms: 47.422
  iterations_since_restore: 176
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1555.4468908309937
  time_this_iter_s: 8.87147307395935
  time_total_s: 1555.4468908309937
  timestamp: 1594850050
  timesteps_since_restore: 880000
  timesteps_this_iter: 5000
  timesteps_total: 880000
  training_iteration: 176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1555 s, 176 iter, 880000 ts, 230 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-54-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 225.27791908624806
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 176
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2035.209
    dispatch_time_ms: 30.37
    learner:
      cur_lr: 0.0013013919815421104
      grad_gnorm: 0.0018346310826018453
      policy_entropy: 0.27239924669265747
      policy_loss: -2.7758826348645016e-08
      var_gnorm: 21.91543960571289
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.0117606058512862e-10
    num_steps_sampled: 885000
    num_steps_trained: 885000
    wait_time_ms: 43.195
  iterations_since_restore: 177
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1584.5033419132233
  time_this_iter_s: 29.056451082229614
  time_total_s: 1584.5033419132233
  timestamp: 1594850079
  timesteps_since_restore: 885000
  timesteps_this_iter: 5000
  timesteps_total: 885000
  training_iteration: 177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1584 s, 177 iter, 885000 ts, 225 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-54-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 211.8679427803433
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 178
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.278
    dispatch_time_ms: 35.963
    learner:
      cur_lr: 0.0013010590337216854
      grad_gnorm: 0.001852213405072689
      policy_entropy: 0.2778500020503998
      policy_loss: -4.829804822747974e-08
      var_gnorm: 21.915353775024414
      vf_explained_var: -1.0
      vf_loss: 5.5407116394956546e-11
    num_steps_sampled: 890000
    num_steps_trained: 890000
    wait_time_ms: 47.892
  iterations_since_restore: 178
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1592.7438044548035
  time_this_iter_s: 8.2404625415802
  time_total_s: 1592.7438044548035
  timestamp: 1594850087
  timesteps_since_restore: 890000
  timesteps_this_iter: 5000
  timesteps_total: 890000
  training_iteration: 178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1592 s, 178 iter, 890000 ts, 212 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-55-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 211.8679427803433
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 178
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.248
    dispatch_time_ms: 19.111
    learner:
      cur_lr: 0.0013007259694859385
      grad_gnorm: 0.23417453467845917
      policy_entropy: 0.2870907187461853
      policy_loss: -6.51647787890397e-05
      var_gnorm: 21.915246963500977
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.380349855637178e-05
    num_steps_sampled: 895000
    num_steps_trained: 895000
    wait_time_ms: 69.782
  iterations_since_restore: 179
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1607.756630897522
  time_this_iter_s: 15.012826442718506
  time_total_s: 1607.756630897522
  timestamp: 1594850102
  timesteps_since_restore: 895000
  timesteps_this_iter: 5000
  timesteps_total: 895000
  training_iteration: 179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1607 s, 179 iter, 895000 ts, 212 rew

agent-1: 15.96848428665548
agent-2: 19.968484286655507
agent-3: 18.968484286655514
agent-4: 17.968484286655514
agent-5: 16.96848428665551
Extrinsic Rewards:
0
4
3
2
1
Sum Reward: 10
Avg Reward: 2.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 13.460746133443916
agent-2: 14.460746133443909
agent-3: 15.460746133443909
agent-4: 11.460746133443909
agent-5: 11.460746133443909
Extrinsic Rewards:
2
3
4
0
0
Sum Reward: 9
Avg Reward: 1.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.4888888888888889
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-55-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 212.13324648328242
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 180
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.622
    dispatch_time_ms: 24.833
    learner:
      cur_lr: 0.0013003930216655135
      grad_gnorm: 40.0
      policy_entropy: 7.866817474365234
      policy_loss: -22.418092727661133
      var_gnorm: 21.90674591064453
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 65.60758209228516
    num_steps_sampled: 900000
    num_steps_trained: 900000
    wait_time_ms: 68.059
  iterations_since_restore: 180
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1616.5086913108826
  time_this_iter_s: 8.752060413360596
  time_total_s: 1616.5086913108826
  timestamp: 1594850111
  timesteps_since_restore: 900000
  timesteps_this_iter: 5000
  timesteps_total: 900000
  training_iteration: 180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1616 s, 180 iter, 900000 ts, 212 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-55-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 212.13324648328242
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 180
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 19.36
    learner:
      cur_lr: 0.0013000599574297667
      grad_gnorm: 9.654630661010742
      policy_entropy: 0.022032879292964935
      policy_loss: -0.0003671794547699392
      var_gnorm: 21.92234230041504
      vf_explained_var: 0.0
      vf_loss: 0.07446659356355667
    num_steps_sampled: 905000
    num_steps_trained: 905000
    wait_time_ms: 60.196
  iterations_since_restore: 181
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1625.397388935089
  time_this_iter_s: 8.888697624206543
  time_total_s: 1625.397388935089
  timestamp: 1594850120
  timesteps_since_restore: 905000
  timesteps_this_iter: 5000
  timesteps_total: 905000
  training_iteration: 181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1625 s, 181 iter, 905000 ts, 212 rew

agent-1: 41.79999999661963
agent-2: 38.79999999661965
agent-3: 46.79999999661963
agent-4: 38.79999999661965
agent-5: 40.79999999661965
Extrinsic Rewards:
5
2
10
2
4
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.33043478260869563
20:20 Ratio: 5.0
Max-min Ratio: 5.0
agent-1: 41.99999999554832
agent-2: 44.999999995548336
agent-3: 46.99999999554834
agent-4: 39.99999999554833
agent-5: 50.99999999554834
Extrinsic Rewards:
2
5
7
0
11
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.432
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-55-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 208.9833232180147
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 182
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.645
    dispatch_time_ms: 33.036
    learner:
      cur_lr: 0.0012997270096093416
      grad_gnorm: 2.0712473392486572
      policy_entropy: 0.03257641941308975
      policy_loss: -0.00013882943312637508
      var_gnorm: 21.922151565551758
      vf_explained_var: -1.0
      vf_loss: 0.028587985783815384
    num_steps_sampled: 910000
    num_steps_trained: 910000
    wait_time_ms: 55.024
  iterations_since_restore: 182
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1634.2269186973572
  time_this_iter_s: 8.829529762268066
  time_total_s: 1634.2269186973572
  timestamp: 1594850129
  timesteps_since_restore: 910000
  timesteps_this_iter: 5000
  timesteps_total: 910000
  training_iteration: 182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1634 s, 182 iter, 910000 ts, 209 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-55-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 208.9833232180147
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 182
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.525
    dispatch_time_ms: 44.888
    learner:
      cur_lr: 0.0012993939453735948
      grad_gnorm: 0.006283619906753302
      policy_entropy: 0.021045861765742302
      policy_loss: 1.2400174398408126e-07
      var_gnorm: 21.922143936157227
      vf_explained_var: 0.0
      vf_loss: 4.6117062169059864e-08
    num_steps_sampled: 915000
    num_steps_trained: 915000
    wait_time_ms: 42.9
  iterations_since_restore: 183
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1642.7615702152252
  time_this_iter_s: 8.534651517868042
  time_total_s: 1642.7615702152252
  timestamp: 1594850137
  timesteps_since_restore: 915000
  timesteps_this_iter: 5000
  timesteps_total: 915000
  training_iteration: 183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1642 s, 183 iter, 915000 ts, 209 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-55-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 199.80332398303963
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 184
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.054
    dispatch_time_ms: 21.728
    learner:
      cur_lr: 0.0012990609975531697
      grad_gnorm: 2.0662965774536133
      policy_entropy: 0.032617710530757904
      policy_loss: -0.0001389980170642957
      var_gnorm: 21.92214012145996
      vf_explained_var: -1.0
      vf_loss: 0.02840273082256317
    num_steps_sampled: 920000
    num_steps_trained: 920000
    wait_time_ms: 59.041
  iterations_since_restore: 184
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1651.2194702625275
  time_this_iter_s: 8.457900047302246
  time_total_s: 1651.2194702625275
  timestamp: 1594850146
  timesteps_since_restore: 920000
  timesteps_this_iter: 5000
  timesteps_total: 920000
  training_iteration: 184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1651 s, 184 iter, 920000 ts, 200 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-55-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 199.80332398303963
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 184
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.96
    dispatch_time_ms: 26.433
    learner:
      cur_lr: 0.0012987280497327447
      grad_gnorm: 0.00089084985665977
      policy_entropy: 0.021080804988741875
      policy_loss: -1.5404639341909387e-08
      var_gnorm: 21.922130584716797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.251655304545523e-10
    num_steps_sampled: 925000
    num_steps_trained: 925000
    wait_time_ms: 48.637
  iterations_since_restore: 185
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1659.7206842899323
  time_this_iter_s: 8.501214027404785
  time_total_s: 1659.7206842899323
  timestamp: 1594850154
  timesteps_since_restore: 925000
  timesteps_this_iter: 5000
  timesteps_total: 925000
  training_iteration: 185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1659 s, 185 iter, 925000 ts, 200 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-56-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 197.19332398316615
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 185
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.724
    dispatch_time_ms: 23.13
    learner:
      cur_lr: 0.0012983949854969978
      grad_gnorm: 2.0609118938446045
      policy_entropy: 0.03267313912510872
      policy_loss: -0.00013884429063182324
      var_gnorm: 21.92212677001953
      vf_explained_var: -1.0
      vf_loss: 0.028254041448235512
    num_steps_sampled: 930000
    num_steps_trained: 930000
    wait_time_ms: 59.12
  iterations_since_restore: 186
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1668.2721803188324
  time_this_iter_s: 8.551496028900146
  time_total_s: 1668.2721803188324
  timestamp: 1594850163
  timesteps_since_restore: 930000
  timesteps_this_iter: 5000
  timesteps_total: 930000
  training_iteration: 186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1668 s, 186 iter, 930000 ts, 197 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-56-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 193.77332398352075
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 186
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.802
    dispatch_time_ms: 28.182
    learner:
      cur_lr: 0.0012980620376765728
      grad_gnorm: 0.004860040731728077
      policy_entropy: 0.02112087979912758
      policy_loss: 1.1785274267595014e-07
      var_gnorm: 21.922117233276367
      vf_explained_var: 0.0
      vf_loss: 2.42516478010657e-08
    num_steps_sampled: 935000
    num_steps_trained: 935000
    wait_time_ms: 44.448
  iterations_since_restore: 187
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1676.7774574756622
  time_this_iter_s: 8.505277156829834
  time_total_s: 1676.7774574756622
  timestamp: 1594850171
  timesteps_since_restore: 935000
  timesteps_this_iter: 5000
  timesteps_total: 935000
  training_iteration: 187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1676 s, 187 iter, 935000 ts, 194 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-56-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 183.24381956227
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 188
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.902
    dispatch_time_ms: 24.062
    learner:
      cur_lr: 0.001297728973440826
      grad_gnorm: 0.0008804464596323669
      policy_entropy: 0.021137921139597893
      policy_loss: -8.610910207096367e-09
      var_gnorm: 21.9221134185791
      vf_explained_var: -1.0
      vf_loss: 4.795102093169135e-10
    num_steps_sampled: 940000
    num_steps_trained: 940000
    wait_time_ms: 49.426
  iterations_since_restore: 188
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1685.124403476715
  time_this_iter_s: 8.346946001052856
  time_total_s: 1685.124403476715
  timestamp: 1594850180
  timesteps_since_restore: 940000
  timesteps_this_iter: 5000
  timesteps_total: 940000
  training_iteration: 188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1685 s, 188 iter, 940000 ts, 183 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-56-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 183.24381956227
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 188
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.954
    dispatch_time_ms: 34.182
    learner:
      cur_lr: 0.001297396025620401
      grad_gnorm: 0.00023018331557977945
      policy_entropy: 0.021158313378691673
      policy_loss: -3.8815169745021194e-08
      var_gnorm: 21.922101974487305
      vf_explained_var: 0.0
      vf_loss: 3.894315980801366e-09
    num_steps_sampled: 945000
    num_steps_trained: 945000
    wait_time_ms: 39.918
  iterations_since_restore: 189
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1693.4453094005585
  time_this_iter_s: 8.320905923843384
  time_total_s: 1693.4453094005585
  timestamp: 1594850188
  timesteps_since_restore: 945000
  timesteps_this_iter: 5000
  timesteps_total: 945000
  training_iteration: 189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1693 s, 189 iter, 945000 ts, 183 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-56-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 179.0138195624647
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 190
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 24.79
    learner:
      cur_lr: 0.001297062961384654
      grad_gnorm: 0.0003554603608790785
      policy_entropy: 0.021182706579566002
      policy_loss: 2.969294365939845e-09
      var_gnorm: 21.92209815979004
      vf_explained_var: -1.0
      vf_loss: 6.870372326606144e-11
    num_steps_sampled: 950000
    num_steps_trained: 950000
    wait_time_ms: 54.399
  iterations_since_restore: 190
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1701.7408397197723
  time_this_iter_s: 8.295530319213867
  time_total_s: 1701.7408397197723
  timestamp: 1594850196
  timesteps_since_restore: 950000
  timesteps_this_iter: 5000
  timesteps_total: 950000
  training_iteration: 190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1701 s, 190 iter, 950000 ts, 179 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-56-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 179.0138195624647
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 190
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.757
    dispatch_time_ms: 25.503
    learner:
      cur_lr: 0.001296730013564229
      grad_gnorm: 0.0005919228424318135
      policy_entropy: 0.021204819902777672
      policy_loss: 1.1263561638941155e-08
      var_gnorm: 21.922086715698242
      vf_explained_var: 0.0
      vf_loss: 2.6343319192712045e-10
    num_steps_sampled: 955000
    num_steps_trained: 955000
    wait_time_ms: 50.691
  iterations_since_restore: 191
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1710.0932080745697
  time_this_iter_s: 8.352368354797363
  time_total_s: 1710.0932080745697
  timestamp: 1594850205
  timesteps_since_restore: 955000
  timesteps_this_iter: 5000
  timesteps_total: 955000
  training_iteration: 191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1710 s, 191 iter, 955000 ts, 179 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-56-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 174.96381956265685
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 192
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.028
    dispatch_time_ms: 34.996
    learner:
      cur_lr: 0.0012963969493284822
      grad_gnorm: 0.00039176084101200104
      policy_entropy: 0.021224575117230415
      policy_loss: 3.2910367764316106e-09
      var_gnorm: 21.922080993652344
      vf_explained_var: -1.0
      vf_loss: 8.582783789234938e-11
    num_steps_sampled: 960000
    num_steps_trained: 960000
    wait_time_ms: 52.689
  iterations_since_restore: 192
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1718.451786518097
  time_this_iter_s: 8.358578443527222
  time_total_s: 1718.451786518097
  timestamp: 1594850213
  timesteps_since_restore: 960000
  timesteps_this_iter: 5000
  timesteps_total: 960000
  training_iteration: 192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1718 s, 192 iter, 960000 ts, 175 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-57-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 174.96381956265685
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 192
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.498
    dispatch_time_ms: 20.253
    learner:
      cur_lr: 0.0012960640015080571
      grad_gnorm: 0.00015821802662685513
      policy_entropy: 0.021250057965517044
      policy_loss: 1.010899808306931e-09
      var_gnorm: 21.922069549560547
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.648091803284183e-12
    num_steps_sampled: 965000
    num_steps_trained: 965000
    wait_time_ms: 61.107
  iterations_since_restore: 193
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1726.727693080902
  time_this_iter_s: 8.275906562805176
  time_total_s: 1726.727693080902
  timestamp: 1594850221
  timesteps_since_restore: 965000
  timesteps_this_iter: 5000
  timesteps_total: 965000
  training_iteration: 193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1726 s, 193 iter, 965000 ts, 175 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-57-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 171.00381956274305
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 194
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 35.608
    learner:
      cur_lr: 0.001295731053687632
      grad_gnorm: 0.0006566816009581089
      policy_entropy: 0.021279558539390564
      policy_loss: 5.764407617903089e-09
      var_gnorm: 21.922061920166016
      vf_explained_var: -1.0
      vf_loss: 2.616223626628056e-10
    num_steps_sampled: 970000
    num_steps_trained: 970000
    wait_time_ms: 36.879
  iterations_since_restore: 194
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1735.1317417621613
  time_this_iter_s: 8.404048681259155
  time_total_s: 1735.1317417621613
  timestamp: 1594850230
  timesteps_since_restore: 970000
  timesteps_this_iter: 5000
  timesteps_total: 970000
  training_iteration: 194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1735 s, 194 iter, 970000 ts, 171 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-57-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 171.00381956274305
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 194
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.114
    dispatch_time_ms: 23.921
    learner:
      cur_lr: 0.0012953979894518852
      grad_gnorm: 0.0003934405685868114
      policy_entropy: 0.02130774036049843
      policy_loss: -7.371456778315633e-09
      var_gnorm: 21.922048568725586
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.0850942366857907e-10
    num_steps_sampled: 975000
    num_steps_trained: 975000
    wait_time_ms: 56.376
  iterations_since_restore: 195
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1743.5176494121552
  time_this_iter_s: 8.385907649993896
  time_total_s: 1743.5176494121552
  timestamp: 1594850238
  timesteps_since_restore: 975000
  timesteps_this_iter: 5000
  timesteps_total: 975000
  training_iteration: 195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1743 s, 195 iter, 975000 ts, 171 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-57-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 160.74382022707633
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 196
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.775
    dispatch_time_ms: 25.984
    learner:
      cur_lr: 0.0012950650416314602
      grad_gnorm: 0.00024582017795182765
      policy_entropy: 0.021338343620300293
      policy_loss: -1.847239139429746e-09
      var_gnorm: 21.922042846679688
      vf_explained_var: -1.0
      vf_loss: 2.6789164636609186e-11
    num_steps_sampled: 980000
    num_steps_trained: 980000
    wait_time_ms: 55.869
  iterations_since_restore: 196
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1751.9578385353088
  time_this_iter_s: 8.440189123153687
  time_total_s: 1751.9578385353088
  timestamp: 1594850247
  timesteps_since_restore: 980000
  timesteps_this_iter: 5000
  timesteps_total: 980000
  training_iteration: 196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1751 s, 196 iter, 980000 ts, 161 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-57-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 160.74382022707633
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 196
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.039
    dispatch_time_ms: 18.799
    learner:
      cur_lr: 0.0012947319773957133
      grad_gnorm: 0.008728740736842155
      policy_entropy: 0.021368984133005142
      policy_loss: -1.7757397330342428e-08
      var_gnorm: 21.922027587890625
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.882940629613586e-08
    num_steps_sampled: 985000
    num_steps_trained: 985000
    wait_time_ms: 75.927
  iterations_since_restore: 197
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1760.4926073551178
  time_this_iter_s: 8.53476881980896
  time_total_s: 1760.4926073551178
  timestamp: 1594850255
  timesteps_since_restore: 985000
  timesteps_this_iter: 5000
  timesteps_total: 985000
  training_iteration: 197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1760 s, 197 iter, 985000 ts, 161 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-57-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 156.60382023340648
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 197
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.916
    dispatch_time_ms: 27.026
    learner:
      cur_lr: 0.0012943990295752883
      grad_gnorm: 0.0001372676488244906
      policy_entropy: 0.021403983235359192
      policy_loss: 2.2708544766825156e-10
      var_gnorm: 21.922019958496094
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.9463782719115215e-13
    num_steps_sampled: 990000
    num_steps_trained: 990000
    wait_time_ms: 53.085
  iterations_since_restore: 198
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1768.8679692745209
  time_this_iter_s: 8.375361919403076
  time_total_s: 1768.8679692745209
  timestamp: 1594850264
  timesteps_since_restore: 990000
  timesteps_this_iter: 5000
  timesteps_total: 990000
  training_iteration: 198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1768 s, 198 iter, 990000 ts, 157 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-57-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 148.59697424757104
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 198
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.653
    dispatch_time_ms: 33.91
    learner:
      cur_lr: 0.0012940659653395414
      grad_gnorm: 0.00047301038284786046
      policy_entropy: 0.021444426849484444
      policy_loss: -1.2520500192181316e-08
      var_gnorm: 21.9220027923584
      vf_explained_var: 0.0
      vf_loss: 1.7801161933395093e-10
    num_steps_sampled: 995000
    num_steps_trained: 995000
    wait_time_ms: 47.38
  iterations_since_restore: 199
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1777.329543352127
  time_this_iter_s: 8.461574077606201
  time_total_s: 1777.329543352127
  timestamp: 1594850272
  timesteps_since_restore: 995000
  timesteps_this_iter: 5000
  timesteps_total: 995000
  training_iteration: 199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1777 s, 199 iter, 995000 ts, 149 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-58-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 143.37697424801428
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 200
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.118
    dispatch_time_ms: 22.47
    learner:
      cur_lr: 0.0012937330175191164
      grad_gnorm: 0.00023528134624939412
      policy_entropy: 0.02147555537521839
      policy_loss: -1.7379307992726467e-09
      var_gnorm: 21.921993255615234
      vf_explained_var: -1.0
      vf_loss: 2.3430913459465685e-11
    num_steps_sampled: 1000000
    num_steps_trained: 1000000
    wait_time_ms: 58.02
  iterations_since_restore: 200
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1785.7779939174652
  time_this_iter_s: 8.448450565338135
  time_total_s: 1785.7779939174652
  timestamp: 1594850281
  timesteps_since_restore: 1000000
  timesteps_this_iter: 5000
  timesteps_total: 1000000
  training_iteration: 200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1785 s, 200 iter, 1000000 ts, 143 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-58-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 143.37697424801428
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 200
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 35.795
    learner:
      cur_lr: 0.0012933999532833695
      grad_gnorm: 0.0006333579658530653
      policy_entropy: 0.021519450470805168
      policy_loss: -8.936299700224026e-09
      var_gnorm: 21.921977996826172
      vf_explained_var: 0.0
      vf_loss: 3.082244737218076e-10
    num_steps_sampled: 1005000
    num_steps_trained: 1005000
    wait_time_ms: 49.691
  iterations_since_restore: 201
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1794.2762138843536
  time_this_iter_s: 8.498219966888428
  time_total_s: 1794.2762138843536
  timestamp: 1594850289
  timesteps_since_restore: 1005000
  timesteps_this_iter: 5000
  timesteps_total: 1005000
  training_iteration: 201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1794 s, 201 iter, 1005000 ts, 143 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-58-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 133.9270429309596
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 202
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.091
    dispatch_time_ms: 34.308
    learner:
      cur_lr: 0.0012930670054629445
      grad_gnorm: 0.0003981257905252278
      policy_entropy: 0.021555092185735703
      policy_loss: 3.214388977212934e-09
      var_gnorm: 21.921966552734375
      vf_explained_var: -1.0
      vf_loss: 8.865486122999755e-11
    num_steps_sampled: 1010000
    num_steps_trained: 1010000
    wait_time_ms: 61.927
  iterations_since_restore: 202
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1802.8284940719604
  time_this_iter_s: 8.552280187606812
  time_total_s: 1802.8284940719604
  timestamp: 1594850298
  timesteps_since_restore: 1010000
  timesteps_this_iter: 5000
  timesteps_total: 1010000
  training_iteration: 202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1802 s, 202 iter, 1010000 ts, 134 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-58-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 133.9270429309596
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 202
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.674
    dispatch_time_ms: 26.616
    learner:
      cur_lr: 0.0012927340576425195
      grad_gnorm: 0.00015154387801885605
      policy_entropy: 0.021604018285870552
      policy_loss: -3.6749461251872617e-09
      var_gnorm: 21.921947479248047
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.706399766435387e-12
    num_steps_sampled: 1015000
    num_steps_trained: 1015000
    wait_time_ms: 55.807
  iterations_since_restore: 203
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1811.2432906627655
  time_this_iter_s: 8.414796590805054
  time_total_s: 1811.2432906627655
  timestamp: 1594850306
  timesteps_since_restore: 1015000
  timesteps_this_iter: 5000
  timesteps_total: 1015000
  training_iteration: 203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1811 s, 203 iter, 1015000 ts, 134 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-58-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 131.22704293109757
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 203
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.606
    dispatch_time_ms: 26.966
    learner:
      cur_lr: 0.0012924009934067726
      grad_gnorm: 1.9792228937149048
      policy_entropy: 0.03344655781984329
      policy_loss: -0.00013640131510328501
      var_gnorm: 21.92193603515625
      vf_explained_var: -1.0
      vf_loss: 0.026058463379740715
    num_steps_sampled: 1020000
    num_steps_trained: 1020000
    wait_time_ms: 56.12
  iterations_since_restore: 204
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1819.711788892746
  time_this_iter_s: 8.468498229980469
  time_total_s: 1819.711788892746
  timestamp: 1594850315
  timesteps_since_restore: 1020000
  timesteps_this_iter: 5000
  timesteps_total: 1020000
  training_iteration: 204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1819 s, 204 iter, 1020000 ts, 131 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-58-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 127.35704293252638
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 204
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.596
    dispatch_time_ms: 30.213
    learner:
      cur_lr: 0.0012920680455863476
      grad_gnorm: 0.001507235923781991
      policy_entropy: 0.02176574431359768
      policy_loss: 1.2137787663846211e-08
      var_gnorm: 21.92190170288086
      vf_explained_var: 0.0
      vf_loss: 1.7912610283943309e-09
    num_steps_sampled: 1025000
    num_steps_trained: 1025000
    wait_time_ms: 61.314
  iterations_since_restore: 205
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1828.2977333068848
  time_this_iter_s: 8.585944414138794
  time_total_s: 1828.2977333068848
  timestamp: 1594850323
  timesteps_since_restore: 1025000
  timesteps_this_iter: 5000
  timesteps_total: 1025000
  training_iteration: 205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1828 s, 205 iter, 1025000 ts, 127 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-58-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 122.94704293275964
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 206
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.644
    dispatch_time_ms: 24.623
    learner:
      cur_lr: 0.0012917349813506007
      grad_gnorm: 1.9650441408157349
      policy_entropy: 0.033682387322187424
      policy_loss: -0.00013635157665703446
      var_gnorm: 21.92188835144043
      vf_explained_var: -1.0
      vf_loss: 0.025687603279948235
    num_steps_sampled: 1030000
    num_steps_trained: 1030000
    wait_time_ms: 67.176
  iterations_since_restore: 206
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1836.7706851959229
  time_this_iter_s: 8.472951889038086
  time_total_s: 1836.7706851959229
  timestamp: 1594850332
  timesteps_since_restore: 1030000
  timesteps_this_iter: 5000
  timesteps_total: 1030000
  training_iteration: 206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1836 s, 206 iter, 1030000 ts, 123 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-59-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 122.94704293275964
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 206
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.698
    dispatch_time_ms: 37.443
    learner:
      cur_lr: 0.0012914020335301757
      grad_gnorm: 0.4011524021625519
      policy_entropy: 0.02184511162340641
      policy_loss: -2.9554123102570884e-05
      var_gnorm: 21.921875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00012857673573307693
    num_steps_sampled: 1035000
    num_steps_trained: 1035000
    wait_time_ms: 59.034
  iterations_since_restore: 207
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1851.51478099823
  time_this_iter_s: 14.744095802307129
  time_total_s: 1851.51478099823
  timestamp: 1594850347
  timesteps_since_restore: 1035000
  timesteps_this_iter: 5000
  timesteps_total: 1035000
  training_iteration: 207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1851 s, 207 iter, 1035000 ts, 123 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-59-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 121.2370429333117
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 207
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.151
    dispatch_time_ms: 30.786
    learner:
      cur_lr: 0.0012910689692944288
      grad_gnorm: 0.029480542987585068
      policy_entropy: 0.021906154230237007
      policy_loss: -1.181527068183641e-06
      var_gnorm: 21.92185401916504
      vf_explained_var: 0.0
      vf_loss: 6.943733978914679e-07
    num_steps_sampled: 1040000
    num_steps_trained: 1040000
    wait_time_ms: 40.374
  iterations_since_restore: 208
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1859.910986661911
  time_this_iter_s: 8.39620566368103
  time_total_s: 1859.910986661911
  timestamp: 1594850355
  timesteps_since_restore: 1040000
  timesteps_this_iter: 5000
  timesteps_total: 1040000
  training_iteration: 208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1859 s, 208 iter, 1040000 ts, 121 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-59-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 119.0770429336309
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 208
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.719
    dispatch_time_ms: 41.909
    learner:
      cur_lr: 0.0012907360214740038
      grad_gnorm: 0.007574667222797871
      policy_entropy: 0.021964237093925476
      policy_loss: -1.640140467884521e-09
      var_gnorm: 21.921831130981445
      vf_explained_var: 0.0
      vf_loss: 3.63854404383801e-08
    num_steps_sampled: 1045000
    num_steps_trained: 1045000
    wait_time_ms: 61.37
  iterations_since_restore: 209
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1868.5411386489868
  time_this_iter_s: 8.630151987075806
  time_total_s: 1868.5411386489868
  timestamp: 1594850364
  timesteps_since_restore: 1045000
  timesteps_this_iter: 5000
  timesteps_total: 1045000
  training_iteration: 209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1868 s, 209 iter, 1045000 ts, 119 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-59-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 106.56708261845128
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 210
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.521
    dispatch_time_ms: 31.228
    learner:
      cur_lr: 0.001290402957238257
      grad_gnorm: 0.646125316619873
      policy_entropy: 0.02203134074807167
      policy_loss: -4.190387203895085e-10
      var_gnorm: 21.92181396484375
      vf_explained_var: 7.873773574829102e-05
      vf_loss: 0.00026430789148434997
    num_steps_sampled: 1050000
    num_steps_trained: 1050000
    wait_time_ms: 57.887
  iterations_since_restore: 210
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1876.927702665329
  time_this_iter_s: 8.386564016342163
  time_total_s: 1876.927702665329
  timestamp: 1594850372
  timesteps_since_restore: 1050000
  timesteps_this_iter: 5000
  timesteps_total: 1050000
  training_iteration: 210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1876 s, 210 iter, 1050000 ts, 107 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-59-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 106.56708261845128
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 210
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 25.774
    learner:
      cur_lr: 0.001290070009417832
      grad_gnorm: 0.00015340355457738042
      policy_entropy: 0.022102801129221916
      policy_loss: 1.5608547787593352e-09
      var_gnorm: 21.92178726196289
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.1629269515998093e-12
    num_steps_sampled: 1055000
    num_steps_trained: 1055000
    wait_time_ms: 55.786
  iterations_since_restore: 211
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1885.354979276657
  time_this_iter_s: 8.427276611328125
  time_total_s: 1885.354979276657
  timestamp: 1594850381
  timesteps_since_restore: 1055000
  timesteps_this_iter: 5000
  timesteps_total: 1055000
  training_iteration: 211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1885 s, 211 iter, 1055000 ts, 107 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-59-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 100.62708262271808
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 212
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 16.751
    learner:
      cur_lr: 0.001289736945182085
      grad_gnorm: 1.9225201606750488
      policy_entropy: 0.03418818861246109
      policy_loss: -0.00013539606879930943
      var_gnorm: 21.921770095825195
      vf_explained_var: -1.0
      vf_loss: 0.02458634227514267
    num_steps_sampled: 1060000
    num_steps_trained: 1060000
    wait_time_ms: 64.131
  iterations_since_restore: 212
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1893.8988416194916
  time_this_iter_s: 8.543862342834473
  time_total_s: 1893.8988416194916
  timestamp: 1594850389
  timesteps_since_restore: 1060000
  timesteps_this_iter: 5000
  timesteps_total: 1060000
  training_iteration: 212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1893 s, 212 iter, 1060000 ts, 101 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_17-59-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 100.62708262271806
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 212
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.568
    dispatch_time_ms: 30.957
    learner:
      cur_lr: 0.00128940399736166
      grad_gnorm: 0.0029445113614201546
      policy_entropy: 0.022249091416597366
      policy_loss: 4.593462055169084e-09
      var_gnorm: 21.921741485595703
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.520050194718351e-09
    num_steps_sampled: 1065000
    num_steps_trained: 1065000
    wait_time_ms: 59.731
  iterations_since_restore: 213
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1902.4770822525024
  time_this_iter_s: 8.578240633010864
  time_total_s: 1902.4770822525024
  timestamp: 1594850398
  timesteps_since_restore: 1065000
  timesteps_this_iter: 5000
  timesteps_total: 1065000
  training_iteration: 213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1902 s, 213 iter, 1065000 ts, 101 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-00-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 91.8970842963189
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 214
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.731
    dispatch_time_ms: 22.804
    learner:
      cur_lr: 0.001289071049541235
      grad_gnorm: 0.00020647361816372722
      policy_entropy: 0.02232331596314907
      policy_loss: -1.4273563442301906e-09
      var_gnorm: 21.921722412109375
      vf_explained_var: -1.0
      vf_loss: 1.4438450435250161e-11
    num_steps_sampled: 1070000
    num_steps_trained: 1070000
    wait_time_ms: 49.514
  iterations_since_restore: 214
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1910.8545060157776
  time_this_iter_s: 8.377423763275146
  time_total_s: 1910.8545060157776
  timestamp: 1594850406
  timesteps_since_restore: 1070000
  timesteps_this_iter: 5000
  timesteps_total: 1070000
  training_iteration: 214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1910 s, 214 iter, 1070000 ts, 91.9 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-00-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 91.8970842963189
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 214
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.527
    dispatch_time_ms: 34.762
    learner:
      cur_lr: 0.0012887379853054881
      grad_gnorm: 0.0034846016205847263
      policy_entropy: 0.022418312728405
      policy_loss: 4.18839150029271e-08
      var_gnorm: 21.921689987182617
      vf_explained_var: 0.0
      vf_loss: 9.733810202305904e-09
    num_steps_sampled: 1075000
    num_steps_trained: 1075000
    wait_time_ms: 44.082
  iterations_since_restore: 215
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1919.3397889137268
  time_this_iter_s: 8.485282897949219
  time_total_s: 1919.3397889137268
  timestamp: 1594850415
  timesteps_since_restore: 1075000
  timesteps_this_iter: 5000
  timesteps_total: 1075000
  training_iteration: 215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1919 s, 215 iter, 1075000 ts, 91.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-00-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 83.2571210284845
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 216
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 42.523
    learner:
      cur_lr: 0.001288405037485063
      grad_gnorm: 0.0001589149615028873
      policy_entropy: 0.022501394152641296
      policy_loss: -4.2376486817374825e-06
      var_gnorm: 21.921667098999023
      vf_explained_var: -1.0
      vf_loss: 4.028049595261596e-12
    num_steps_sampled: 1080000
    num_steps_trained: 1080000
    wait_time_ms: 53.495
  iterations_since_restore: 216
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1928.0344414710999
  time_this_iter_s: 8.694652557373047
  time_total_s: 1928.0344414710999
  timestamp: 1594850424
  timesteps_since_restore: 1080000
  timesteps_this_iter: 5000
  timesteps_total: 1080000
  training_iteration: 216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1928 s, 216 iter, 1080000 ts, 83.3 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-00-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 83.25712102848449
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 216
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 24.62
    learner:
      cur_lr: 0.0012880719732493162
      grad_gnorm: 0.01560481172055006
      policy_entropy: 0.022594332695007324
      policy_loss: -5.376591047934198e-07
      var_gnorm: 21.921632766723633
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.9472523149488552e-07
    num_steps_sampled: 1085000
    num_steps_trained: 1085000
    wait_time_ms: 58.462
  iterations_since_restore: 217
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1936.2739131450653
  time_this_iter_s: 8.239471673965454
  time_total_s: 1936.2739131450653
  timestamp: 1594850432
  timesteps_since_restore: 1085000
  timesteps_this_iter: 5000
  timesteps_total: 1085000
  training_iteration: 217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1936 s, 217 iter, 1085000 ts, 83.3 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-00-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 77.72368607865009
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 218
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.994
    dispatch_time_ms: 20.591
    learner:
      cur_lr: 0.0012877390254288912
      grad_gnorm: 1.8716213703155518
      policy_entropy: 0.0349271334707737
      policy_loss: -0.00013450172264128923
      var_gnorm: 21.92160987854004
      vf_explained_var: -1.0
      vf_loss: 0.023301182314753532
    num_steps_sampled: 1090000
    num_steps_trained: 1090000
    wait_time_ms: 60.916
  iterations_since_restore: 218
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1944.796029806137
  time_this_iter_s: 8.522116661071777
  time_total_s: 1944.796029806137
  timestamp: 1594850440
  timesteps_since_restore: 1090000
  timesteps_this_iter: 5000
  timesteps_total: 1090000
  training_iteration: 218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1944 s, 218 iter, 1090000 ts, 77.7 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-00-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 77.72368607865009
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 218
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.301
    dispatch_time_ms: 19.3
    learner:
      cur_lr: 0.0012874059611931443
      grad_gnorm: 0.0003841235884465277
      policy_entropy: 0.02280760370194912
      policy_loss: -1.0158986540886872e-08
      var_gnorm: 21.921571731567383
      vf_explained_var: 0.0
      vf_loss: 1.0276340195458644e-10
    num_steps_sampled: 1095000
    num_steps_trained: 1095000
    wait_time_ms: 50.752
  iterations_since_restore: 219
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1953.2144632339478
  time_this_iter_s: 8.418433427810669
  time_total_s: 1953.2144632339478
  timestamp: 1594850449
  timesteps_since_restore: 1095000
  timesteps_this_iter: 5000
  timesteps_total: 1095000
  training_iteration: 219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1953 s, 219 iter, 1095000 ts, 77.7 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-00-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 72.95368616004434
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 219
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.92
    dispatch_time_ms: 35.057
    learner:
      cur_lr: 0.0012870730133727193
      grad_gnorm: 0.00015309301670640707
      policy_entropy: 0.022910933941602707
      policy_loss: 1.7263904084074966e-08
      var_gnorm: 21.92154312133789
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.7773814104532493e-12
    num_steps_sampled: 1100000
    num_steps_trained: 1100000
    wait_time_ms: 48.255
  iterations_since_restore: 220
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1961.6935606002808
  time_this_iter_s: 8.479097366333008
  time_total_s: 1961.6935606002808
  timestamp: 1594850457
  timesteps_since_restore: 1100000
  timesteps_this_iter: 5000
  timesteps_total: 1100000
  training_iteration: 220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1961 s, 220 iter, 1100000 ts, 73 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-01-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 69.62368621786437
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 220
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 30.225
    learner:
      cur_lr: 0.0012867399491369724
      grad_gnorm: 0.0013413052074611187
      policy_entropy: 0.023039784282445908
      policy_loss: 1.4052381480667009e-08
      var_gnorm: 21.921499252319336
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.4338443765637976e-09
    num_steps_sampled: 1105000
    num_steps_trained: 1105000
    wait_time_ms: 47.22
  iterations_since_restore: 221
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1970.258249759674
  time_this_iter_s: 8.56468915939331
  time_total_s: 1970.258249759674
  timestamp: 1594850466
  timesteps_since_restore: 1105000
  timesteps_this_iter: 5000
  timesteps_total: 1105000
  training_iteration: 221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1970 s, 221 iter, 1105000 ts, 69.6 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-01-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 63.81596439730074
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 222
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.17
    dispatch_time_ms: 35.378
    learner:
      cur_lr: 0.0012864070013165474
      grad_gnorm: 0.000247570569626987
      policy_entropy: 0.023160407319664955
      policy_loss: -3.291880323885721e-09
      var_gnorm: 21.921470642089844
      vf_explained_var: -1.0
      vf_loss: 2.5292268279741847e-11
    num_steps_sampled: 1110000
    num_steps_trained: 1110000
    wait_time_ms: 51.112
  iterations_since_restore: 222
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1978.7349224090576
  time_this_iter_s: 8.476672649383545
  time_total_s: 1978.7349224090576
  timestamp: 1594850475
  timesteps_since_restore: 1110000
  timesteps_this_iter: 5000
  timesteps_total: 1110000
  training_iteration: 222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1978 s, 222 iter, 1110000 ts, 63.8 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-01-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 63.81596439730074
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 222
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 27.793
    learner:
      cur_lr: 0.0012860740534961224
      grad_gnorm: 0.1141095981001854
      policy_entropy: 0.02331208623945713
      policy_loss: 2.256663719890639e-06
      var_gnorm: 21.921419143676758
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 1.0403897249489091e-05
    num_steps_sampled: 1115000
    num_steps_trained: 1115000
    wait_time_ms: 53.826
  iterations_since_restore: 223
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1987.2205157279968
  time_this_iter_s: 8.485593318939209
  time_total_s: 1987.2205157279968
  timestamp: 1594850483
  timesteps_since_restore: 1115000
  timesteps_this_iter: 5000
  timesteps_total: 1115000
  training_iteration: 223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1987 s, 223 iter, 1115000 ts, 63.8 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-01-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 54.81596444226282
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 224
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 25.462
    learner:
      cur_lr: 0.0012857409892603755
      grad_gnorm: 0.02565215900540352
      policy_entropy: 0.023440001532435417
      policy_loss: 3.1042301884554035e-07
      var_gnorm: 21.921388626098633
      vf_explained_var: -1.0
      vf_loss: 4.165917175669165e-07
    num_steps_sampled: 1120000
    num_steps_trained: 1120000
    wait_time_ms: 58.206
  iterations_since_restore: 224
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 1995.7341327667236
  time_this_iter_s: 8.513617038726807
  time_total_s: 1995.7341327667236
  timestamp: 1594850492
  timesteps_since_restore: 1120000
  timesteps_this_iter: 5000
  timesteps_total: 1120000
  training_iteration: 224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 1995 s, 224 iter, 1120000 ts, 54.8 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-01-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 54.81596444226282
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 224
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 25.216
    learner:
      cur_lr: 0.0012854080414399505
      grad_gnorm: 0.003928971476852894
      policy_entropy: 0.023604942485690117
      policy_loss: 8.64386109356019e-08
      var_gnorm: 21.921337127685547
      vf_explained_var: 0.0
      vf_loss: 1.2378218450237455e-08
    num_steps_sampled: 1125000
    num_steps_trained: 1125000
    wait_time_ms: 58.133
  iterations_since_restore: 225
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2004.1470487117767
  time_this_iter_s: 8.4129159450531
  time_total_s: 2004.1470487117767
  timestamp: 1594850500
  timesteps_since_restore: 1125000
  timesteps_this_iter: 5000
  timesteps_total: 1125000
  training_iteration: 225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2004 s, 225 iter, 1125000 ts, 54.8 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-01-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 52.08118806908975
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 226
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.112
    dispatch_time_ms: 21.679
    learner:
      cur_lr: 0.0012850749772042036
      grad_gnorm: 0.00027630123076960444
      policy_entropy: 0.023754626512527466
      policy_loss: 9.388659627518336e-09
      var_gnorm: 21.921300888061523
      vf_explained_var: 0.0
      vf_loss: 4.711101647680849e-11
    num_steps_sampled: 1130000
    num_steps_trained: 1130000
    wait_time_ms: 65.797
  iterations_since_restore: 226
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2012.7324986457825
  time_this_iter_s: 8.585449934005737
  time_total_s: 2012.7324986457825
  timestamp: 1594850509
  timesteps_since_restore: 1130000
  timesteps_this_iter: 5000
  timesteps_total: 1130000
  training_iteration: 226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2012 s, 226 iter, 1130000 ts, 52.1 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-01-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 52.08118806908975
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 226
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 16.328
    learner:
      cur_lr: 0.0012847420293837786
      grad_gnorm: 0.000705600599758327
      policy_entropy: 0.02395199052989483
      policy_loss: 3.2187475795808496e-08
      var_gnorm: 21.921239852905273
      vf_explained_var: 0.0
      vf_loss: 3.6793090796294337e-10
    num_steps_sampled: 1135000
    num_steps_trained: 1135000
    wait_time_ms: 59.776
  iterations_since_restore: 227
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2021.0970585346222
  time_this_iter_s: 8.364559888839722
  time_total_s: 2021.0970585346222
  timestamp: 1594850517
  timesteps_since_restore: 1135000
  timesteps_this_iter: 5000
  timesteps_total: 1135000
  training_iteration: 227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2021 s, 227 iter, 1135000 ts, 52.1 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-02-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 49.65118806942554
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 227
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 30.971
    learner:
      cur_lr: 0.0012844089651480317
      grad_gnorm: 0.07549219578504562
      policy_entropy: 0.02413140796124935
      policy_loss: -9.637635230319574e-06
      var_gnorm: 21.92119598388672
      vf_explained_var: 0.0
      vf_loss: 4.553518465399975e-06
    num_steps_sampled: 1140000
    num_steps_trained: 1140000
    wait_time_ms: 53.728
  iterations_since_restore: 228
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2029.652815580368
  time_this_iter_s: 8.55575704574585
  time_total_s: 2029.652815580368
  timestamp: 1594850526
  timesteps_since_restore: 1140000
  timesteps_this_iter: 5000
  timesteps_total: 1140000
  training_iteration: 228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2029 s, 228 iter, 1140000 ts, 49.7 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-02-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 48.211188069458515
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 228
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.114
    dispatch_time_ms: 28.088
    learner:
      cur_lr: 0.0012840760173276067
      grad_gnorm: 0.06375350803136826
      policy_entropy: 0.024369660764932632
      policy_loss: -9.509280062047765e-06
      var_gnorm: 21.921127319335938
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.2472660222993e-06
    num_steps_sampled: 1145000
    num_steps_trained: 1145000
    wait_time_ms: 51.114
  iterations_since_restore: 229
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2038.0718877315521
  time_this_iter_s: 8.419072151184082
  time_total_s: 2038.0718877315521
  timestamp: 1594850534
  timesteps_since_restore: 1145000
  timesteps_this_iter: 5000
  timesteps_total: 1145000
  training_iteration: 229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2038 s, 229 iter, 1145000 ts, 48.2 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-02-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 47.311188069467036
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 230
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 60.898
    learner:
      cur_lr: 0.0012837429530918598
      grad_gnorm: 18.04059410095215
      policy_entropy: 0.024577569216489792
      policy_loss: 2.4687508357601473e-06
      var_gnorm: 21.921085357666016
      vf_explained_var: 1.3113021850585938e-06
      vf_loss: 0.20606182515621185
    num_steps_sampled: 1150000
    num_steps_trained: 1150000
    wait_time_ms: 37.311
  iterations_since_restore: 230
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2047.1517732143402
  time_this_iter_s: 9.079885482788086
  time_total_s: 2047.1517732143402
  timestamp: 1594850543
  timesteps_since_restore: 1150000
  timesteps_this_iter: 5000
  timesteps_total: 1150000
  training_iteration: 230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2047 s, 230 iter, 1150000 ts, 47.3 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-02-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 47.311188069467036
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 230
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.029
    dispatch_time_ms: 27.721
    learner:
      cur_lr: 0.0012834100052714348
      grad_gnorm: 0.07754350453615189
      policy_entropy: 0.024905037134885788
      policy_loss: -2.205845703429077e-06
      var_gnorm: 21.920995712280273
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.804051968676504e-06
    num_steps_sampled: 1155000
    num_steps_trained: 1155000
    wait_time_ms: 47.013
  iterations_since_restore: 231
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2055.3766162395477
  time_this_iter_s: 8.22484302520752
  time_total_s: 2055.3766162395477
  timestamp: 1594850551
  timesteps_since_restore: 1155000
  timesteps_this_iter: 5000
  timesteps_total: 1155000
  training_iteration: 231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2055 s, 231 iter, 1155000 ts, 47.3 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-02-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 46.50135969177889
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 232
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.685
    dispatch_time_ms: 25.05
    learner:
      cur_lr: 0.0012830770574510098
      grad_gnorm: 0.002381205791607499
      policy_entropy: 0.025147713720798492
      policy_loss: -2.8353511538625753e-08
      var_gnorm: 21.920940399169922
      vf_explained_var: -1.0
      vf_loss: 3.5738390025130684e-09
    num_steps_sampled: 1160000
    num_steps_trained: 1160000
    wait_time_ms: 60.451
  iterations_since_restore: 232
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2063.8893411159515
  time_this_iter_s: 8.512724876403809
  time_total_s: 2063.8893411159515
  timestamp: 1594850560
  timesteps_since_restore: 1160000
  timesteps_this_iter: 5000
  timesteps_total: 1160000
  training_iteration: 232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2063 s, 232 iter, 1160000 ts, 46.5 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-02-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 46.50135969177889
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 232
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 27.037
    learner:
      cur_lr: 0.0012827439932152629
      grad_gnorm: 0.00021624659711960703
      policy_entropy: 0.025428999215364456
      policy_loss: 6.1519647154284485e-09
      var_gnorm: 21.920869827270508
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.658181231212197e-11
    num_steps_sampled: 1165000
    num_steps_trained: 1165000
    wait_time_ms: 56.922
  iterations_since_restore: 233
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2072.305848836899
  time_this_iter_s: 8.416507720947266
  time_total_s: 2072.305848836899
  timestamp: 1594850568
  timesteps_since_restore: 1165000
  timesteps_this_iter: 5000
  timesteps_total: 1165000
  training_iteration: 233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2072 s, 233 iter, 1165000 ts, 46.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-02-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 45.24348922991024
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 234
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.318
    dispatch_time_ms: 26.497
    learner:
      cur_lr: 0.0012824110453948379
      grad_gnorm: 1.6880970001220703
      policy_entropy: 0.039151135832071304
      policy_loss: -0.0001357249857392162
      var_gnorm: 21.92081069946289
      vf_explained_var: -1.0
      vf_loss: 0.018956612795591354
    num_steps_sampled: 1170000
    num_steps_trained: 1170000
    wait_time_ms: 45.82
  iterations_since_restore: 234
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2080.784661054611
  time_this_iter_s: 8.478812217712402
  time_total_s: 2080.784661054611
  timestamp: 1594850577
  timesteps_since_restore: 1170000
  timesteps_this_iter: 5000
  timesteps_total: 1170000
  training_iteration: 234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2080 s, 234 iter, 1170000 ts, 45.2 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-03-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 45.24348922991024
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 234
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 10.123
    learner:
      cur_lr: 0.001282077981159091
      grad_gnorm: 0.0012441835133358836
      policy_entropy: 0.026011373847723007
      policy_loss: 3.072120335900763e-08
      var_gnorm: 21.920734405517578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.2154122153162916e-09
    num_steps_sampled: 1175000
    num_steps_trained: 1175000
    wait_time_ms: 67.113
  iterations_since_restore: 235
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2096.0190098285675
  time_this_iter_s: 15.234348773956299
  time_total_s: 2096.0190098285675
  timestamp: 1594850592
  timesteps_since_restore: 1175000
  timesteps_this_iter: 5000
  timesteps_total: 1175000
  training_iteration: 235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2096 s, 235 iter, 1175000 ts, 45.2 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-03-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 37.143615611288176
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 236
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 8.544
    learner:
      cur_lr: 0.001281745033338666
      grad_gnorm: 0.00020946953736711293
      policy_entropy: 0.026319770142436028
      policy_loss: -1.4507467449575984e-09
      var_gnorm: 21.920669555664062
      vf_explained_var: -1.0
      vf_loss: 1.0353718750411023e-11
    num_steps_sampled: 1180000
    num_steps_trained: 1180000
    wait_time_ms: 70.646
  iterations_since_restore: 236
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2104.076725959778
  time_this_iter_s: 8.057716131210327
  time_total_s: 2104.076725959778
  timestamp: 1594850600
  timesteps_since_restore: 1180000
  timesteps_this_iter: 5000
  timesteps_total: 1180000
  training_iteration: 236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2104 s, 236 iter, 1180000 ts, 37.1 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-03-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 872.988509808252
  episode_reward_mean: 37.143615611288176
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 236
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.993
    dispatch_time_ms: 11.957
    learner:
      cur_lr: 0.001281411969102919
      grad_gnorm: 0.005210984498262405
      policy_entropy: 0.026698991656303406
      policy_loss: -6.447917400009828e-08
      var_gnorm: 21.92057991027832
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.160152234864654e-08
    num_steps_sampled: 1185000
    num_steps_trained: 1185000
    wait_time_ms: 64.964
  iterations_since_restore: 237
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2112.1139793395996
  time_this_iter_s: 8.037253379821777
  time_total_s: 2112.1139793395996
  timestamp: 1594850609
  timesteps_since_restore: 1185000
  timesteps_this_iter: 5000
  timesteps_total: 1185000
  training_iteration: 237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2112 s, 237 iter, 1185000 ts, 37.1 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-03-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 21.753736683211898
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 238
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.55
    dispatch_time_ms: 6.332
    learner:
      cur_lr: 0.001281079021282494
      grad_gnorm: 1.6705511808395386
      policy_entropy: 0.04105664789676666
      policy_loss: -0.00014069302415009588
      var_gnorm: 21.920507431030273
      vf_explained_var: -1.0
      vf_loss: 0.018563656136393547
    num_steps_sampled: 1190000
    num_steps_trained: 1190000
    wait_time_ms: 76.515
  iterations_since_restore: 238
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2120.1879827976227
  time_this_iter_s: 8.074003458023071
  time_total_s: 2120.1879827976227
  timestamp: 1594850617
  timesteps_since_restore: 1190000
  timesteps_this_iter: 5000
  timesteps_total: 1190000
  training_iteration: 238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2120 s, 238 iter, 1190000 ts, 21.8 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-03-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 21.753736683211898
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 238
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.895
    dispatch_time_ms: 7.837
    learner:
      cur_lr: 0.0012807459570467472
      grad_gnorm: 0.004578377585858107
      policy_entropy: 0.027488311752676964
      policy_loss: -7.209010277620109e-08
      var_gnorm: 21.920408248901367
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.6687717874219743e-08
    num_steps_sampled: 1195000
    num_steps_trained: 1195000
    wait_time_ms: 70.006
  iterations_since_restore: 239
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2128.143869638443
  time_this_iter_s: 7.9558868408203125
  time_total_s: 2128.143869638443
  timestamp: 1594850625
  timesteps_since_restore: 1195000
  timesteps_this_iter: 5000
  timesteps_total: 1195000
  training_iteration: 239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2128 s, 239 iter, 1195000 ts, 21.8 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-03-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 21.663736712777737
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 240
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 8.189
    learner:
      cur_lr: 0.0012804130092263222
      grad_gnorm: 0.0007382261683233082
      policy_entropy: 0.02791081741452217
      policy_loss: -8.688490815700334e-09
      var_gnorm: 21.92032241821289
      vf_explained_var: -1.0
      vf_loss: 3.254314040468387e-10
    num_steps_sampled: 1200000
    num_steps_trained: 1200000
    wait_time_ms: 69.25
  iterations_since_restore: 240
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2136.183807373047
  time_this_iter_s: 8.039937734603882
  time_total_s: 2136.183807373047
  timestamp: 1594850633
  timesteps_since_restore: 1200000
  timesteps_this_iter: 5000
  timesteps_total: 1200000
  training_iteration: 240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2136 s, 240 iter, 1200000 ts, 21.7 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-04-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 21.66373671277773
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 240
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.595
    dispatch_time_ms: 7.938
    learner:
      cur_lr: 0.0012800799449905753
      grad_gnorm: 0.003706268733367324
      policy_entropy: 0.028413232415914536
      policy_loss: -4.5635875522975766e-08
      var_gnorm: 21.920211791992188
      vf_explained_var: 0.0
      vf_loss: 1.0920316206863845e-08
    num_steps_sampled: 1205000
    num_steps_trained: 1205000
    wait_time_ms: 70.57
  iterations_since_restore: 241
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2144.1562674045563
  time_this_iter_s: 7.972460031509399
  time_total_s: 2144.1562674045563
  timestamp: 1594850641
  timesteps_since_restore: 1205000
  timesteps_this_iter: 5000
  timesteps_total: 1205000
  training_iteration: 241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2144 s, 241 iter, 1205000 ts, 21.7 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-04-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 21.51650116912824
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 242
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.121
    dispatch_time_ms: 7.487
    learner:
      cur_lr: 0.0012797469971701503
      grad_gnorm: 0.000789905374404043
      policy_entropy: 0.028916118666529655
      policy_loss: -1.0534709105058937e-08
      var_gnorm: 21.920116424560547
      vf_explained_var: -1.0
      vf_loss: 3.739935583446652e-10
    num_steps_sampled: 1210000
    num_steps_trained: 1210000
    wait_time_ms: 68.199
  iterations_since_restore: 242
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2152.257208108902
  time_this_iter_s: 8.100940704345703
  time_total_s: 2152.257208108902
  timestamp: 1594850649
  timesteps_since_restore: 1210000
  timesteps_this_iter: 5000
  timesteps_total: 1210000
  training_iteration: 242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2152 s, 242 iter, 1210000 ts, 21.5 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-04-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 21.51650116912824
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 242
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.841
    dispatch_time_ms: 8.731
    learner:
      cur_lr: 0.0012794140493497252
      grad_gnorm: 0.0017494502244517207
      policy_entropy: 0.02951822429895401
      policy_loss: -7.991685890829103e-08
      var_gnorm: 21.91999053955078
      vf_explained_var: 0.0
      vf_loss: 2.4243076435226385e-09
    num_steps_sampled: 1215000
    num_steps_trained: 1215000
    wait_time_ms: 65.488
  iterations_since_restore: 243
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2160.1946380138397
  time_this_iter_s: 7.937429904937744
  time_total_s: 2160.1946380138397
  timestamp: 1594850657
  timesteps_since_restore: 1215000
  timesteps_this_iter: 5000
  timesteps_total: 1215000
  training_iteration: 243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2160 s, 243 iter, 1215000 ts, 21.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-04-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 21.487054879555043
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 244
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.983
    dispatch_time_ms: 6.524
    learner:
      cur_lr: 0.0012790809851139784
      grad_gnorm: 1.6368098258972168
      policy_entropy: 0.04531490430235863
      policy_loss: -0.00015181236085481942
      var_gnorm: 21.91988182067871
      vf_explained_var: -1.0
      vf_loss: 0.01782296411693096
    num_steps_sampled: 1220000
    num_steps_trained: 1220000
    wait_time_ms: 74.371
  iterations_since_restore: 244
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2168.2116935253143
  time_this_iter_s: 8.01705551147461
  time_total_s: 2168.2116935253143
  timestamp: 1594850665
  timesteps_since_restore: 1220000
  timesteps_this_iter: 5000
  timesteps_total: 1220000
  training_iteration: 244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2168 s, 244 iter, 1220000 ts, 21.5 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-04-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 21.487054879555043
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 244
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 9.121
    learner:
      cur_lr: 0.0012787480372935534
      grad_gnorm: 0.006082491483539343
      policy_entropy: 0.030819742009043694
      policy_loss: 4.2230215768768176e-08
      var_gnorm: 21.91973876953125
      vf_explained_var: 0.0
      vf_loss: 2.9517538635559504e-08
    num_steps_sampled: 1225000
    num_steps_trained: 1225000
    wait_time_ms: 69.565
  iterations_since_restore: 245
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2176.0857713222504
  time_this_iter_s: 7.874077796936035
  time_total_s: 2176.0857713222504
  timestamp: 1594850673
  timesteps_since_restore: 1225000
  timesteps_this_iter: 5000
  timesteps_total: 1225000
  training_iteration: 245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2176 s, 245 iter, 1225000 ts, 21.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-04-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 21.487054879555043
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 246
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.564
    dispatch_time_ms: 7.45
    learner:
      cur_lr: 0.0012784149730578065
      grad_gnorm: 1.6233259439468384
      policy_entropy: 0.047283612191677094
      policy_loss: -0.00015696535410825163
      var_gnorm: 21.919614791870117
      vf_explained_var: -1.0
      vf_loss: 0.017529932782053947
    num_steps_sampled: 1230000
    num_steps_trained: 1230000
    wait_time_ms: 65.531
  iterations_since_restore: 246
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2184.075699329376
  time_this_iter_s: 7.9899280071258545
  time_total_s: 2184.075699329376
  timestamp: 1594850681
  timesteps_since_restore: 1230000
  timesteps_this_iter: 5000
  timesteps_total: 1230000
  training_iteration: 246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2184 s, 246 iter, 1230000 ts, 21.5 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-04-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 21.487054879555043
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 246
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.012
    dispatch_time_ms: 8.648
    learner:
      cur_lr: 0.0012780820252373815
      grad_gnorm: 0.007857675664126873
      policy_entropy: 0.032421886920928955
      policy_loss: 1.33872433139004e-07
      var_gnorm: 21.919448852539062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.9298297000177627e-08
    num_steps_sampled: 1235000
    num_steps_trained: 1235000
    wait_time_ms: 67.809
  iterations_since_restore: 247
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2191.9147992134094
  time_this_iter_s: 7.839099884033203
  time_total_s: 2191.9147992134094
  timestamp: 1594850689
  timesteps_since_restore: 1235000
  timesteps_this_iter: 5000
  timesteps_total: 1235000
  training_iteration: 247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2191 s, 247 iter, 1235000 ts, 21.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-04-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 21.487054879555043
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 248
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.764
    dispatch_time_ms: 7.944
    learner:
      cur_lr: 0.0012777489610016346
      grad_gnorm: 1.6085785627365112
      policy_entropy: 0.04972401261329651
      policy_loss: -0.0001633719657547772
      var_gnorm: 21.9193058013916
      vf_explained_var: -1.0
      vf_loss: 0.01721169240772724
    num_steps_sampled: 1240000
    num_steps_trained: 1240000
    wait_time_ms: 67.092
  iterations_since_restore: 248
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2199.901675462723
  time_this_iter_s: 7.9868762493133545
  time_total_s: 2199.901675462723
  timestamp: 1594850697
  timesteps_since_restore: 1240000
  timesteps_this_iter: 5000
  timesteps_total: 1240000
  training_iteration: 248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2199 s, 248 iter, 1240000 ts, 21.5 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-05-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 21.487054879555043
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 248
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.491
    dispatch_time_ms: 7.12
    learner:
      cur_lr: 0.0012774160131812096
      grad_gnorm: 0.00492755277082324
      policy_entropy: 0.03440641239285469
      policy_loss: 1.5276012277354312e-07
      var_gnorm: 21.91911506652832
      vf_explained_var: 0.0
      vf_loss: 1.939185345634087e-08
    num_steps_sampled: 1245000
    num_steps_trained: 1245000
    wait_time_ms: 71.372
  iterations_since_restore: 249
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2207.83207321167
  time_this_iter_s: 7.9303977489471436
  time_total_s: 2207.83207321167
  timestamp: 1594850705
  timesteps_since_restore: 1245000
  timesteps_this_iter: 5000
  timesteps_total: 1245000
  training_iteration: 249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2207 s, 249 iter, 1245000 ts, 21.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-05-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 18.031454962917582
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 250
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.179
    dispatch_time_ms: 7.383
    learner:
      cur_lr: 0.0012770829489454627
      grad_gnorm: 1.5923662185668945
      policy_entropy: 0.05274380370974541
      policy_loss: -0.00017139408737421036
      var_gnorm: 21.918947219848633
      vf_explained_var: -1.0
      vf_loss: 0.016867149621248245
    num_steps_sampled: 1250000
    num_steps_trained: 1250000
    wait_time_ms: 69.394
  iterations_since_restore: 250
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2215.757402896881
  time_this_iter_s: 7.925329685211182
  time_total_s: 2215.757402896881
  timestamp: 1594850713
  timesteps_since_restore: 1250000
  timesteps_this_iter: 5000
  timesteps_total: 1250000
  training_iteration: 250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2215 s, 250 iter, 1250000 ts, 18 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-05-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 18.031454962917586
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 250
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.027
    dispatch_time_ms: 7.765
    learner:
      cur_lr: 0.0012767500011250377
      grad_gnorm: 0.0028877032455056906
      policy_entropy: 0.03689141571521759
      policy_loss: 1.1881392225632226e-07
      var_gnorm: 21.918725967407227
      vf_explained_var: 0.0
      vf_loss: 6.575012534426605e-09
    num_steps_sampled: 1255000
    num_steps_trained: 1255000
    wait_time_ms: 70.444
  iterations_since_restore: 251
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2223.636102437973
  time_this_iter_s: 7.878699541091919
  time_total_s: 2223.636102437973
  timestamp: 1594850721
  timesteps_since_restore: 1255000
  timesteps_this_iter: 5000
  timesteps_total: 1255000
  training_iteration: 251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2223 s, 251 iter, 1255000 ts, 18 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-05-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 242.99999984518533
  episode_reward_mean: 16.501454962983328
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 251
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.594
    dispatch_time_ms: 7.324
    learner:
      cur_lr: 0.0012764170533046126
      grad_gnorm: 0.00044207973405718803
      policy_entropy: 0.038272675126791
      policy_loss: 5.673078895540584e-09
      var_gnorm: 21.918535232543945
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.1282257766920267e-10
    num_steps_sampled: 1260000
    num_steps_trained: 1260000
    wait_time_ms: 71.377
  iterations_since_restore: 252
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2231.4494535923004
  time_this_iter_s: 7.813351154327393
  time_total_s: 2231.4494535923004
  timestamp: 1594850729
  timesteps_since_restore: 1260000
  timesteps_this_iter: 5000
  timesteps_total: 1260000
  training_iteration: 252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2231 s, 252 iter, 1260000 ts, 16.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-05-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 14.071454964531474
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 252
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 7.538
    learner:
      cur_lr: 0.0012760839890688658
      grad_gnorm: 0.002696140669286251
      policy_entropy: 0.040063656866550446
      policy_loss: 6.509984018521209e-08
      var_gnorm: 21.918275833129883
      vf_explained_var: 0.0
      vf_loss: 5.720749207682729e-09
    num_steps_sampled: 1265000
    num_steps_trained: 1265000
    wait_time_ms: 69.661
  iterations_since_restore: 253
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2239.412480354309
  time_this_iter_s: 7.963026762008667
  time_total_s: 2239.412480354309
  timestamp: 1594850737
  timesteps_since_restore: 1265000
  timesteps_this_iter: 5000
  timesteps_total: 1265000
  training_iteration: 253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2239 s, 253 iter, 1265000 ts, 14.1 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-05-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 13.801454964534024
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 253
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 10.592
    learner:
      cur_lr: 0.0012757510412484407
      grad_gnorm: 0.051063064485788345
      policy_entropy: 0.04189946502447128
      policy_loss: 9.664132676334702e-07
      var_gnorm: 21.918046951293945
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.0837255760852713e-06
    num_steps_sampled: 1270000
    num_steps_trained: 1270000
    wait_time_ms: 67.539
  iterations_since_restore: 254
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2247.4612712860107
  time_this_iter_s: 8.04879093170166
  time_total_s: 2247.4612712860107
  timestamp: 1594850745
  timesteps_since_restore: 1270000
  timesteps_this_iter: 5000
  timesteps_total: 1270000
  training_iteration: 254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2247 s, 254 iter, 1270000 ts, 13.8 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-05-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 13.801454964534024
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 254
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.594
    dispatch_time_ms: 18.982
    learner:
      cur_lr: 0.0012754179770126939
      grad_gnorm: 0.044771187007427216
      policy_entropy: 0.0442560538649559
      policy_loss: -4.288343546932083e-08
      var_gnorm: 21.91774559020996
      vf_explained_var: 0.0
      vf_loss: 1.2697012152784737e-06
    num_steps_sampled: 1275000
    num_steps_trained: 1275000
    wait_time_ms: 63.138
  iterations_since_restore: 255
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2255.7299699783325
  time_this_iter_s: 8.268698692321777
  time_total_s: 2255.7299699783325
  timestamp: 1594850753
  timesteps_since_restore: 1275000
  timesteps_this_iter: 5000
  timesteps_total: 1275000
  training_iteration: 255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2255 s, 255 iter, 1275000 ts, 13.8 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-06-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 13.441454964537535
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 255
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.616
    dispatch_time_ms: 27.885
    learner:
      cur_lr: 0.0012750850291922688
      grad_gnorm: 0.10612744092941284
      policy_entropy: 0.04678121954202652
      policy_loss: -3.160827327519655e-05
      var_gnorm: 21.917463302612305
      vf_explained_var: 0.0
      vf_loss: 8.998372322821524e-06
    num_steps_sampled: 1280000
    num_steps_trained: 1280000
    wait_time_ms: 56.976
  iterations_since_restore: 256
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2264.240168571472
  time_this_iter_s: 8.510198593139648
  time_total_s: 2264.240168571472
  timestamp: 1594850762
  timesteps_since_restore: 1280000
  timesteps_this_iter: 5000
  timesteps_total: 1280000
  training_iteration: 256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2264 s, 256 iter, 1280000 ts, 13.4 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-06-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 13.17145496454013
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 256
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.576
    dispatch_time_ms: 30.784
    learner:
      cur_lr: 0.001274751964956522
      grad_gnorm: 0.03055415488779545
      policy_entropy: 0.04926195368170738
      policy_loss: 4.482027179619763e-06
      var_gnorm: 21.917173385620117
      vf_explained_var: 0.0
      vf_loss: 7.463136739715992e-07
    num_steps_sampled: 1285000
    num_steps_trained: 1285000
    wait_time_ms: 52.918
  iterations_since_restore: 257
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2272.703637599945
  time_this_iter_s: 8.4634690284729
  time_total_s: 2272.703637599945
  timestamp: 1594850770
  timesteps_since_restore: 1285000
  timesteps_this_iter: 5000
  timesteps_total: 1285000
  training_iteration: 257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2272 s, 257 iter, 1285000 ts, 13.2 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-06-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 13.17145496454013
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 257
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 25.78
    learner:
      cur_lr: 0.001274419017136097
      grad_gnorm: 0.17382340133190155
      policy_entropy: 0.0527183935046196
      policy_loss: -3.551652480382472e-05
      var_gnorm: 21.91683578491211
      vf_explained_var: 0.0
      vf_loss: 2.4142000256688334e-05
    num_steps_sampled: 1290000
    num_steps_trained: 1290000
    wait_time_ms: 71.545
  iterations_since_restore: 258
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2281.37171626091
  time_this_iter_s: 8.668078660964966
  time_total_s: 2281.37171626091
  timestamp: 1594850779
  timesteps_since_restore: 1290000
  timesteps_this_iter: 5000
  timesteps_total: 1290000
  training_iteration: 258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2281 s, 258 iter, 1290000 ts, 13.2 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-06-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 12.90145496454268
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 258
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.565
    dispatch_time_ms: 26.344
    learner:
      cur_lr: 0.00127408595290035
      grad_gnorm: 0.03072434477508068
      policy_entropy: 0.05156921222805977
      policy_loss: -2.1157502487767488e-06
      var_gnorm: 21.91685676574707
      vf_explained_var: 0.0
      vf_loss: 7.54489121845836e-07
    num_steps_sampled: 1295000
    num_steps_trained: 1295000
    wait_time_ms: 58.683
  iterations_since_restore: 259
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2289.8782529830933
  time_this_iter_s: 8.506536722183228
  time_total_s: 2289.8782529830933
  timestamp: 1594850787
  timesteps_since_restore: 1295000
  timesteps_this_iter: 5000
  timesteps_total: 1295000
  training_iteration: 259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2289 s, 259 iter, 1295000 ts, 12.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-06-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 12.54145496454613
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 259
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 27.77
    learner:
      cur_lr: 0.001273753005079925
      grad_gnorm: 0.044181063771247864
      policy_entropy: 0.055614303797483444
      policy_loss: -1.591857107996475e-05
      var_gnorm: 21.916492462158203
      vf_explained_var: 0.0
      vf_loss: 1.5594511069139116e-06
    num_steps_sampled: 1300000
    num_steps_trained: 1300000
    wait_time_ms: 49.476
  iterations_since_restore: 260
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2298.4316873550415
  time_this_iter_s: 8.553434371948242
  time_total_s: 2298.4316873550415
  timestamp: 1594850796
  timesteps_since_restore: 1300000
  timesteps_this_iter: 5000
  timesteps_total: 1300000
  training_iteration: 260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2298 s, 260 iter, 1300000 ts, 12.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-06-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 12.361454964547809
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 260
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.996
    dispatch_time_ms: 30.866
    learner:
      cur_lr: 0.0012734200572595
      grad_gnorm: 0.0003673112078104168
      policy_entropy: 0.05732809379696846
      policy_loss: -1.2318412956346947e-09
      var_gnorm: 21.91630744934082
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.849391721517549e-12
    num_steps_sampled: 1305000
    num_steps_trained: 1305000
    wait_time_ms: 57.134
  iterations_since_restore: 261
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2306.973647594452
  time_this_iter_s: 8.5419602394104
  time_total_s: 2306.973647594452
  timestamp: 1594850805
  timesteps_since_restore: 1305000
  timesteps_this_iter: 5000
  timesteps_total: 1305000
  training_iteration: 261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2306 s, 261 iter, 1305000 ts, 12.4 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-06-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 11.461454964556301
  episode_reward_min: 0.0
  episodes_this_iter: 2
  episodes_total: 262
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.576
    dispatch_time_ms: 25.89
    learner:
      cur_lr: 0.0012730869930237532
      grad_gnorm: 0.0005038808449171484
      policy_entropy: 0.06322433054447174
      policy_loss: 1.047122978603543e-11
      var_gnorm: 21.915857315063477
      vf_explained_var: 0.0
      vf_loss: 6.22134010974662e-11
    num_steps_sampled: 1310000
    num_steps_trained: 1310000
    wait_time_ms: 77.362
  iterations_since_restore: 262
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2315.6029064655304
  time_this_iter_s: 8.629258871078491
  time_total_s: 2315.6029064655304
  timestamp: 1594850813
  timesteps_since_restore: 1310000
  timesteps_this_iter: 5000
  timesteps_total: 1310000
  training_iteration: 262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2315 s, 262 iter, 1310000 ts, 11.5 rew

Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-07-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 11.4614549645563
  episode_reward_min: 0.0
  episodes_this_iter: 0
  episodes_total: 262
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.817
    dispatch_time_ms: 25.19
    learner:
      cur_lr: 0.0012727540452033281
      grad_gnorm: 0.7875123023986816
      policy_entropy: 0.07488760352134705
      policy_loss: 1.5111675111256773e-07
      var_gnorm: 21.91530990600586
      vf_explained_var: 4.231929779052734e-06
      vf_loss: 0.00039263995131477714
    num_steps_sampled: 1315000
    num_steps_trained: 1315000
    wait_time_ms: 116.377
  iterations_since_restore: 263
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2324.4811210632324
  time_this_iter_s: 8.878214597702026
  time_total_s: 2324.4811210632324
  timestamp: 1594850822
  timesteps_since_restore: 1315000
  timesteps_this_iter: 5000
  timesteps_total: 1315000
  training_iteration: 263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2324 s, 263 iter, 1315000 ts, 11.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-07-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 11.10145496455975
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 263
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.492
    dispatch_time_ms: 7.153
    learner:
      cur_lr: 0.0012724209809675813
      grad_gnorm: 0.08937551826238632
      policy_entropy: 0.08473118394613266
      policy_loss: -1.6443409549538046e-05
      var_gnorm: 21.9148006439209
      vf_explained_var: 0.0
      vf_loss: 6.3816437432251405e-06
    num_steps_sampled: 1320000
    num_steps_trained: 1320000
    wait_time_ms: 70.828
  iterations_since_restore: 264
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2332.3132677078247
  time_this_iter_s: 7.832146644592285
  time_total_s: 2332.3132677078247
  timestamp: 1594850830
  timesteps_since_restore: 1320000
  timesteps_this_iter: 5000
  timesteps_total: 1320000
  training_iteration: 264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2332 s, 264 iter, 1320000 ts, 11.1 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-07-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 10.651454964563987
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 264
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.785
    dispatch_time_ms: 8.324
    learner:
      cur_lr: 0.0012720880331471562
      grad_gnorm: 0.009989338926970959
      policy_entropy: 0.10030385106801987
      policy_loss: 4.931021067022812e-07
      var_gnorm: 21.913955688476562
      vf_explained_var: 0.0
      vf_loss: 7.940484891832966e-08
    num_steps_sampled: 1325000
    num_steps_trained: 1325000
    wait_time_ms: 71.331
  iterations_since_restore: 265
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2340.4106509685516
  time_this_iter_s: 8.097383260726929
  time_total_s: 2340.4106509685516
  timestamp: 1594850838
  timesteps_since_restore: 1325000
  timesteps_this_iter: 5000
  timesteps_total: 1325000
  training_iteration: 265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2340 s, 265 iter, 1325000 ts, 10.7 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-07-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 10.20145496456835
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 265
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.172
    dispatch_time_ms: 6.221
    learner:
      cur_lr: 0.0012717549689114094
      grad_gnorm: 0.05184882879257202
      policy_entropy: 0.12541864812374115
      policy_loss: 3.2869534152268898e-06
      var_gnorm: 21.91312026977539
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.14724582292547e-06
    num_steps_sampled: 1330000
    num_steps_trained: 1330000
    wait_time_ms: 74.691
  iterations_since_restore: 266
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2348.5310883522034
  time_this_iter_s: 8.120437383651733
  time_total_s: 2348.5310883522034
  timestamp: 1594850846
  timesteps_since_restore: 1330000
  timesteps_this_iter: 5000
  timesteps_total: 1330000
  training_iteration: 266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2348 s, 266 iter, 1330000 ts, 10.2 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-07-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 9.841454964571732
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 266
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.017
    dispatch_time_ms: 9.328
    learner:
      cur_lr: 0.0012714220210909843
      grad_gnorm: 0.006269859615713358
      policy_entropy: 0.1741017997264862
      policy_loss: 2.1258774722809903e-06
      var_gnorm: 21.911958694458008
      vf_explained_var: 0.0
      vf_loss: 3.051156838296265e-08
    num_steps_sampled: 1335000
    num_steps_trained: 1335000
    wait_time_ms: 70.675
  iterations_since_restore: 267
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2356.615511417389
  time_this_iter_s: 8.084423065185547
  time_total_s: 2356.615511417389
  timestamp: 1594850854
  timesteps_since_restore: 1335000
  timesteps_this_iter: 5000
  timesteps_total: 1335000
  training_iteration: 267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2356 s, 267 iter, 1335000 ts, 9.84 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-07-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 9.841454964571733
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 267
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.061
    dispatch_time_ms: 10.551
    learner:
      cur_lr: 0.0012710889568552375
      grad_gnorm: 0.1475970447063446
      policy_entropy: 0.2778829038143158
      policy_loss: -1.0766902960313018e-06
      var_gnorm: 21.910703659057617
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.740038896969054e-05
    num_steps_sampled: 1340000
    num_steps_trained: 1340000
    wait_time_ms: 68.071
  iterations_since_restore: 268
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2364.7039716243744
  time_this_iter_s: 8.088460206985474
  time_total_s: 2364.7039716243744
  timestamp: 1594850863
  timesteps_since_restore: 1340000
  timesteps_this_iter: 5000
  timesteps_total: 1340000
  training_iteration: 268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2364 s, 268 iter, 1340000 ts, 9.84 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-07-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 9.571454964574281
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 268
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 6.346
    learner:
      cur_lr: 0.0012707560090348125
      grad_gnorm: 0.022868085652589798
      policy_entropy: 3.1248526573181152
      policy_loss: -4.900691783404909e-05
      var_gnorm: 21.940616607666016
      vf_explained_var: 0.0
      vf_loss: 1.5069676351231465e-07
    num_steps_sampled: 1345000
    num_steps_trained: 1345000
    wait_time_ms: 75.859
  iterations_since_restore: 269
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2372.8383252620697
  time_this_iter_s: 8.134353637695312
  time_total_s: 2372.8383252620697
  timestamp: 1594850871
  timesteps_since_restore: 1345000
  timesteps_this_iter: 5000
  timesteps_total: 1345000
  training_iteration: 269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2372 s, 269 iter, 1345000 ts, 9.57 rew

agent-1: 14.132690702724519
agent-2: 20.132690702724513
agent-3: 19.13269070272452
agent-4: 14.132690702724522
agent-5: 15.13269070272452
Extrinsic Rewards:
1
7
6
1
2
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.4
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-07-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 10.038089499714019
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 269
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.792
    dispatch_time_ms: 8.91
    learner:
      cur_lr: 0.0012704229447990656
      grad_gnorm: 39.999996185302734
      policy_entropy: 26.16029930114746
      policy_loss: 52.118133544921875
      var_gnorm: 22.026121139526367
      vf_explained_var: 0.0
      vf_loss: 113.94293975830078
    num_steps_sampled: 1350000
    num_steps_trained: 1350000
    wait_time_ms: 75.128
  iterations_since_restore: 270
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2380.9528172016144
  time_this_iter_s: 8.114491939544678
  time_total_s: 2380.9528172016144
  timestamp: 1594850879
  timesteps_since_restore: 1350000
  timesteps_this_iter: 5000
  timesteps_total: 1350000
  training_iteration: 270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2380 s, 270 iter, 1350000 ts, 10 rew

agent-1: 20.4771512162245
agent-2: 22.477151216224502
agent-3: 20.4771512162245
agent-4: 35.47715121622453
agent-5: 20.4771512162245
Extrinsic Rewards:
0
2
0
15
0
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 15
Gini Coefficient: 0.7529411764705882
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-08-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.99999997774333
  episode_reward_mean: 10.87194706052869
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 270
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.426
    dispatch_time_ms: 8.469
    learner:
      cur_lr: 0.0012700899969786406
      grad_gnorm: 2.1385433673858643
      policy_entropy: 0.7074429988861084
      policy_loss: -0.0010735770920291543
      var_gnorm: 21.993545532226562
      vf_explained_var: 0.0
      vf_loss: 0.0036540841683745384
    num_steps_sampled: 1355000
    num_steps_trained: 1355000
    wait_time_ms: 73.365
  iterations_since_restore: 271
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2389.4480464458466
  time_this_iter_s: 8.495229244232178
  time_total_s: 2389.4480464458466
  timestamp: 1594850887
  timesteps_since_restore: 1355000
  timesteps_this_iter: 5000
  timesteps_total: 1355000
  training_iteration: 271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2389 s, 271 iter, 1355000 ts, 10.9 rew

agent-1: 39.99999999812889
agent-2: 41.99999999812889
agent-3: 47.99999999812889
agent-4: 45.99999999812889
agent-5: 48.99999999812889
Extrinsic Rewards:
0
2
8
6
9
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.384
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-08-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.9999999906436
  episode_reward_mean: 12.581953539300958
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 271
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 6.782
    learner:
      cur_lr: 0.0012697570491582155
      grad_gnorm: 0.06902158260345459
      policy_entropy: 0.44156089425086975
      policy_loss: 1.8097811334882863e-05
      var_gnorm: 21.994861602783203
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.8011162359907757e-06
    num_steps_sampled: 1360000
    num_steps_trained: 1360000
    wait_time_ms: 71.086
  iterations_since_restore: 272
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2397.8160541057587
  time_this_iter_s: 8.36800765991211
  time_total_s: 2397.8160541057587
  timestamp: 1594850896
  timesteps_since_restore: 1360000
  timesteps_this_iter: 5000
  timesteps_total: 1360000
  training_iteration: 272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2397 s, 272 iter, 1360000 ts, 12.6 rew

agent-1: 32.39999999951928
agent-2: 31.399999999519274
agent-3: 41.399999999519274
agent-4: 30.399999999519274
agent-5: 35.39999999951928
Extrinsic Rewards:
2
1
11
0
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.5473684210526316
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-08-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.9999999906436
  episode_reward_mean: 13.661953539282939
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 272
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.609
    dispatch_time_ms: 5.747
    learner:
      cur_lr: 0.0012694239849224687
      grad_gnorm: 0.0028308231849223375
      policy_entropy: 0.4467460811138153
      policy_loss: 2.0601868300218484e-07
      var_gnorm: 21.994834899902344
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.588157354046274e-10
    num_steps_sampled: 1365000
    num_steps_trained: 1365000
    wait_time_ms: 71.853
  iterations_since_restore: 273
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2405.9442343711853
  time_this_iter_s: 8.128180265426636
  time_total_s: 2405.9442343711853
  timestamp: 1594850904
  timesteps_since_restore: 1365000
  timesteps_this_iter: 5000
  timesteps_total: 1365000
  training_iteration: 273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2405 s, 273 iter, 1365000 ts, 13.7 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-08-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.9999999906436
  episode_reward_mean: 13.031953539289006
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 273
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.104
    dispatch_time_ms: 9.97
    learner:
      cur_lr: 0.0012690910371020436
      grad_gnorm: 0.05068973824381828
      policy_entropy: 0.4479345679283142
      policy_loss: 5.214060365688056e-06
      var_gnorm: 21.994789123535156
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.047260068138712e-06
    num_steps_sampled: 1370000
    num_steps_trained: 1370000
    wait_time_ms: 68.491
  iterations_since_restore: 274
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2414.0609798431396
  time_this_iter_s: 8.116745471954346
  time_total_s: 2414.0609798431396
  timestamp: 1594850912
  timesteps_since_restore: 1370000
  timesteps_this_iter: 5000
  timesteps_total: 1370000
  training_iteration: 274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2414 s, 274 iter, 1370000 ts, 13 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-08-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.9999999906436
  episode_reward_mean: 12.581953539293277
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 274
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 9.726
    learner:
      cur_lr: 0.0012687579728662968
      grad_gnorm: 0.0029022276867181063
      policy_entropy: 0.44772109389305115
      policy_loss: 6.981525075389072e-06
      var_gnorm: 21.994728088378906
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.846562206064277e-10
    num_steps_sampled: 1375000
    num_steps_trained: 1375000
    wait_time_ms: 69.801
  iterations_since_restore: 275
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2422.155361175537
  time_this_iter_s: 8.094381332397461
  time_total_s: 2422.155361175537
  timestamp: 1594850920
  timesteps_since_restore: 1375000
  timesteps_this_iter: 5000
  timesteps_total: 1375000
  training_iteration: 275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2422 s, 275 iter, 1375000 ts, 12.6 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-08-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.9999999906436
  episode_reward_mean: 12.40195361643805
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 275
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.028
    dispatch_time_ms: 6.392
    learner:
      cur_lr: 0.0012684250250458717
      grad_gnorm: 5.121992588043213
      policy_entropy: 0.6917667984962463
      policy_loss: -0.0019479722250252962
      var_gnorm: 21.9936466217041
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.020960401743650436
    num_steps_sampled: 1380000
    num_steps_trained: 1380000
    wait_time_ms: 74.859
  iterations_since_restore: 276
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2430.22296333313
  time_this_iter_s: 8.067602157592773
  time_total_s: 2430.22296333313
  timestamp: 1594850928
  timesteps_since_restore: 1380000
  timesteps_this_iter: 5000
  timesteps_total: 1380000
  training_iteration: 276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2430 s, 276 iter, 1380000 ts, 12.4 rew

agent-1: 1.5193388081076968
agent-2: 1.5193388081076968
agent-3: 1.5193388081076968
agent-4: 1.5193388081076968
agent-5: 2.519338808107697
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-08-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.9999999906436
  episode_reward_mean: 11.947920556848626
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 276
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.283
    dispatch_time_ms: 10.597
    learner:
      cur_lr: 0.0012680919608101249
      grad_gnorm: 0.042149174958467484
      policy_entropy: 0.831218957901001
      policy_loss: 1.8152471966459416e-05
      var_gnorm: 21.99308967590332
      vf_explained_var: 0.0
      vf_loss: 1.3995578456160729e-06
    num_steps_sampled: 1385000
    num_steps_trained: 1385000
    wait_time_ms: 67.175
  iterations_since_restore: 277
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2438.2960443496704
  time_this_iter_s: 8.073081016540527
  time_total_s: 2438.2960443496704
  timestamp: 1594850937
  timesteps_since_restore: 1385000
  timesteps_this_iter: 5000
  timesteps_total: 1385000
  training_iteration: 277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2438 s, 277 iter, 1385000 ts, 11.9 rew

agent-1: 4.580776240849552
agent-2: 4.580776240849553
agent-3: 4.580776240849553
agent-4: 3.580776240849554
agent-5: 3.580776240849554
Extrinsic Rewards:
1
1
1
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-09-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.9999999906436
  episode_reward_mean: 12.156959368891103
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 277
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.977
    dispatch_time_ms: 8.51
    learner:
      cur_lr: 0.0012677590129896998
      grad_gnorm: 6.025665760040283
      policy_entropy: 3.7727231979370117
      policy_loss: -0.23414884507656097
      var_gnorm: 21.990102767944336
      vf_explained_var: 0.0
      vf_loss: 0.028926050290465355
    num_steps_sampled: 1390000
    num_steps_trained: 1390000
    wait_time_ms: 70.959
  iterations_since_restore: 278
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2446.3611330986023
  time_this_iter_s: 8.065088748931885
  time_total_s: 2446.3611330986023
  timestamp: 1594850945
  timesteps_since_restore: 1390000
  timesteps_this_iter: 5000
  timesteps_total: 1390000
  training_iteration: 278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2446 s, 278 iter, 1390000 ts, 12.2 rew

agent-1: 1.1488190362545319
agent-2: 1.1488190362545319
agent-3: 2.1488190362545323
agent-4: 1.1488190362545319
agent-5: 1.1488190362545319
Extrinsic Rewards:
0
0
1
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-09-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.9999999906436
  episode_reward_mean: 12.22440032070383
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 278
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 5.496
    learner:
      cur_lr: 0.001267425948753953
      grad_gnorm: 40.00000762939453
      policy_entropy: 5.370131492614746
      policy_loss: -1.2852190732955933
      var_gnorm: 22.007200241088867
      vf_explained_var: 0.0
      vf_loss: 4.26335334777832
    num_steps_sampled: 1395000
    num_steps_trained: 1395000
    wait_time_ms: 79.845
  iterations_since_restore: 279
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2454.875001192093
  time_this_iter_s: 8.5138680934906
  time_total_s: 2454.875001192093
  timestamp: 1594850953
  timesteps_since_restore: 1395000
  timesteps_this_iter: 5000
  timesteps_total: 1395000
  training_iteration: 279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2454 s, 279 iter, 1395000 ts, 12.2 rew

agent-1: 40.999999835924164
agent-2: 34.99999983592415
agent-3: 36.999999835924164
agent-4: 34.99999983592416
agent-5: 31.99999983592412
Extrinsic Rewards:
9
3
5
3
0
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-09-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 224.9999999906436
  episode_reward_mean: 13.125976098167271
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 279
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.999
    dispatch_time_ms: 10.26
    learner:
      cur_lr: 0.001267093000933528
      grad_gnorm: 2.763918399810791
      policy_entropy: 1.7043269872665405
      policy_loss: -0.0008458381635136902
      var_gnorm: 21.990449905395508
      vf_explained_var: 0.0
      vf_loss: 0.00610326649621129
    num_steps_sampled: 1400000
    num_steps_trained: 1400000
    wait_time_ms: 73.562
  iterations_since_restore: 280
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2463.556007385254
  time_this_iter_s: 8.68100619316101
  time_total_s: 2463.556007385254
  timestamp: 1594850962
  timesteps_since_restore: 1400000
  timesteps_this_iter: 5000
  timesteps_total: 1400000
  training_iteration: 280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2463 s, 280 iter, 1400000 ts, 13.1 rew

agent-1: 61.599999888805144
agent-2: 70.59999988880487
agent-3: 65.59999988880486
agent-4: 57.59999988880516
agent-5: 68.5999998888049
Extrinsic Rewards:
4
13
8
0
11
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.36666666666666664
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-09-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 323.999999444028
  episode_reward_mean: 15.702938785935356
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 280
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.877
    dispatch_time_ms: 8.052
    learner:
      cur_lr: 0.001266760053113103
      grad_gnorm: 39.999996185302734
      policy_entropy: 19.46964454650879
      policy_loss: 34.81377029418945
      var_gnorm: 22.02404022216797
      vf_explained_var: 0.0
      vf_loss: 62.91061782836914
    num_steps_sampled: 1405000
    num_steps_trained: 1405000
    wait_time_ms: 76.332
  iterations_since_restore: 281
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2471.931615114212
  time_this_iter_s: 8.37560772895813
  time_total_s: 2471.931615114212
  timestamp: 1594850970
  timesteps_since_restore: 1405000
  timesteps_this_iter: 5000
  timesteps_total: 1405000
  training_iteration: 281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2471 s, 281 iter, 1405000 ts, 15.7 rew

agent-1: 68.59994922558283
agent-2: 80.59994922558285
agent-3: 74.59994922558286
agent-4: 69.59994922558283
agent-5: 75.59994922558285
Extrinsic Rewards:
3
15
9
4
10
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 3
Max Reward: 15
Gini Coefficient: 0.2926829268292683
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-09-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 368.9997461279149
  episode_reward_mean: 17.322936247383524
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 281
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.164
    dispatch_time_ms: 9.002
    learner:
      cur_lr: 0.001266426988877356
      grad_gnorm: 5.29845666885376
      policy_entropy: 1.4296984672546387
      policy_loss: -0.005670967046171427
      var_gnorm: 21.989704132080078
      vf_explained_var: 0.0
      vf_loss: 0.0224261786788702
    num_steps_sampled: 1410000
    num_steps_trained: 1410000
    wait_time_ms: 68.489
  iterations_since_restore: 282
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2480.3006067276
  time_this_iter_s: 8.368991613388062
  time_total_s: 2480.3006067276
  timestamp: 1594850979
  timesteps_since_restore: 1410000
  timesteps_this_iter: 5000
  timesteps_total: 1410000
  training_iteration: 282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2480 s, 282 iter, 1410000 ts, 17.3 rew

agent-1: 90.19990693284389
agent-2: 87.19990693284389
agent-3: 94.19990693284386
agent-4: 99.19990693284389
agent-5: 97.19990693284386
Extrinsic Rewards:
7
4
11
16
14
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 4
Max Reward: 16
Gini Coefficient: 0.23846153846153847
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-09-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 467.99953466422056
  episode_reward_mean: 19.752931594248295
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 282
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 7.923
    learner:
      cur_lr: 0.001266094041056931
      grad_gnorm: 5.434484958648682
      policy_entropy: 2.9633426666259766
      policy_loss: -0.21809329092502594
      var_gnorm: 21.98830223083496
      vf_explained_var: 0.0
      vf_loss: 0.02351214922964573
    num_steps_sampled: 1415000
    num_steps_trained: 1415000
    wait_time_ms: 71.164
  iterations_since_restore: 283
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2488.454064130783
  time_this_iter_s: 8.153457403182983
  time_total_s: 2488.454064130783
  timestamp: 1594850987
  timesteps_since_restore: 1415000
  timesteps_this_iter: 5000
  timesteps_total: 1415000
  training_iteration: 283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2488 s, 283 iter, 1415000 ts, 19.8 rew

agent-1: 17.09089631861123
agent-2: 23.090896318611208
agent-3: 23.090896318611225
agent-4: 16.090896318611232
agent-5: 16.090896318611232
Extrinsic Rewards:
1
7
7
0
0
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.56
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-09-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 467.99953466422056
  episode_reward_mean: 20.70747641017886
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 283
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.319
    dispatch_time_ms: 7.848
    learner:
      cur_lr: 0.0012657609768211842
      grad_gnorm: 40.0
      policy_entropy: 35.03640365600586
      policy_loss: 55.559532165527344
      var_gnorm: 22.001134872436523
      vf_explained_var: 0.0
      vf_loss: 88.52237701416016
    num_steps_sampled: 1420000
    num_steps_trained: 1420000
    wait_time_ms: 73.057
  iterations_since_restore: 284
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2496.5836210250854
  time_this_iter_s: 8.129556894302368
  time_total_s: 2496.5836210250854
  timestamp: 1594850995
  timesteps_since_restore: 1420000
  timesteps_this_iter: 5000
  timesteps_total: 1420000
  training_iteration: 284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2496 s, 284 iter, 1420000 ts, 20.7 rew

agent-1: 46.10155386987387
agent-2: 45.10155386987387
agent-3: 56.10155386987387
agent-4: 54.101553869873854
agent-5: 59.10155386987387
Extrinsic Rewards:
1
0
11
9
14
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.4342857142857143
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-10-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 467.99953466422056
  episode_reward_mean: 23.312554103672554
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 284
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.496
    dispatch_time_ms: 7.466
    learner:
      cur_lr: 0.0012654280290007591
      grad_gnorm: 40.0
      policy_entropy: 15.150513648986816
      policy_loss: -4.299953460693359
      var_gnorm: 22.006141662597656
      vf_explained_var: 0.0
      vf_loss: 5.808187961578369
    num_steps_sampled: 1425000
    num_steps_trained: 1425000
    wait_time_ms: 74.71
  iterations_since_restore: 285
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2505.1102039813995
  time_this_iter_s: 8.526582956314087
  time_total_s: 2505.1102039813995
  timestamp: 1594851004
  timesteps_since_restore: 1425000
  timesteps_this_iter: 5000
  timesteps_total: 1425000
  training_iteration: 285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2505 s, 285 iter, 1425000 ts, 23.3 rew

agent-1: 56.59999998809954
agent-2: 51.59999998809954
agent-3: 52.59999998809954
agent-4: 60.59999998809954
agent-5: 57.59999998809954
Extrinsic Rewards:
7
2
3
11
8
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.2967741935483871
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-10-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 467.99953466422056
  episode_reward_mean: 26.102554103077527
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 285
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.407
    dispatch_time_ms: 7.25
    learner:
      cur_lr: 0.0012650949647650123
      grad_gnorm: 40.0
      policy_entropy: 34.341796875
      policy_loss: 41.26515197753906
      var_gnorm: 21.979717254638672
      vf_explained_var: 0.0
      vf_loss: 45.83351135253906
    num_steps_sampled: 1430000
    num_steps_trained: 1430000
    wait_time_ms: 73.492
  iterations_since_restore: 286
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2513.7972552776337
  time_this_iter_s: 8.68705129623413
  time_total_s: 2513.7972552776337
  timestamp: 1594851012
  timesteps_since_restore: 1430000
  timesteps_this_iter: 5000
  timesteps_total: 1430000
  training_iteration: 286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2513 s, 286 iter, 1430000 ts, 26.1 rew

agent-1: 65.79999953267563
agent-2: 68.79999953267561
agent-3: 69.79999953267563
agent-4: 73.79999953267563
agent-5: 63.79999953267563
Extrinsic Rewards:
5
8
9
13
3
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.25263157894736843
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-10-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 467.99953466422056
  episode_reward_mean: 29.522554079711323
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 286
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.027
    dispatch_time_ms: 8.294
    learner:
      cur_lr: 0.0012647620169445872
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.272377014160156
      policy_loss: 3.8153905868530273
      var_gnorm: 21.98635482788086
      vf_explained_var: 0.0
      vf_loss: 1.6876120567321777
    num_steps_sampled: 1435000
    num_steps_trained: 1435000
    wait_time_ms: 75.153
  iterations_since_restore: 287
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2522.350905895233
  time_this_iter_s: 8.553650617599487
  time_total_s: 2522.350905895233
  timestamp: 1594851021
  timesteps_since_restore: 1435000
  timesteps_this_iter: 5000
  timesteps_total: 1435000
  training_iteration: 287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2522 s, 287 iter, 1435000 ts, 29.5 rew

agent-1: 45.59999999834889
agent-2: 50.599999998348906
agent-3: 46.59999999834889
agent-4: 47.599999998348906
agent-5: 43.599999998348906
Extrinsic Rewards:
4
9
5
6
2
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.24615384615384617
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-10-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 467.99953466422056
  episode_reward_mean: 31.862554079628765
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 287
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.122
    dispatch_time_ms: 7.854
    learner:
      cur_lr: 0.0012644289527088404
      grad_gnorm: 0.4980001747608185
      policy_entropy: 6.413603782653809
      policy_loss: -0.01090591587126255
      var_gnorm: 21.9809513092041
      vf_explained_var: 0.0
      vf_loss: 0.0001975654304260388
    num_steps_sampled: 1440000
    num_steps_trained: 1440000
    wait_time_ms: 73.093
  iterations_since_restore: 288
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2531.0891423225403
  time_this_iter_s: 8.738236427307129
  time_total_s: 2531.0891423225403
  timestamp: 1594851030
  timesteps_since_restore: 1440000
  timesteps_this_iter: 5000
  timesteps_total: 1440000
  training_iteration: 288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2531 s, 288 iter, 1440000 ts, 31.9 rew

agent-1: 99.59997917552523
agent-2: 96.59997917552529
agent-3: 88.59997917552532
agent-4: 90.59997917552533
agent-5: 83.59997917552532
Extrinsic Rewards:
18
15
7
9
2
Sum Reward: 51
Avg Reward: 10.2
Min Reward: 2
Max Reward: 18
Gini Coefficient: 0.3137254901960784
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-10-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 467.99953466422056
  episode_reward_mean: 36.45255303840497
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 288
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.684
    dispatch_time_ms: 8.287
    learner:
      cur_lr: 0.0012640960048884153
      grad_gnorm: 40.0
      policy_entropy: 14.591438293457031
      policy_loss: -5.323840141296387
      var_gnorm: 22.013885498046875
      vf_explained_var: 0.0
      vf_loss: 5.403295040130615
    num_steps_sampled: 1445000
    num_steps_trained: 1445000
    wait_time_ms: 76.293
  iterations_since_restore: 289
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2539.733261346817
  time_this_iter_s: 8.644119024276733
  time_total_s: 2539.733261346817
  timestamp: 1594851039
  timesteps_since_restore: 1445000
  timesteps_this_iter: 5000
  timesteps_total: 1445000
  training_iteration: 289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2539 s, 289 iter, 1445000 ts, 36.5 rew

agent-1: 95.59999712410801
agent-2: 106.59999712410804
agent-3: 96.59999712410801
agent-4: 98.59999712410801
agent-5: 106.59999712410801
Extrinsic Rewards:
6
17
7
9
17
Sum Reward: 56
Avg Reward: 11.2
Min Reward: 6
Max Reward: 17
Gini Coefficient: 0.22857142857142856
20:20 Ratio: 2.8333333333333335
Max-min Ratio: 2.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-10-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 503.9999856205402
  episode_reward_mean: 41.49255289461037
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 289
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.529
    dispatch_time_ms: 8.003
    learner:
      cur_lr: 0.0012637630570679903
      grad_gnorm: 2.660550355911255
      policy_entropy: 2.472667694091797
      policy_loss: -0.0636504739522934
      var_gnorm: 21.983440399169922
      vf_explained_var: 0.0
      vf_loss: 0.005651245824992657
    num_steps_sampled: 1450000
    num_steps_trained: 1450000
    wait_time_ms: 80.435
  iterations_since_restore: 290
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2548.4598636627197
  time_this_iter_s: 8.72660231590271
  time_total_s: 2548.4598636627197
  timestamp: 1594851047
  timesteps_since_restore: 1450000
  timesteps_this_iter: 5000
  timesteps_total: 1450000
  training_iteration: 290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2548 s, 290 iter, 1450000 ts, 41.5 rew

agent-1: 90.19999896132994
agent-2: 102.19999896132998
agent-3: 94.19999896132992
agent-4: 85.19999896132995
agent-5: 96.19999896132997
Extrinsic Rewards:
7
19
11
2
13
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 2
Max Reward: 19
Gini Coefficient: 0.3076923076923077
20:20 Ratio: 9.5
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-10-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 503.9999856205402
  episode_reward_mean: 46.17255284267688
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 290
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.457
    dispatch_time_ms: 6.804
    learner:
      cur_lr: 0.0012634299928322434
      grad_gnorm: 40.0
      policy_entropy: 8.704154014587402
      policy_loss: 5.635895252227783
      var_gnorm: 21.985994338989258
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 102.34516906738281
    num_steps_sampled: 1455000
    num_steps_trained: 1455000
    wait_time_ms: 73.193
  iterations_since_restore: 291
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2556.809967279434
  time_this_iter_s: 8.350103616714478
  time_total_s: 2556.809967279434
  timestamp: 1594851056
  timesteps_since_restore: 1455000
  timesteps_this_iter: 5000
  timesteps_total: 1455000
  training_iteration: 291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2556 s, 291 iter, 1455000 ts, 46.2 rew

agent-1: 121.19491821787405
agent-2: 117.19491821787402
agent-3: 116.19491821787402
agent-4: 119.19491821787402
agent-5: 118.19491821787405
Extrinsic Rewards:
16
12
11
14
13
Sum Reward: 66
Avg Reward: 13.2
Min Reward: 11
Max Reward: 16
Gini Coefficient: 0.07272727272727272
20:20 Ratio: 1.4545454545454546
Max-min Ratio: 1.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-11-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 591.9745910893713
  episode_reward_mean: 52.09229875357059
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 291
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 9.504
    learner:
      cur_lr: 0.0012630970450118184
      grad_gnorm: 40.0
      policy_entropy: 22.093917846679688
      policy_loss: -16.46213150024414
      var_gnorm: 22.031919479370117
      vf_explained_var: 0.0
      vf_loss: 11.035944938659668
    num_steps_sampled: 1460000
    num_steps_trained: 1460000
    wait_time_ms: 74.536
  iterations_since_restore: 292
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2565.6956775188446
  time_this_iter_s: 8.8857102394104
  time_total_s: 2565.6956775188446
  timestamp: 1594851065
  timesteps_since_restore: 1460000
  timesteps_this_iter: 5000
  timesteps_total: 1460000
  training_iteration: 292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2565 s, 292 iter, 1460000 ts, 52.1 rew

agent-1: 129.45332725476416
agent-2: 140.45332725476422
agent-3: 140.45332725476422
agent-4: 136.45332725476416
agent-5: 136.45332725476416
Extrinsic Rewards:
8
19
19
15
15
Sum Reward: 76
Avg Reward: 15.2
Min Reward: 8
Max Reward: 19
Gini Coefficient: 0.1368421052631579
20:20 Ratio: 2.375
Max-min Ratio: 2.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-11-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 683.2666362738203
  episode_reward_mean: 58.92496511630878
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 292
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.393
    dispatch_time_ms: 8.289
    learner:
      cur_lr: 0.0012627639807760715
      grad_gnorm: 39.999996185302734
      policy_entropy: 5.388430118560791
      policy_loss: -0.5307185053825378
      var_gnorm: 22.003021240234375
      vf_explained_var: 0.0
      vf_loss: 6.285128593444824
    num_steps_sampled: 1465000
    num_steps_trained: 1465000
    wait_time_ms: 78.031
  iterations_since_restore: 293
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2574.3460590839386
  time_this_iter_s: 8.650381565093994
  time_total_s: 2574.3460590839386
  timestamp: 1594851073
  timesteps_since_restore: 1465000
  timesteps_this_iter: 5000
  timesteps_total: 1465000
  training_iteration: 293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2574 s, 293 iter, 1465000 ts, 58.9 rew

agent-1: 76.7999999918027
agent-2: 77.7999999918027
agent-3: 79.7999999918027
agent-4: 75.79999999180272
agent-5: 76.7999999918027
Extrinsic Rewards:
8
9
11
7
8
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 7
Max Reward: 11
Gini Coefficient: 0.08372093023255814
20:20 Ratio: 1.5714285714285714
Max-min Ratio: 1.5714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-11-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 683.2666362738203
  episode_reward_mean: 62.79496511589893
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 293
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.617
    dispatch_time_ms: 8.105
    learner:
      cur_lr: 0.0012624310329556465
      grad_gnorm: 0.24076032638549805
      policy_entropy: 3.797154188156128
      policy_loss: 0.012581412680447102
      var_gnorm: 22.142658233642578
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.422473648446612e-05
    num_steps_sampled: 1470000
    num_steps_trained: 1470000
    wait_time_ms: 75.093
  iterations_since_restore: 294
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2583.0862321853638
  time_this_iter_s: 8.740173101425171
  time_total_s: 2583.0862321853638
  timestamp: 1594851082
  timesteps_since_restore: 1470000
  timesteps_this_iter: 5000
  timesteps_total: 1470000
  training_iteration: 294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2583 s, 294 iter, 1470000 ts, 62.8 rew

agent-1: 40.79999999585215
agent-2: 42.79999999585213
agent-3: 40.79999999585214
agent-4: 39.79999999585214
agent-5: 42.79999999585213
Extrinsic Rewards:
4
6
4
3
6
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 3
Max Reward: 6
Gini Coefficient: 0.1391304347826087
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-11-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 683.2666362738203
  episode_reward_mean: 64.86496511569153
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 294
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 8.477
    learner:
      cur_lr: 0.0012620979687198997
      grad_gnorm: 40.0
      policy_entropy: 30.982040405273438
      policy_loss: 7.6376051902771
      var_gnorm: 22.230724334716797
      vf_explained_var: 0.0
      vf_loss: 1.8457392454147339
    num_steps_sampled: 1475000
    num_steps_trained: 1475000
    wait_time_ms: 76.562
  iterations_since_restore: 295
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2591.6052362918854
  time_this_iter_s: 8.519004106521606
  time_total_s: 2591.6052362918854
  timestamp: 1594851091
  timesteps_since_restore: 1475000
  timesteps_this_iter: 5000
  timesteps_total: 1475000
  training_iteration: 295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2591 s, 295 iter, 1475000 ts, 64.9 rew

agent-1: 178.51154506469646
agent-2: 162.5115450646965
agent-3: 187.51154506469646
agent-4: 189.51154506469658
agent-5: 182.5115450646965
Extrinsic Rewards:
19
3
28
30
23
Sum Reward: 103
Avg Reward: 20.6
Min Reward: 3
Max Reward: 30
Gini Coefficient: 0.2446601941747573
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-11-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 73.87054236892638
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 295
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.554
    dispatch_time_ms: 6.111
    learner:
      cur_lr: 0.0012617650208994746
      grad_gnorm: 40.0
      policy_entropy: 32.15243911743164
      policy_loss: 43.82160949707031
      var_gnorm: 22.22602653503418
      vf_explained_var: 0.0
      vf_loss: 48.03768539428711
    num_steps_sampled: 1480000
    num_steps_trained: 1480000
    wait_time_ms: 78.333
  iterations_since_restore: 296
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2600.0751798152924
  time_this_iter_s: 8.469943523406982
  time_total_s: 2600.0751798152924
  timestamp: 1594851099
  timesteps_since_restore: 1480000
  timesteps_this_iter: 5000
  timesteps_total: 1480000
  training_iteration: 296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2600 s, 296 iter, 1480000 ts, 73.9 rew

agent-1: 59.79999983769641
agent-2: 62.799999837696426
agent-3: 57.79999983769641
agent-4: 57.79999983769641
agent-5: 58.79999983769641
Extrinsic Rewards:
7
10
5
5
6
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 5
Max Reward: 10
Gini Coefficient: 0.14545454545454545
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-11-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 76.84054236081118
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 296
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.028
    dispatch_time_ms: 9.364
    learner:
      cur_lr: 0.0012614319566637278
      grad_gnorm: 40.000003814697266
      policy_entropy: 2.4664835929870605
      policy_loss: -1.2929939031600952
      var_gnorm: 22.21527862548828
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.250368356704712
    num_steps_sampled: 1485000
    num_steps_trained: 1485000
    wait_time_ms: 77.106
  iterations_since_restore: 297
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2608.7902953624725
  time_this_iter_s: 8.715115547180176
  time_total_s: 2608.7902953624725
  timestamp: 1594851108
  timesteps_since_restore: 1485000
  timesteps_this_iter: 5000
  timesteps_total: 1485000
  training_iteration: 297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2608 s, 297 iter, 1485000 ts, 76.8 rew

agent-1: 42.39999999241218
agent-2: 47.39999999241218
agent-3: 43.39999999241218
agent-4: 44.399999992412184
agent-5: 38.3999999924122
Extrinsic Rewards:
4
9
5
6
0
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.3333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-11-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 79.0005423604318
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 297
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.935
    dispatch_time_ms: 9.448
    learner:
      cur_lr: 0.0012610990088433027
      grad_gnorm: 1.2272920608520508
      policy_entropy: 1.2926346063613892
      policy_loss: 0.24997802078723907
      var_gnorm: 22.212099075317383
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0009768798481673002
    num_steps_sampled: 1490000
    num_steps_trained: 1490000
    wait_time_ms: 73.628
  iterations_since_restore: 298
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2617.4628982543945
  time_this_iter_s: 8.672602891921997
  time_total_s: 2617.4628982543945
  timestamp: 1594851117
  timesteps_since_restore: 1490000
  timesteps_this_iter: 5000
  timesteps_total: 1490000
  training_iteration: 298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2617 s, 298 iter, 1490000 ts, 79 rew

agent-1: 37.19999999898096
agent-2: 41.19999999898096
agent-3: 39.19999999898096
agent-4: 37.19999999898096
agent-5: 43.19999999898095
Extrinsic Rewards:
2
6
4
2
8
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2909090909090909
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-12-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 80.98054236038085
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 298
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 8.213
    learner:
      cur_lr: 0.0012607659446075559
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.670063972473145
      policy_loss: 14.315479278564453
      var_gnorm: 22.219703674316406
      vf_explained_var: 0.0
      vf_loss: 15.733185768127441
    num_steps_sampled: 1495000
    num_steps_trained: 1495000
    wait_time_ms: 73.529
  iterations_since_restore: 299
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2625.951237678528
  time_this_iter_s: 8.4883394241333
  time_total_s: 2625.951237678528
  timestamp: 1594851125
  timesteps_since_restore: 1495000
  timesteps_this_iter: 5000
  timesteps_total: 1495000
  training_iteration: 299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2625 s, 299 iter, 1495000 ts, 81 rew

agent-1: 157.06239923026618
agent-2: 148.06239923026615
agent-3: 142.0623992302662
agent-4: 142.0623992302662
agent-5: 148.06239923026615
Extrinsic Rewards:
26
17
11
11
17
Sum Reward: 82
Avg Reward: 16.4
Min Reward: 11
Max Reward: 26
Gini Coefficient: 0.17560975609756097
20:20 Ratio: 2.3636363636363638
Max-min Ratio: 2.3636363636363638
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-12-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 88.35366232189409
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 299
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 8.432
    learner:
      cur_lr: 0.0012604329967871308
      grad_gnorm: 39.999996185302734
      policy_entropy: 6.440085411071777
      policy_loss: 0.5754228830337524
      var_gnorm: 22.23082160949707
      vf_explained_var: 0.0
      vf_loss: 12.593467712402344
    num_steps_sampled: 1500000
    num_steps_trained: 1500000
    wait_time_ms: 73.479
  iterations_since_restore: 300
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2634.5647649765015
  time_this_iter_s: 8.613527297973633
  time_total_s: 2634.5647649765015
  timestamp: 1594851134
  timesteps_since_restore: 1500000
  timesteps_this_iter: 5000
  timesteps_total: 1500000
  training_iteration: 300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2634 s, 300 iter, 1500000 ts, 88.4 rew

agent-1: 118.79933421765891
agent-2: 111.79933421765891
agent-3: 121.79933421765897
agent-4: 104.79933421765895
agent-5: 109.79933421765892
Extrinsic Rewards:
18
11
21
4
9
Sum Reward: 63
Avg Reward: 12.6
Min Reward: 4
Max Reward: 21
Gini Coefficient: 0.273015873015873
20:20 Ratio: 5.25
Max-min Ratio: 5.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-12-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 94.02362903277712
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 300
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.512
    dispatch_time_ms: 8.585
    learner:
      cur_lr: 0.0012601000489667058
      grad_gnorm: 40.0
      policy_entropy: 13.192605972290039
      policy_loss: -7.12306022644043
      var_gnorm: 22.243896484375
      vf_explained_var: 0.0
      vf_loss: 9.204798698425293
    num_steps_sampled: 1505000
    num_steps_trained: 1505000
    wait_time_ms: 76.45
  iterations_since_restore: 301
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2642.970495223999
  time_this_iter_s: 8.405730247497559
  time_total_s: 2642.970495223999
  timestamp: 1594851142
  timesteps_since_restore: 1505000
  timesteps_this_iter: 5000
  timesteps_total: 1505000
  training_iteration: 301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2642 s, 301 iter, 1505000 ts, 94 rew

agent-1: 93.79999892507179
agent-2: 93.79999892507175
agent-3: 94.79999892507176
agent-4: 92.79999892507179
agent-5: 101.79999892507178
Extrinsic Rewards:
9
9
10
8
17
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 8
Max Reward: 17
Gini Coefficient: 0.14339622641509434
20:20 Ratio: 2.125
Max-min Ratio: 2.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-12-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 98.79362897903073
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 301
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.396
    dispatch_time_ms: 9.284
    learner:
      cur_lr: 0.001259766984730959
      grad_gnorm: 8.441354751586914
      policy_entropy: 2.4654853343963623
      policy_loss: -0.01775474287569523
      var_gnorm: 22.211368560791016
      vf_explained_var: 0.0
      vf_loss: 0.05514900013804436
    num_steps_sampled: 1510000
    num_steps_trained: 1510000
    wait_time_ms: 73.996
  iterations_since_restore: 302
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2651.6360170841217
  time_this_iter_s: 8.66552186012268
  time_total_s: 2651.6360170841217
  timestamp: 1594851151
  timesteps_since_restore: 1510000
  timesteps_this_iter: 5000
  timesteps_total: 1510000
  training_iteration: 302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2651 s, 302 iter, 1510000 ts, 98.8 rew

agent-1: 77.59999997257601
agent-2: 84.599999972576
agent-3: 85.59999997257601
agent-4: 84.59999997257601
agent-5: 81.59999997257601
Extrinsic Rewards:
4
11
12
11
8
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.16521739130434782
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-12-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 102.93362897765957
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 302
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.336
    dispatch_time_ms: 8.604
    learner:
      cur_lr: 0.001259434036910534
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.180420875549316
      policy_loss: 39.77530288696289
      var_gnorm: 22.23080825805664
      vf_explained_var: 0.0
      vf_loss: 151.87234497070312
    num_steps_sampled: 1515000
    num_steps_trained: 1515000
    wait_time_ms: 72.615
  iterations_since_restore: 303
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2659.878839492798
  time_this_iter_s: 8.242822408676147
  time_total_s: 2659.878839492798
  timestamp: 1594851159
  timesteps_since_restore: 1515000
  timesteps_this_iter: 5000
  timesteps_total: 1515000
  training_iteration: 303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2659 s, 303 iter, 1515000 ts, 103 rew

agent-1: 99.9999897094543
agent-2: 94.9999897094543
agent-3: 98.9999897094543
agent-4: 100.9999897094543
agent-5: 99.9999897094543
Extrinsic Rewards:
12
7
11
13
12
Sum Reward: 55
Avg Reward: 11.0
Min Reward: 7
Max Reward: 13
Gini Coefficient: 0.09454545454545454
20:20 Ratio: 1.8571428571428572
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-12-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 107.88362846313231
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 303
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.939
    dispatch_time_ms: 10.609
    learner:
      cur_lr: 0.001259100972674787
      grad_gnorm: 17.684667587280273
      policy_entropy: 4.588830947875977
      policy_loss: -1.203195571899414
      var_gnorm: 22.209304809570312
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.23817314207553864
    num_steps_sampled: 1520000
    num_steps_trained: 1520000
    wait_time_ms: 71.606
  iterations_since_restore: 304
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2668.4230496883392
  time_this_iter_s: 8.544210195541382
  time_total_s: 2668.4230496883392
  timestamp: 1594851168
  timesteps_since_restore: 1520000
  timesteps_this_iter: 5000
  timesteps_total: 1520000
  training_iteration: 304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2668 s, 304 iter, 1520000 ts, 108 rew

agent-1: 169.79997073333053
agent-2: 147.79997073333053
agent-3: 142.79997073333064
agent-4: 145.79997073333058
agent-5: 140.79997073333064
Extrinsic Rewards:
37
15
10
13
8
Sum Reward: 83
Avg Reward: 16.6
Min Reward: 8
Max Reward: 37
Gini Coefficient: 0.3036144578313253
20:20 Ratio: 4.625
Max-min Ratio: 4.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-12-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 115.35362699979883
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 304
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 9.062
    learner:
      cur_lr: 0.001258768024854362
      grad_gnorm: 40.0
      policy_entropy: 6.178925037384033
      policy_loss: -0.6693025827407837
      var_gnorm: 22.221410751342773
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.196340560913086
    num_steps_sampled: 1525000
    num_steps_trained: 1525000
    wait_time_ms: 75.381
  iterations_since_restore: 305
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2676.8566570281982
  time_this_iter_s: 8.433607339859009
  time_total_s: 2676.8566570281982
  timestamp: 1594851176
  timesteps_since_restore: 1525000
  timesteps_this_iter: 5000
  timesteps_total: 1525000
  training_iteration: 305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2676 s, 305 iter, 1525000 ts, 115 rew

agent-1: 91.99999933438819
agent-2: 92.99999933438819
agent-3: 89.99999933438818
agent-4: 89.99999933438819
agent-5: 84.99999933438816
Extrinsic Rewards:
12
13
10
10
5
Sum Reward: 50
Avg Reward: 10.0
Min Reward: 5
Max Reward: 13
Gini Coefficient: 0.144
20:20 Ratio: 2.6
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-13-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 119.85362696651826
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 305
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.967
    dispatch_time_ms: 8.614
    learner:
      cur_lr: 0.0012584349606186152
      grad_gnorm: 40.0
      policy_entropy: 2.9166007041931152
      policy_loss: 4.263656139373779
      var_gnorm: 22.209028244018555
      vf_explained_var: 0.0
      vf_loss: 3.9812607765197754
    num_steps_sampled: 1530000
    num_steps_trained: 1530000
    wait_time_ms: 73.54
  iterations_since_restore: 306
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2685.410633087158
  time_this_iter_s: 8.553976058959961
  time_total_s: 2685.410633087158
  timestamp: 1594851185
  timesteps_since_restore: 1530000
  timesteps_this_iter: 5000
  timesteps_total: 1530000
  training_iteration: 306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2685 s, 306 iter, 1530000 ts, 120 rew

agent-1: 74.39999987038347
agent-2: 80.39999987038344
agent-3: 81.39999987038343
agent-4: 88.39999987038343
agent-5: 71.39999987038347
Extrinsic Rewards:
4
10
11
18
1
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 1
Max Reward: 18
Gini Coefficient: 0.37272727272727274
20:20 Ratio: 18.0
Max-min Ratio: 18.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-13-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 123.81362696003744
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 306
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.545
    dispatch_time_ms: 7.055
    learner:
      cur_lr: 0.0012581020127981901
      grad_gnorm: 39.99999237060547
      policy_entropy: 34.85464859008789
      policy_loss: -8.965486526489258
      var_gnorm: 22.228330612182617
      vf_explained_var: 0.0
      vf_loss: 2.109105110168457
    num_steps_sampled: 1535000
    num_steps_trained: 1535000
    wait_time_ms: 77.689
  iterations_since_restore: 307
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2693.7816269397736
  time_this_iter_s: 8.370993852615356
  time_total_s: 2693.7816269397736
  timestamp: 1594851193
  timesteps_since_restore: 1535000
  timesteps_this_iter: 5000
  timesteps_total: 1535000
  training_iteration: 307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2693 s, 307 iter, 1535000 ts, 124 rew

agent-1: 112.39995436273743
agent-2: 120.3999543627374
agent-3: 115.3999543627374
agent-4: 119.39995436273743
agent-5: 108.3999543627374
Extrinsic Rewards:
10
18
13
17
6
Sum Reward: 64
Avg Reward: 12.8
Min Reward: 6
Max Reward: 18
Gini Coefficient: 0.19375
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-13-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 129.57362467817424
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 307
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 7.121
    learner:
      cur_lr: 0.0012577689485624433
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.10466480255127
      policy_loss: 35.99570083618164
      var_gnorm: 22.207048416137695
      vf_explained_var: 0.0
      vf_loss: 94.00188446044922
    num_steps_sampled: 1540000
    num_steps_trained: 1540000
    wait_time_ms: 76.109
  iterations_since_restore: 308
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2702.3755915164948
  time_this_iter_s: 8.593964576721191
  time_total_s: 2702.3755915164948
  timestamp: 1594851202
  timesteps_since_restore: 1540000
  timesteps_this_iter: 5000
  timesteps_total: 1540000
  training_iteration: 308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2702 s, 308 iter, 1540000 ts, 130 rew

agent-1: 85.39999887938468
agent-2: 91.39999887938463
agent-3: 82.39999887938465
agent-4: 90.39999887938465
agent-5: 91.39999887938463
Extrinsic Rewards:
7
13
4
12
13
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 4
Max Reward: 13
Gini Coefficient: 0.19591836734693877
20:20 Ratio: 3.25
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-13-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 133.98362462214348
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 308
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.131
    dispatch_time_ms: 7.509
    learner:
      cur_lr: 0.0012574360007420182
      grad_gnorm: 15.89134407043457
      policy_entropy: 29.504169464111328
      policy_loss: -2.428164005279541
      var_gnorm: 22.20568084716797
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.1940736323595047
    num_steps_sampled: 1545000
    num_steps_trained: 1545000
    wait_time_ms: 72.453
  iterations_since_restore: 309
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2710.8137805461884
  time_this_iter_s: 8.438189029693604
  time_total_s: 2710.8137805461884
  timestamp: 1594851210
  timesteps_since_restore: 1545000
  timesteps_this_iter: 5000
  timesteps_total: 1545000
  training_iteration: 309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2710 s, 309 iter, 1545000 ts, 134 rew

agent-1: 84.19999998610797
agent-2: 72.19999998610797
agent-3: 77.19999998610797
agent-4: 73.19999998610798
agent-5: 71.19999998610798
Extrinsic Rewards:
17
5
10
6
4
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 4
Max Reward: 17
Gini Coefficient: 0.29523809523809524
20:20 Ratio: 4.25
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-13-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 137.76362462144886
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 309
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 9.645
    learner:
      cur_lr: 0.0012571030529215932
      grad_gnorm: 2.424665927886963
      policy_entropy: 34.63595199584961
      policy_loss: 0.43278494477272034
      var_gnorm: 22.205331802368164
      vf_explained_var: 0.0
      vf_loss: 0.0010271057253703475
    num_steps_sampled: 1550000
    num_steps_trained: 1550000
    wait_time_ms: 72.776
  iterations_since_restore: 310
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2719.3264644145966
  time_this_iter_s: 8.512683868408203
  time_total_s: 2719.3264644145966
  timestamp: 1594851219
  timesteps_since_restore: 1550000
  timesteps_this_iter: 5000
  timesteps_total: 1550000
  training_iteration: 310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2719 s, 310 iter, 1550000 ts, 138 rew

agent-1: 53.59999999714551
agent-2: 59.5999999971455
agent-3: 52.5999999971455
agent-4: 58.59999999714549
agent-5: 54.599999997145495
Extrinsic Rewards:
4
10
3
9
5
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.24516129032258063
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-13-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 140.55362462130614
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 310
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.502
    dispatch_time_ms: 9.993
    learner:
      cur_lr: 0.0012567699886858463
      grad_gnorm: 7.247488975524902
      policy_entropy: 33.60987091064453
      policy_loss: -1.435256004333496
      var_gnorm: 22.203617095947266
      vf_explained_var: 0.0
      vf_loss: 0.03488096594810486
    num_steps_sampled: 1555000
    num_steps_trained: 1555000
    wait_time_ms: 77.003
  iterations_since_restore: 311
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2727.9912729263306
  time_this_iter_s: 8.664808511734009
  time_total_s: 2727.9912729263306
  timestamp: 1594851228
  timesteps_since_restore: 1555000
  timesteps_this_iter: 5000
  timesteps_total: 1555000
  training_iteration: 311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2727 s, 311 iter, 1555000 ts, 141 rew

agent-1: 42.3999999985539
agent-2: 47.399999998553916
agent-3: 42.3999999985539
agent-4: 42.3999999985539
agent-5: 41.3999999985539
Extrinsic Rewards:
4
9
4
4
3
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.2
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-13-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 142.71362462123383
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 311
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.986
    dispatch_time_ms: 8.533
    learner:
      cur_lr: 0.0012564370408654213
      grad_gnorm: 1.4001413583755493
      policy_entropy: 34.7412109375
      policy_loss: 0.18317601084709167
      var_gnorm: 22.202884674072266
      vf_explained_var: 0.0
      vf_loss: 0.0010342353489249945
    num_steps_sampled: 1560000
    num_steps_trained: 1560000
    wait_time_ms: 74.311
  iterations_since_restore: 312
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2736.616818189621
  time_this_iter_s: 8.625545263290405
  time_total_s: 2736.616818189621
  timestamp: 1594851236
  timesteps_since_restore: 1560000
  timesteps_this_iter: 5000
  timesteps_total: 1560000
  training_iteration: 312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2736 s, 312 iter, 1560000 ts, 143 rew

agent-1: 40.199999999090316
agent-2: 38.19999999909032
agent-3: 40.199999999090316
agent-4: 42.1999999990903
agent-5: 37.199999999090316
Extrinsic Rewards:
5
3
5
7
2
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.21818181818181817
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-14-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 144.69362462118835
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 312
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.575
    dispatch_time_ms: 5.525
    learner:
      cur_lr: 0.0012561039766296744
      grad_gnorm: 37.971946716308594
      policy_entropy: 34.75612258911133
      policy_loss: -6.411571502685547
      var_gnorm: 22.206829071044922
      vf_explained_var: 0.0
      vf_loss: 1.0786610841751099
    num_steps_sampled: 1565000
    num_steps_trained: 1565000
    wait_time_ms: 80.652
  iterations_since_restore: 313
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2745.199256181717
  time_this_iter_s: 8.582437992095947
  time_total_s: 2745.199256181717
  timestamp: 1594851245
  timesteps_since_restore: 1565000
  timesteps_this_iter: 5000
  timesteps_total: 1565000
  training_iteration: 313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2745 s, 313 iter, 1565000 ts, 145 rew

agent-1: 48.79999999750393
agent-2: 54.79999999750393
agent-3: 50.799999997503924
agent-4: 45.79999999750394
agent-5: 51.79999999750393
Extrinsic Rewards:
4
10
6
1
7
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.3
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-14-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 147.21362462106356
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 313
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 10.136
    learner:
      cur_lr: 0.0012557710288092494
      grad_gnorm: 40.0
      policy_entropy: 14.316322326660156
      policy_loss: 11.31324291229248
      var_gnorm: 22.203744888305664
      vf_explained_var: 0.0
      vf_loss: 13.977028846740723
    num_steps_sampled: 1570000
    num_steps_trained: 1570000
    wait_time_ms: 68.461
  iterations_since_restore: 314
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2753.794906139374
  time_this_iter_s: 8.59564995765686
  time_total_s: 2753.794906139374
  timestamp: 1594851253
  timesteps_since_restore: 1570000
  timesteps_this_iter: 5000
  timesteps_total: 1570000
  training_iteration: 314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2753 s, 314 iter, 1570000 ts, 147 rew

agent-1: 105.99986558105883
agent-2: 109.9998655810588
agent-3: 107.99986558105883
agent-4: 102.99986558105886
agent-5: 112.99986558105877
Extrinsic Rewards:
10
14
12
7
17
Sum Reward: 60
Avg Reward: 12.0
Min Reward: 7
Max Reward: 17
Gini Coefficient: 0.16
20:20 Ratio: 2.4285714285714284
Max-min Ratio: 2.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-14-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 152.61361790011657
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 314
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.902
    dispatch_time_ms: 8.298
    learner:
      cur_lr: 0.0012554379645735025
      grad_gnorm: 31.727542877197266
      policy_entropy: 34.020362854003906
      policy_loss: -5.404459476470947
      var_gnorm: 22.201099395751953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.7311860918998718
    num_steps_sampled: 1575000
    num_steps_trained: 1575000
    wait_time_ms: 74.067
  iterations_since_restore: 315
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2762.253406047821
  time_this_iter_s: 8.458499908447266
  time_total_s: 2762.253406047821
  timestamp: 1594851262
  timesteps_since_restore: 1575000
  timesteps_this_iter: 5000
  timesteps_total: 1575000
  training_iteration: 315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2762 s, 315 iter, 1575000 ts, 153 rew

agent-1: 71.39999996924045
agent-2: 55.399999969240504
agent-3: 60.399999969240504
agent-4: 58.399999969240504
agent-5: 60.399999969240504
Extrinsic Rewards:
17
1
6
4
6
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 1
Max Reward: 17
Gini Coefficient: 0.4
20:20 Ratio: 17.0
Max-min Ratio: 17.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-14-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 155.6736178985786
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 315
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 8.399
    learner:
      cur_lr: 0.0012551050167530775
      grad_gnorm: 1.0746155977249146
      policy_entropy: 31.130874633789062
      policy_loss: 0.12802274525165558
      var_gnorm: 22.19721221923828
      vf_explained_var: 0.0
      vf_loss: 0.0007551007438451052
    num_steps_sampled: 1580000
    num_steps_trained: 1580000
    wait_time_ms: 72.642
  iterations_since_restore: 316
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2770.8316485881805
  time_this_iter_s: 8.578242540359497
  time_total_s: 2770.8316485881805
  timestamp: 1594851271
  timesteps_since_restore: 1580000
  timesteps_this_iter: 5000
  timesteps_total: 1580000
  training_iteration: 316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2770 s, 316 iter, 1580000 ts, 156 rew

agent-1: 49.79999996744884
agent-2: 50.79999996744884
agent-3: 53.799999967448834
agent-4: 52.799999967448834
agent-5: 44.79999996744886
Extrinsic Rewards:
5
6
9
8
0
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.3
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-14-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 158.19361789695103
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 316
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.299
    dispatch_time_ms: 10.628
    learner:
      cur_lr: 0.0012547719525173306
      grad_gnorm: 20.21670913696289
      policy_entropy: 5.458032608032227
      policy_loss: -0.1949796974658966
      var_gnorm: 22.201509475708008
      vf_explained_var: 0.0
      vf_loss: 0.3152122497558594
    num_steps_sampled: 1585000
    num_steps_trained: 1585000
    wait_time_ms: 71.787
  iterations_since_restore: 317
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2779.400713443756
  time_this_iter_s: 8.569064855575562
  time_total_s: 2779.400713443756
  timestamp: 1594851279
  timesteps_since_restore: 1585000
  timesteps_this_iter: 5000
  timesteps_total: 1585000
  training_iteration: 317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2779 s, 317 iter, 1585000 ts, 158 rew

agent-1: 41.7999999950976
agent-2: 40.799999995097615
agent-3: 42.7999999950976
agent-4: 38.799999995097615
agent-5: 42.7999999950976
Extrinsic Rewards:
5
4
6
2
6
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.17391304347826086
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-14-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 160.26361789670594
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 317
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.143
    dispatch_time_ms: 7.275
    learner:
      cur_lr: 0.0012544390046969056
      grad_gnorm: 1.0213273763656616
      policy_entropy: 6.828797340393066
      policy_loss: -0.020109042525291443
      var_gnorm: 22.19964027404785
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0008077261736616492
    num_steps_sampled: 1590000
    num_steps_trained: 1590000
    wait_time_ms: 78.26
  iterations_since_restore: 318
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2788.1040329933167
  time_this_iter_s: 8.703319549560547
  time_total_s: 2788.1040329933167
  timestamp: 1594851288
  timesteps_since_restore: 1590000
  timesteps_this_iter: 5000
  timesteps_total: 1590000
  training_iteration: 318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2788 s, 318 iter, 1590000 ts, 160 rew

agent-1: 50.39999998180486
agent-2: 47.399999981804875
agent-3: 54.39999998180486
agent-4: 57.39999998180485
agent-5: 51.39999998180486
Extrinsic Rewards:
4
1
8
11
5
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.3310344827586207
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-14-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 162.87361789579614
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 318
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.707
    dispatch_time_ms: 7.581
    learner:
      cur_lr: 0.0012541060568764806
      grad_gnorm: 26.18366050720215
      policy_entropy: 8.640788078308105
      policy_loss: -0.8129492998123169
      var_gnorm: 22.20125389099121
      vf_explained_var: 0.0
      vf_loss: 0.5292173624038696
    num_steps_sampled: 1595000
    num_steps_trained: 1595000
    wait_time_ms: 75.235
  iterations_since_restore: 319
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2796.6671392917633
  time_this_iter_s: 8.563106298446655
  time_total_s: 2796.6671392917633
  timestamp: 1594851297
  timesteps_since_restore: 1595000
  timesteps_this_iter: 5000
  timesteps_total: 1595000
  training_iteration: 319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2796 s, 319 iter, 1595000 ts, 163 rew

agent-1: 64.59999989945798
agent-2: 71.59999989945793
agent-3: 62.599999899458055
agent-4: 61.59999989945805
agent-5: 63.599999899458055
Extrinsic Rewards:
7
14
5
4
6
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 4
Max Reward: 14
Gini Coefficient: 0.24444444444444444
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-15-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 166.11361789076906
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 319
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 10.609
    learner:
      cur_lr: 0.0012537729926407337
      grad_gnorm: 0.3770636022090912
      policy_entropy: 5.476261138916016
      policy_loss: -0.0035282387398183346
      var_gnorm: 22.199495315551758
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0001060076683643274
    num_steps_sampled: 1600000
    num_steps_trained: 1600000
    wait_time_ms: 72.518
  iterations_since_restore: 320
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2805.5151908397675
  time_this_iter_s: 8.84805154800415
  time_total_s: 2805.5151908397675
  timestamp: 1594851305
  timesteps_since_restore: 1600000
  timesteps_this_iter: 5000
  timesteps_total: 1600000
  training_iteration: 320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2805 s, 320 iter, 1600000 ts, 166 rew

agent-1: 49.399999993231035
agent-2: 58.39999999323105
agent-3: 48.399999993231035
agent-4: 54.39999999323105
agent-5: 50.39999999323105
Extrinsic Rewards:
3
12
2
8
4
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.3448275862068966
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-15-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 168.72361789043057
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 320
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.835
    dispatch_time_ms: 8.829
    learner:
      cur_lr: 0.0012534400448203087
      grad_gnorm: 14.551515579223633
      policy_entropy: 34.59607696533203
      policy_loss: 2.495011806488037
      var_gnorm: 22.213603973388672
      vf_explained_var: 0.0
      vf_loss: 0.19037961959838867
    num_steps_sampled: 1605000
    num_steps_trained: 1605000
    wait_time_ms: 74.173
  iterations_since_restore: 321
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2813.651529312134
  time_this_iter_s: 8.136338472366333
  time_total_s: 2813.651529312134
  timestamp: 1594851314
  timesteps_since_restore: 1605000
  timesteps_this_iter: 5000
  timesteps_total: 1605000
  training_iteration: 321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2813 s, 321 iter, 1605000 ts, 169 rew

agent-1: 64.59987242237698
agent-2: 61.59987242237672
agent-3: 69.59987242237703
agent-4: 61.59987242237672
agent-5: 66.59987242237705
Extrinsic Rewards:
7
4
12
4
9
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.23333333333333334
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-15-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 171.9636115115494
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 321
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.767
    dispatch_time_ms: 6.223
    learner:
      cur_lr: 0.0012531069805845618
      grad_gnorm: 39.99999237060547
      policy_entropy: 33.97882843017578
      policy_loss: 50.890586853027344
      var_gnorm: 22.196752548217773
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 70.16969299316406
    num_steps_sampled: 1610000
    num_steps_trained: 1610000
    wait_time_ms: 76.021
  iterations_since_restore: 322
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2822.29612660408
  time_this_iter_s: 8.644597291946411
  time_total_s: 2822.29612660408
  timestamp: 1594851322
  timesteps_since_restore: 1610000
  timesteps_this_iter: 5000
  timesteps_total: 1610000
  training_iteration: 322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2822 s, 322 iter, 1610000 ts, 172 rew

agent-1: 48.9999974149353
agent-2: 55.99999741493529
agent-3: 56.99999741493529
agent-4: 54.9999974149353
agent-5: 52.9999974149353
Extrinsic Rewards:
1
8
9
7
5
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.25333333333333335
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-15-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 174.66361138229615
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 322
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 8.779
    learner:
      cur_lr: 0.0012527740327641368
      grad_gnorm: 39.999996185302734
      policy_entropy: 33.43377685546875
      policy_loss: -6.247352123260498
      var_gnorm: 22.222084045410156
      vf_explained_var: 0.0
      vf_loss: 1.2495394945144653
    num_steps_sampled: 1615000
    num_steps_trained: 1615000
    wait_time_ms: 77.344
  iterations_since_restore: 323
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2830.8623535633087
  time_this_iter_s: 8.566226959228516
  time_total_s: 2830.8623535633087
  timestamp: 1594851331
  timesteps_since_restore: 1615000
  timesteps_this_iter: 5000
  timesteps_total: 1615000
  training_iteration: 323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2830 s, 323 iter, 1615000 ts, 175 rew

agent-1: 120.99997720025547
agent-2: 126.99997720025549
agent-3: 113.9999772002555
agent-4: 112.99997720025549
agent-5: 109.99997720025549
Extrinsic Rewards:
17
23
10
9
6
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 6
Max Reward: 23
Gini Coefficient: 0.25846153846153846
20:20 Ratio: 3.8333333333333335
Max-min Ratio: 3.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-15-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 180.51361024230897
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 323
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 8.35
    learner:
      cur_lr: 0.00125244096852839
      grad_gnorm: 3.5599520206451416
      policy_entropy: 11.307604789733887
      policy_loss: -0.09931159019470215
      var_gnorm: 22.197845458984375
      vf_explained_var: 0.0
      vf_loss: 0.009718634188175201
    num_steps_sampled: 1620000
    num_steps_trained: 1620000
    wait_time_ms: 73.93
  iterations_since_restore: 324
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2839.5214715003967
  time_this_iter_s: 8.659117937088013
  time_total_s: 2839.5214715003967
  timestamp: 1594851340
  timesteps_since_restore: 1620000
  timesteps_this_iter: 5000
  timesteps_total: 1620000
  training_iteration: 324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2839 s, 324 iter, 1620000 ts, 181 rew

agent-1: 73.99999993077189
agent-2: 74.99999993077188
agent-3: 69.99999993077182
agent-4: 71.99999993077188
agent-5: 68.99999993077184
Extrinsic Rewards:
10
11
6
8
5
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 5
Max Reward: 11
Gini Coefficient: 0.16
20:20 Ratio: 2.2
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-15-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 184.11361023884763
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 324
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.949
    dispatch_time_ms: 9.906
    learner:
      cur_lr: 0.001252108020707965
      grad_gnorm: 20.278968811035156
      policy_entropy: 31.116092681884766
      policy_loss: -2.5356204509735107
      var_gnorm: 22.205347061157227
      vf_explained_var: 0.0
      vf_loss: 0.2775822877883911
    num_steps_sampled: 1625000
    num_steps_trained: 1625000
    wait_time_ms: 74.181
  iterations_since_restore: 325
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2848.2077946662903
  time_this_iter_s: 8.686323165893555
  time_total_s: 2848.2077946662903
  timestamp: 1594851348
  timesteps_since_restore: 1625000
  timesteps_this_iter: 5000
  timesteps_total: 1625000
  training_iteration: 325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2848 s, 325 iter, 1625000 ts, 184 rew

agent-1: 47.39999998512087
agent-2: 59.39999998512087
agent-3: 52.39999998512087
agent-4: 49.39999998512088
agent-5: 52.399999985120864
Extrinsic Rewards:
1
13
6
3
6
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.3724137931034483
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-15-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 186.72361023810373
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 325
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.718
    dispatch_time_ms: 8.477
    learner:
      cur_lr: 0.001251774956472218
      grad_gnorm: 1.4832179546356201
      policy_entropy: 32.541969299316406
      policy_loss: -0.18356163799762726
      var_gnorm: 22.1916446685791
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0017012100433930755
    num_steps_sampled: 1630000
    num_steps_trained: 1630000
    wait_time_ms: 73.511
  iterations_since_restore: 326
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2856.7025258541107
  time_this_iter_s: 8.494731187820435
  time_total_s: 2856.7025258541107
  timestamp: 1594851357
  timesteps_since_restore: 1630000
  timesteps_this_iter: 5000
  timesteps_total: 1630000
  training_iteration: 326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2856 s, 326 iter, 1630000 ts, 187 rew

agent-1: 128.19999905051196
agent-2: 143.19999905051176
agent-3: 133.1999990505117
agent-4: 147.19999905051182
agent-5: 141.19999905051176
Extrinsic Rewards:
5
20
10
24
18
Sum Reward: 77
Avg Reward: 15.4
Min Reward: 5
Max Reward: 24
Gini Coefficient: 0.24935064935064935
20:20 Ratio: 4.8
Max-min Ratio: 4.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-16-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 193.6536101906293
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 326
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.708
    dispatch_time_ms: 8.39
    learner:
      cur_lr: 0.001251442008651793
      grad_gnorm: 28.139345169067383
      policy_entropy: 14.79321002960205
      policy_loss: 2.1558711528778076
      var_gnorm: 22.223791122436523
      vf_explained_var: 0.0
      vf_loss: 0.680587649345398
    num_steps_sampled: 1635000
    num_steps_trained: 1635000
    wait_time_ms: 74.15
  iterations_since_restore: 327
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2865.139607191086
  time_this_iter_s: 8.437081336975098
  time_total_s: 2865.139607191086
  timestamp: 1594851365
  timesteps_since_restore: 1635000
  timesteps_this_iter: 5000
  timesteps_total: 1635000
  training_iteration: 327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2865 s, 327 iter, 1635000 ts, 194 rew

agent-1: 109.7999404192982
agent-2: 103.79994041929818
agent-3: 99.79994041929818
agent-4: 107.79994041929818
agent-5: 100.79994041929821
Extrinsic Rewards:
17
11
7
15
8
Sum Reward: 58
Avg Reward: 11.6
Min Reward: 7
Max Reward: 17
Gini Coefficient: 0.18620689655172415
20:20 Ratio: 2.4285714285714284
Max-min Ratio: 2.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-16-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 198.87360721159425
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 327
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.164
    dispatch_time_ms: 7.679
    learner:
      cur_lr: 0.0012511089444160461
      grad_gnorm: 12.424711227416992
      policy_entropy: 9.185303688049316
      policy_loss: -0.3493158221244812
      var_gnorm: 22.196043014526367
      vf_explained_var: 0.0
      vf_loss: 0.11894892156124115
    num_steps_sampled: 1640000
    num_steps_trained: 1640000
    wait_time_ms: 73.98
  iterations_since_restore: 328
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2873.8822259902954
  time_this_iter_s: 8.742618799209595
  time_total_s: 2873.8822259902954
  timestamp: 1594851374
  timesteps_since_restore: 1640000
  timesteps_this_iter: 5000
  timesteps_total: 1640000
  training_iteration: 328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2873 s, 328 iter, 1640000 ts, 199 rew

agent-1: 84.59999822202282
agent-2: 85.59999822202282
agent-3: 91.59999822202282
agent-4: 78.59999822202276
agent-5: 73.59999822202269
Extrinsic Rewards:
11
12
18
5
0
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 0
Max Reward: 18
Gini Coefficient: 0.3739130434782609
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-16-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 203.01360712269536
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 328
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.811
    dispatch_time_ms: 9.195
    learner:
      cur_lr: 0.0012507759965956211
      grad_gnorm: 40.0
      policy_entropy: 25.551307678222656
      policy_loss: 15.451277732849121
      var_gnorm: 22.21961212158203
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 12.001255989074707
    num_steps_sampled: 1645000
    num_steps_trained: 1645000
    wait_time_ms: 76.87
  iterations_since_restore: 329
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2882.5860674381256
  time_this_iter_s: 8.7038414478302
  time_total_s: 2882.5860674381256
  timestamp: 1594851383
  timesteps_since_restore: 1645000
  timesteps_this_iter: 5000
  timesteps_total: 1645000
  training_iteration: 329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2882 s, 329 iter, 1645000 ts, 203 rew

agent-1: 131.99986904144723
agent-2: 136.99986904144723
agent-3: 136.99986904144725
agent-4: 130.99986904144717
agent-5: 137.99986904144723
Extrinsic Rewards:
12
17
17
11
18
Sum Reward: 75
Avg Reward: 15.0
Min Reward: 11
Max Reward: 18
Gini Coefficient: 0.10133333333333333
20:20 Ratio: 1.6363636363636365
Max-min Ratio: 1.6363636363636365
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-16-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 209.76360057476765
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 329
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.587
    dispatch_time_ms: 8.645
    learner:
      cur_lr: 0.001250443048775196
      grad_gnorm: 10.4409761428833
      policy_entropy: 4.423289775848389
      policy_loss: -0.045040350407361984
      var_gnorm: 22.196752548217773
      vf_explained_var: 0.0
      vf_loss: 0.08420395106077194
    num_steps_sampled: 1650000
    num_steps_trained: 1650000
    wait_time_ms: 75.314
  iterations_since_restore: 330
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2891.2209692001343
  time_this_iter_s: 8.634901762008667
  time_total_s: 2891.2209692001343
  timestamp: 1594851392
  timesteps_since_restore: 1650000
  timesteps_this_iter: 5000
  timesteps_total: 1650000
  training_iteration: 330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2891 s, 330 iter, 1650000 ts, 210 rew

agent-1: 76.19999995222153
agent-2: 73.19999995222155
agent-3: 78.19999995222153
agent-4: 74.19999995222153
agent-5: 76.19999995222155
Extrinsic Rewards:
9
6
11
7
9
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 6
Max Reward: 11
Gini Coefficient: 0.11428571428571428
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-16-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 213.54360057237866
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 330
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 9.113
    learner:
      cur_lr: 0.0012501099845394492
      grad_gnorm: 34.253929138183594
      policy_entropy: 34.260902404785156
      policy_loss: -6.125931262969971
      var_gnorm: 22.197053909301758
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.8728715181350708
    num_steps_sampled: 1655000
    num_steps_trained: 1655000
    wait_time_ms: 75.197
  iterations_since_restore: 331
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2899.8606050014496
  time_this_iter_s: 8.639635801315308
  time_total_s: 2899.8606050014496
  timestamp: 1594851400
  timesteps_since_restore: 1655000
  timesteps_this_iter: 5000
  timesteps_total: 1655000
  training_iteration: 331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2899 s, 331 iter, 1655000 ts, 214 rew

agent-1: 45.999999935517785
agent-2: 39.999999935517785
agent-3: 44.999999935517785
agent-4: 46.9999999355178
agent-5: 46.999999935517785
Extrinsic Rewards:
6
0
5
7
7
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.256
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-16-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 215.7936005691546
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 331
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.111
    dispatch_time_ms: 10.801
    learner:
      cur_lr: 0.0012497770367190242
      grad_gnorm: 40.0
      policy_entropy: 34.475807189941406
      policy_loss: 55.56611633300781
      var_gnorm: 22.191425323486328
      vf_explained_var: 0.0
      vf_loss: 80.11531829833984
    num_steps_sampled: 1660000
    num_steps_trained: 1660000
    wait_time_ms: 72.279
  iterations_since_restore: 332
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2908.4651029109955
  time_this_iter_s: 8.604497909545898
  time_total_s: 2908.4651029109955
  timestamp: 1594851409
  timesteps_since_restore: 1660000
  timesteps_this_iter: 5000
  timesteps_total: 1660000
  training_iteration: 332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2908 s, 332 iter, 1660000 ts, 216 rew

agent-1: 43.59999993686296
agent-2: 41.599999936862936
agent-3: 50.59999993686294
agent-4: 49.59999993686296
agent-5: 48.59999993686296
Extrinsic Rewards:
2
0
9
8
7
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.36923076923076925
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-16-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 218.13360056599774
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 332
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.64
    dispatch_time_ms: 10.55
    learner:
      cur_lr: 0.0012494439724832773
      grad_gnorm: 13.228596687316895
      policy_entropy: 27.561445236206055
      policy_loss: -1.6011608839035034
      var_gnorm: 22.193201065063477
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.1326686143875122
    num_steps_sampled: 1665000
    num_steps_trained: 1665000
    wait_time_ms: 74.796
  iterations_since_restore: 333
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2917.1026589870453
  time_this_iter_s: 8.637556076049805
  time_total_s: 2917.1026589870453
  timestamp: 1594851418
  timesteps_since_restore: 1665000
  timesteps_this_iter: 5000
  timesteps_total: 1665000
  training_iteration: 333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2917 s, 333 iter, 1665000 ts, 218 rew

agent-1: 59.99999999477167
agent-2: 50.999999994771656
agent-3: 51.999999994771656
agent-4: 54.999999994771656
agent-5: 51.999999994771656
Extrinsic Rewards:
12
3
4
7
4
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.28
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-17-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 220.83360056573628
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 333
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.254
    dispatch_time_ms: 7.566
    learner:
      cur_lr: 0.0012491110246628523
      grad_gnorm: 3.342999219894409
      policy_entropy: 32.06112289428711
      policy_loss: -0.1338760107755661
      var_gnorm: 22.191509246826172
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.008653153665363789
    num_steps_sampled: 1670000
    num_steps_trained: 1670000
    wait_time_ms: 76.997
  iterations_since_restore: 334
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2925.7384610176086
  time_this_iter_s: 8.635802030563354
  time_total_s: 2925.7384610176086
  timestamp: 1594851426
  timesteps_since_restore: 1670000
  timesteps_this_iter: 5000
  timesteps_total: 1670000
  training_iteration: 334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2925 s, 334 iter, 1670000 ts, 221 rew

agent-1: 48.79999999685711
agent-2: 50.799999996857096
agent-3: 51.7999999968571
agent-4: 45.799999996857096
agent-5: 54.7999999968571
Extrinsic Rewards:
4
6
7
1
10
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.3
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-17-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 223.35360056557911
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 334
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.076
    dispatch_time_ms: 6.718
    learner:
      cur_lr: 0.0012487779604271054
      grad_gnorm: 10.436867713928223
      policy_entropy: 21.86070442199707
      policy_loss: -0.8061954379081726
      var_gnorm: 22.193073272705078
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.08083783090114594
    num_steps_sampled: 1675000
    num_steps_trained: 1675000
    wait_time_ms: 78.196
  iterations_since_restore: 335
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2934.408784389496
  time_this_iter_s: 8.670323371887207
  time_total_s: 2934.408784389496
  timestamp: 1594851435
  timesteps_since_restore: 1675000
  timesteps_this_iter: 5000
  timesteps_total: 1675000
  training_iteration: 335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2934 s, 335 iter, 1675000 ts, 223 rew

agent-1: 41.199999999114056
agent-2: 35.19999999911407
agent-3: 36.19999999911406
agent-4: 48.19999999911405
agent-5: 37.199999999114056
Extrinsic Rewards:
6
0
1
13
2
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.5636363636363636
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-17-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 225.33360056553482
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 335
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.269
    dispatch_time_ms: 7.607
    learner:
      cur_lr: 0.0012484450126066804
      grad_gnorm: 39.99999237060547
      policy_entropy: 21.051359176635742
      policy_loss: 57.1360969543457
      var_gnorm: 22.19217300415039
      vf_explained_var: 0.0
      vf_loss: 161.2040252685547
    num_steps_sampled: 1680000
    num_steps_trained: 1680000
    wait_time_ms: 74.446
  iterations_since_restore: 336
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2943.0622022151947
  time_this_iter_s: 8.653417825698853
  time_total_s: 2943.0622022151947
  timestamp: 1594851444
  timesteps_since_restore: 1680000
  timesteps_this_iter: 5000
  timesteps_total: 1680000
  training_iteration: 336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2943 s, 336 iter, 1680000 ts, 225 rew

agent-1: 44.199999997261074
agent-2: 49.199999997261074
agent-3: 43.199999997261074
agent-4: 48.19999999726108
agent-5: 58.199999997261074
Extrinsic Rewards:
1
6
0
5
15
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 0
Max Reward: 15
Gini Coefficient: 0.5185185185185185
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-17-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 227.7636005653979
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 336
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.631
    dispatch_time_ms: 10.427
    learner:
      cur_lr: 0.0012481119483709335
      grad_gnorm: 11.696600914001465
      policy_entropy: 8.212017059326172
      policy_loss: -0.40111371874809265
      var_gnorm: 22.204538345336914
      vf_explained_var: 0.0
      vf_loss: 0.10519912093877792
    num_steps_sampled: 1685000
    num_steps_trained: 1685000
    wait_time_ms: 74.65
  iterations_since_restore: 337
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2951.754838705063
  time_this_iter_s: 8.692636489868164
  time_total_s: 2951.754838705063
  timestamp: 1594851452
  timesteps_since_restore: 1685000
  timesteps_this_iter: 5000
  timesteps_total: 1685000
  training_iteration: 337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2951 s, 337 iter, 1685000 ts, 228 rew

agent-1: 66.99999997894487
agent-2: 70.99999997894486
agent-3: 75.99999997894484
agent-4: 74.99999997894483
agent-5: 70.99999997894486
Extrinsic Rewards:
3
7
12
11
7
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.22
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-17-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 231.36360056434506
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 337
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.205
    dispatch_time_ms: 9.161
    learner:
      cur_lr: 0.0012477790005505085
      grad_gnorm: 2.9679949283599854
      policy_entropy: 10.174614906311035
      policy_loss: -0.03824169188737869
      var_gnorm: 22.202083587646484
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.006643369328230619
    num_steps_sampled: 1690000
    num_steps_trained: 1690000
    wait_time_ms: 72.27
  iterations_since_restore: 338
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2960.4510576725006
  time_this_iter_s: 8.696218967437744
  time_total_s: 2960.4510576725006
  timestamp: 1594851461
  timesteps_since_restore: 1690000
  timesteps_this_iter: 5000
  timesteps_total: 1690000
  training_iteration: 338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2960 s, 338 iter, 1690000 ts, 231 rew

agent-1: 40.39999999870883
agent-2: 44.39999999870882
agent-3: 43.39999999870881
agent-4: 40.39999999870883
agent-5: 47.39999999870882
Extrinsic Rewards:
2
6
5
2
9
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.3
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-17-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 233.52360056428057
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 338
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 7.184
    learner:
      cur_lr: 0.0012474460527300835
      grad_gnorm: 36.90156936645508
      policy_entropy: 33.59400939941406
      policy_loss: -5.6521477699279785
      var_gnorm: 22.234460830688477
      vf_explained_var: 0.0
      vf_loss: 0.9610934257507324
    num_steps_sampled: 1695000
    num_steps_trained: 1695000
    wait_time_ms: 79.939
  iterations_since_restore: 339
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2969.0781881809235
  time_this_iter_s: 8.627130508422852
  time_total_s: 2969.0781881809235
  timestamp: 1594851470
  timesteps_since_restore: 1695000
  timesteps_this_iter: 5000
  timesteps_total: 1695000
  training_iteration: 339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2969 s, 339 iter, 1695000 ts, 234 rew

agent-1: 120.79999324881393
agent-2: 122.7999932488139
agent-3: 124.7999932488139
agent-4: 123.7999932488139
agent-5: 119.7999932488139
Extrinsic Rewards:
12
14
16
15
11
Sum Reward: 68
Avg Reward: 13.6
Min Reward: 11
Max Reward: 16
Gini Coefficient: 0.07647058823529412
20:20 Ratio: 1.4545454545454546
Max-min Ratio: 1.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-17-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 239.64360022672122
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 339
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.504
    dispatch_time_ms: 9.613
    learner:
      cur_lr: 0.0012471129884943366
      grad_gnorm: 40.0
      policy_entropy: 7.424355506896973
      policy_loss: 0.9672080278396606
      var_gnorm: 22.196765899658203
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 11.014419555664062
    num_steps_sampled: 1700000
    num_steps_trained: 1700000
    wait_time_ms: 75.249
  iterations_since_restore: 340
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2977.7070813179016
  time_this_iter_s: 8.62889313697815
  time_total_s: 2977.7070813179016
  timestamp: 1594851478
  timesteps_since_restore: 1700000
  timesteps_this_iter: 5000
  timesteps_total: 1700000
  training_iteration: 340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2977 s, 340 iter, 1700000 ts, 240 rew

agent-1: 122.39931279902635
agent-2: 139.3993127990258
agent-3: 133.399312799026
agent-4: 130.39931279902606
agent-5: 140.39931279902606
Extrinsic Rewards:
4
21
15
12
22
Sum Reward: 74
Avg Reward: 14.8
Min Reward: 4
Max Reward: 22
Gini Coefficient: 0.24324324324324326
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-18-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 246.30356586667259
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 340
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.066
    dispatch_time_ms: 8.819
    learner:
      cur_lr: 0.0012467800406739116
      grad_gnorm: 40.0
      policy_entropy: 29.69575309753418
      policy_loss: -11.6087007522583
      var_gnorm: 22.228960037231445
      vf_explained_var: 0.0
      vf_loss: 6.830702304840088
    num_steps_sampled: 1705000
    num_steps_trained: 1705000
    wait_time_ms: 75.545
  iterations_since_restore: 341
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2986.276117324829
  time_this_iter_s: 8.56903600692749
  time_total_s: 2986.276117324829
  timestamp: 1594851487
  timesteps_since_restore: 1705000
  timesteps_this_iter: 5000
  timesteps_total: 1705000
  training_iteration: 341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2986 s, 341 iter, 1705000 ts, 246 rew

agent-1: 118.7999954234739
agent-2: 120.79999542347393
agent-3: 100.79999542347393
agent-4: 116.79999542347396
agent-5: 109.79999542347396
Extrinsic Rewards:
18
20
0
16
9
Sum Reward: 63
Avg Reward: 12.6
Min Reward: 0
Max Reward: 20
Gini Coefficient: 0.3111111111111111
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-18-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 251.97356563784626
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 341
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 6.812
    learner:
      cur_lr: 0.0012464469764381647
      grad_gnorm: 7.892130374908447
      policy_entropy: 15.565597534179688
      policy_loss: -1.1800110340118408
      var_gnorm: 22.188819885253906
      vf_explained_var: 0.0
      vf_loss: 0.04609018564224243
    num_steps_sampled: 1710000
    num_steps_trained: 1710000
    wait_time_ms: 71.588
  iterations_since_restore: 342
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 2994.7520661354065
  time_this_iter_s: 8.475948810577393
  time_total_s: 2994.7520661354065
  timestamp: 1594851496
  timesteps_since_restore: 1710000
  timesteps_this_iter: 5000
  timesteps_total: 1710000
  training_iteration: 342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 2994 s, 342 iter, 1710000 ts, 252 rew

agent-1: 116.99999842129853
agent-2: 115.99999842129856
agent-3: 123.99999842129859
agent-4: 117.99999842129856
agent-5: 109.99999842129853
Extrinsic Rewards:
13
12
20
14
6
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 6
Max Reward: 20
Gini Coefficient: 0.18461538461538463
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-18-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 257.8235655589112
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 342
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 8.505
    learner:
      cur_lr: 0.0012461140286177397
      grad_gnorm: 40.0
      policy_entropy: 32.12472152709961
      policy_loss: -11.305930137634277
      var_gnorm: 22.213224411010742
      vf_explained_var: 0.0
      vf_loss: 3.612273693084717
    num_steps_sampled: 1715000
    num_steps_trained: 1715000
    wait_time_ms: 75.062
  iterations_since_restore: 343
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3003.1958014965057
  time_this_iter_s: 8.443735361099243
  time_total_s: 3003.1958014965057
  timestamp: 1594851504
  timesteps_since_restore: 1715000
  timesteps_this_iter: 5000
  timesteps_total: 1715000
  training_iteration: 343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3003 s, 343 iter, 1715000 ts, 258 rew

agent-1: 92.79998894010686
agent-2: 103.7999889401069
agent-3: 102.79998894010686
agent-4: 84.79998894010681
agent-5: 92.79998894010686
Extrinsic Rewards:
8
19
18
0
8
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 0
Max Reward: 19
Gini Coefficient: 0.3622641509433962
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-18-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 262.59356500591656
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 343
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.414
    dispatch_time_ms: 8.991
    learner:
      cur_lr: 0.0012457809643819928
      grad_gnorm: 1.5635409355163574
      policy_entropy: 9.740943908691406
      policy_loss: -0.017861660569906235
      var_gnorm: 22.19156837463379
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.001843728474341333
    num_steps_sampled: 1720000
    num_steps_trained: 1720000
    wait_time_ms: 70.671
  iterations_since_restore: 344
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3011.631451845169
  time_this_iter_s: 8.43565034866333
  time_total_s: 3011.631451845169
  timestamp: 1594851512
  timesteps_since_restore: 1720000
  timesteps_this_iter: 5000
  timesteps_total: 1720000
  training_iteration: 344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3011 s, 344 iter, 1720000 ts, 263 rew

agent-1: 66.79999987458524
agent-2: 61.799999874585225
agent-3: 72.7999998745852
agent-4: 74.7999998745852
agent-5: 65.79999987458521
Extrinsic Rewards:
6
1
12
14
5
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.3473684210526316
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-18-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 266.01356499964584
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 344
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 8.111
    learner:
      cur_lr: 0.0012454480165615678
      grad_gnorm: 40.0
      policy_entropy: 34.07284927368164
      policy_loss: -7.39807653427124
      var_gnorm: 22.200950622558594
      vf_explained_var: 0.0
      vf_loss: 1.4322435855865479
    num_steps_sampled: 1725000
    num_steps_trained: 1725000
    wait_time_ms: 75.466
  iterations_since_restore: 345
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3020.054072380066
  time_this_iter_s: 8.42262053489685
  time_total_s: 3020.054072380066
  timestamp: 1594851521
  timesteps_since_restore: 1725000
  timesteps_this_iter: 5000
  timesteps_total: 1725000
  training_iteration: 345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3020 s, 345 iter, 1725000 ts, 266 rew

agent-1: 55.39999949504871
agent-2: 52.399999495048725
agent-3: 47.39999949504871
agent-4: 53.39999949504871
agent-5: 52.39999949504871
Extrinsic Rewards:
9
6
1
7
6
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.23448275862068965
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-18-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 268.6235649743983
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 345
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 8.919
    learner:
      cur_lr: 0.001245114952325821
      grad_gnorm: 2.7105252742767334
      policy_entropy: 27.216716766357422
      policy_loss: -0.2515963613986969
      var_gnorm: 22.190086364746094
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0055854953825473785
    num_steps_sampled: 1730000
    num_steps_trained: 1730000
    wait_time_ms: 73.605
  iterations_since_restore: 346
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3028.7213621139526
  time_this_iter_s: 8.667289733886719
  time_total_s: 3028.7213621139526
  timestamp: 1594851530
  timesteps_since_restore: 1730000
  timesteps_this_iter: 5000
  timesteps_total: 1730000
  training_iteration: 346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3028 s, 346 iter, 1730000 ts, 269 rew

agent-1: 51.799999965452265
agent-2: 44.79999996545227
agent-3: 51.799999965452265
agent-4: 50.799999965452265
agent-5: 52.79999996545227
Extrinsic Rewards:
7
0
7
6
8
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.24285714285714285
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-18-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 271.1435649726709
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 346
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.639
    dispatch_time_ms: 6.963
    learner:
      cur_lr: 0.0012447820045053959
      grad_gnorm: 10.366467475891113
      policy_entropy: 18.33974266052246
      policy_loss: -1.9910005331039429
      var_gnorm: 22.19385528564453
      vf_explained_var: 0.0
      vf_loss: 0.06558689475059509
    num_steps_sampled: 1735000
    num_steps_trained: 1735000
    wait_time_ms: 75.612
  iterations_since_restore: 347
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3037.3824071884155
  time_this_iter_s: 8.66104507446289
  time_total_s: 3037.3824071884155
  timestamp: 1594851538
  timesteps_since_restore: 1735000
  timesteps_this_iter: 5000
  timesteps_total: 1735000
  training_iteration: 347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3037 s, 347 iter, 1735000 ts, 271 rew

agent-1: 33.599999998360296
agent-2: 42.599999998360275
agent-3: 37.599999998360296
agent-4: 40.599999998360275
agent-5: 34.59999999836029
Extrinsic Rewards:
0
9
4
7
1
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.45714285714285713
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-19-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 273.0335649725889
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 347
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.31
    dispatch_time_ms: 9.966
    learner:
      cur_lr: 0.0012444490566849709
      grad_gnorm: 3.1098697185516357
      policy_entropy: 18.756832122802734
      policy_loss: -0.15781736373901367
      var_gnorm: 22.192846298217773
      vf_explained_var: 0.0
      vf_loss: 0.007319426629692316
    num_steps_sampled: 1740000
    num_steps_trained: 1740000
    wait_time_ms: 49.216
  iterations_since_restore: 348
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3051.4645535945892
  time_this_iter_s: 14.082146406173706
  time_total_s: 3051.4645535945892
  timestamp: 1594851552
  timesteps_since_restore: 1740000
  timesteps_this_iter: 5000
  timesteps_total: 1740000
  training_iteration: 348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3051 s, 348 iter, 1740000 ts, 273 rew

agent-1: 40.3999999983554
agent-2: 45.39999999835539
agent-3: 44.3999999983554
agent-4: 45.39999999835539
agent-5: 40.3999999983554
Extrinsic Rewards:
2
7
6
7
2
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.25
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-19-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 275.1935649725067
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 348
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.129
    dispatch_time_ms: 38.968
    learner:
      cur_lr: 0.001244115992449224
      grad_gnorm: 39.761619567871094
      policy_entropy: 22.625041961669922
      policy_loss: -4.4534196853637695
      var_gnorm: 22.20195198059082
      vf_explained_var: 0.0
      vf_loss: 1.2243858575820923
    num_steps_sampled: 1745000
    num_steps_trained: 1745000
    wait_time_ms: 58.104
  iterations_since_restore: 349
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3060.466856241226
  time_this_iter_s: 9.002302646636963
  time_total_s: 3060.466856241226
  timestamp: 1594851562
  timesteps_since_restore: 1745000
  timesteps_this_iter: 5000
  timesteps_total: 1745000
  training_iteration: 349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3060 s, 349 iter, 1745000 ts, 275 rew

agent-1: 56.59999999744772
agent-2: 53.5999999974477
agent-3: 65.59999999744774
agent-4: 50.5999999974477
agent-5: 52.5999999974477
Extrinsic Rewards:
7
4
16
1
3
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 1
Max Reward: 16
Gini Coefficient: 0.43870967741935485
20:20 Ratio: 16.0
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-19-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 277.98356497237904
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 349
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.588
    dispatch_time_ms: 17.125
    learner:
      cur_lr: 0.001243783044628799
      grad_gnorm: 5.694237232208252
      policy_entropy: 14.916175842285156
      policy_loss: 0.14540906250476837
      var_gnorm: 22.19440269470215
      vf_explained_var: 0.0
      vf_loss: 0.02485702373087406
    num_steps_sampled: 1750000
    num_steps_trained: 1750000
    wait_time_ms: 75.769
  iterations_since_restore: 350
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3069.586933851242
  time_this_iter_s: 9.12007761001587
  time_total_s: 3069.586933851242
  timestamp: 1594851571
  timesteps_since_restore: 1750000
  timesteps_this_iter: 5000
  timesteps_total: 1750000
  training_iteration: 350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3069 s, 350 iter, 1750000 ts, 278 rew

agent-1: 106.99999876968327
agent-2: 110.99999876968329
agent-3: 115.9999987696833
agent-4: 103.99999876968327
agent-5: 101.99999876968326
Extrinsic Rewards:
11
15
20
8
6
Sum Reward: 60
Avg Reward: 12.0
Min Reward: 6
Max Reward: 20
Gini Coefficient: 0.23333333333333334
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-19-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 283.3835649108632
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 350
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.617
    dispatch_time_ms: 17.701
    learner:
      cur_lr: 0.001243449980393052
      grad_gnorm: 40.0
      policy_entropy: 16.8793888092041
      policy_loss: -6.837847709655762
      var_gnorm: 22.215639114379883
      vf_explained_var: 0.0
      vf_loss: 3.898479700088501
    num_steps_sampled: 1755000
    num_steps_trained: 1755000
    wait_time_ms: 73.927
  iterations_since_restore: 351
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3078.619654893875
  time_this_iter_s: 9.032721042633057
  time_total_s: 3078.619654893875
  timestamp: 1594851580
  timesteps_since_restore: 1755000
  timesteps_this_iter: 5000
  timesteps_total: 1755000
  training_iteration: 351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3078 s, 351 iter, 1755000 ts, 283 rew

agent-1: 126.19998633947878
agent-2: 123.19998633947884
agent-3: 118.19998633947883
agent-4: 124.19998633947883
agent-5: 111.19998633947885
Extrinsic Rewards:
19
16
11
17
4
Sum Reward: 67
Avg Reward: 13.4
Min Reward: 4
Max Reward: 19
Gini Coefficient: 0.21492537313432836
20:20 Ratio: 4.75
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-19-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 289.4135642278371
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 351
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.146
    dispatch_time_ms: 24.507
    learner:
      cur_lr: 0.001243117032572627
      grad_gnorm: 39.999996185302734
      policy_entropy: 16.842065811157227
      policy_loss: 13.987791061401367
      var_gnorm: 22.19243049621582
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 46.01950454711914
    num_steps_sampled: 1760000
    num_steps_trained: 1760000
    wait_time_ms: 61.66
  iterations_since_restore: 352
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3088.05677819252
  time_this_iter_s: 9.43712329864502
  time_total_s: 3088.05677819252
  timestamp: 1594851589
  timesteps_since_restore: 1760000
  timesteps_this_iter: 5000
  timesteps_total: 1760000
  training_iteration: 352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3088 s, 352 iter, 1760000 ts, 289 rew

agent-1: 61.79999998729908
agent-2: 57.79999998729908
agent-3: 58.79999998729908
agent-4: 58.79999998729908
agent-5: 59.79999998729908
Extrinsic Rewards:
9
5
6
6
7
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 5
Max Reward: 9
Gini Coefficient: 0.10909090909090909
20:20 Ratio: 1.8
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-19-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 292.3835642272021
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 352
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 19.558
    learner:
      cur_lr: 0.0012427839683368802
      grad_gnorm: 30.03178596496582
      policy_entropy: 34.45094680786133
      policy_loss: -5.671879768371582
      var_gnorm: 22.196035385131836
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.38420531153678894
    num_steps_sampled: 1765000
    num_steps_trained: 1765000
    wait_time_ms: 70.069
  iterations_since_restore: 353
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3096.835687637329
  time_this_iter_s: 8.77890944480896
  time_total_s: 3096.835687637329
  timestamp: 1594851598
  timesteps_since_restore: 1765000
  timesteps_this_iter: 5000
  timesteps_total: 1765000
  training_iteration: 353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3096 s, 353 iter, 1765000 ts, 292 rew

agent-1: 70.39999998946088
agent-2: 71.39999998946088
agent-3: 72.39999998946088
agent-4: 71.39999998946088
agent-5: 65.39999998946082
Extrinsic Rewards:
8
9
10
9
3
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.15384615384615385
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-20-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 295.89356422667515
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 353
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.812
    dispatch_time_ms: 31.604
    learner:
      cur_lr: 0.0012424510205164552
      grad_gnorm: 39.99999237060547
      policy_entropy: 13.37078857421875
      policy_loss: 6.914956092834473
      var_gnorm: 22.1922550201416
      vf_explained_var: 0.0
      vf_loss: 6.981234550476074
    num_steps_sampled: 1770000
    num_steps_trained: 1770000
    wait_time_ms: 57.449
  iterations_since_restore: 354
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3106.0462391376495
  time_this_iter_s: 9.210551500320435
  time_total_s: 3106.0462391376495
  timestamp: 1594851607
  timesteps_since_restore: 1770000
  timesteps_this_iter: 5000
  timesteps_total: 1770000
  training_iteration: 354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3106 s, 354 iter, 1770000 ts, 296 rew

agent-1: 70.9999999873939
agent-2: 69.9999999873939
agent-3: 73.99999998739392
agent-4: 69.9999999873939
agent-5: 74.99999998739395
Extrinsic Rewards:
7
6
10
6
11
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 6
Max Reward: 11
Gini Coefficient: 0.14
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-20-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 299.49356422604484
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 354
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.908
    dispatch_time_ms: 17.978
    learner:
      cur_lr: 0.0012421179562807083
      grad_gnorm: 12.546285629272461
      policy_entropy: 20.869564056396484
      policy_loss: -2.9320311546325684
      var_gnorm: 22.192575454711914
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.11710774153470993
    num_steps_sampled: 1775000
    num_steps_trained: 1775000
    wait_time_ms: 67.495
  iterations_since_restore: 355
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3115.0503356456757
  time_this_iter_s: 9.004096508026123
  time_total_s: 3115.0503356456757
  timestamp: 1594851616
  timesteps_since_restore: 1775000
  timesteps_this_iter: 5000
  timesteps_total: 1775000
  training_iteration: 355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3115 s, 355 iter, 1775000 ts, 299 rew

agent-1: 38.599999998295125
agent-2: 42.59999999829513
agent-3: 36.599999998295125
agent-4: 37.59999999829513
agent-5: 33.599999998295125
Extrinsic Rewards:
5
9
3
4
0
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.38095238095238093
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-20-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 301.3835642259596
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 355
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.478
    dispatch_time_ms: 9.367
    learner:
      cur_lr: 0.0012417850084602833
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.974440574645996
      policy_loss: 36.597145080566406
      var_gnorm: 22.19121742248535
      vf_explained_var: 0.0
      vf_loss: 231.4287109375
    num_steps_sampled: 1780000
    num_steps_trained: 1780000
    wait_time_ms: 71.264
  iterations_since_restore: 356
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3123.7854261398315
  time_this_iter_s: 8.735090494155884
  time_total_s: 3123.7854261398315
  timestamp: 1594851625
  timesteps_since_restore: 1780000
  timesteps_this_iter: 5000
  timesteps_total: 1780000
  training_iteration: 356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3123 s, 356 iter, 1780000 ts, 301 rew

agent-1: 57.79999999745602
agent-2: 44.799999997456005
agent-3: 48.79999999745601
agent-4: 53.79999999745602
agent-5: 46.799999997456005
Extrinsic Rewards:
13
0
4
9
2
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.4714285714285714
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-20-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 303.9035642258324
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 356
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 7.852
    learner:
      cur_lr: 0.0012414519442245364
      grad_gnorm: 9.798012733459473
      policy_entropy: 24.766157150268555
      policy_loss: -1.482206106185913
      var_gnorm: 22.225284576416016
      vf_explained_var: 0.0
      vf_loss: 0.07406602799892426
    num_steps_sampled: 1785000
    num_steps_trained: 1785000
    wait_time_ms: 74.845
  iterations_since_restore: 357
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3132.2039506435394
  time_this_iter_s: 8.418524503707886
  time_total_s: 3132.2039506435394
  timestamp: 1594851634
  timesteps_since_restore: 1785000
  timesteps_this_iter: 5000
  timesteps_total: 1785000
  training_iteration: 357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3132 s, 357 iter, 1785000 ts, 304 rew

agent-1: 67.39999995488849
agent-2: 70.39999995488849
agent-3: 72.39999995488844
agent-4: 70.39999995488847
agent-5: 70.39999995488846
Extrinsic Rewards:
5
8
10
8
8
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 5
Max Reward: 10
Gini Coefficient: 0.10256410256410256
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-20-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 307.41356422357677
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 357
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.475
    dispatch_time_ms: 8.513
    learner:
      cur_lr: 0.0012411189964041114
      grad_gnorm: 40.0
      policy_entropy: 19.16051483154297
      policy_loss: 80.28438568115234
      var_gnorm: 22.221534729003906
      vf_explained_var: 0.0
      vf_loss: 136.7256622314453
    num_steps_sampled: 1790000
    num_steps_trained: 1790000
    wait_time_ms: 69.372
  iterations_since_restore: 358
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3140.776785135269
  time_this_iter_s: 8.572834491729736
  time_total_s: 3140.776785135269
  timestamp: 1594851642
  timesteps_since_restore: 1790000
  timesteps_this_iter: 5000
  timesteps_total: 1790000
  training_iteration: 358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3140 s, 358 iter, 1790000 ts, 307 rew

agent-1: 31.79999999960367
agent-2: 33.79999999960369
agent-3: 29.79999999960367
agent-4: 35.79999999960366
agent-5: 30.79999999960367
Extrinsic Rewards:
3
5
1
7
2
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.3333333333333333
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-20-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 309.033564223557
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 358
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.295
    dispatch_time_ms: 7.877
    learner:
      cur_lr: 0.0012407860485836864
      grad_gnorm: 8.798443794250488
      policy_entropy: 8.329150199890137
      policy_loss: -0.7078806161880493
      var_gnorm: 22.214746475219727
      vf_explained_var: 0.0
      vf_loss: 0.05929664149880409
    num_steps_sampled: 1795000
    num_steps_trained: 1795000
    wait_time_ms: 74.091
  iterations_since_restore: 359
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3149.2968447208405
  time_this_iter_s: 8.520059585571289
  time_total_s: 3149.2968447208405
  timestamp: 1594851651
  timesteps_since_restore: 1795000
  timesteps_this_iter: 5000
  timesteps_total: 1795000
  training_iteration: 359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3149 s, 359 iter, 1795000 ts, 309 rew

agent-1: 76.7999999848663
agent-2: 76.7999999848663
agent-3: 79.7999999848663
agent-4: 75.7999999848663
agent-5: 77.79999998486633
Extrinsic Rewards:
8
8
11
7
9
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 7
Max Reward: 11
Gini Coefficient: 0.08372093023255814
20:20 Ratio: 1.5714285714285714
Max-min Ratio: 1.5714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-20-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 312.9035642228003
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 359
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.032
    dispatch_time_ms: 7.028
    learner:
      cur_lr: 0.0012404529843479395
      grad_gnorm: 40.0
      policy_entropy: 5.480106830596924
      policy_loss: 3.1193668842315674
      var_gnorm: 22.21337127685547
      vf_explained_var: 0.0
      vf_loss: 2.6884946823120117
    num_steps_sampled: 1800000
    num_steps_trained: 1800000
    wait_time_ms: 74.659
  iterations_since_restore: 360
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3157.7871763706207
  time_this_iter_s: 8.490331649780273
  time_total_s: 3157.7871763706207
  timestamp: 1594851659
  timesteps_since_restore: 1800000
  timesteps_this_iter: 5000
  timesteps_total: 1800000
  training_iteration: 360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3157 s, 360 iter, 1800000 ts, 313 rew

agent-1: 30.399999999266438
agent-2: 38.39999999926642
agent-3: 35.39999999926641
agent-4: 32.399999999266385
agent-5: 34.3999999992664
Extrinsic Rewards:
0
8
5
2
4
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-21-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 314.6135642227636
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 360
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 25.479
    learner:
      cur_lr: 0.0012401200365275145
      grad_gnorm: 40.0
      policy_entropy: 26.148591995239258
      policy_loss: 11.965156555175781
      var_gnorm: 22.23444175720215
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.0256733894348145
    num_steps_sampled: 1805000
    num_steps_trained: 1805000
    wait_time_ms: 53.219
  iterations_since_restore: 361
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3166.5309336185455
  time_this_iter_s: 8.743757247924805
  time_total_s: 3166.5309336185455
  timestamp: 1594851668
  timesteps_since_restore: 1805000
  timesteps_this_iter: 5000
  timesteps_total: 1805000
  training_iteration: 361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3166 s, 361 iter, 1805000 ts, 315 rew

agent-1: 91.199996552009
agent-2: 100.19999655200897
agent-3: 91.199996552009
agent-4: 96.19999655200898
agent-5: 89.19999655200901
Extrinsic Rewards:
8
17
8
13
6
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 6
Max Reward: 17
Gini Coefficient: 0.2076923076923077
20:20 Ratio: 2.8333333333333335
Max-min Ratio: 2.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-21-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 319.293564050364
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 361
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.9
    dispatch_time_ms: 25.563
    learner:
      cur_lr: 0.0012397869722917676
      grad_gnorm: 26.659645080566406
      policy_entropy: 6.123905658721924
      policy_loss: 1.3041919469833374
      var_gnorm: 22.210065841674805
      vf_explained_var: 0.0
      vf_loss: 0.5652225613594055
    num_steps_sampled: 1810000
    num_steps_trained: 1810000
    wait_time_ms: 61.25
  iterations_since_restore: 362
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3175.4174616336823
  time_this_iter_s: 8.886528015136719
  time_total_s: 3175.4174616336823
  timestamp: 1594851677
  timesteps_since_restore: 1810000
  timesteps_this_iter: 5000
  timesteps_total: 1810000
  training_iteration: 362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3175 s, 362 iter, 1810000 ts, 319 rew

agent-1: 93.39999818888515
agent-2: 90.39999818888515
agent-3: 82.39999818888514
agent-4: 87.39999818888515
agent-5: 87.39999818888515
Extrinsic Rewards:
15
12
4
9
9
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 4
Max Reward: 15
Gini Coefficient: 0.20408163265306123
20:20 Ratio: 3.75
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-21-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 323.7035639598083
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 362
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.936
    dispatch_time_ms: 13.805
    learner:
      cur_lr: 0.0012394540244713426
      grad_gnorm: 40.0
      policy_entropy: 24.050188064575195
      policy_loss: 14.125316619873047
      var_gnorm: 22.24557876586914
      vf_explained_var: 0.0
      vf_loss: 15.798157691955566
    num_steps_sampled: 1815000
    num_steps_trained: 1815000
    wait_time_ms: 67.293
  iterations_since_restore: 363
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3184.4040489196777
  time_this_iter_s: 8.986587285995483
  time_total_s: 3184.4040489196777
  timestamp: 1594851686
  timesteps_since_restore: 1815000
  timesteps_this_iter: 5000
  timesteps_total: 1815000
  training_iteration: 363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3184 s, 363 iter, 1815000 ts, 324 rew

agent-1: 112.7999375470062
agent-2: 118.79993754700622
agent-3: 117.79993754700625
agent-4: 110.79993754700625
agent-5: 106.79993754700625
Extrinsic Rewards:
12
18
17
10
6
Sum Reward: 63
Avg Reward: 12.6
Min Reward: 6
Max Reward: 18
Gini Coefficient: 0.19682539682539682
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-21-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 329.3735608371586
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 363
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.5
    dispatch_time_ms: 27.577
    learner:
      cur_lr: 0.0012391209602355957
      grad_gnorm: 23.996572494506836
      policy_entropy: 0.0018251247238367796
      policy_loss: -2.4246963221230544e-05
      var_gnorm: 22.22947883605957
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.4459613561630249
    num_steps_sampled: 1820000
    num_steps_trained: 1820000
    wait_time_ms: 58.758
  iterations_since_restore: 364
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3193.284938097
  time_this_iter_s: 8.880889177322388
  time_total_s: 3193.284938097
  timestamp: 1594851695
  timesteps_since_restore: 1820000
  timesteps_this_iter: 5000
  timesteps_total: 1820000
  training_iteration: 364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3193 s, 364 iter, 1820000 ts, 329 rew

agent-1: 121.79999807894852
agent-2: 117.79999807894852
agent-3: 113.79999807894853
agent-4: 107.79999807894853
agent-5: 105.79999807894853
Extrinsic Rewards:
21
17
13
7
5
Sum Reward: 63
Avg Reward: 12.6
Min Reward: 5
Max Reward: 21
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 4.2
Max-min Ratio: 4.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-21-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 335.04356074110615
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 364
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.938
    dispatch_time_ms: 30.639
    learner:
      cur_lr: 0.0012387880124151707
      grad_gnorm: 0.6340793371200562
      policy_entropy: 0.0017883912660181522
      policy_loss: -4.6869013203831855e-07
      var_gnorm: 22.227720260620117
      vf_explained_var: 0.0
      vf_loss: 0.0003113800485152751
    num_steps_sampled: 1825000
    num_steps_trained: 1825000
    wait_time_ms: 52.243
  iterations_since_restore: 365
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3201.810426235199
  time_this_iter_s: 8.525488138198853
  time_total_s: 3201.810426235199
  timestamp: 1594851703
  timesteps_since_restore: 1825000
  timesteps_this_iter: 5000
  timesteps_total: 1825000
  training_iteration: 365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3201 s, 365 iter, 1825000 ts, 335 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-21-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 335.04356074110615
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 365
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.618
    dispatch_time_ms: 22.111
    learner:
      cur_lr: 0.0012384549481794238
      grad_gnorm: 0.01265031285583973
      policy_entropy: 0.0017884239787235856
      policy_loss: -3.283237148821172e-08
      var_gnorm: 22.227706909179688
      vf_explained_var: 0.0
      vf_loss: 1.24108439081283e-07
    num_steps_sampled: 1830000
    num_steps_trained: 1830000
    wait_time_ms: 63.2
  iterations_since_restore: 366
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3210.2993519306183
  time_this_iter_s: 8.488925695419312
  time_total_s: 3210.2993519306183
  timestamp: 1594851712
  timesteps_since_restore: 1830000
  timesteps_this_iter: 5000
  timesteps_total: 1830000
  training_iteration: 366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3210 s, 366 iter, 1830000 ts, 335 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-22-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 335.04356074110615
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 366
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.675
    dispatch_time_ms: 26.328
    learner:
      cur_lr: 0.0012381220003589988
      grad_gnorm: 0.001470664399676025
      policy_entropy: 0.0017884523840621114
      policy_loss: 1.1643437325403738e-09
      var_gnorm: 22.22770118713379
      vf_explained_var: 0.0
      vf_loss: 1.652550762898386e-09
    num_steps_sampled: 1835000
    num_steps_trained: 1835000
    wait_time_ms: 52.652
  iterations_since_restore: 367
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3218.828106403351
  time_this_iter_s: 8.528754472732544
  time_total_s: 3218.828106403351
  timestamp: 1594851721
  timesteps_since_restore: 1835000
  timesteps_this_iter: 5000
  timesteps_total: 1835000
  training_iteration: 367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3218 s, 367 iter, 1835000 ts, 335 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-22-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 335.04356074110615
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 367
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.897
    dispatch_time_ms: 10.042
    learner:
      cur_lr: 0.0012377890525385737
      grad_gnorm: 0.009962424635887146
      policy_entropy: 0.0017884833505377173
      policy_loss: 5.584098961008976e-09
      var_gnorm: 22.227691650390625
      vf_explained_var: 0.0
      vf_loss: 7.701941484583585e-08
    num_steps_sampled: 1840000
    num_steps_trained: 1840000
    wait_time_ms: 69.907
  iterations_since_restore: 368
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3227.2510845661163
  time_this_iter_s: 8.422978162765503
  time_total_s: 3227.2510845661163
  timestamp: 1594851729
  timesteps_since_restore: 1840000
  timesteps_this_iter: 5000
  timesteps_total: 1840000
  training_iteration: 368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3227 s, 368 iter, 1840000 ts, 335 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-22-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 335.04356074110603
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 368
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.146
    dispatch_time_ms: 8.259
    learner:
      cur_lr: 0.0012374559883028269
      grad_gnorm: 0.00023154303198680282
      policy_entropy: 0.0017885135021060705
      policy_loss: -1.3657604214234453e-10
      var_gnorm: 22.227684020996094
      vf_explained_var: 0.0
      vf_loss: 3.7521014073504944e-11
    num_steps_sampled: 1845000
    num_steps_trained: 1845000
    wait_time_ms: 69.275
  iterations_since_restore: 369
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3235.360457420349
  time_this_iter_s: 8.109372854232788
  time_total_s: 3235.360457420349
  timestamp: 1594851737
  timesteps_since_restore: 1845000
  timesteps_this_iter: 5000
  timesteps_total: 1845000
  training_iteration: 369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3235 s, 369 iter, 1845000 ts, 335 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-22-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 334.2169262059699
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 369
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 6.655
    learner:
      cur_lr: 0.0012371230404824018
      grad_gnorm: 0.010903245769441128
      policy_entropy: 0.0017885470297187567
      policy_loss: 6.32830809976781e-09
      var_gnorm: 22.227676391601562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.204710949006767e-08
    num_steps_sampled: 1850000
    num_steps_trained: 1850000
    wait_time_ms: 69.667
  iterations_since_restore: 370
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3246.690687894821
  time_this_iter_s: 11.330230474472046
  time_total_s: 3246.690687894821
  timestamp: 1594851749
  timesteps_since_restore: 1850000
  timesteps_this_iter: 5000
  timesteps_total: 1850000
  training_iteration: 370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3246 s, 370 iter, 1850000 ts, 334 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-22-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 333.0230686451586
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 370
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.823
    dispatch_time_ms: 8.173
    learner:
      cur_lr: 0.001236789976246655
      grad_gnorm: 0.00031992868753150105
      policy_entropy: 0.001788584515452385
      policy_loss: -1.8736254214779535e-10
      var_gnorm: 22.2276668548584
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.794732914678804e-11
    num_steps_sampled: 1855000
    num_steps_trained: 1855000
    wait_time_ms: 75.639
  iterations_since_restore: 371
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3254.8609693050385
  time_this_iter_s: 8.170281410217285
  time_total_s: 3254.8609693050385
  timestamp: 1594851757
  timesteps_since_restore: 1855000
  timesteps_this_iter: 5000
  timesteps_total: 1855000
  training_iteration: 371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3254 s, 371 iter, 1855000 ts, 333 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-22-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 330.7730686452523
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 371
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.73
    dispatch_time_ms: 10.905
    learner:
      cur_lr: 0.00123645702842623
      grad_gnorm: 0.011787602677941322
      policy_entropy: 0.0017886230489239097
      policy_loss: 6.980904743159044e-09
      var_gnorm: 22.227657318115234
      vf_explained_var: 0.0
      vf_loss: 1.0760915358787315e-07
    num_steps_sampled: 1860000
    num_steps_trained: 1860000
    wait_time_ms: 66.782
  iterations_since_restore: 372
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3262.9115793704987
  time_this_iter_s: 8.050610065460205
  time_total_s: 3262.9115793704987
  timestamp: 1594851765
  timesteps_since_restore: 1860000
  timesteps_this_iter: 5000
  timesteps_total: 1860000
  training_iteration: 372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3262 s, 372 iter, 1860000 ts, 331 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-22-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 329.0630686452762
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 372
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 7.381
    learner:
      cur_lr: 0.001236123964190483
      grad_gnorm: 0.0004550589364953339
      policy_entropy: 0.0017886655405163765
      policy_loss: -2.8677418772993235e-10
      var_gnorm: 22.22764778137207
      vf_explained_var: 0.0
      vf_loss: 1.5683906950947346e-10
    num_steps_sampled: 1865000
    num_steps_trained: 1865000
    wait_time_ms: 67.146
  iterations_since_restore: 373
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3270.952813386917
  time_this_iter_s: 8.041234016418457
  time_total_s: 3270.952813386917
  timestamp: 1594851773
  timesteps_since_restore: 1865000
  timesteps_this_iter: 5000
  timesteps_total: 1865000
  training_iteration: 373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3270 s, 373 iter, 1865000 ts, 329 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-23-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 329.0630686452763
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 373
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.211
    dispatch_time_ms: 8.035
    learner:
      cur_lr: 0.001235791016370058
      grad_gnorm: 0.012799876742064953
      policy_entropy: 0.0017887083813548088
      policy_loss: 7.559903814069457e-09
      var_gnorm: 22.227638244628906
      vf_explained_var: 0.0
      vf_loss: 1.2681061889452394e-07
    num_steps_sampled: 1870000
    num_steps_trained: 1870000
    wait_time_ms: 73.738
  iterations_since_restore: 374
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3279.107104539871
  time_this_iter_s: 8.154291152954102
  time_total_s: 3279.107104539871
  timestamp: 1594851781
  timesteps_since_restore: 1870000
  timesteps_this_iter: 5000
  timesteps_total: 1870000
  training_iteration: 374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3279 s, 374 iter, 1870000 ts, 329 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-23-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 329.0630686452763
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 374
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.515
    dispatch_time_ms: 9.252
    learner:
      cur_lr: 0.0012354579521343112
      grad_gnorm: 0.0005057572852820158
      policy_entropy: 0.0017887527355924249
      policy_loss: -2.9863028716548e-10
      var_gnorm: 22.227628707885742
      vf_explained_var: 0.0
      vf_loss: 1.941719979248191e-10
    num_steps_sampled: 1875000
    num_steps_trained: 1875000
    wait_time_ms: 70.896
  iterations_since_restore: 375
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3287.166170358658
  time_this_iter_s: 8.059065818786621
  time_total_s: 3287.166170358658
  timestamp: 1594851789
  timesteps_since_restore: 1875000
  timesteps_this_iter: 5000
  timesteps_total: 1875000
  training_iteration: 375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3287 s, 375 iter, 1875000 ts, 329 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-23-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 329.0630686452763
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 375
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 8.414
    learner:
      cur_lr: 0.0012351250043138862
      grad_gnorm: 0.013745519332587719
      policy_entropy: 0.0017887972062453628
      policy_loss: 8.184857236415155e-09
      var_gnorm: 22.227619171142578
      vf_explained_var: 0.0
      vf_loss: 1.4643219969912025e-07
    num_steps_sampled: 1880000
    num_steps_trained: 1880000
    wait_time_ms: 69.874
  iterations_since_restore: 376
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3295.218724966049
  time_this_iter_s: 8.052554607391357
  time_total_s: 3295.218724966049
  timestamp: 1594851797
  timesteps_since_restore: 1880000
  timesteps_this_iter: 5000
  timesteps_total: 1880000
  training_iteration: 376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3295 s, 376 iter, 1880000 ts, 329 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-23-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 328.97710170487085
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 376
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.051
    dispatch_time_ms: 7.232
    learner:
      cur_lr: 0.0012347920564934611
      grad_gnorm: 0.0007056856993585825
      policy_entropy: 0.0017888424918055534
      policy_loss: -5.847567430272704e-10
      var_gnorm: 22.22760581970215
      vf_explained_var: 0.0
      vf_loss: 3.855663011087529e-10
    num_steps_sampled: 1885000
    num_steps_trained: 1885000
    wait_time_ms: 71.034
  iterations_since_restore: 377
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3309.4611892700195
  time_this_iter_s: 14.242464303970337
  time_total_s: 3309.4611892700195
  timestamp: 1594851812
  timesteps_since_restore: 1885000
  timesteps_this_iter: 5000
  timesteps_total: 1885000
  training_iteration: 377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3309 s, 377 iter, 1885000 ts, 329 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-23-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 328.76806289282837
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 377
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.711
    dispatch_time_ms: 8.226
    learner:
      cur_lr: 0.0012344589922577143
      grad_gnorm: 0.014299499802291393
      policy_entropy: 0.0017888942966237664
      policy_loss: 8.445619315011754e-09
      var_gnorm: 22.22759437561035
      vf_explained_var: 0.0
      vf_loss: 1.5835811950637435e-07
    num_steps_sampled: 1890000
    num_steps_trained: 1890000
    wait_time_ms: 70.802
  iterations_since_restore: 378
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3317.6144556999207
  time_this_iter_s: 8.153266429901123
  time_total_s: 3317.6144556999207
  timestamp: 1594851820
  timesteps_since_restore: 1890000
  timesteps_this_iter: 5000
  timesteps_total: 1890000
  training_iteration: 378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3317 s, 378 iter, 1890000 ts, 329 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-23-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 328.7006219410157
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 378
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.401
    dispatch_time_ms: 12.01
    learner:
      cur_lr: 0.0012341260444372892
      grad_gnorm: 0.0005292119458317757
      policy_entropy: 0.0017949161119759083
      policy_loss: -3.2811103833907396e-10
      var_gnorm: 22.227584838867188
      vf_explained_var: 0.0
      vf_loss: 2.1991324039571936e-10
    num_steps_sampled: 1895000
    num_steps_trained: 1895000
    wait_time_ms: 66.251
  iterations_since_restore: 379
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3325.6898350715637
  time_this_iter_s: 8.075379371643066
  time_total_s: 3325.6898350715637
  timestamp: 1594851828
  timesteps_since_restore: 1895000
  timesteps_this_iter: 5000
  timesteps_total: 1895000
  training_iteration: 379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3325 s, 379 iter, 1895000 ts, 329 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-23-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 326.90062194921944
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 379
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.139
    dispatch_time_ms: 11.449
    learner:
      cur_lr: 0.0012337929802015424
      grad_gnorm: 0.015183821320533752
      policy_entropy: 0.0017949789762496948
      policy_loss: 9.84189796326973e-09
      var_gnorm: 22.22757339477539
      vf_explained_var: 0.0
      vf_loss: 1.7860907064459752e-07
    num_steps_sampled: 1900000
    num_steps_trained: 1900000
    wait_time_ms: 67.583
  iterations_since_restore: 380
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3333.8093497753143
  time_this_iter_s: 8.11951470375061
  time_total_s: 3333.8093497753143
  timestamp: 1594851836
  timesteps_since_restore: 1900000
  timesteps_this_iter: 5000
  timesteps_total: 1900000
  training_iteration: 380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3333 s, 380 iter, 1900000 ts, 327 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-24-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 323.6606219547792
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 380
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.801
    dispatch_time_ms: 6.925
    learner:
      cur_lr: 0.0012334600323811173
      grad_gnorm: 0.000628958223387599
      policy_entropy: 0.00179504684638232
      policy_loss: -5.40664624182341e-10
      var_gnorm: 22.22756004333496
      vf_explained_var: 0.0
      vf_loss: 2.9037003357323954e-10
    num_steps_sampled: 1905000
    num_steps_trained: 1905000
    wait_time_ms: 69.781
  iterations_since_restore: 381
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3341.8235716819763
  time_this_iter_s: 8.014221906661987
  time_total_s: 3341.8235716819763
  timestamp: 1594851844
  timesteps_since_restore: 1905000
  timesteps_this_iter: 5000
  timesteps_total: 1905000
  training_iteration: 381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3341 s, 381 iter, 1905000 ts, 324 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-24-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 319.97062449350005
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 381
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.869
    dispatch_time_ms: 8.496
    learner:
      cur_lr: 0.0012331269681453705
      grad_gnorm: 0.015445041470229626
      policy_entropy: 0.0017951182089745998
      policy_loss: 9.578310589120065e-09
      var_gnorm: 22.22754669189453
      vf_explained_var: 0.0
      vf_loss: 1.8498612064377085e-07
    num_steps_sampled: 1910000
    num_steps_trained: 1910000
    wait_time_ms: 71.489
  iterations_since_restore: 382
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3349.960486650467
  time_this_iter_s: 8.1369149684906
  time_total_s: 3349.960486650467
  timestamp: 1594851852
  timesteps_since_restore: 1910000
  timesteps_this_iter: 5000
  timesteps_total: 1910000
  training_iteration: 382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3349 s, 382 iter, 1910000 ts, 320 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-24-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 315.29062914685784
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 382
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.146
    dispatch_time_ms: 8.708
    learner:
      cur_lr: 0.0012327940203249454
      grad_gnorm: 0.00038164047873578966
      policy_entropy: 0.0017951909685507417
      policy_loss: -2.3656218650636163e-10
      var_gnorm: 22.227535247802734
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.189660453482233e-10
    num_steps_sampled: 1915000
    num_steps_trained: 1915000
    wait_time_ms: 66.259
  iterations_since_restore: 383
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3358.0696654319763
  time_this_iter_s: 8.1091787815094
  time_total_s: 3358.0696654319763
  timestamp: 1594851860
  timesteps_since_restore: 1915000
  timesteps_this_iter: 5000
  timesteps_total: 1915000
  training_iteration: 383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3358 s, 383 iter, 1915000 ts, 315 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-24-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 314.3360843309273
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 383
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.278
    dispatch_time_ms: 7.342
    learner:
      cur_lr: 0.0012324609560891986
      grad_gnorm: 0.016889311373233795
      policy_entropy: 0.0017952652415260673
      policy_loss: 1.1186217285796829e-08
      var_gnorm: 22.227519989013672
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.2065260907311313e-07
    num_steps_sampled: 1920000
    num_steps_trained: 1920000
    wait_time_ms: 69.854
  iterations_since_restore: 384
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3366.189385175705
  time_this_iter_s: 8.119719743728638
  time_total_s: 3366.189385175705
  timestamp: 1594851869
  timesteps_since_restore: 1920000
  timesteps_this_iter: 5000
  timesteps_total: 1920000
  training_iteration: 384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3366 s, 384 iter, 1920000 ts, 314 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-24-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 311.7310066374336
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 384
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.424
    dispatch_time_ms: 7.927
    learner:
      cur_lr: 0.0012321280082687736
      grad_gnorm: 0.00014434503100346774
      policy_entropy: 0.0017953556962311268
      policy_loss: -2.181191199879251e-10
      var_gnorm: 22.227506637573242
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.5245285936438258e-11
    num_steps_sampled: 1925000
    num_steps_trained: 1925000
    wait_time_ms: 69.972
  iterations_since_restore: 385
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3374.1907148361206
  time_this_iter_s: 8.00132966041565
  time_total_s: 3374.1907148361206
  timestamp: 1594851877
  timesteps_since_restore: 1925000
  timesteps_this_iter: 5000
  timesteps_total: 1925000
  training_iteration: 385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3374 s, 385 iter, 1925000 ts, 312 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-24-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 308.9410066380286
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 385
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.523
    dispatch_time_ms: 11.744
    learner:
      cur_lr: 0.0012317949440330267
      grad_gnorm: 0.017565470188856125
      policy_entropy: 0.0017954426584765315
      policy_loss: 1.59621418305278e-08
      var_gnorm: 22.227493286132812
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.389899407262419e-07
    num_steps_sampled: 1930000
    num_steps_trained: 1930000
    wait_time_ms: 66.555
  iterations_since_restore: 386
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3382.2517738342285
  time_this_iter_s: 8.06105899810791
  time_total_s: 3382.2517738342285
  timestamp: 1594851885
  timesteps_since_restore: 1930000
  timesteps_this_iter: 5000
  timesteps_total: 1930000
  training_iteration: 386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3382 s, 386 iter, 1930000 ts, 309 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-24-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 305.52100666139484
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 386
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.084
    dispatch_time_ms: 6.484
    learner:
      cur_lr: 0.0012314619962126017
      grad_gnorm: 0.000498090113978833
      policy_entropy: 0.0017955353250727057
      policy_loss: 3.088056754751989e-10
      var_gnorm: 22.22747802734375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.9497184422512248e-10
    num_steps_sampled: 1935000
    num_steps_trained: 1935000
    wait_time_ms: 74.202
  iterations_since_restore: 387
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3390.394937515259
  time_this_iter_s: 8.143163681030273
  time_total_s: 3390.394937515259
  timestamp: 1594851893
  timesteps_since_restore: 1935000
  timesteps_this_iter: 5000
  timesteps_total: 1935000
  training_iteration: 387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3390 s, 387 iter, 1935000 ts, 306 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-25-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 303.18100666147734
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 387
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 7.592
    learner:
      cur_lr: 0.0012311290483921766
      grad_gnorm: 0.017023559659719467
      policy_entropy: 0.001795643474906683
      policy_loss: 1.2952393824150477e-08
      var_gnorm: 22.227462768554688
      vf_explained_var: 0.0
      vf_loss: 2.2457125226083008e-07
    num_steps_sampled: 1940000
    num_steps_trained: 1940000
    wait_time_ms: 70.399
  iterations_since_restore: 388
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3398.385354042053
  time_this_iter_s: 7.990416526794434
  time_total_s: 3398.385354042053
  timestamp: 1594851901
  timesteps_since_restore: 1940000
  timesteps_this_iter: 5000
  timesteps_total: 1940000
  training_iteration: 388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3398 s, 388 iter, 1940000 ts, 303 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-25-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 298.59100770270123
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 388
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.853
    dispatch_time_ms: 8.889
    learner:
      cur_lr: 0.0012307959841564298
      grad_gnorm: 0.0009786088485270739
      policy_entropy: 0.0017957498785108328
      policy_loss: 5.45549938557599e-10
      var_gnorm: 22.227447509765625
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.453807571167204e-10
    num_steps_sampled: 1945000
    num_steps_trained: 1945000
    wait_time_ms: 70.539
  iterations_since_restore: 389
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3406.5322318077087
  time_this_iter_s: 8.146877765655518
  time_total_s: 3406.5322318077087
  timestamp: 1594851909
  timesteps_since_restore: 1945000
  timesteps_this_iter: 5000
  timesteps_total: 1945000
  training_iteration: 389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3406 s, 389 iter, 1945000 ts, 299 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-25-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 293.5510078464958
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 389
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.807
    dispatch_time_ms: 10.107
    learner:
      cur_lr: 0.0012304630363360047
      grad_gnorm: 0.014465616084635258
      policy_entropy: 0.001795868156477809
      policy_loss: 1.0640895276026185e-08
      var_gnorm: 22.227432250976562
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.6161251892299333e-07
    num_steps_sampled: 1950000
    num_steps_trained: 1950000
    wait_time_ms: 67.071
  iterations_since_restore: 390
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3414.642946243286
  time_this_iter_s: 8.110714435577393
  time_total_s: 3414.642946243286
  timestamp: 1594851917
  timesteps_since_restore: 1950000
  timesteps_this_iter: 5000
  timesteps_total: 1950000
  training_iteration: 390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3414 s, 390 iter, 1950000 ts, 294 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-25-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 288.8710078984293
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 390
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 9.64
    learner:
      cur_lr: 0.0012301299721002579
      grad_gnorm: 0.0013191206380724907
      policy_entropy: 0.0017959879478439689
      policy_loss: 8.180255917089596e-10
      var_gnorm: 22.2274169921875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.3324128467218088e-09
    num_steps_sampled: 1955000
    num_steps_trained: 1955000
    wait_time_ms: 69.672
  iterations_since_restore: 391
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3422.7012481689453
  time_this_iter_s: 8.05830192565918
  time_total_s: 3422.7012481689453
  timestamp: 1594851925
  timesteps_since_restore: 1955000
  timesteps_this_iter: 5000
  timesteps_total: 1955000
  training_iteration: 391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3422 s, 391 iter, 1955000 ts, 289 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-25-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 282.9512619875356
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 391
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.234
    dispatch_time_ms: 8.143
    learner:
      cur_lr: 0.0012297970242798328
      grad_gnorm: 0.013816189020872116
      policy_entropy: 0.0017961305566132069
      policy_loss: 1.0546861162197274e-08
      var_gnorm: 22.227399826049805
      vf_explained_var: 0.0
      vf_loss: 1.4778086665501178e-07
    num_steps_sampled: 1960000
    num_steps_trained: 1960000
    wait_time_ms: 69.264
  iterations_since_restore: 392
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3430.7667820453644
  time_this_iter_s: 8.065533876419067
  time_total_s: 3430.7667820453644
  timestamp: 1594851934
  timesteps_since_restore: 1960000
  timesteps_this_iter: 5000
  timesteps_total: 1960000
  training_iteration: 392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3430 s, 392 iter, 1960000 ts, 283 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-25-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 276.11859562479736
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 392
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 7.245
    learner:
      cur_lr: 0.001229463960044086
      grad_gnorm: 0.0015378955285996199
      policy_entropy: 0.0017963284626603127
      policy_loss: 9.537046707919217e-10
      var_gnorm: 22.22738265991211
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.8405594826020888e-09
    num_steps_sampled: 1965000
    num_steps_trained: 1965000
    wait_time_ms: 73.116
  iterations_since_restore: 393
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3438.8294730186462
  time_this_iter_s: 8.06269097328186
  time_total_s: 3438.8294730186462
  timestamp: 1594851942
  timesteps_since_restore: 1965000
  timesteps_this_iter: 5000
  timesteps_total: 1965000
  training_iteration: 393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3438 s, 393 iter, 1965000 ts, 276 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-25-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 272.2485956252072
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 393
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.989
    dispatch_time_ms: 6.996
    learner:
      cur_lr: 0.001229131012223661
      grad_gnorm: 0.012730705551803112
      policy_entropy: 0.0017965366132557392
      policy_loss: 7.89500020914602e-09
      var_gnorm: 22.227365493774414
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.2546796313017694e-07
    num_steps_sampled: 1970000
    num_steps_trained: 1970000
    wait_time_ms: 71.126
  iterations_since_restore: 394
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3446.8835878372192
  time_this_iter_s: 8.054114818572998
  time_total_s: 3446.8835878372192
  timestamp: 1594851950
  timesteps_since_restore: 1970000
  timesteps_this_iter: 5000
  timesteps_total: 1970000
  training_iteration: 394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3446 s, 394 iter, 1970000 ts, 272 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-25-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 900.5577253234846
  episode_reward_mean: 270.1785956254146
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 394
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.605
    dispatch_time_ms: 15.508
    learner:
      cur_lr: 0.001228797947987914
      grad_gnorm: 0.0015261812368407845
      policy_entropy: 0.0017967532621696591
      policy_loss: 3.5214968718833006e-09
      var_gnorm: 22.22734832763672
      vf_explained_var: 0.0
      vf_loss: 1.8156861569806892e-09
    num_steps_sampled: 1975000
    num_steps_trained: 1975000
    wait_time_ms: 65.871
  iterations_since_restore: 395
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3455.192739725113
  time_this_iter_s: 8.309151887893677
  time_total_s: 3455.192739725113
  timestamp: 1594851958
  timesteps_since_restore: 1975000
  timesteps_this_iter: 5000
  timesteps_total: 1975000
  training_iteration: 395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3455 s, 395 iter, 1975000 ts, 270 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-26-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9998536666525
  episode_reward_mean: 261.17301837217974
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 395
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 16.433
    learner:
      cur_lr: 0.001228465000167489
      grad_gnorm: 0.011415581218898296
      policy_entropy: 0.0017969779437407851
      policy_loss: 1.7964143950166545e-08
      var_gnorm: 22.22732925415039
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.0103448744303023e-07
    num_steps_sampled: 1980000
    num_steps_trained: 1980000
    wait_time_ms: 66.029
  iterations_since_restore: 396
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3463.5610201358795
  time_this_iter_s: 8.368280410766602
  time_total_s: 3463.5610201358795
  timestamp: 1594851966
  timesteps_since_restore: 1980000
  timesteps_this_iter: 5000
  timesteps_total: 1980000
  training_iteration: 396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3463 s, 396 iter, 1980000 ts, 261 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-26-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9998536666525
  episode_reward_mean: 258.20301838029496
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 396
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.841
    dispatch_time_ms: 21.096
    learner:
      cur_lr: 0.001228132052347064
      grad_gnorm: 0.000529104785528034
      policy_entropy: 0.0017972176428884268
      policy_loss: 1.9373755377749546e-10
      var_gnorm: 22.227312088012695
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.8398990664358905e-10
    num_steps_sampled: 1985000
    num_steps_trained: 1985000
    wait_time_ms: 53.505
  iterations_since_restore: 397
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3472.064222574234
  time_this_iter_s: 8.503202438354492
  time_total_s: 3472.064222574234
  timestamp: 1594851975
  timesteps_since_restore: 1985000
  timesteps_this_iter: 5000
  timesteps_total: 1985000
  training_iteration: 397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3472 s, 397 iter, 1985000 ts, 258 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-26-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9998536666525
  episode_reward_mean: 256.0430183806743
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 397
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.517
    dispatch_time_ms: 36.14
    learner:
      cur_lr: 0.0012277989881113172
      grad_gnorm: 0.016240926459431648
      policy_entropy: 0.001797491917386651
      policy_loss: 1.8184353578476475e-08
      var_gnorm: 22.227293014526367
      vf_explained_var: 0.0
      vf_loss: 2.047498242063739e-07
    num_steps_sampled: 1990000
    num_steps_trained: 1990000
    wait_time_ms: 44.173
  iterations_since_restore: 398
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3480.963922023773
  time_this_iter_s: 8.899699449539185
  time_total_s: 3480.963922023773
  timestamp: 1594851984
  timesteps_since_restore: 1990000
  timesteps_this_iter: 5000
  timesteps_total: 1990000
  training_iteration: 398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3480 s, 398 iter, 1990000 ts, 256 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-26-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9998536666525
  episode_reward_mean: 254.0630183807253
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 398
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.111
    dispatch_time_ms: 34.591
    learner:
      cur_lr: 0.0012274660402908921
      grad_gnorm: 0.00019893833086825907
      policy_entropy: 0.001797765726223588
      policy_loss: -2.0876469997155311e-10
      var_gnorm: 22.227272033691406
      vf_explained_var: 0.0
      vf_loss: 3.54706472527333e-11
    num_steps_sampled: 1995000
    num_steps_trained: 1995000
    wait_time_ms: 48.608
  iterations_since_restore: 399
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3489.4923832416534
  time_this_iter_s: 8.528461217880249
  time_total_s: 3489.4923832416534
  timestamp: 1594851992
  timesteps_since_restore: 1995000
  timesteps_this_iter: 5000
  timesteps_total: 1995000
  training_iteration: 399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3489 s, 399 iter, 1995000 ts, 254 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-26-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9998536666525
  episode_reward_mean: 246.68989841921203
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 399
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.065
    dispatch_time_ms: 26.358
    learner:
      cur_lr: 0.0012271329760551453
      grad_gnorm: 0.01921401545405388
      policy_entropy: 0.001798061653971672
      policy_loss: 7.129472123779124e-08
      var_gnorm: 22.227252960205078
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.8591355771823146e-07
    num_steps_sampled: 2000000
    num_steps_trained: 2000000
    wait_time_ms: 60.17
  iterations_since_restore: 400
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3497.9901015758514
  time_this_iter_s: 8.497718334197998
  time_total_s: 3497.9901015758514
  timestamp: 1594852001
  timesteps_since_restore: 2000000
  timesteps_this_iter: 5000
  timesteps_total: 2000000
  training_iteration: 400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3497 s, 400 iter, 2000000 ts, 247 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-26-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9998536666525
  episode_reward_mean: 241.019931708329
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 400
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.711
    dispatch_time_ms: 23.324
    learner:
      cur_lr: 0.0012268000282347202
      grad_gnorm: 0.00102704344317317
      policy_entropy: 0.0017985665472224355
      policy_loss: 2.0084842677903225e-09
      var_gnorm: 22.22722816467285
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 8.228168701940319e-10
    num_steps_sampled: 2005000
    num_steps_trained: 2005000
    wait_time_ms: 45.308
  iterations_since_restore: 401
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3506.463796377182
  time_this_iter_s: 8.473694801330566
  time_total_s: 3506.463796377182
  timestamp: 1594852010
  timesteps_since_restore: 2005000
  timesteps_this_iter: 5000
  timesteps_total: 2005000
  training_iteration: 401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3506 s, 401 iter, 2005000 ts, 241 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-26-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9998536666525
  episode_reward_mean: 236.24993176207542
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 401
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.918
    dispatch_time_ms: 26.27
    learner:
      cur_lr: 0.0012264669639989734
      grad_gnorm: 0.0029920872766524553
      policy_entropy: 0.0017991368658840656
      policy_loss: 1.2486419898039003e-08
      var_gnorm: 22.227205276489258
      vf_explained_var: 0.0
      vf_loss: 6.910255034853208e-09
    num_steps_sampled: 2010000
    num_steps_trained: 2010000
    wait_time_ms: 62.292
  iterations_since_restore: 402
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3515.04035449028
  time_this_iter_s: 8.576558113098145
  time_total_s: 3515.04035449028
  timestamp: 1594852018
  timesteps_since_restore: 2010000
  timesteps_this_iter: 5000
  timesteps_total: 2010000
  training_iteration: 402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3515 s, 402 iter, 2010000 ts, 236 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-27-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9998536666525
  episode_reward_mean: 232.10993176344658
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 402
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.443
    dispatch_time_ms: 33.836
    learner:
      cur_lr: 0.0012261340161785483
      grad_gnorm: 0.00564217334613204
      policy_entropy: 0.001799717079848051
      policy_loss: -1.9812242124661594e-10
      var_gnorm: 22.22718048095703
      vf_explained_var: 0.0
      vf_loss: 1.9549345253722095e-08
    num_steps_sampled: 2015000
    num_steps_trained: 2015000
    wait_time_ms: 52.586
  iterations_since_restore: 403
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3523.5364882946014
  time_this_iter_s: 8.496133804321289
  time_total_s: 3523.5364882946014
  timestamp: 1594852027
  timesteps_since_restore: 2015000
  timesteps_this_iter: 5000
  timesteps_total: 2015000
  training_iteration: 403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3523 s, 403 iter, 2015000 ts, 232 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-27-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9998536666525
  episode_reward_mean: 227.15993227797387
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 403
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.583
    dispatch_time_ms: 23.878
    learner:
      cur_lr: 0.0012258009519428015
      grad_gnorm: 0.01210766937583685
      policy_entropy: 0.0018003026489168406
      policy_loss: 9.261496103363243e-08
      var_gnorm: 22.227155685424805
      vf_explained_var: 0.0
      vf_loss: 1.1343870198743389e-07
    num_steps_sampled: 2020000
    num_steps_trained: 2020000
    wait_time_ms: 65.358
  iterations_since_restore: 404
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3532.1602029800415
  time_this_iter_s: 8.623714685440063
  time_total_s: 3532.1602029800415
  timestamp: 1594852035
  timesteps_since_restore: 2020000
  timesteps_this_iter: 5000
  timesteps_total: 2020000
  training_iteration: 404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3532 s, 404 iter, 2020000 ts, 227 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-27-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 219.68993374130733
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 404
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.993
    dispatch_time_ms: 8.674
    learner:
      cur_lr: 0.0012254680041223764
      grad_gnorm: 0.013125644065439701
      policy_entropy: 0.0018009103368967772
      policy_loss: 7.126946588442706e-09
      var_gnorm: 22.227128982543945
      vf_explained_var: 0.0
      vf_loss: 1.3327354508874123e-07
    num_steps_sampled: 2025000
    num_steps_trained: 2025000
    wait_time_ms: 70.149
  iterations_since_restore: 405
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3540.6630594730377
  time_this_iter_s: 8.502856492996216
  time_total_s: 3540.6630594730377
  timestamp: 1594852044
  timesteps_since_restore: 2025000
  timesteps_this_iter: 5000
  timesteps_total: 2025000
  training_iteration: 405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3540 s, 405 iter, 2025000 ts, 220 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-27-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 215.18993377458793
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 405
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.623
    dispatch_time_ms: 10.72
    learner:
      cur_lr: 0.0012251350563019514
      grad_gnorm: 0.012915153987705708
      policy_entropy: 0.001801400212571025
      policy_loss: 2.926185871388043e-08
      var_gnorm: 22.22710418701172
      vf_explained_var: 0.0
      vf_loss: 1.2910572877444793e-07
    num_steps_sampled: 2030000
    num_steps_trained: 2030000
    wait_time_ms: 69.542
  iterations_since_restore: 406
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3548.6826405525208
  time_this_iter_s: 8.019581079483032
  time_total_s: 3548.6826405525208
  timestamp: 1594852052
  timesteps_since_restore: 2030000
  timesteps_this_iter: 5000
  timesteps_total: 2030000
  training_iteration: 406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3548 s, 406 iter, 2030000 ts, 215 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-27-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 211.2299337810687
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 406
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 7.849
    learner:
      cur_lr: 0.0012248019920662045
      grad_gnorm: 0.0004601801047101617
      policy_entropy: 0.0018020323477685452
      policy_loss: -2.083313521694663e-09
      var_gnorm: 22.227079391479492
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.6127722768377595e-10
    num_steps_sampled: 2035000
    num_steps_trained: 2035000
    wait_time_ms: 72.076
  iterations_since_restore: 407
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3556.776468038559
  time_this_iter_s: 8.093827486038208
  time_total_s: 3556.776468038559
  timestamp: 1594852060
  timesteps_since_restore: 2035000
  timesteps_this_iter: 5000
  timesteps_total: 2035000
  training_iteration: 407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3556 s, 407 iter, 2035000 ts, 211 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-27-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 205.46993606293188
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 407
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.325
    dispatch_time_ms: 9.58
    learner:
      cur_lr: 0.0012244690442457795
      grad_gnorm: 0.0005721310153603554
      policy_entropy: 0.0018026545876637101
      policy_loss: -3.5473302073540935e-10
      var_gnorm: 22.22705078125
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.490649353426022e-10
    num_steps_sampled: 2040000
    num_steps_trained: 2040000
    wait_time_ms: 68.792
  iterations_since_restore: 408
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3564.9206697940826
  time_this_iter_s: 8.144201755523682
  time_total_s: 3564.9206697940826
  timestamp: 1594852068
  timesteps_since_restore: 2040000
  timesteps_this_iter: 5000
  timesteps_total: 2040000
  training_iteration: 408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3564 s, 408 iter, 2040000 ts, 205 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-27-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 201.05993611896264
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 408
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.847
    dispatch_time_ms: 8.11
    learner:
      cur_lr: 0.0012241359800100327
      grad_gnorm: 0.0006158851902000606
      policy_entropy: 0.00180329498834908
      policy_loss: -6.83303913451283e-10
      var_gnorm: 22.227022171020508
      vf_explained_var: 0.0
      vf_loss: 2.912952101752353e-10
    num_steps_sampled: 2045000
    num_steps_trained: 2045000
    wait_time_ms: 69.861
  iterations_since_restore: 409
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3573.030890226364
  time_this_iter_s: 8.110220432281494
  time_total_s: 3573.030890226364
  timestamp: 1594852076
  timesteps_since_restore: 2045000
  timesteps_this_iter: 5000
  timesteps_total: 2045000
  training_iteration: 409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3573 s, 409 iter, 2045000 ts, 201 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-28-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 197.2799361196573
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 409
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 9.123
    learner:
      cur_lr: 0.0012238030321896076
      grad_gnorm: 0.005078321322798729
      policy_entropy: 0.0018039580900222063
      policy_loss: 1.7524614648323222e-08
      var_gnorm: 22.22699546813965
      vf_explained_var: 0.0
      vf_loss: 2.000222210085667e-08
    num_steps_sampled: 2050000
    num_steps_trained: 2050000
    wait_time_ms: 67.505
  iterations_since_restore: 410
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3581.147094964981
  time_this_iter_s: 8.116204738616943
  time_total_s: 3581.147094964981
  timestamp: 1594852085
  timesteps_since_restore: 2050000
  timesteps_this_iter: 5000
  timesteps_total: 2050000
  training_iteration: 410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3581 s, 410 iter, 2050000 ts, 197 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-28-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 194.4899361198
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 410
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.643
    dispatch_time_ms: 9.035
    learner:
      cur_lr: 0.0012234699679538608
      grad_gnorm: 0.0014890397433191538
      policy_entropy: 0.001804651110433042
      policy_loss: 9.234050191153642e-10
      var_gnorm: 22.226966857910156
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.7315969769171602e-09
    num_steps_sampled: 2055000
    num_steps_trained: 2055000
    wait_time_ms: 69.846
  iterations_since_restore: 411
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3589.230106830597
  time_this_iter_s: 8.083011865615845
  time_total_s: 3589.230106830597
  timestamp: 1594852093
  timesteps_since_restore: 2055000
  timesteps_this_iter: 5000
  timesteps_total: 2055000
  training_iteration: 411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3589 s, 411 iter, 2055000 ts, 194 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-28-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 192.3299361198723
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 411
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.975
    dispatch_time_ms: 5.389
    learner:
      cur_lr: 0.0012231370201334357
      grad_gnorm: 0.0004443833895493299
      policy_entropy: 0.001805364154279232
      policy_loss: -2.754874384169881e-10
      var_gnorm: 22.226938247680664
      vf_explained_var: 0.0
      vf_loss: 1.5197446079362464e-10
    num_steps_sampled: 2060000
    num_steps_trained: 2060000
    wait_time_ms: 73.159
  iterations_since_restore: 412
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3597.189311027527
  time_this_iter_s: 7.959204196929932
  time_total_s: 3597.189311027527
  timestamp: 1594852101
  timesteps_since_restore: 2060000
  timesteps_this_iter: 5000
  timesteps_total: 2060000
  training_iteration: 412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3597 s, 412 iter, 2060000 ts, 192 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-28-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 190.34993611991777
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 412
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.002
    dispatch_time_ms: 7.078
    learner:
      cur_lr: 0.0012228039558976889
      grad_gnorm: 0.0021096791606396437
      policy_entropy: 0.0018060790607705712
      policy_loss: 1.5694067156957203e-09
      var_gnorm: 22.22690773010254
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.4145390959139377e-09
    num_steps_sampled: 2065000
    num_steps_trained: 2065000
    wait_time_ms: 67.864
  iterations_since_restore: 413
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3605.101066350937
  time_this_iter_s: 7.911755323410034
  time_total_s: 3605.101066350937
  timestamp: 1594852109
  timesteps_since_restore: 2065000
  timesteps_this_iter: 5000
  timesteps_total: 2065000
  training_iteration: 413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3605 s, 413 iter, 2065000 ts, 190 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-28-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 187.8299361200426
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 413
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.285
    dispatch_time_ms: 8.961
    learner:
      cur_lr: 0.0012224710080772638
      grad_gnorm: 0.006647167261689901
      policy_entropy: 0.0018068271456286311
      policy_loss: -4.122265639949774e-09
      var_gnorm: 22.226879119873047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.41679253779148e-08
    num_steps_sampled: 2070000
    num_steps_trained: 2070000
    wait_time_ms: 67.956
  iterations_since_restore: 414
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3613.0467207431793
  time_this_iter_s: 7.945654392242432
  time_total_s: 3613.0467207431793
  timestamp: 1594852117
  timesteps_since_restore: 2070000
  timesteps_this_iter: 5000
  timesteps_total: 2070000
  training_iteration: 414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3613 s, 414 iter, 2070000 ts, 188 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-28-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 182.42994284098958
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 414
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.687
    dispatch_time_ms: 6.651
    learner:
      cur_lr: 0.001222137943841517
      grad_gnorm: 0.0028082947246730328
      policy_entropy: 0.0018076556734740734
      policy_loss: 1.7415600073178439e-09
      var_gnorm: 22.226848602294922
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.096838145452921e-09
    num_steps_sampled: 2075000
    num_steps_trained: 2075000
    wait_time_ms: 71.53
  iterations_since_restore: 415
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3620.909131526947
  time_this_iter_s: 7.8624107837677
  time_total_s: 3620.909131526947
  timestamp: 1594852124
  timesteps_since_restore: 2075000
  timesteps_this_iter: 5000
  timesteps_total: 2075000
  training_iteration: 415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3620 s, 415 iter, 2075000 ts, 182 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-28-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 179.36994284252754
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 415
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.338
    dispatch_time_ms: 6.303
    learner:
      cur_lr: 0.001221804996021092
      grad_gnorm: 0.012025146745145321
      policy_entropy: 0.0018084943294525146
      policy_loss: 2.8246518013474997e-08
      var_gnorm: 22.22681999206543
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.1194343585430033e-07
    num_steps_sampled: 2080000
    num_steps_trained: 2080000
    wait_time_ms: 68.252
  iterations_since_restore: 416
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3628.828109025955
  time_this_iter_s: 7.918977499008179
  time_total_s: 3628.828109025955
  timestamp: 1594852132
  timesteps_since_restore: 2080000
  timesteps_this_iter: 5000
  timesteps_total: 2080000
  training_iteration: 416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3628 s, 416 iter, 2080000 ts, 179 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-29-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 176.84994284415512
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 416
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.605
    dispatch_time_ms: 7.212
    learner:
      cur_lr: 0.001221472048200667
      grad_gnorm: 0.00270381523296237
      policy_entropy: 0.0018093909602612257
      policy_loss: 1.590057391309685e-10
      var_gnorm: 22.226787567138672
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.651226153702282e-09
    num_steps_sampled: 2085000
    num_steps_trained: 2085000
    wait_time_ms: 68.902
  iterations_since_restore: 417
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3636.786148071289
  time_this_iter_s: 7.958039045333862
  time_total_s: 3636.786148071289
  timestamp: 1594852140
  timesteps_since_restore: 2085000
  timesteps_this_iter: 5000
  timesteps_total: 2085000
  training_iteration: 417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3636 s, 417 iter, 2085000 ts, 177 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-29-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 174.7799428444002
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 417
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 6.165
    learner:
      cur_lr: 0.00122113898396492
      grad_gnorm: 0.021706439554691315
      policy_entropy: 0.0018102764151990414
      policy_loss: 2.7345970821102128e-08
      var_gnorm: 22.226757049560547
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.651537952009676e-07
    num_steps_sampled: 2090000
    num_steps_trained: 2090000
    wait_time_ms: 70.524
  iterations_since_restore: 418
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3644.706916809082
  time_this_iter_s: 7.920768737792969
  time_total_s: 3644.706916809082
  timestamp: 1594852148
  timesteps_since_restore: 2090000
  timesteps_this_iter: 5000
  timesteps_total: 2090000
  training_iteration: 418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3644 s, 418 iter, 2090000 ts, 175 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-29-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 172.16994284531
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 418
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.506
    dispatch_time_ms: 9.359
    learner:
      cur_lr: 0.001220806036144495
      grad_gnorm: 0.005234864540398121
      policy_entropy: 0.0018112005200237036
      policy_loss: 4.050213053830021e-09
      var_gnorm: 22.22672462463379
      vf_explained_var: 0.0
      vf_loss: 2.118262720784969e-08
    num_steps_sampled: 2095000
    num_steps_trained: 2095000
    wait_time_ms: 67.221
  iterations_since_restore: 419
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3652.6052367687225
  time_this_iter_s: 7.898319959640503
  time_total_s: 3652.6052367687225
  timestamp: 1594852156
  timesteps_since_restore: 2095000
  timesteps_this_iter: 5000
  timesteps_total: 2095000
  training_iteration: 419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3652 s, 419 iter, 2095000 ts, 172 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-29-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 168.92994285033706
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 419
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.744
    dispatch_time_ms: 6.9
    learner:
      cur_lr: 0.0012204729719087481
      grad_gnorm: 0.03626375272870064
      policy_entropy: 0.0018121559405699372
      policy_loss: -6.351742687371598e-09
      var_gnorm: 22.226694107055664
      vf_explained_var: 0.0
      vf_loss: 1.0190215107286349e-06
    num_steps_sampled: 2100000
    num_steps_trained: 2100000
    wait_time_ms: 71.228
  iterations_since_restore: 420
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3660.581491947174
  time_this_iter_s: 7.976255178451538
  time_total_s: 3660.581491947174
  timestamp: 1594852164
  timesteps_since_restore: 2100000
  timesteps_this_iter: 5000
  timesteps_total: 2100000
  training_iteration: 420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3660 s, 420 iter, 2100000 ts, 169 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-29-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 166.31994285067557
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 420
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 6.547
    learner:
      cur_lr: 0.0012201400240883231
      grad_gnorm: 0.002240844303742051
      policy_entropy: 0.0018131535034626722
      policy_loss: 1.3896498396448465e-09
      var_gnorm: 22.226661682128906
      vf_explained_var: 0.0
      vf_loss: 3.884418564581438e-09
    num_steps_sampled: 2105000
    num_steps_trained: 2105000
    wait_time_ms: 70.138
  iterations_since_restore: 421
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3668.5104393959045
  time_this_iter_s: 7.928947448730469
  time_total_s: 3668.5104393959045
  timestamp: 1594852172
  timesteps_since_restore: 2105000
  timesteps_this_iter: 5000
  timesteps_total: 2105000
  training_iteration: 421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3668 s, 421 iter, 2105000 ts, 166 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-29-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 163.07994922955675
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 421
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.584
    dispatch_time_ms: 8.373
    learner:
      cur_lr: 0.0012198069598525763
      grad_gnorm: 0.03803402930498123
      policy_entropy: 0.001814187504351139
      policy_loss: -2.3586970598898915e-08
      var_gnorm: 22.22662925720215
      vf_explained_var: 0.0
      vf_loss: 1.1208387604710879e-06
    num_steps_sampled: 2110000
    num_steps_trained: 2110000
    wait_time_ms: 69.3
  iterations_since_restore: 422
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3676.5759739875793
  time_this_iter_s: 8.065534591674805
  time_total_s: 3676.5759739875793
  timestamp: 1594852180
  timesteps_since_restore: 2110000
  timesteps_this_iter: 5000
  timesteps_total: 2110000
  training_iteration: 422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3676 s, 422 iter, 2110000 ts, 163 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-29-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 160.37994935880997
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 422
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.605
    dispatch_time_ms: 9.329
    learner:
      cur_lr: 0.0012194740120321512
      grad_gnorm: 0.010583743453025818
      policy_entropy: 0.0018155260477215052
      policy_loss: -1.2939022075997286e-09
      var_gnorm: 22.226593017578125
      vf_explained_var: 0.0
      vf_loss: 8.660840933316649e-08
    num_steps_sampled: 2115000
    num_steps_trained: 2115000
    wait_time_ms: 71.19
  iterations_since_restore: 423
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3684.6989781856537
  time_this_iter_s: 8.12300419807434
  time_total_s: 3684.6989781856537
  timestamp: 1594852189
  timesteps_since_restore: 2115000
  timesteps_this_iter: 5000
  timesteps_total: 2115000
  training_iteration: 423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3684 s, 423 iter, 2115000 ts, 160 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-29-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 154.52995049879712
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 423
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 7.281
    learner:
      cur_lr: 0.0012191409477964044
      grad_gnorm: 0.056093838065862656
      policy_entropy: 0.001816893694922328
      policy_loss: -1.4274555759641316e-08
      var_gnorm: 22.226558685302734
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.437067905702861e-06
    num_steps_sampled: 2120000
    num_steps_trained: 2120000
    wait_time_ms: 68.889
  iterations_since_restore: 424
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3692.737249851227
  time_this_iter_s: 8.03827166557312
  time_total_s: 3692.737249851227
  timestamp: 1594852197
  timesteps_since_restore: 2120000
  timesteps_this_iter: 5000
  timesteps_total: 2120000
  training_iteration: 424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3692 s, 424 iter, 2120000 ts, 155 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-30-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 150.92995050225852
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 424
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.043
    dispatch_time_ms: 8.473
    learner:
      cur_lr: 0.0012188079999759793
      grad_gnorm: 0.010330292396247387
      policy_entropy: 0.0018183605279773474
      policy_loss: -6.406373209699723e-09
      var_gnorm: 22.22652244567871
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 8.24868280346891e-08
    num_steps_sampled: 2125000
    num_steps_trained: 2125000
    wait_time_ms: 69.666
  iterations_since_restore: 425
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3700.8926520347595
  time_this_iter_s: 8.155402183532715
  time_total_s: 3700.8926520347595
  timestamp: 1594852205
  timesteps_since_restore: 2125000
  timesteps_this_iter: 5000
  timesteps_total: 2125000
  training_iteration: 425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3700 s, 425 iter, 2125000 ts, 151 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-30-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 692.999995252562
  episode_reward_mean: 148.31995050300245
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 425
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.004
    dispatch_time_ms: 8.852
    learner:
      cur_lr: 0.0012184750521555543
      grad_gnorm: 0.06089434772729874
      policy_entropy: 0.0018198555335402489
      policy_loss: -3.776390755660941e-08
      var_gnorm: 22.22648811340332
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.8720262434944743e-06
    num_steps_sampled: 2130000
    num_steps_trained: 2130000
    wait_time_ms: 71.899
  iterations_since_restore: 426
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3708.975882291794
  time_this_iter_s: 8.083230257034302
  time_total_s: 3708.975882291794
  timestamp: 1594852213
  timesteps_since_restore: 2130000
  timesteps_this_iter: 5000
  timesteps_total: 2130000
  training_iteration: 426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3708 s, 426 iter, 2130000 ts, 148 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-30-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 674.9993452072281
  episode_reward_mean: 141.3899505504768
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 426
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 7.526
    learner:
      cur_lr: 0.0012181419879198074
      grad_gnorm: 0.04383392632007599
      policy_entropy: 0.0018273568712174892
      policy_loss: 3.396476699890627e-08
      var_gnorm: 22.226451873779297
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.4885655446050805e-06
    num_steps_sampled: 2135000
    num_steps_trained: 2135000
    wait_time_ms: 70.543
  iterations_since_restore: 427
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3717.057656288147
  time_this_iter_s: 8.08177399635315
  time_total_s: 3717.057656288147
  timestamp: 1594852221
  timesteps_since_restore: 2135000
  timesteps_this_iter: 5000
  timesteps_total: 2135000
  training_iteration: 427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3717 s, 427 iter, 2135000 ts, 141 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-30-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 674.9993452072281
  episode_reward_mean: 136.1699535295119
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 427
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.85
    dispatch_time_ms: 9.478
    learner:
      cur_lr: 0.0012178090400993824
      grad_gnorm: 0.011487891897559166
      policy_entropy: 0.0018289312720298767
      policy_loss: -7.463514251071501e-09
      var_gnorm: 22.22641944885254
      vf_explained_var: 0.0
      vf_loss: 1.0234012393084413e-07
    num_steps_sampled: 2140000
    num_steps_trained: 2140000
    wait_time_ms: 70.073
  iterations_since_restore: 428
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3725.169549703598
  time_this_iter_s: 8.11189341545105
  time_total_s: 3725.169549703598
  timestamp: 1594852229
  timesteps_since_restore: 2140000
  timesteps_this_iter: 5000
  timesteps_total: 2140000
  training_iteration: 428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3725 s, 428 iter, 2140000 ts, 136 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-30-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 674.9993452072281
  episode_reward_mean: 132.02995361841076
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 428
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.636
    dispatch_time_ms: 8.089
    learner:
      cur_lr: 0.0012174759758636355
      grad_gnorm: 0.08940921723842621
      policy_entropy: 0.0018305849516764283
      policy_loss: -1.990788423000822e-09
      var_gnorm: 22.226383209228516
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.1906898736197036e-06
    num_steps_sampled: 2145000
    num_steps_trained: 2145000
    wait_time_ms: 70.128
  iterations_since_restore: 429
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3733.2507417201996
  time_this_iter_s: 8.081192016601562
  time_total_s: 3733.2507417201996
  timestamp: 1594852237
  timesteps_since_restore: 2145000
  timesteps_this_iter: 5000
  timesteps_total: 2145000
  training_iteration: 429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3733 s, 429 iter, 2145000 ts, 132 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-30-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9965639951372
  episode_reward_mean: 125.2799601663385
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 429
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.001
    dispatch_time_ms: 8.315
    learner:
      cur_lr: 0.0012171430280432105
      grad_gnorm: 0.3049594759941101
      policy_entropy: 0.0018322770483791828
      policy_loss: -2.203986895210619e-07
      var_gnorm: 22.226350784301758
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.202670531114563e-05
    num_steps_sampled: 2150000
    num_steps_trained: 2150000
    wait_time_ms: 69.783
  iterations_since_restore: 430
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3741.3079121112823
  time_this_iter_s: 8.057170391082764
  time_total_s: 3741.3079121112823
  timestamp: 1594852245
  timesteps_since_restore: 2150000
  timesteps_this_iter: 5000
  timesteps_total: 2150000
  training_iteration: 430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3741 s, 430 iter, 2150000 ts, 125 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-30-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9965639951372
  episode_reward_mean: 121.49996016872741
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 430
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.828
    dispatch_time_ms: 8.966
    learner:
      cur_lr: 0.0012168099638074636
      grad_gnorm: 0.6101058125495911
      policy_entropy: 0.001834098482504487
      policy_loss: -1.8527799738876638e-07
      var_gnorm: 22.2263240814209
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0002882787957787514
    num_steps_sampled: 2155000
    num_steps_trained: 2155000
    wait_time_ms: 69.85
  iterations_since_restore: 431
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3749.3720602989197
  time_this_iter_s: 8.064148187637329
  time_total_s: 3749.3720602989197
  timestamp: 1594852254
  timesteps_since_restore: 2155000
  timesteps_this_iter: 5000
  timesteps_total: 2155000
  training_iteration: 431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3749 s, 431 iter, 2155000 ts, 121 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-31-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9965639951372
  episode_reward_mean: 119.24996017195153
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 431
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 5.43
    learner:
      cur_lr: 0.0012164770159870386
      grad_gnorm: 0.43538767099380493
      policy_entropy: 0.0018362898845225573
      policy_loss: -5.454682536765176e-07
      var_gnorm: 22.226289749145508
      vf_explained_var: 0.0
      vf_loss: 0.00014680840831715614
    num_steps_sampled: 2160000
    num_steps_trained: 2160000
    wait_time_ms: 75.979
  iterations_since_restore: 432
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3757.4668974876404
  time_this_iter_s: 8.094837188720703
  time_total_s: 3757.4668974876404
  timestamp: 1594852262
  timesteps_since_restore: 2160000
  timesteps_this_iter: 5000
  timesteps_total: 2160000
  training_iteration: 432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3757 s, 432 iter, 2160000 ts, 119 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-31-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9965639951372
  episode_reward_mean: 116.90996017510841
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 432
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.403
    dispatch_time_ms: 10.01
    learner:
      cur_lr: 0.0012161439517512918
      grad_gnorm: 1.9125689268112183
      policy_entropy: 0.0018378791864961386
      policy_loss: 2.967964519484667e-06
      var_gnorm: 22.226285934448242
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.002832881873473525
    num_steps_sampled: 2165000
    num_steps_trained: 2165000
    wait_time_ms: 68.103
  iterations_since_restore: 433
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3765.927722930908
  time_this_iter_s: 8.460825443267822
  time_total_s: 3765.927722930908
  timestamp: 1594852270
  timesteps_since_restore: 2165000
  timesteps_this_iter: 5000
  timesteps_total: 2165000
  training_iteration: 433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3765 s, 433 iter, 2165000 ts, 117 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-31-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9965639951372
  episode_reward_mean: 114.20996017536986
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 433
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.484
    dispatch_time_ms: 7.86
    learner:
      cur_lr: 0.0012158110039308667
      grad_gnorm: 0.07120898365974426
      policy_entropy: 0.0018389284377917647
      policy_loss: 8.508109772265016e-08
      var_gnorm: 22.226253509521484
      vf_explained_var: 0.0
      vf_loss: 3.928034402633784e-06
    num_steps_sampled: 2170000
    num_steps_trained: 2170000
    wait_time_ms: 71.097
  iterations_since_restore: 434
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3774.03134393692
  time_this_iter_s: 8.103621006011963
  time_total_s: 3774.03134393692
  timestamp: 1594852278
  timesteps_since_restore: 2170000
  timesteps_this_iter: 5000
  timesteps_total: 2170000
  training_iteration: 434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3774 s, 434 iter, 2170000 ts, 114 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-31-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9965639951372
  episode_reward_mean: 111.689960175527
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 434
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 7.884
    learner:
      cur_lr: 0.0012154780561104417
      grad_gnorm: 0.0009676917688921094
      policy_entropy: 0.0018412466160953045
      policy_loss: -5.954526871576604e-10
      var_gnorm: 22.226221084594727
      vf_explained_var: 0.0
      vf_loss: 7.12295222804471e-10
    num_steps_sampled: 2175000
    num_steps_trained: 2175000
    wait_time_ms: 71.111
  iterations_since_restore: 435
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3782.098869562149
  time_this_iter_s: 8.067525625228882
  time_total_s: 3782.098869562149
  timestamp: 1594852286
  timesteps_since_restore: 2175000
  timesteps_this_iter: 5000
  timesteps_total: 2175000
  training_iteration: 435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3782 s, 435 iter, 2175000 ts, 112 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-31-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9965639951372
  episode_reward_mean: 109.70996017557128
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 435
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.533
    dispatch_time_ms: 8.13
    learner:
      cur_lr: 0.0012151449918746948
      grad_gnorm: 0.020210307091474533
      policy_entropy: 0.0018436324317008257
      policy_loss: 1.3130343923251075e-08
      var_gnorm: 22.2261905670166
      vf_explained_var: 0.0
      vf_loss: 3.1598153782397276e-07
    num_steps_sampled: 2180000
    num_steps_trained: 2180000
    wait_time_ms: 71.157
  iterations_since_restore: 436
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3790.1387236118317
  time_this_iter_s: 8.039854049682617
  time_total_s: 3790.1387236118317
  timestamp: 1594852294
  timesteps_since_restore: 2180000
  timesteps_this_iter: 5000
  timesteps_total: 2180000
  training_iteration: 436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3790 s, 436 iter, 2180000 ts, 110 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-31-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9965639951372
  episode_reward_mean: 107.27996017570825
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 436
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.444
    dispatch_time_ms: 9.197
    learner:
      cur_lr: 0.0012148120440542698
      grad_gnorm: 0.0009292637696489692
      policy_entropy: 0.0018462095176801085
      policy_loss: -1.2952438011026857e-09
      var_gnorm: 22.22616195678711
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.633162907832002e-10
    num_steps_sampled: 2185000
    num_steps_trained: 2185000
    wait_time_ms: 68.243
  iterations_since_restore: 437
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3798.2693071365356
  time_this_iter_s: 8.13058352470398
  time_total_s: 3798.2693071365356
  timestamp: 1594852303
  timesteps_since_restore: 2185000
  timesteps_this_iter: 5000
  timesteps_total: 2185000
  training_iteration: 437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3798 s, 437 iter, 2185000 ts, 107 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-31-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9965639951372
  episode_reward_mean: 103.679960176761
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 437
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.834
    dispatch_time_ms: 7.314
    learner:
      cur_lr: 0.001214478979818523
      grad_gnorm: 0.015864860266447067
      policy_entropy: 0.0018488342175260186
      policy_loss: 1.0307165787537542e-08
      var_gnorm: 22.226137161254883
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.9495708158956404e-07
    num_steps_sampled: 2190000
    num_steps_trained: 2190000
    wait_time_ms: 70.116
  iterations_since_restore: 438
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3806.298282146454
  time_this_iter_s: 8.028975009918213
  time_total_s: 3806.298282146454
  timestamp: 1594852311
  timesteps_since_restore: 2190000
  timesteps_this_iter: 5000
  timesteps_total: 2190000
  training_iteration: 438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3806 s, 438 iter, 2190000 ts, 104 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-31-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9965639951372
  episode_reward_mean: 101.51996017682555
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 438
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.67
    dispatch_time_ms: 9.247
    learner:
      cur_lr: 0.001214146031998098
      grad_gnorm: 0.0017866735579445958
      policy_entropy: 0.001851638313382864
      policy_loss: 3.7722350243463154e-10
      var_gnorm: 22.226112365722656
      vf_explained_var: 0.0
      vf_loss: 2.438140356275653e-09
    num_steps_sampled: 2195000
    num_steps_trained: 2195000
    wait_time_ms: 67.479
  iterations_since_restore: 439
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3814.382073163986
  time_this_iter_s: 8.083791017532349
  time_total_s: 3814.382073163986
  timestamp: 1594852319
  timesteps_since_restore: 2195000
  timesteps_this_iter: 5000
  timesteps_total: 2195000
  training_iteration: 439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3814 s, 439 iter, 2195000 ts, 102 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-32-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9965639951372
  episode_reward_mean: 95.39996051438493
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 439
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.602
    dispatch_time_ms: 7.097
    learner:
      cur_lr: 0.001213812967762351
      grad_gnorm: 0.00956711545586586
      policy_entropy: 0.0018547819927334785
      policy_loss: 1.1222906159957802e-08
      var_gnorm: 22.226089477539062
      vf_explained_var: 0.0
      vf_loss: 7.075667696199162e-08
    num_steps_sampled: 2200000
    num_steps_trained: 2200000
    wait_time_ms: 72.355
  iterations_since_restore: 440
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3822.4868569374084
  time_this_iter_s: 8.104783773422241
  time_total_s: 3822.4868569374084
  timestamp: 1594852327
  timesteps_since_restore: 2200000
  timesteps_this_iter: 5000
  timesteps_total: 2200000
  training_iteration: 440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3822 s, 440 iter, 2200000 ts, 95.4 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-32-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 602.9999316973922
  episode_reward_mean: 88.73999487443356
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 440
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.933
    dispatch_time_ms: 7.892
    learner:
      cur_lr: 0.001213480019941926
      grad_gnorm: 0.0009537955047562718
      policy_entropy: 0.001858026604168117
      policy_loss: -1.0362436464461666e-09
      var_gnorm: 22.226070404052734
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.081426556254655e-10
    num_steps_sampled: 2205000
    num_steps_trained: 2205000
    wait_time_ms: 68.946
  iterations_since_restore: 441
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3830.534353494644
  time_this_iter_s: 8.047496557235718
  time_total_s: 3830.534353494644
  timestamp: 1594852335
  timesteps_since_restore: 2205000
  timesteps_this_iter: 5000
  timesteps_total: 2205000
  training_iteration: 441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3830 s, 441 iter, 2205000 ts, 88.7 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-32-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 602.9999316973922
  episode_reward_mean: 83.06999510325986
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 441
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.798
    dispatch_time_ms: 9.609
    learner:
      cur_lr: 0.0012131469557061791
      grad_gnorm: 0.011640018783509731
      policy_entropy: 0.0018613511929288507
      policy_loss: 7.562348969258892e-09
      var_gnorm: 22.226058959960938
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.0468447442235629e-07
    num_steps_sampled: 2210000
    num_steps_trained: 2210000
    wait_time_ms: 67.346
  iterations_since_restore: 442
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3838.5509901046753
  time_this_iter_s: 8.016636610031128
  time_total_s: 3838.5509901046753
  timestamp: 1594852343
  timesteps_since_restore: 2210000
  timesteps_this_iter: 5000
  timesteps_total: 2210000
  training_iteration: 442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3838 s, 442 iter, 2210000 ts, 83.1 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-32-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 602.9999316973922
  episode_reward_mean: 77.21999518219495
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 442
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.725
    dispatch_time_ms: 8.969
    learner:
      cur_lr: 0.0012128140078857541
      grad_gnorm: 0.003730272874236107
      policy_entropy: 0.0018649246776476502
      policy_loss: 5.204018993509862e-09
      var_gnorm: 22.226049423217773
      vf_explained_var: 0.0
      vf_loss: 1.0740508038509233e-08
    num_steps_sampled: 2215000
    num_steps_trained: 2215000
    wait_time_ms: 68.58
  iterations_since_restore: 443
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3846.6302580833435
  time_this_iter_s: 8.079267978668213
  time_total_s: 3846.6302580833435
  timestamp: 1594852351
  timesteps_since_restore: 2215000
  timesteps_this_iter: 5000
  timesteps_total: 2215000
  training_iteration: 443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3846 s, 443 iter, 2215000 ts, 77.2 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-32-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 602.9999316973922
  episode_reward_mean: 72.44999573518957
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 443
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.65
    dispatch_time_ms: 11.378
    learner:
      cur_lr: 0.0012124809436500072
      grad_gnorm: 0.0025242483243346214
      policy_entropy: 0.0018686891999095678
      policy_loss: 2.9632859721573368e-08
      var_gnorm: 22.226049423217773
      vf_explained_var: 0.0
      vf_loss: 4.979024748053007e-09
    num_steps_sampled: 2220000
    num_steps_trained: 2220000
    wait_time_ms: 68.189
  iterations_since_restore: 444
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3854.7213406562805
  time_this_iter_s: 8.091082572937012
  time_total_s: 3854.7213406562805
  timestamp: 1594852359
  timesteps_since_restore: 2220000
  timesteps_this_iter: 5000
  timesteps_total: 2220000
  training_iteration: 444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3854 s, 444 iter, 2220000 ts, 72.4 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-32-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 602.9999316973922
  episode_reward_mean: 69.02999574146033
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 444
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.689
    dispatch_time_ms: 9.451
    learner:
      cur_lr: 0.0012121479958295822
      grad_gnorm: 0.0004322962195146829
      policy_entropy: 0.0018728089053183794
      policy_loss: 6.876095692831541e-09
      var_gnorm: 22.226055145263672
      vf_explained_var: 0.0
      vf_loss: 1.3830085687782656e-10
    num_steps_sampled: 2225000
    num_steps_trained: 2225000
    wait_time_ms: 69.206
  iterations_since_restore: 445
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3862.800355911255
  time_this_iter_s: 8.079015254974365
  time_total_s: 3862.800355911255
  timestamp: 1594852367
  timesteps_since_restore: 2225000
  timesteps_this_iter: 5000
  timesteps_total: 2225000
  training_iteration: 445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3862 s, 445 iter, 2225000 ts, 69 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-32-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 602.9999316973922
  episode_reward_mean: 66.41999576670786
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 445
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.605
    dispatch_time_ms: 10.283
    learner:
      cur_lr: 0.0012118150480091572
      grad_gnorm: 0.0043424684554338455
      policy_entropy: 0.0018771312898024917
      policy_loss: 2.527303699650929e-08
      var_gnorm: 22.22607421875
      vf_explained_var: 0.0
      vf_loss: 1.4679945259388205e-08
    num_steps_sampled: 2230000
    num_steps_trained: 2230000
    wait_time_ms: 70.933
  iterations_since_restore: 446
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3870.895184993744
  time_this_iter_s: 8.094829082489014
  time_total_s: 3870.895184993744
  timestamp: 1594852376
  timesteps_since_restore: 2230000
  timesteps_this_iter: 5000
  timesteps_total: 2230000
  training_iteration: 446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3870 s, 446 iter, 2230000 ts, 66.4 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-33-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 602.9999316973922
  episode_reward_mean: 63.89999576843524
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 446
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.744
    dispatch_time_ms: 7.406
    learner:
      cur_lr: 0.0012114819837734103
      grad_gnorm: 0.08621123433113098
      policy_entropy: 0.0018816703232005239
      policy_loss: 7.838480087229982e-08
      var_gnorm: 22.22610855102539
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.7547431424609385e-06
    num_steps_sampled: 2235000
    num_steps_trained: 2235000
    wait_time_ms: 74.621
  iterations_since_restore: 447
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3879.490441799164
  time_this_iter_s: 8.595256805419922
  time_total_s: 3879.490441799164
  timestamp: 1594852384
  timesteps_since_restore: 2235000
  timesteps_this_iter: 5000
  timesteps_total: 2235000
  training_iteration: 447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3879 s, 447 iter, 2235000 ts, 63.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-33-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 602.9999316973922
  episode_reward_mean: 62.00999576851722
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 447
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.175
    dispatch_time_ms: 8.807
    learner:
      cur_lr: 0.0012111490359529853
      grad_gnorm: 0.01114096399396658
      policy_entropy: 0.001886530895717442
      policy_loss: 6.096296800706114e-08
      var_gnorm: 22.22616195678711
      vf_explained_var: 0.0
      vf_loss: 9.614814899805424e-08
    num_steps_sampled: 2240000
    num_steps_trained: 2240000
    wait_time_ms: 68.629
  iterations_since_restore: 448
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3887.5063874721527
  time_this_iter_s: 8.015945672988892
  time_total_s: 3887.5063874721527
  timestamp: 1594852392
  timesteps_since_restore: 2240000
  timesteps_this_iter: 5000
  timesteps_total: 2240000
  training_iteration: 448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3887 s, 448 iter, 2240000 ts, 62 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-33-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 602.9999316973922
  episode_reward_mean: 59.84999576859946
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 448
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.79
    dispatch_time_ms: 8.413
    learner:
      cur_lr: 0.0012108159717172384
      grad_gnorm: 0.0036930921487510204
      policy_entropy: 0.0018918756395578384
      policy_loss: 2.3993356190743498e-09
      var_gnorm: 22.226242065429688
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.049886311221826e-08
    num_steps_sampled: 2245000
    num_steps_trained: 2245000
    wait_time_ms: 70.141
  iterations_since_restore: 449
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3895.5786645412445
  time_this_iter_s: 8.072277069091797
  time_total_s: 3895.5786645412445
  timestamp: 1594852400
  timesteps_since_restore: 2245000
  timesteps_this_iter: 5000
  timesteps_total: 2245000
  training_iteration: 449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3895 s, 449 iter, 2245000 ts, 59.8 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-33-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 602.9999316973922
  episode_reward_mean: 57.05999576872709
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 449
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.624
    dispatch_time_ms: 8.259
    learner:
      cur_lr: 0.0012104830238968134
      grad_gnorm: 0.006462142337113619
      policy_entropy: 0.0018976634601131082
      policy_loss: 3.4143326388402784e-08
      var_gnorm: 22.226360321044922
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.234076828562138e-08
    num_steps_sampled: 2250000
    num_steps_trained: 2250000
    wait_time_ms: 67.727
  iterations_since_restore: 450
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3903.660723209381
  time_this_iter_s: 8.082058668136597
  time_total_s: 3903.660723209381
  timestamp: 1594852408
  timesteps_since_restore: 2250000
  timesteps_this_iter: 5000
  timesteps_total: 2250000
  training_iteration: 450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3903 s, 450 iter, 2250000 ts, 57.1 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-33-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 602.9999316973922
  episode_reward_mean: 51.65999583024295
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 450
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.521
    dispatch_time_ms: 8.38
    learner:
      cur_lr: 0.0012101499596610665
      grad_gnorm: 0.0012386596063151956
      policy_entropy: 0.001904049888253212
      policy_loss: 6.936384799871576e-10
      var_gnorm: 22.22653579711914
      vf_explained_var: 0.0
      vf_loss: 1.18572462959321e-09
    num_steps_sampled: 2255000
    num_steps_trained: 2255000
    wait_time_ms: 71.327
  iterations_since_restore: 451
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3911.7366428375244
  time_this_iter_s: 8.07591962814331
  time_total_s: 3911.7366428375244
  timestamp: 1594852417
  timesteps_since_restore: 2255000
  timesteps_this_iter: 5000
  timesteps_total: 2255000
  training_iteration: 451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3911 s, 451 iter, 2255000 ts, 51.7 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-33-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999903947497
  episode_reward_mean: 45.629996513269035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 451
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.174
    dispatch_time_ms: 6.842
    learner:
      cur_lr: 0.0012098170118406415
      grad_gnorm: 0.012662203051149845
      policy_entropy: 0.0019113838206976652
      policy_loss: 3.3616053940477286e-08
      var_gnorm: 22.226802825927734
      vf_explained_var: 0.0
      vf_loss: 1.241944573848741e-07
    num_steps_sampled: 2260000
    num_steps_trained: 2260000
    wait_time_ms: 74.891
  iterations_since_restore: 452
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3919.8749771118164
  time_this_iter_s: 8.138334274291992
  time_total_s: 3919.8749771118164
  timestamp: 1594852425
  timesteps_since_restore: 2260000
  timesteps_this_iter: 5000
  timesteps_total: 2260000
  training_iteration: 452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3919 s, 452 iter, 2260000 ts, 45.6 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-33-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999903947497
  episode_reward_mean: 42.65999651390406
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 452
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.702
    dispatch_time_ms: 9.041
    learner:
      cur_lr: 0.0012094839476048946
      grad_gnorm: 0.004122603219002485
      policy_entropy: 0.0019200051901862025
      policy_loss: 1.239464308966376e-09
      var_gnorm: 22.22722625732422
      vf_explained_var: 0.0
      vf_loss: 1.3186448377666693e-08
    num_steps_sampled: 2265000
    num_steps_trained: 2265000
    wait_time_ms: 69.415
  iterations_since_restore: 453
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3927.9510991573334
  time_this_iter_s: 8.076122045516968
  time_total_s: 3927.9510991573334
  timestamp: 1594852433
  timesteps_since_restore: 2265000
  timesteps_this_iter: 5000
  timesteps_total: 2265000
  training_iteration: 453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3927 s, 453 iter, 2265000 ts, 42.7 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-34-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999903947497
  episode_reward_mean: 39.14999651443101
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 453
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.233
    dispatch_time_ms: 10.598
    learner:
      cur_lr: 0.0012091509997844696
      grad_gnorm: 0.03827352821826935
      policy_entropy: 0.0019317521946504712
      policy_loss: -2.8167379539922877e-09
      var_gnorm: 22.22797203063965
      vf_explained_var: 0.0
      vf_loss: 1.1351428383932216e-06
    num_steps_sampled: 2270000
    num_steps_trained: 2270000
    wait_time_ms: 68.921
  iterations_since_restore: 454
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3936.0135354995728
  time_this_iter_s: 8.06243634223938
  time_total_s: 3936.0135354995728
  timestamp: 1594852441
  timesteps_since_restore: 2270000
  timesteps_this_iter: 5000
  timesteps_total: 2270000
  training_iteration: 454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3936 s, 454 iter, 2270000 ts, 39.1 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-34-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999903947497
  episode_reward_mean: 35.54999651506131
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 454
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.244
    dispatch_time_ms: 7.748
    learner:
      cur_lr: 0.0012088180519640446
      grad_gnorm: 0.003481578081846237
      policy_entropy: 0.001961123663932085
      policy_loss: -1.214027722795663e-08
      var_gnorm: 22.22962760925293
      vf_explained_var: 0.0
      vf_loss: 9.434809378205955e-09
    num_steps_sampled: 2275000
    num_steps_trained: 2275000
    wait_time_ms: 69.807
  iterations_since_restore: 455
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3944.076129436493
  time_this_iter_s: 8.062593936920166
  time_total_s: 3944.076129436493
  timestamp: 1594852449
  timesteps_since_restore: 2275000
  timesteps_this_iter: 5000
  timesteps_total: 2275000
  training_iteration: 455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3944 s, 455 iter, 2275000 ts, 35.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-34-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999903947497
  episode_reward_mean: 33.65999651514653
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 455
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 9.185
    learner:
      cur_lr: 0.0012084849877282977
      grad_gnorm: 0.02963813580572605
      policy_entropy: 0.0023396145552396774
      policy_loss: -1.4632402844938497e-08
      var_gnorm: 22.238622665405273
      vf_explained_var: 0.0
      vf_loss: 6.797844775974227e-07
    num_steps_sampled: 2280000
    num_steps_trained: 2280000
    wait_time_ms: 68.624
  iterations_since_restore: 456
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3952.1523525714874
  time_this_iter_s: 8.076223134994507
  time_total_s: 3952.1523525714874
  timestamp: 1594852457
  timesteps_since_restore: 2280000
  timesteps_this_iter: 5000
  timesteps_total: 2280000
  training_iteration: 456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3952 s, 456 iter, 2280000 ts, 33.7 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-34-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999903947497
  episode_reward_mean: 31.139996515273744
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 456
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.071
    dispatch_time_ms: 9.168
    learner:
      cur_lr: 0.0012081520399078727
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.25691032409668
      policy_loss: -9.945027351379395
      var_gnorm: 22.393056869506836
      vf_explained_var: 0.0
      vf_loss: 10.963497161865234
    num_steps_sampled: 2285000
    num_steps_trained: 2285000
    wait_time_ms: 75.185
  iterations_since_restore: 457
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3960.6047768592834
  time_this_iter_s: 8.45242428779602
  time_total_s: 3960.6047768592834
  timestamp: 1594852466
  timesteps_since_restore: 2285000
  timesteps_this_iter: 5000
  timesteps_total: 2285000
  training_iteration: 457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3960 s, 457 iter, 2285000 ts, 31.1 rew

agent-1: 38.79997962306749
agent-2: 45.79997962306748
agent-3: 38.79997962306748
agent-4: 40.79997962306748
agent-5: 42.79997962306749
Extrinsic Rewards:
2
9
2
4
6
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.3130434782608696
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-34-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999903947497
  episode_reward_mean: 29.699995498682682
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 457
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.83
    dispatch_time_ms: 9.368
    learner:
      cur_lr: 0.0012078189756721258
      grad_gnorm: 11.360103607177734
      policy_entropy: 11.02487564086914
      policy_loss: -0.3476179540157318
      var_gnorm: 22.34347152709961
      vf_explained_var: 0.0
      vf_loss: 0.09776807576417923
    num_steps_sampled: 2290000
    num_steps_trained: 2290000
    wait_time_ms: 70.866
  iterations_since_restore: 458
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3969.0445659160614
  time_this_iter_s: 8.439789056777954
  time_total_s: 3969.0445659160614
  timestamp: 1594852474
  timesteps_since_restore: 2290000
  timesteps_this_iter: 5000
  timesteps_total: 2290000
  training_iteration: 458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3969 s, 458 iter, 2290000 ts, 29.7 rew

agent-1: 63.7999998815908
agent-2: 64.7999998815906
agent-3: 76.79999988159062
agent-4: 68.79999988159061
agent-5: 67.79999988159058
Extrinsic Rewards:
3
4
16
8
7
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 3
Max Reward: 16
Gini Coefficient: 0.3157894736842105
20:20 Ratio: 5.333333333333333
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-34-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999903947497
  episode_reward_mean: 31.499995492782023
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 458
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.084
    dispatch_time_ms: 7.737
    learner:
      cur_lr: 0.0012074860278517008
      grad_gnorm: 40.0
      policy_entropy: 29.414499282836914
      policy_loss: -11.343470573425293
      var_gnorm: 22.366941452026367
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.72988748550415
    num_steps_sampled: 2295000
    num_steps_trained: 2295000
    wait_time_ms: 75.932
  iterations_since_restore: 459
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3977.576365709305
  time_this_iter_s: 8.531799793243408
  time_total_s: 3977.576365709305
  timestamp: 1594852483
  timesteps_since_restore: 2295000
  timesteps_this_iter: 5000
  timesteps_total: 2295000
  training_iteration: 459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3977 s, 459 iter, 2295000 ts, 31.5 rew

agent-1: 59.399998519032536
agent-2: 56.39999851903255
agent-3: 54.39999851903255
agent-4: 58.399998519032536
agent-5: 77.39999851903244
Extrinsic Rewards:
5
2
0
4
23
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 0
Max Reward: 23
Gini Coefficient: 0.5764705882352941
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-34-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999903947497
  episode_reward_mean: 30.68999541949036
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 459
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 8.745
    learner:
      cur_lr: 0.001207152963615954
      grad_gnorm: 2.253386974334717
      policy_entropy: 1.8557085990905762
      policy_loss: 0.009790405631065369
      var_gnorm: 22.346723556518555
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.004531698301434517
    num_steps_sampled: 2300000
    num_steps_trained: 2300000
    wait_time_ms: 74.246
  iterations_since_restore: 460
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3986.247136592865
  time_this_iter_s: 8.67077088356018
  time_total_s: 3986.247136592865
  timestamp: 1594852491
  timesteps_since_restore: 2300000
  timesteps_this_iter: 5000
  timesteps_total: 2300000
  training_iteration: 460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3986 s, 460 iter, 2300000 ts, 30.7 rew

agent-1: 56.59999995680597
agent-2: 52.59999995680598
agent-3: 55.59999995680599
agent-4: 61.599999956805966
agent-5: 52.59999995680598
Extrinsic Rewards:
7
3
6
12
3
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.2838709677419355
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-35-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999903947497
  episode_reward_mean: 31.76999541736735
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 460
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.967
    dispatch_time_ms: 192.37
    learner:
      cur_lr: 0.0012068200157955289
      grad_gnorm: 40.000003814697266
      policy_entropy: 34.65870666503906
      policy_loss: 17.71095848083496
      var_gnorm: 22.37551498413086
      vf_explained_var: 0.0
      vf_loss: 6.372385501861572
    num_steps_sampled: 2305000
    num_steps_trained: 2305000
    wait_time_ms: 52.674
  iterations_since_restore: 461
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 3996.319712638855
  time_this_iter_s: 10.07257604598999
  time_total_s: 3996.319712638855
  timestamp: 1594852502
  timesteps_since_restore: 2305000
  timesteps_this_iter: 5000
  timesteps_total: 2305000
  training_iteration: 461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 3996 s, 461 iter, 2305000 ts, 31.8 rew

agent-1: 108.59971813621506
agent-2: 112.59971813621506
agent-3: 112.59971813621506
agent-4: 105.59971813621509
agent-5: 109.59971813621506
Extrinsic Rewards:
11
15
15
8
12
Sum Reward: 61
Avg Reward: 12.2
Min Reward: 8
Max Reward: 15
Gini Coefficient: 0.1180327868852459
20:20 Ratio: 1.875
Max-min Ratio: 1.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-35-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999903947497
  episode_reward_mean: 32.579981496577695
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 461
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.418
    dispatch_time_ms: 6.586
    learner:
      cur_lr: 0.001206486951559782
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.70894241333008
      policy_loss: -8.04517650604248
      var_gnorm: 22.349557876586914
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.8159340620040894
    num_steps_sampled: 2310000
    num_steps_trained: 2310000
    wait_time_ms: 77.357
  iterations_since_restore: 462
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4004.3583607673645
  time_this_iter_s: 8.038648128509521
  time_total_s: 4004.3583607673645
  timestamp: 1594852510
  timesteps_since_restore: 2310000
  timesteps_this_iter: 5000
  timesteps_total: 2310000
  training_iteration: 462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4004 s, 462 iter, 2310000 ts, 32.6 rew

agent-1: 121.99505910012485
agent-2: 139.99505910012445
agent-3: 120.99505910012488
agent-4: 120.99505910012486
agent-5: 125.99505910012483
Extrinsic Rewards:
10
28
9
9
14
Sum Reward: 70
Avg Reward: 14.0
Min Reward: 9
Max Reward: 28
Gini Coefficient: 0.24571428571428572
20:20 Ratio: 3.111111111111111
Max-min Ratio: 3.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-35-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 629.9752955006289
  episode_reward_mean: 34.469734542139705
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 462
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.19
    dispatch_time_ms: 8.795
    learner:
      cur_lr: 0.001206154003739357
      grad_gnorm: 21.853364944458008
      policy_entropy: 21.775053024291992
      policy_loss: -2.718411684036255
      var_gnorm: 22.3439884185791
      vf_explained_var: 0.0
      vf_loss: 0.3651134669780731
    num_steps_sampled: 2315000
    num_steps_trained: 2315000
    wait_time_ms: 77.455
  iterations_since_restore: 463
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4013.0015728473663
  time_this_iter_s: 8.643212080001831
  time_total_s: 4013.0015728473663
  timestamp: 1594852518
  timesteps_since_restore: 2315000
  timesteps_this_iter: 5000
  timesteps_total: 2315000
  training_iteration: 463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4013 s, 463 iter, 2315000 ts, 34.5 rew

agent-1: 72.79999996347837
agent-2: 78.79999996347837
agent-3: 77.79999996347838
agent-4: 84.79999996347838
agent-5: 72.7999999634784
Extrinsic Rewards:
4
10
9
16
4
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 4
Max Reward: 16
Gini Coefficient: 0.27906976744186046
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-35-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 629.9752955006289
  episode_reward_mean: 32.669737662963314
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 463
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 7.835
    learner:
      cur_lr: 0.001205821055918932
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.882701873779297
      policy_loss: 26.607450485229492
      var_gnorm: 22.34313201904297
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 51.72626495361328
    num_steps_sampled: 2320000
    num_steps_trained: 2320000
    wait_time_ms: 73.757
  iterations_since_restore: 464
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4021.6748995780945
  time_this_iter_s: 8.67332673072815
  time_total_s: 4021.6748995780945
  timestamp: 1594852527
  timesteps_since_restore: 2320000
  timesteps_this_iter: 5000
  timesteps_total: 2320000
  training_iteration: 464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4021 s, 464 iter, 2320000 ts, 32.7 rew

agent-1: 44.999999998458435
agent-2: 47.999999998458435
agent-3: 42.999999998458435
agent-4: 42.999999998458435
agent-5: 45.999999998458435
Extrinsic Rewards:
5
8
3
3
6
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 3
Max Reward: 8
Gini Coefficient: 0.208
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-35-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 629.9752955006289
  episode_reward_mean: 29.249737758938714
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 464
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.016
    dispatch_time_ms: 8.132
    learner:
      cur_lr: 0.001205487991683185
      grad_gnorm: 38.296688079833984
      policy_entropy: 11.234671592712402
      policy_loss: -2.209804058074951
      var_gnorm: 22.34795570373535
      vf_explained_var: 0.0
      vf_loss: 1.1357307434082031
    num_steps_sampled: 2325000
    num_steps_trained: 2325000
    wait_time_ms: 75.859
  iterations_since_restore: 465
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4030.3583641052246
  time_this_iter_s: 8.683464527130127
  time_total_s: 4030.3583641052246
  timestamp: 1594852536
  timesteps_since_restore: 2325000
  timesteps_this_iter: 5000
  timesteps_total: 2325000
  training_iteration: 465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4030 s, 465 iter, 2325000 ts, 29.2 rew

agent-1: 48.59999999799595
agent-2: 49.599999997995944
agent-3: 43.59999999799598
agent-4: 44.599999997995965
agent-5: 47.59999999799596
Extrinsic Rewards:
7
8
2
3
6
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.24615384615384617
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-35-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 629.9752955006289
  episode_reward_mean: 31.58973775883852
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 465
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.725
    dispatch_time_ms: 9.377
    learner:
      cur_lr: 0.00120515504386276
      grad_gnorm: 34.2384147644043
      policy_entropy: 12.11172866821289
      policy_loss: -2.134021043777466
      var_gnorm: 22.34739875793457
      vf_explained_var: 0.0
      vf_loss: 0.9068087935447693
    num_steps_sampled: 2330000
    num_steps_trained: 2330000
    wait_time_ms: 75.073
  iterations_since_restore: 466
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4039.062609434128
  time_this_iter_s: 8.704245328903198
  time_total_s: 4039.062609434128
  timestamp: 1594852544
  timesteps_since_restore: 2330000
  timesteps_this_iter: 5000
  timesteps_total: 2330000
  training_iteration: 466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4039 s, 466 iter, 2330000 ts, 31.6 rew

agent-1: 149.19414964327174
agent-2: 162.19414964327157
agent-3: 159.1941496432716
agent-4: 155.1941496432716
agent-5: 157.1941496432716
Extrinsic Rewards:
10
23
20
16
18
Sum Reward: 87
Avg Reward: 17.4
Min Reward: 10
Max Reward: 23
Gini Coefficient: 0.13793103448275862
20:20 Ratio: 2.3
Max-min Ratio: 2.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-35-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 782.9707482163524
  episode_reward_mean: 39.419445241002045
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 466
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.643
    dispatch_time_ms: 7.072
    learner:
      cur_lr: 0.0012048219796270132
      grad_gnorm: 20.869218826293945
      policy_entropy: 13.567429542541504
      policy_loss: -2.244629383087158
      var_gnorm: 22.344879150390625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.32880252599716187
    num_steps_sampled: 2335000
    num_steps_trained: 2335000
    wait_time_ms: 79.314
  iterations_since_restore: 467
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4047.750684738159
  time_this_iter_s: 8.688075304031372
  time_total_s: 4047.750684738159
  timestamp: 1594852553
  timesteps_since_restore: 2335000
  timesteps_this_iter: 5000
  timesteps_total: 2335000
  training_iteration: 467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4047 s, 467 iter, 2335000 ts, 39.4 rew

agent-1: 62.39999995634538
agent-2: 73.39999995634525
agent-3: 67.39999995634527
agent-4: 78.3999999563452
agent-5: 69.39999995634525
Extrinsic Rewards:
0
11
5
16
7
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 0
Max Reward: 16
Gini Coefficient: 0.38974358974358975
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-36-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 782.9707482163524
  episode_reward_mean: 42.929445238819305
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 467
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.899
    dispatch_time_ms: 8.648
    learner:
      cur_lr: 0.0012044890318065882
      grad_gnorm: 39.999996185302734
      policy_entropy: 12.403058052062988
      policy_loss: 28.706314086914062
      var_gnorm: 22.343975067138672
      vf_explained_var: 0.0
      vf_loss: 93.35810852050781
    num_steps_sampled: 2340000
    num_steps_trained: 2340000
    wait_time_ms: 70.936
  iterations_since_restore: 468
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4056.4377031326294
  time_this_iter_s: 8.687018394470215
  time_total_s: 4056.4377031326294
  timestamp: 1594852562
  timesteps_since_restore: 2340000
  timesteps_this_iter: 5000
  timesteps_total: 2340000
  training_iteration: 468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4056 s, 468 iter, 2340000 ts, 42.9 rew

agent-1: 31.39999999859288
agent-2: 38.399999998592996
agent-3: 37.399999998592996
agent-4: 31.399999998592875
agent-5: 32.39999999859298
Extrinsic Rewards:
1
8
7
1
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.42105263157894735
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-36-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 782.9707482163524
  episode_reward_mean: 44.639445238748955
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 468
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 8.082
    learner:
      cur_lr: 0.0012041559675708413
      grad_gnorm: 40.0
      policy_entropy: 16.265588760375977
      policy_loss: -2.4445483684539795
      var_gnorm: 22.34834861755371
      vf_explained_var: 0.0
      vf_loss: 1.2670581340789795
    num_steps_sampled: 2345000
    num_steps_trained: 2345000
    wait_time_ms: 76.176
  iterations_since_restore: 469
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4065.0653553009033
  time_this_iter_s: 8.627652168273926
  time_total_s: 4065.0653553009033
  timestamp: 1594852571
  timesteps_since_restore: 2345000
  timesteps_this_iter: 5000
  timesteps_total: 2345000
  training_iteration: 469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4065 s, 469 iter, 2345000 ts, 44.6 rew

agent-1: 46.79999999534055
agent-2: 47.79999999534055
agent-3: 53.79999999534052
agent-4: 54.79999999534052
agent-5: 48.799999995340535
Extrinsic Rewards:
2
3
9
10
4
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.3142857142857143
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-36-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 782.9707482163524
  episode_reward_mean: 47.15944523851599
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 469
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.98
    dispatch_time_ms: 8.357
    learner:
      cur_lr: 0.0012038230197504163
      grad_gnorm: 40.0
      policy_entropy: 12.66711711883545
      policy_loss: 15.694208145141602
      var_gnorm: 22.348440170288086
      vf_explained_var: 0.0
      vf_loss: 66.59016418457031
    num_steps_sampled: 2350000
    num_steps_trained: 2350000
    wait_time_ms: 70.062
  iterations_since_restore: 470
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4073.5622668266296
  time_this_iter_s: 8.496911525726318
  time_total_s: 4073.5622668266296
  timestamp: 1594852579
  timesteps_since_restore: 2350000
  timesteps_this_iter: 5000
  timesteps_total: 2350000
  training_iteration: 470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4073 s, 470 iter, 2350000 ts, 47.2 rew

agent-1: 185.69571838832965
agent-2: 183.6957183883297
agent-3: 178.69571838832968
agent-4: 183.69571838832962
agent-5: 180.69571838832965
Extrinsic Rewards:
25
23
18
23
20
Sum Reward: 109
Avg Reward: 21.8
Min Reward: 18
Max Reward: 25
Gini Coefficient: 0.062385321100917435
20:20 Ratio: 1.3888888888888888
Max-min Ratio: 1.3888888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-36-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 56.284231157932446
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 470
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.61
    dispatch_time_ms: 7.519
    learner:
      cur_lr: 0.0012034899555146694
      grad_gnorm: 33.939369201660156
      policy_entropy: 17.182580947875977
      policy_loss: -2.4201889038085938
      var_gnorm: 22.347076416015625
      vf_explained_var: 0.0
      vf_loss: 0.8760382533073425
    num_steps_sampled: 2355000
    num_steps_trained: 2355000
    wait_time_ms: 74.734
  iterations_since_restore: 471
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4082.0751774311066
  time_this_iter_s: 8.512910604476929
  time_total_s: 4082.0751774311066
  timestamp: 1594852588
  timesteps_since_restore: 2355000
  timesteps_this_iter: 5000
  timesteps_total: 2355000
  training_iteration: 471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4082 s, 471 iter, 2355000 ts, 56.3 rew

agent-1: 58.19999997421196
agent-2: 61.19999997421198
agent-3: 57.19999997421196
agent-4: 54.19999997421198
agent-5: 57.19999997421196
Extrinsic Rewards:
7
10
6
3
6
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.1875
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-36-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 59.164231156642984
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 471
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 9.283
    learner:
      cur_lr: 0.0012031570076942444
      grad_gnorm: 40.0
      policy_entropy: 33.956207275390625
      policy_loss: 53.35541534423828
      var_gnorm: 22.343364715576172
      vf_explained_var: 0.0
      vf_loss: 87.78074645996094
    num_steps_sampled: 2360000
    num_steps_trained: 2360000
    wait_time_ms: 72.299
  iterations_since_restore: 472
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4090.555493116379
  time_this_iter_s: 8.480315685272217
  time_total_s: 4090.555493116379
  timestamp: 1594852596
  timesteps_since_restore: 2360000
  timesteps_this_iter: 5000
  timesteps_total: 2360000
  training_iteration: 472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4090 s, 472 iter, 2360000 ts, 59.2 rew

agent-1: 34.799999999287145
agent-2: 31.799999999287145
agent-3: 29.799999999287145
agent-4: 31.799999999287145
agent-5: 33.799999999287145
Extrinsic Rewards:
6
3
1
3
5
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-36-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 60.78423115660734
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 472
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 19.921
    learner:
      cur_lr: 0.0012028239434584975
      grad_gnorm: 7.983696460723877
      policy_entropy: 19.246158599853516
      policy_loss: -1.1868962049484253
      var_gnorm: 22.34415626525879
      vf_explained_var: 0.0
      vf_loss: 0.049267806112766266
    num_steps_sampled: 2365000
    num_steps_trained: 2365000
    wait_time_ms: 66.469
  iterations_since_restore: 473
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4099.403968572617
  time_this_iter_s: 8.848475456237793
  time_total_s: 4099.403968572617
  timestamp: 1594852605
  timesteps_since_restore: 2365000
  timesteps_this_iter: 5000
  timesteps_total: 2365000
  training_iteration: 473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4099 s, 473 iter, 2365000 ts, 60.8 rew

agent-1: 31.39999999853054
agent-2: 39.39999999853059
agent-3: 30.39999999853054
agent-4: 34.39999999853058
agent-5: 35.399999998530575
Extrinsic Rewards:
1
9
0
4
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.4631578947368421
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-36-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 62.49423115653388
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 473
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.064
    dispatch_time_ms: 7.332
    learner:
      cur_lr: 0.0012024909956380725
      grad_gnorm: 40.0
      policy_entropy: 22.05414581298828
      policy_loss: 25.21670913696289
      var_gnorm: 22.34403419494629
      vf_explained_var: 0.0
      vf_loss: 30.780353546142578
    num_steps_sampled: 2370000
    num_steps_trained: 2370000
    wait_time_ms: 70.805
  iterations_since_restore: 474
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4107.863617181778
  time_this_iter_s: 8.459648609161377
  time_total_s: 4107.863617181778
  timestamp: 1594852614
  timesteps_since_restore: 2370000
  timesteps_this_iter: 5000
  timesteps_total: 2370000
  training_iteration: 474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4107 s, 474 iter, 2370000 ts, 62.5 rew

agent-1: 38.199999999169655
agent-2: 39.19999999916965
agent-3: 37.19999999916965
agent-4: 40.199999999169655
agent-5: 43.199999999169655
Extrinsic Rewards:
3
4
2
5
8
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-37-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 64.47423115649235
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 474
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.661
    dispatch_time_ms: 8.693
    learner:
      cur_lr: 0.0012021580478176475
      grad_gnorm: 40.0
      policy_entropy: 19.005605697631836
      policy_loss: -7.555400371551514
      var_gnorm: 22.36284065246582
      vf_explained_var: 0.0
      vf_loss: 2.6709036827087402
    num_steps_sampled: 2375000
    num_steps_trained: 2375000
    wait_time_ms: 72.481
  iterations_since_restore: 475
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4116.217525959015
  time_this_iter_s: 8.353908777236938
  time_total_s: 4116.217525959015
  timestamp: 1594852622
  timesteps_since_restore: 2375000
  timesteps_this_iter: 5000
  timesteps_total: 2375000
  training_iteration: 475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4116 s, 475 iter, 2375000 ts, 64.5 rew

agent-1: 116.5999435041045
agent-2: 100.59994350410452
agent-3: 119.59994350410453
agent-4: 105.59994350410447
agent-5: 106.59994350410449
Extrinsic Rewards:
19
3
22
8
9
Sum Reward: 61
Avg Reward: 12.2
Min Reward: 3
Max Reward: 22
Gini Coefficient: 0.32131147540983607
20:20 Ratio: 7.333333333333333
Max-min Ratio: 7.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-37-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 69.9642283316976
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 475
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 9.387
    learner:
      cur_lr: 0.0012018249835819006
      grad_gnorm: 5.278549671173096
      policy_entropy: 3.737204074859619
      policy_loss: -0.10689298063516617
      var_gnorm: 22.346080780029297
      vf_explained_var: 0.0
      vf_loss: 0.02157822996377945
    num_steps_sampled: 2380000
    num_steps_trained: 2380000
    wait_time_ms: 70.953
  iterations_since_restore: 476
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4124.790119171143
  time_this_iter_s: 8.572593212127686
  time_total_s: 4124.790119171143
  timestamp: 1594852631
  timesteps_since_restore: 2380000
  timesteps_this_iter: 5000
  timesteps_total: 2380000
  training_iteration: 476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4124 s, 476 iter, 2380000 ts, 70 rew

agent-1: 49.79999981235798
agent-2: 52.799999812357996
agent-3: 48.79999981235799
agent-4: 50.799999812357974
agent-5: 49.799999812357974
Extrinsic Rewards:
5
8
4
6
5
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 4
Max Reward: 8
Gini Coefficient: 0.12857142857142856
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-37-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 72.48422832231549
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 476
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.662
    dispatch_time_ms: 5.493
    learner:
      cur_lr: 0.0012014920357614756
      grad_gnorm: 39.999996185302734
      policy_entropy: 12.554329872131348
      policy_loss: 2.6494219303131104
      var_gnorm: 22.370956420898438
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.401253581047058
    num_steps_sampled: 2385000
    num_steps_trained: 2385000
    wait_time_ms: 76.541
  iterations_since_restore: 477
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4133.2327291965485
  time_this_iter_s: 8.442610025405884
  time_total_s: 4133.2327291965485
  timestamp: 1594852639
  timesteps_since_restore: 2385000
  timesteps_this_iter: 5000
  timesteps_total: 2385000
  training_iteration: 477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4133 s, 477 iter, 2385000 ts, 72.5 rew

agent-1: 112.57553206246553
agent-2: 120.57553206246554
agent-3: 115.57553206246556
agent-4: 126.57553206246558
agent-5: 118.57553206246556
Extrinsic Rewards:
7
15
10
21
13
Sum Reward: 66
Avg Reward: 13.2
Min Reward: 7
Max Reward: 21
Gini Coefficient: 0.2
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-37-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 78.42300492543876
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 477
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 9.267
    learner:
      cur_lr: 0.0012011589715257287
      grad_gnorm: 40.00000762939453
      policy_entropy: 23.164926528930664
      policy_loss: 19.654451370239258
      var_gnorm: 22.35980987548828
      vf_explained_var: 0.0
      vf_loss: 64.1483383178711
    num_steps_sampled: 2390000
    num_steps_trained: 2390000
    wait_time_ms: 72.511
  iterations_since_restore: 478
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4141.711039066315
  time_this_iter_s: 8.478309869766235
  time_total_s: 4141.711039066315
  timestamp: 1594852648
  timesteps_since_restore: 2390000
  timesteps_this_iter: 5000
  timesteps_total: 2390000
  training_iteration: 478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4141 s, 478 iter, 2390000 ts, 78.4 rew

agent-1: 108.19997235167124
agent-2: 117.19997235167125
agent-3: 113.19997235167122
agent-4: 112.19997235167124
agent-5: 107.19997235167122
Extrinsic Rewards:
9
18
14
13
8
Sum Reward: 62
Avg Reward: 12.4
Min Reward: 8
Max Reward: 18
Gini Coefficient: 0.16129032258064516
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-37-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 84.00300354302234
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 478
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 9.077
    learner:
      cur_lr: 0.0012008260237053037
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.70311737060547
      policy_loss: -5.214351177215576
      var_gnorm: 22.381099700927734
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.5790501832962036
    num_steps_sampled: 2395000
    num_steps_trained: 2395000
    wait_time_ms: 75.335
  iterations_since_restore: 479
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4150.298769235611
  time_this_iter_s: 8.587730169296265
  time_total_s: 4150.298769235611
  timestamp: 1594852656
  timesteps_since_restore: 2395000
  timesteps_this_iter: 5000
  timesteps_total: 2395000
  training_iteration: 479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4150 s, 479 iter, 2395000 ts, 84 rew

agent-1: 70.7999988396937
agent-2: 73.7999988396937
agent-3: 75.79999883969366
agent-4: 83.79999883969364
agent-5: 82.79999883969366
Extrinsic Rewards:
2
5
7
15
14
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.32558139534883723
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-37-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 87.87300348500702
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 479
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.978
    dispatch_time_ms: 10.286
    learner:
      cur_lr: 0.0012004929594695568
      grad_gnorm: 16.5059757232666
      policy_entropy: 17.96440887451172
      policy_loss: -0.9070382118225098
      var_gnorm: 22.345447540283203
      vf_explained_var: 0.0
      vf_loss: 0.20123878121376038
    num_steps_sampled: 2400000
    num_steps_trained: 2400000
    wait_time_ms: 71.523
  iterations_since_restore: 480
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4158.8214910030365
  time_this_iter_s: 8.522721767425537
  time_total_s: 4158.8214910030365
  timestamp: 1594852665
  timesteps_since_restore: 2400000
  timesteps_this_iter: 5000
  timesteps_total: 2400000
  training_iteration: 480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4158 s, 480 iter, 2400000 ts, 87.9 rew

agent-1: 117.39999943153141
agent-2: 125.39999943153138
agent-3: 126.39999943153138
agent-4: 121.39999943153141
agent-5: 130.39999943153214
Extrinsic Rewards:
7
15
16
11
20
Sum Reward: 69
Avg Reward: 13.8
Min Reward: 7
Max Reward: 20
Gini Coefficient: 0.17971014492753623
20:20 Ratio: 2.857142857142857
Max-min Ratio: 2.857142857142857
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-37-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 94.0830034565836
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 480
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.373
    dispatch_time_ms: 9.941
    learner:
      cur_lr: 0.0012001600116491318
      grad_gnorm: 33.45418167114258
      policy_entropy: 13.362286567687988
      policy_loss: -1.7902896404266357
      var_gnorm: 22.347822189331055
      vf_explained_var: 0.0
      vf_loss: 0.8634689450263977
    num_steps_sampled: 2405000
    num_steps_trained: 2405000
    wait_time_ms: 75.741
  iterations_since_restore: 481
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4166.8330953121185
  time_this_iter_s: 8.011604309082031
  time_total_s: 4166.8330953121185
  timestamp: 1594852674
  timesteps_since_restore: 2405000
  timesteps_this_iter: 5000
  timesteps_total: 2405000
  training_iteration: 481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4166 s, 481 iter, 2405000 ts, 94.1 rew

agent-1: 79.79999925492501
agent-2: 69.79999925492503
agent-3: 74.799999254925
agent-4: 76.79999925492501
agent-5: 85.799999254925
Extrinsic Rewards:
11
1
6
8
17
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 1
Max Reward: 17
Gini Coefficient: 0.34418604651162793
20:20 Ratio: 17.0
Max-min Ratio: 17.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-38-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 97.95300341932982
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 481
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.792
    dispatch_time_ms: 8.512
    learner:
      cur_lr: 0.001199826947413385
      grad_gnorm: 40.0
      policy_entropy: 14.956075668334961
      policy_loss: 23.739206314086914
      var_gnorm: 22.344987869262695
      vf_explained_var: 0.0
      vf_loss: 50.82398986816406
    num_steps_sampled: 2410000
    num_steps_trained: 2410000
    wait_time_ms: 75.047
  iterations_since_restore: 482
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4175.475083351135
  time_this_iter_s: 8.641988039016724
  time_total_s: 4175.475083351135
  timestamp: 1594852682
  timesteps_since_restore: 2410000
  timesteps_this_iter: 5000
  timesteps_total: 2410000
  training_iteration: 482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4175 s, 482 iter, 2410000 ts, 98 rew

agent-1: 46.39999999805162
agent-2: 41.3999999980516
agent-3: 45.39999999805161
agent-4: 39.3999999980516
agent-5: 43.39999999805162
Extrinsic Rewards:
8
3
7
1
5
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.3
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-38-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 100.11300341923237
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 482
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.477
    dispatch_time_ms: 5.193
    learner:
      cur_lr: 0.0011994939995929599
      grad_gnorm: 40.0
      policy_entropy: 26.86394500732422
      policy_loss: -8.240459442138672
      var_gnorm: 22.36039924621582
      vf_explained_var: 0.0
      vf_loss: 3.166048288345337
    num_steps_sampled: 2415000
    num_steps_trained: 2415000
    wait_time_ms: 81.995
  iterations_since_restore: 483
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4184.068264961243
  time_this_iter_s: 8.593181610107422
  time_total_s: 4184.068264961243
  timestamp: 1594852691
  timesteps_since_restore: 2415000
  timesteps_this_iter: 5000
  timesteps_total: 2415000
  training_iteration: 483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4184 s, 483 iter, 2415000 ts, 100 rew

agent-1: 152.7999781759052
agent-2: 151.79997817590518
agent-3: 140.79997817590524
agent-4: 151.7999781759052
agent-5: 149.79997817590524
Extrinsic Rewards:
20
19
8
19
17
Sum Reward: 83
Avg Reward: 16.6
Min Reward: 8
Max Reward: 20
Gini Coefficient: 0.12530120481927712
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-38-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 107.58300232802769
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 483
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.511
    dispatch_time_ms: 8.4
    learner:
      cur_lr: 0.0011991610517725348
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.391530990600586
      policy_loss: 31.74834442138672
      var_gnorm: 22.345041275024414
      vf_explained_var: 0.0
      vf_loss: 27.178972244262695
    num_steps_sampled: 2420000
    num_steps_trained: 2420000
    wait_time_ms: 74.58
  iterations_since_restore: 484
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4192.717178106308
  time_this_iter_s: 8.648913145065308
  time_total_s: 4192.717178106308
  timestamp: 1594852700
  timesteps_since_restore: 2420000
  timesteps_this_iter: 5000
  timesteps_total: 2420000
  training_iteration: 484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4192 s, 484 iter, 2420000 ts, 108 rew

agent-1: 71.79999988903276
agent-2: 87.79999988903279
agent-3: 77.79999988903275
agent-4: 71.79999988903279
agent-5: 77.79999988903276
Extrinsic Rewards:
3
19
9
3
9
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 3
Max Reward: 19
Gini Coefficient: 0.35348837209302325
20:20 Ratio: 6.333333333333333
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-38-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 111.45300232247936
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 484
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.444
    dispatch_time_ms: 7.992
    learner:
      cur_lr: 0.001198827987536788
      grad_gnorm: 21.169198989868164
      policy_entropy: 30.95383644104004
      policy_loss: -4.042287349700928
      var_gnorm: 22.345542907714844
      vf_explained_var: 0.0
      vf_loss: 0.31854724884033203
    num_steps_sampled: 2425000
    num_steps_trained: 2425000
    wait_time_ms: 76.158
  iterations_since_restore: 485
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4201.314078330994
  time_this_iter_s: 8.596900224685669
  time_total_s: 4201.314078330994
  timestamp: 1594852708
  timesteps_since_restore: 2425000
  timesteps_this_iter: 5000
  timesteps_total: 2425000
  training_iteration: 485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4201 s, 485 iter, 2425000 ts, 111 rew

agent-1: 37.19999999865639
agent-2: 40.1999999986564
agent-3: 35.19999999865636
agent-4: 42.19999999865639
agent-5: 43.19999999865639
Extrinsic Rewards:
2
5
0
7
8
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.38181818181818183
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-38-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 113.4330023224122
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 485
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 9.485
    learner:
      cur_lr: 0.001198495039716363
      grad_gnorm: 5.46544885635376
      policy_entropy: 6.667183876037598
      policy_loss: -0.017422987148165703
      var_gnorm: 22.34718132019043
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.02309117093682289
    num_steps_sampled: 2430000
    num_steps_trained: 2430000
    wait_time_ms: 75.952
  iterations_since_restore: 486
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4210.089855194092
  time_this_iter_s: 8.775776863098145
  time_total_s: 4210.089855194092
  timestamp: 1594852717
  timesteps_since_restore: 2430000
  timesteps_this_iter: 5000
  timesteps_total: 2430000
  training_iteration: 486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4210 s, 486 iter, 2430000 ts, 113 rew

agent-1: 68.19999998817617
agent-2: 60.19999998817619
agent-3: 65.19999998817619
agent-4: 70.19999998817617
agent-5: 69.19999998817617
Extrinsic Rewards:
9
1
6
11
10
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.2594594594594595
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-38-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 116.763002321821
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 486
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.797
    dispatch_time_ms: 7.738
    learner:
      cur_lr: 0.001198161975480616
      grad_gnorm: 40.000003814697266
      policy_entropy: 34.42344284057617
      policy_loss: -10.77257251739502
      var_gnorm: 22.367431640625
      vf_explained_var: 0.0
      vf_loss: 3.1307568550109863
    num_steps_sampled: 2435000
    num_steps_trained: 2435000
    wait_time_ms: 76.519
  iterations_since_restore: 487
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4218.646436929703
  time_this_iter_s: 8.556581735610962
  time_total_s: 4218.646436929703
  timestamp: 1594852726
  timesteps_since_restore: 2435000
  timesteps_this_iter: 5000
  timesteps_total: 2435000
  training_iteration: 487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4218 s, 487 iter, 2435000 ts, 117 rew

agent-1: 111.39996505805085
agent-2: 115.39996505805085
agent-3: 112.39996505805085
agent-4: 109.39996505805082
agent-5: 127.39996505805082
Extrinsic Rewards:
9
13
10
7
25
Sum Reward: 64
Avg Reward: 12.8
Min Reward: 7
Max Reward: 25
Gini Coefficient: 0.25
20:20 Ratio: 3.5714285714285716
Max-min Ratio: 3.5714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-38-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 912.4785919416447
  episode_reward_mean: 122.5230005747236
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 487
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.596
    dispatch_time_ms: 8.775
    learner:
      cur_lr: 0.001197829027660191
      grad_gnorm: 40.0
      policy_entropy: 32.684471130371094
      policy_loss: 37.52865219116211
      var_gnorm: 22.371545791625977
      vf_explained_var: 0.0
      vf_loss: 45.41286849975586
    num_steps_sampled: 2440000
    num_steps_trained: 2440000
    wait_time_ms: 70.439
  iterations_since_restore: 488
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4227.106791496277
  time_this_iter_s: 8.460354566574097
  time_total_s: 4227.106791496277
  timestamp: 1594852734
  timesteps_since_restore: 2440000
  timesteps_this_iter: 5000
  timesteps_total: 2440000
  training_iteration: 488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4227 s, 488 iter, 2440000 ts, 123 rew

agent-1: 199.20016546310225
agent-2: 195.20016546310225
agent-3: 166.20016546310214
agent-4: 173.20016546310228
agent-5: 179.2001654631023
Extrinsic Rewards:
37
33
4
11
17
Sum Reward: 102
Avg Reward: 20.4
Min Reward: 4
Max Reward: 37
Gini Coefficient: 0.34509803921568627
20:20 Ratio: 9.25
Max-min Ratio: 9.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-39-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 131.65300884787874
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 488
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.955
    dispatch_time_ms: 10.972
    learner:
      cur_lr: 0.0011974959634244442
      grad_gnorm: 40.0
      policy_entropy: 32.088592529296875
      policy_loss: -13.00160026550293
      var_gnorm: 22.365915298461914
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 5.772427082061768
    num_steps_sampled: 2445000
    num_steps_trained: 2445000
    wait_time_ms: 74.343
  iterations_since_restore: 489
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4235.791133403778
  time_this_iter_s: 8.68434190750122
  time_total_s: 4235.791133403778
  timestamp: 1594852743
  timesteps_since_restore: 2445000
  timesteps_this_iter: 5000
  timesteps_total: 2445000
  training_iteration: 489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4235 s, 489 iter, 2445000 ts, 132 rew

agent-1: 75.19999973338572
agent-2: 72.19999973338575
agent-3: 78.1999997333857
agent-4: 78.1999997333857
agent-5: 74.19999973338575
Extrinsic Rewards:
8
5
11
11
7
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 5
Max Reward: 11
Gini Coefficient: 0.1523809523809524
20:20 Ratio: 2.2
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-39-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 135.43300883454802
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 489
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.984
    dispatch_time_ms: 7.569
    learner:
      cur_lr: 0.0011971630156040192
      grad_gnorm: 40.0
      policy_entropy: 30.685426712036133
      policy_loss: 35.5651741027832
      var_gnorm: 22.350400924682617
      vf_explained_var: 0.0
      vf_loss: 29.282245635986328
    num_steps_sampled: 2450000
    num_steps_trained: 2450000
    wait_time_ms: 75.751
  iterations_since_restore: 490
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4252.308851480484
  time_this_iter_s: 16.517718076705933
  time_total_s: 4252.308851480484
  timestamp: 1594852759
  timesteps_since_restore: 2450000
  timesteps_this_iter: 5000
  timesteps_total: 2450000
  training_iteration: 490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4252 s, 490 iter, 2450000 ts, 135 rew

agent-1: 30.599999999601458
agent-2: 26.59999999960145
agent-3: 28.599999999601458
agent-4: 28.599999999601458
agent-5: 29.599999999601458
Extrinsic Rewards:
5
1
3
3
4
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 1
Max Reward: 5
Gini Coefficient: 0.225
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-39-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 136.8730088345281
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 490
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.835
    dispatch_time_ms: 9.856
    learner:
      cur_lr: 0.0011968299513682723
      grad_gnorm: 10.908867835998535
      policy_entropy: 27.70277214050293
      policy_loss: -1.7786364555358887
      var_gnorm: 22.350671768188477
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0849505364894867
    num_steps_sampled: 2455000
    num_steps_trained: 2455000
    wait_time_ms: 75.2
  iterations_since_restore: 491
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4260.990017175674
  time_this_iter_s: 8.68116569519043
  time_total_s: 4260.990017175674
  timestamp: 1594852768
  timesteps_since_restore: 2455000
  timesteps_this_iter: 5000
  timesteps_total: 2455000
  training_iteration: 491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4260 s, 491 iter, 2455000 ts, 137 rew

agent-1: 41.59999999911092
agent-2: 35.59999999911093
agent-3: 33.59999999911094
agent-4: 39.59999999911092
agent-5: 38.59999999911093
Extrinsic Rewards:
8
2
0
6
5
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.38095238095238093
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-39-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 138.76300883448366
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 491
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.016
    dispatch_time_ms: 9.323
    learner:
      cur_lr: 0.0011964970035478473
      grad_gnorm: 4.896655559539795
      policy_entropy: 22.948379516601562
      policy_loss: -0.3113415539264679
      var_gnorm: 22.35216522216797
      vf_explained_var: 0.0
      vf_loss: 0.018362896516919136
    num_steps_sampled: 2460000
    num_steps_trained: 2460000
    wait_time_ms: 73.948
  iterations_since_restore: 492
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4269.7304146289825
  time_this_iter_s: 8.740397453308105
  time_total_s: 4269.7304146289825
  timestamp: 1594852777
  timesteps_since_restore: 2460000
  timesteps_this_iter: 5000
  timesteps_total: 2460000
  training_iteration: 492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4269 s, 492 iter, 2460000 ts, 139 rew

agent-1: 64.99999984680346
agent-2: 60.999999846803455
agent-3: 62.999999846803455
agent-4: 60.99999984680347
agent-5: 64.99999984680346
Extrinsic Rewards:
9
5
7
5
9
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 5
Max Reward: 9
Gini Coefficient: 0.13714285714285715
20:20 Ratio: 1.8
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-39-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 141.91300882682378
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 492
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 6.363
    learner:
      cur_lr: 0.0011961640557274222
      grad_gnorm: 34.333648681640625
      policy_entropy: 29.27182960510254
      policy_loss: -4.460876941680908
      var_gnorm: 22.351150512695312
      vf_explained_var: 0.0
      vf_loss: 0.8591007590293884
    num_steps_sampled: 2465000
    num_steps_trained: 2465000
    wait_time_ms: 78.182
  iterations_since_restore: 493
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4278.4302797317505
  time_this_iter_s: 8.699865102767944
  time_total_s: 4278.4302797317505
  timestamp: 1594852786
  timesteps_since_restore: 2465000
  timesteps_this_iter: 5000
  timesteps_total: 2465000
  training_iteration: 493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4278 s, 493 iter, 2465000 ts, 142 rew

agent-1: 56.59999998829493
agent-2: 60.59999998829494
agent-3: 51.59999998829493
agent-4: 56.59999998829493
agent-5: 53.59999998829493
Extrinsic Rewards:
7
11
2
7
4
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.2709677419354839
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-39-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 144.70300882623857
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 493
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.272
    dispatch_time_ms: 9.411
    learner:
      cur_lr: 0.0011958309914916754
      grad_gnorm: 39.999996185302734
      policy_entropy: 31.59260368347168
      policy_loss: 42.78532409667969
      var_gnorm: 22.35384178161621
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 46.578941345214844
    num_steps_sampled: 2470000
    num_steps_trained: 2470000
    wait_time_ms: 74.02
  iterations_since_restore: 494
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4287.08927154541
  time_this_iter_s: 8.658991813659668
  time_total_s: 4287.08927154541
  timestamp: 1594852794
  timesteps_since_restore: 2470000
  timesteps_this_iter: 5000
  timesteps_total: 2470000
  training_iteration: 494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4287 s, 494 iter, 2470000 ts, 145 rew

agent-1: 92.39999994373844
agent-2: 92.39999994373844
agent-3: 84.39999994373846
agent-4: 80.39999994373845
agent-5: 91.39999994373846
Extrinsic Rewards:
14
14
6
2
13
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.2612244897959184
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-40-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 149.11300882342542
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 494
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.695
    dispatch_time_ms: 9.193
    learner:
      cur_lr: 0.0011954980436712503
      grad_gnorm: 17.15886688232422
      policy_entropy: 33.650848388671875
      policy_loss: -3.236388921737671
      var_gnorm: 22.3503360748291
      vf_explained_var: 0.0
      vf_loss: 0.1965501606464386
    num_steps_sampled: 2475000
    num_steps_trained: 2475000
    wait_time_ms: 76.525
  iterations_since_restore: 495
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4295.735641956329
  time_this_iter_s: 8.64637041091919
  time_total_s: 4295.735641956329
  timestamp: 1594852803
  timesteps_since_restore: 2475000
  timesteps_this_iter: 5000
  timesteps_total: 2475000
  training_iteration: 495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4295 s, 495 iter, 2475000 ts, 149 rew

agent-1: 34.3999999989498
agent-2: 30.39999999894978
agent-3: 35.3999999989498
agent-4: 38.3999999989498
agent-5: 32.399999998949774
Extrinsic Rewards:
4
0
5
8
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-40-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 150.8230088233729
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 495
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.534
    dispatch_time_ms: 8.321
    learner:
      cur_lr: 0.0011951649794355035
      grad_gnorm: 40.0
      policy_entropy: 34.3582878112793
      policy_loss: 65.78321838378906
      var_gnorm: 22.353038787841797
      vf_explained_var: 0.0
      vf_loss: 116.98794555664062
    num_steps_sampled: 2480000
    num_steps_trained: 2480000
    wait_time_ms: 74.341
  iterations_since_restore: 496
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4304.402905702591
  time_this_iter_s: 8.667263746261597
  time_total_s: 4304.402905702591
  timestamp: 1594852812
  timesteps_since_restore: 2480000
  timesteps_this_iter: 5000
  timesteps_total: 2480000
  training_iteration: 496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4304 s, 496 iter, 2480000 ts, 151 rew

agent-1: 59.99999999347886
agent-2: 55.99999999347887
agent-3: 66.9999999934787
agent-4: 60.99999999347887
agent-5: 70.99999999347867
Extrinsic Rewards:
4
0
11
5
15
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 0
Max Reward: 15
Gini Coefficient: 0.4228571428571429
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-40-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 153.97300882304683
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 496
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 9.974
    learner:
      cur_lr: 0.0011948320316150784
      grad_gnorm: 40.0
      policy_entropy: 27.188663482666016
      policy_loss: 40.105751037597656
      var_gnorm: 22.34946060180664
      vf_explained_var: 0.0
      vf_loss: 55.402896881103516
    num_steps_sampled: 2485000
    num_steps_trained: 2485000
    wait_time_ms: 73.312
  iterations_since_restore: 497
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4312.968938112259
  time_this_iter_s: 8.566032409667969
  time_total_s: 4312.968938112259
  timestamp: 1594852820
  timesteps_since_restore: 2485000
  timesteps_this_iter: 5000
  timesteps_total: 2485000
  training_iteration: 497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4312 s, 497 iter, 2485000 ts, 154 rew

agent-1: 82.59999995925216
agent-2: 83.59999995925214
agent-3: 83.59999995925216
agent-4: 84.59999995925213
agent-5: 79.59999995925214
Extrinsic Rewards:
9
10
10
11
6
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 6
Max Reward: 11
Gini Coefficient: 0.09565217391304348
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-40-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 158.11300882100943
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 497
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.522
    dispatch_time_ms: 7.971
    learner:
      cur_lr: 0.0011944989673793316
      grad_gnorm: 9.019201278686523
      policy_entropy: 16.736412048339844
      policy_loss: -0.7246978282928467
      var_gnorm: 22.350658416748047
      vf_explained_var: 0.0
      vf_loss: 0.06250334531068802
    num_steps_sampled: 2490000
    num_steps_trained: 2490000
    wait_time_ms: 75.427
  iterations_since_restore: 498
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4321.56017780304
  time_this_iter_s: 8.59123969078064
  time_total_s: 4321.56017780304
  timestamp: 1594852829
  timesteps_since_restore: 2490000
  timesteps_this_iter: 5000
  timesteps_total: 2490000
  training_iteration: 498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4321 s, 498 iter, 2490000 ts, 158 rew

agent-1: 103.99997917914578
agent-2: 101.9999791791458
agent-3: 93.99997917914578
agent-4: 94.99997917914578
agent-5: 99.9999791791458
Extrinsic Rewards:
16
14
6
7
12
Sum Reward: 55
Avg Reward: 11.0
Min Reward: 6
Max Reward: 16
Gini Coefficient: 0.19636363636363635
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-40-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 163.06300777996677
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 498
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.148
    dispatch_time_ms: 9.11
    learner:
      cur_lr: 0.0011941660195589066
      grad_gnorm: 9.416326522827148
      policy_entropy: 29.670616149902344
      policy_loss: -1.462769865989685
      var_gnorm: 22.349740982055664
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0679430291056633
    num_steps_sampled: 2495000
    num_steps_trained: 2495000
    wait_time_ms: 74.06
  iterations_since_restore: 499
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4330.255789518356
  time_this_iter_s: 8.695611715316772
  time_total_s: 4330.255789518356
  timestamp: 1594852838
  timesteps_since_restore: 2495000
  timesteps_this_iter: 5000
  timesteps_total: 2495000
  training_iteration: 499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4330 s, 499 iter, 2495000 ts, 163 rew

agent-1: 63.39999999242178
agent-2: 57.3999999924218
agent-3: 59.3999999924218
agent-4: 59.39999999242178
agent-5: 66.3999999924219
Extrinsic Rewards:
9
3
5
5
12
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.25882352941176473
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-40-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 166.12300777958785
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 499
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.871
    dispatch_time_ms: 9.312
    learner:
      cur_lr: 0.0011938329553231597
      grad_gnorm: 40.0
      policy_entropy: 27.73155975341797
      policy_loss: 17.120859146118164
      var_gnorm: 22.350914001464844
      vf_explained_var: 0.0
      vf_loss: 9.333799362182617
    num_steps_sampled: 2500000
    num_steps_trained: 2500000
    wait_time_ms: 74.921
  iterations_since_restore: 500
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4338.948044300079
  time_this_iter_s: 8.692254781723022
  time_total_s: 4338.948044300079
  timestamp: 1594852846
  timesteps_since_restore: 2500000
  timesteps_this_iter: 5000
  timesteps_total: 2500000
  training_iteration: 500
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4338 s, 500 iter, 2500000 ts, 166 rew

agent-1: 33.399999999454806
agent-2: 35.399999999454806
agent-3: 36.399999999454806
agent-4: 33.399999999454806
agent-5: 32.39999999945483
Extrinsic Rewards:
3
5
6
3
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.21052631578947367
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-40-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 167.8330077795606
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 500
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.684
    dispatch_time_ms: 13.044
    learner:
      cur_lr: 0.0011935000075027347
      grad_gnorm: 16.766206741333008
      policy_entropy: 34.65552520751953
      policy_loss: -4.041533946990967
      var_gnorm: 22.34893226623535
      vf_explained_var: 0.0
      vf_loss: 0.21667668223381042
    num_steps_sampled: 2505000
    num_steps_trained: 2505000
    wait_time_ms: 71.962
  iterations_since_restore: 501
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4347.574321269989
  time_this_iter_s: 8.626276969909668
  time_total_s: 4347.574321269989
  timestamp: 1594852855
  timesteps_since_restore: 2505000
  timesteps_this_iter: 5000
  timesteps_total: 2505000
  training_iteration: 501
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4347 s, 501 iter, 2505000 ts, 168 rew

agent-1: 34.799999999512636
agent-2: 29.799999999512604
agent-3: 33.79999999951264
agent-4: 32.79999999951262
agent-5: 30.799999999512604
Extrinsic Rewards:
6
1
5
4
2
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.28888888888888886
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-41-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 169.45300777953625
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 501
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 9.031
    learner:
      cur_lr: 0.0011931669432669878
      grad_gnorm: 5.780165672302246
      policy_entropy: 32.779117584228516
      policy_loss: -0.8233610391616821
      var_gnorm: 22.351350784301758
      vf_explained_var: 0.0
      vf_loss: 0.025821968913078308
    num_steps_sampled: 2510000
    num_steps_trained: 2510000
    wait_time_ms: 75.937
  iterations_since_restore: 502
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4356.220581293106
  time_this_iter_s: 8.646260023117065
  time_total_s: 4356.220581293106
  timestamp: 1594852864
  timesteps_since_restore: 2510000
  timesteps_this_iter: 5000
  timesteps_total: 2510000
  training_iteration: 502
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4356 s, 502 iter, 2510000 ts, 169 rew

agent-1: 56.999999989769016
agent-2: 64.99999998976898
agent-3: 68.99999998976898
agent-4: 59.99999998976904
agent-5: 63.99999998976902
Extrinsic Rewards:
1
9
13
4
8
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.3314285714285714
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-41-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 172.6030077790247
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 502
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.742
    dispatch_time_ms: 9.759
    learner:
      cur_lr: 0.0011928339954465628
      grad_gnorm: 17.78353500366211
      policy_entropy: 27.128572463989258
      policy_loss: -3.446871280670166
      var_gnorm: 22.349002838134766
      vf_explained_var: 0.0
      vf_loss: 0.2299318015575409
    num_steps_sampled: 2515000
    num_steps_trained: 2515000
    wait_time_ms: 78.153
  iterations_since_restore: 503
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4364.914147377014
  time_this_iter_s: 8.693566083908081
  time_total_s: 4364.914147377014
  timestamp: 1594852872
  timesteps_since_restore: 2515000
  timesteps_this_iter: 5000
  timesteps_total: 2515000
  training_iteration: 503
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4364 s, 503 iter, 2515000 ts, 173 rew

agent-1: 34.599999999101584
agent-2: 44.59999999910159
agent-3: 35.59999999910159
agent-4: 37.599999999101584
agent-5: 36.599999999101584
Extrinsic Rewards:
1
11
2
4
3
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.41904761904761906
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-41-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 174.49300777897977
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 503
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.396
    dispatch_time_ms: 6.592
    learner:
      cur_lr: 0.0011925010476261377
      grad_gnorm: 7.031363487243652
      policy_entropy: 15.874256134033203
      policy_loss: -0.17599470913410187
      var_gnorm: 22.351165771484375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.03817763179540634
    num_steps_sampled: 2520000
    num_steps_trained: 2520000
    wait_time_ms: 78.718
  iterations_since_restore: 504
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4373.655887365341
  time_this_iter_s: 8.741739988327026
  time_total_s: 4373.655887365341
  timestamp: 1594852881
  timesteps_since_restore: 2520000
  timesteps_this_iter: 5000
  timesteps_total: 2520000
  training_iteration: 504
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4373 s, 504 iter, 2520000 ts, 174 rew

agent-1: 55.39999999008162
agent-2: 63.39999999008162
agent-3: 59.39999999008162
agent-4: 65.3999999900817
agent-5: 62.39999999008162
Extrinsic Rewards:
1
9
5
11
8
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.2823529411764706
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-41-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 177.5530077784839
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 504
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.305
    dispatch_time_ms: 9.58
    learner:
      cur_lr: 0.0011921679833903909
      grad_gnorm: 40.0
      policy_entropy: 31.934003829956055
      policy_loss: -10.521336555480957
      var_gnorm: 22.353670120239258
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.292829751968384
    num_steps_sampled: 2525000
    num_steps_trained: 2525000
    wait_time_ms: 75.376
  iterations_since_restore: 505
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4382.309200048447
  time_this_iter_s: 8.653312683105469
  time_total_s: 4382.309200048447
  timestamp: 1594852890
  timesteps_since_restore: 2525000
  timesteps_this_iter: 5000
  timesteps_total: 2525000
  training_iteration: 505
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4382 s, 505 iter, 2525000 ts, 178 rew

agent-1: 142.39998367780694
agent-2: 139.3999836778069
agent-3: 147.39998367780703
agent-4: 135.3999836778069
agent-5: 146.399983677807
Extrinsic Rewards:
16
13
21
9
20
Sum Reward: 79
Avg Reward: 15.8
Min Reward: 9
Max Reward: 21
Gini Coefficient: 0.1569620253164557
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-41-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 184.66300696237423
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 505
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.451
    dispatch_time_ms: 9.774
    learner:
      cur_lr: 0.0011918350355699658
      grad_gnorm: 40.0
      policy_entropy: 25.67116928100586
      policy_loss: 27.918479919433594
      var_gnorm: 22.35308074951172
      vf_explained_var: 0.0
      vf_loss: 27.365041732788086
    num_steps_sampled: 2530000
    num_steps_trained: 2530000
    wait_time_ms: 71.483
  iterations_since_restore: 506
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4390.997823476791
  time_this_iter_s: 8.688623428344727
  time_total_s: 4390.997823476791
  timestamp: 1594852899
  timesteps_since_restore: 2530000
  timesteps_this_iter: 5000
  timesteps_total: 2530000
  training_iteration: 506
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4390 s, 506 iter, 2530000 ts, 185 rew

agent-1: 32.39999999892649
agent-2: 34.399999998926475
agent-3: 33.399999998926475
agent-4: 34.399999998926475
agent-5: 36.39999999892649
Extrinsic Rewards:
2
4
3
4
6
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.18947368421052632
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-41-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 186.37300696232055
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 506
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.584
    dispatch_time_ms: 8.801
    learner:
      cur_lr: 0.001191501971334219
      grad_gnorm: 14.127994537353516
      policy_entropy: 27.46723175048828
      policy_loss: -2.369371175765991
      var_gnorm: 22.350189208984375
      vf_explained_var: 0.0
      vf_loss: 0.12392053753137589
    num_steps_sampled: 2535000
    num_steps_trained: 2535000
    wait_time_ms: 71.859
  iterations_since_restore: 507
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4399.677362680435
  time_this_iter_s: 8.679539203643799
  time_total_s: 4399.677362680435
  timestamp: 1594852907
  timesteps_since_restore: 2535000
  timesteps_this_iter: 5000
  timesteps_total: 2535000
  training_iteration: 507
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4399 s, 507 iter, 2535000 ts, 186 rew

agent-1: 43.399999997307305
agent-2: 47.39999999730731
agent-3: 38.399999997307326
agent-4: 47.399999997307326
agent-5: 39.399999997307326
Extrinsic Rewards:
5
9
0
9
1
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.43333333333333335
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-41-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 188.5330069621859
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 507
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.816
    dispatch_time_ms: 13.241
    learner:
      cur_lr: 0.001191169023513794
      grad_gnorm: 4.776226997375488
      policy_entropy: 26.363014221191406
      policy_loss: -0.1814846247434616
      var_gnorm: 22.352863311767578
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0176123958081007
    num_steps_sampled: 2540000
    num_steps_trained: 2540000
    wait_time_ms: 76.979
  iterations_since_restore: 508
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4408.223121643066
  time_this_iter_s: 8.545758962631226
  time_total_s: 4408.223121643066
  timestamp: 1594852916
  timesteps_since_restore: 2540000
  timesteps_this_iter: 5000
  timesteps_total: 2540000
  training_iteration: 508
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4408 s, 508 iter, 2540000 ts, 189 rew

agent-1: 41.99999999749181
agent-2: 46.99999999749181
agent-3: 43.99999999749181
agent-4: 42.99999999749181
agent-5: 48.999999997491805
Extrinsic Rewards:
2
7
4
3
9
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.288
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-42-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 190.7830069620605
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 508
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.778
    dispatch_time_ms: 23.599
    learner:
      cur_lr: 0.001190835959278047
      grad_gnorm: 40.0
      policy_entropy: 27.818370819091797
      policy_loss: 12.24315071105957
      var_gnorm: 22.348228454589844
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.20515251159668
    num_steps_sampled: 2545000
    num_steps_trained: 2545000
    wait_time_ms: 69.499
  iterations_since_restore: 509
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4417.255519866943
  time_this_iter_s: 9.032398223876953
  time_total_s: 4417.255519866943
  timestamp: 1594852925
  timesteps_since_restore: 2545000
  timesteps_this_iter: 5000
  timesteps_total: 2545000
  training_iteration: 509
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4417 s, 509 iter, 2545000 ts, 191 rew

agent-1: 40.79999997952264
agent-2: 37.799999979522646
agent-3: 45.79999997952264
agent-4: 38.79999997952264
agent-5: 43.79999997952264
Extrinsic Rewards:
4
1
9
2
7
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3652173913043478
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-42-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 192.8530069610366
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 509
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.009
    dispatch_time_ms: 24.591
    learner:
      cur_lr: 0.001190503011457622
      grad_gnorm: 15.347723960876465
      policy_entropy: 4.596809387207031
      policy_loss: -0.3146979808807373
      var_gnorm: 22.350223541259766
      vf_explained_var: 0.0
      vf_loss: 0.18240123987197876
    num_steps_sampled: 2550000
    num_steps_trained: 2550000
    wait_time_ms: 57.769
  iterations_since_restore: 510
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4426.416021347046
  time_this_iter_s: 9.160501480102539
  time_total_s: 4426.416021347046
  timestamp: 1594852934
  timesteps_since_restore: 2550000
  timesteps_this_iter: 5000
  timesteps_total: 2550000
  training_iteration: 510
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4426 s, 510 iter, 2550000 ts, 193 rew

agent-1: 143.39981946808672
agent-2: 140.39981946808672
agent-3: 140.39981946808675
agent-4: 136.39981946808666
agent-5: 150.39981946808672
Extrinsic Rewards:
17
14
14
10
24
Sum Reward: 79
Avg Reward: 15.8
Min Reward: 10
Max Reward: 24
Gini Coefficient: 0.1569620253164557
20:20 Ratio: 2.4
Max-min Ratio: 2.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-42-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 199.96299793444095
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 510
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.475
    dispatch_time_ms: 25.804
    learner:
      cur_lr: 0.0011901699472218752
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.283512115478516
      policy_loss: 34.37548828125
      var_gnorm: 22.36394691467285
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 54.04581069946289
    num_steps_sampled: 2555000
    num_steps_trained: 2555000
    wait_time_ms: 66.84
  iterations_since_restore: 511
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4435.379708766937
  time_this_iter_s: 8.963687419891357
  time_total_s: 4435.379708766937
  timestamp: 1594852943
  timesteps_since_restore: 2555000
  timesteps_this_iter: 5000
  timesteps_total: 2555000
  training_iteration: 511
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4435 s, 511 iter, 2555000 ts, 200 rew

agent-1: 163.51756215630255
agent-2: 169.51756215630255
agent-3: 168.51756215630255
agent-4: 171.5175621563026
agent-5: 159.51756215630252
Extrinsic Rewards:
16
22
21
24
12
Sum Reward: 95
Avg Reward: 19.0
Min Reward: 12
Max Reward: 24
Gini Coefficient: 0.12631578947368421
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-42-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 208.28887604225602
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 511
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.886
    dispatch_time_ms: 24.046
    learner:
      cur_lr: 0.0011898369994014502
      grad_gnorm: 40.0
      policy_entropy: 23.157773971557617
      policy_loss: 19.210752487182617
      var_gnorm: 22.36454963684082
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 13.794974327087402
    num_steps_sampled: 2560000
    num_steps_trained: 2560000
    wait_time_ms: 67.713
  iterations_since_restore: 512
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4444.453189373016
  time_this_iter_s: 9.073480606079102
  time_total_s: 4444.453189373016
  timestamp: 1594852952
  timesteps_since_restore: 2560000
  timesteps_this_iter: 5000
  timesteps_total: 2560000
  training_iteration: 512
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4444 s, 512 iter, 2560000 ts, 208 rew

agent-1: 81.79999742685666
agent-2: 86.79999742685665
agent-3: 88.79999742685665
agent-4: 92.79999742685665
agent-5: 81.79999742685666
Extrinsic Rewards:
5
10
12
16
5
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 5
Max Reward: 16
Gini Coefficient: 0.24166666666666667
20:20 Ratio: 3.2
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-42-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 212.6088759135988
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 512
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.823
    dispatch_time_ms: 32.397
    learner:
      cur_lr: 0.0011895040515810251
      grad_gnorm: 32.7420539855957
      policy_entropy: 1.1481455564498901
      policy_loss: -0.04317332059144974
      var_gnorm: 22.354480743408203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.8300594687461853
    num_steps_sampled: 2565000
    num_steps_trained: 2565000
    wait_time_ms: 55.136
  iterations_since_restore: 513
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4453.581496715546
  time_this_iter_s: 9.128307342529297
  time_total_s: 4453.581496715546
  timestamp: 1594852961
  timesteps_since_restore: 2565000
  timesteps_this_iter: 5000
  timesteps_total: 2565000
  training_iteration: 513
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4453 s, 513 iter, 2565000 ts, 213 rew

agent-1: 36.59999999864928
agent-2: 42.59999999864926
agent-3: 34.599999998649274
agent-4: 37.59999999864927
agent-5: 37.59999999864927
Extrinsic Rewards:
3
9
1
4
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3238095238095238
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-42-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 214.4988759135313
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 513
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.088
    dispatch_time_ms: 34.723
    learner:
      cur_lr: 0.0011891709873452783
      grad_gnorm: 1.2063374519348145
      policy_entropy: 1.0115379095077515
      policy_loss: 0.16642701625823975
      var_gnorm: 22.352981567382812
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.003712528385221958
    num_steps_sampled: 2570000
    num_steps_trained: 2570000
    wait_time_ms: 52.881
  iterations_since_restore: 514
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4462.747320890427
  time_this_iter_s: 9.165824174880981
  time_total_s: 4462.747320890427
  timestamp: 1594852971
  timesteps_since_restore: 2570000
  timesteps_this_iter: 5000
  timesteps_total: 2570000
  training_iteration: 514
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4462 s, 514 iter, 2570000 ts, 214 rew

agent-1: 32.999999999114884
agent-2: 32.999999999114884
agent-3: 38.99999999911493
agent-4: 41.99999999911493
agent-5: 32.999999999114884
Extrinsic Rewards:
1
1
7
10
1
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.48
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-43-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 216.29887591348702
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 514
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.698
    dispatch_time_ms: 23.39
    learner:
      cur_lr: 0.0011888380395248532
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.464336395263672
      policy_loss: 7.924081325531006
      var_gnorm: 22.35234832763672
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.511118412017822
    num_steps_sampled: 2575000
    num_steps_trained: 2575000
    wait_time_ms: 51.953
  iterations_since_restore: 515
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4471.722219944
  time_this_iter_s: 8.974899053573608
  time_total_s: 4471.722219944
  timestamp: 1594852980
  timesteps_since_restore: 2575000
  timesteps_this_iter: 5000
  timesteps_total: 2575000
  training_iteration: 515
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4471 s, 515 iter, 2575000 ts, 216 rew

agent-1: 111.48794525605427
agent-2: 115.4879452560543
agent-3: 113.4879452560543
agent-4: 116.4879452560543
agent-5: 115.4879452560543
Extrinsic Rewards:
10
14
12
15
14
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 10
Max Reward: 15
Gini Coefficient: 0.07384615384615385
20:20 Ratio: 1.5
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-43-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 222.02327317628976
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 515
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.279
    dispatch_time_ms: 24.043
    learner:
      cur_lr: 0.0011885049752891064
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.68382453918457
      policy_loss: -9.11001205444336
      var_gnorm: 22.371244430541992
      vf_explained_var: 0.0
      vf_loss: 8.125847816467285
    num_steps_sampled: 2580000
    num_steps_trained: 2580000
    wait_time_ms: 70.676
  iterations_since_restore: 516
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4480.827343225479
  time_this_iter_s: 9.105123281478882
  time_total_s: 4480.827343225479
  timestamp: 1594852989
  timesteps_since_restore: 2580000
  timesteps_this_iter: 5000
  timesteps_total: 2580000
  training_iteration: 516
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4480 s, 516 iter, 2580000 ts, 222 rew

agent-1: 89.99972651940081
agent-2: 93.9997265194008
agent-3: 86.99972651940077
agent-4: 88.99972651940077
agent-5: 89.99972651940078
Extrinsic Rewards:
10
14
7
9
10
Sum Reward: 50
Avg Reward: 10.0
Min Reward: 7
Max Reward: 14
Gini Coefficient: 0.12
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-43-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 226.52325950225975
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 516
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.888
    dispatch_time_ms: 27.168
    learner:
      cur_lr: 0.0011881720274686813
      grad_gnorm: 39.999996185302734
      policy_entropy: 7.74904727935791
      policy_loss: -2.2669363021850586
      var_gnorm: 22.36022186279297
      vf_explained_var: 0.0
      vf_loss: 3.0044198036193848
    num_steps_sampled: 2585000
    num_steps_trained: 2585000
    wait_time_ms: 56.29
  iterations_since_restore: 517
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4489.819575309753
  time_this_iter_s: 8.992232084274292
  time_total_s: 4489.819575309753
  timestamp: 1594852998
  timesteps_since_restore: 2585000
  timesteps_this_iter: 5000
  timesteps_total: 2585000
  training_iteration: 517
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4489 s, 517 iter, 2585000 ts, 227 rew

agent-1: 80.199999969167
agent-2: 70.19999996916697
agent-3: 78.199999969167
agent-4: 80.199999969167
agent-5: 69.19999996916697
Extrinsic Rewards:
13
3
11
13
2
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.3047619047619048
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-43-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 230.30325950071813
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 517
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.401
    dispatch_time_ms: 7.412
    learner:
      cur_lr: 0.0011878389632329345
      grad_gnorm: 28.060544967651367
      policy_entropy: 34.64612579345703
      policy_loss: -4.810692310333252
      var_gnorm: 22.353748321533203
      vf_explained_var: 0.0
      vf_loss: 0.605825662612915
    num_steps_sampled: 2590000
    num_steps_trained: 2590000
    wait_time_ms: 76.383
  iterations_since_restore: 518
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4507.948776245117
  time_this_iter_s: 18.12920093536377
  time_total_s: 4507.948776245117
  timestamp: 1594853016
  timesteps_since_restore: 2590000
  timesteps_this_iter: 5000
  timesteps_total: 2590000
  training_iteration: 518
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4507 s, 518 iter, 2590000 ts, 230 rew

agent-1: 48.199999995915746
agent-2: 48.199999995915746
agent-3: 47.199999995915746
agent-4: 51.199999995915746
agent-5: 48.19999999591575
Extrinsic Rewards:
5
5
4
8
5
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 4
Max Reward: 8
Gini Coefficient: 0.11851851851851852
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-43-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 232.73325950051395
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 518
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.748
    dispatch_time_ms: 9.712
    learner:
      cur_lr: 0.0011875060154125094
      grad_gnorm: 20.661596298217773
      policy_entropy: 10.500686645507812
      policy_loss: -1.2858436107635498
      var_gnorm: 22.35186004638672
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.3305738866329193
    num_steps_sampled: 2595000
    num_steps_trained: 2595000
    wait_time_ms: 77.557
  iterations_since_restore: 519
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4516.558330774307
  time_this_iter_s: 8.609554529190063
  time_total_s: 4516.558330774307
  timestamp: 1594853025
  timesteps_since_restore: 2595000
  timesteps_this_iter: 5000
  timesteps_total: 2595000
  training_iteration: 519
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4516 s, 519 iter, 2595000 ts, 233 rew

agent-1: 66.79999983196274
agent-2: 61.79999983196271
agent-3: 57.7999998319627
agent-4: 54.7999998319627
agent-5: 55.799999831962694
Extrinsic Rewards:
14
9
5
2
3
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.36363636363636365
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-43-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 235.70325949211212
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 519
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.077
    dispatch_time_ms: 7.962
    learner:
      cur_lr: 0.0011871729511767626
      grad_gnorm: 40.0
      policy_entropy: 9.804189682006836
      policy_loss: 17.784364700317383
      var_gnorm: 22.354145050048828
      vf_explained_var: 0.0
      vf_loss: 102.73760986328125
    num_steps_sampled: 2600000
    num_steps_trained: 2600000
    wait_time_ms: 75.446
  iterations_since_restore: 520
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4525.215248823166
  time_this_iter_s: 8.656918048858643
  time_total_s: 4525.215248823166
  timestamp: 1594853033
  timesteps_since_restore: 2600000
  timesteps_this_iter: 5000
  timesteps_total: 2600000
  training_iteration: 520
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4525 s, 520 iter, 2600000 ts, 236 rew

agent-1: 34.39999999935565
agent-2: 30.399999999355625
agent-3: 32.399999999355686
agent-4: 37.39999999935566
agent-5: 36.39999999935565
Extrinsic Rewards:
4
0
2
7
6
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.37894736842105264
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-44-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 913.0008273155165
  episode_reward_mean: 237.41325949207987
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 520
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.768
    dispatch_time_ms: 9.589
    learner:
      cur_lr: 0.0011868400033563375
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.49151039123535
      policy_loss: -8.940210342407227
      var_gnorm: 22.352798461914062
      vf_explained_var: 0.0
      vf_loss: 2.4106550216674805
    num_steps_sampled: 2605000
    num_steps_trained: 2605000
    wait_time_ms: 75.989
  iterations_since_restore: 521
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4533.827414751053
  time_this_iter_s: 8.612165927886963
  time_total_s: 4533.827414751053
  timestamp: 1594853042
  timesteps_since_restore: 2605000
  timesteps_this_iter: 5000
  timesteps_total: 2605000
  training_iteration: 521
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4533 s, 521 iter, 2605000 ts, 237 rew

agent-1: 181.79928120761713
agent-2: 181.79928120761724
agent-3: 190.79928120761735
agent-4: 186.7992812076173
agent-5: 185.7992812076172
Extrinsic Rewards:
17
17
26
22
21
Sum Reward: 103
Avg Reward: 20.6
Min Reward: 17
Max Reward: 26
Gini Coefficient: 0.08932038834951456
20:20 Ratio: 1.5294117647058822
Max-min Ratio: 1.5294117647058822
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-44-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 246.68322355246076
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 521
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.786
    dispatch_time_ms: 7.288
    learner:
      cur_lr: 0.0011865070555359125
      grad_gnorm: 40.0
      policy_entropy: 18.605937957763672
      policy_loss: 9.71882152557373
      var_gnorm: 22.35602569580078
      vf_explained_var: 0.0
      vf_loss: 12.568564414978027
    num_steps_sampled: 2610000
    num_steps_trained: 2610000
    wait_time_ms: 79.016
  iterations_since_restore: 522
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4542.523122310638
  time_this_iter_s: 8.695707559585571
  time_total_s: 4542.523122310638
  timestamp: 1594853051
  timesteps_since_restore: 2610000
  timesteps_this_iter: 5000
  timesteps_total: 2610000
  training_iteration: 522
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4542 s, 522 iter, 2610000 ts, 247 rew

agent-1: 34.39999999936938
agent-2: 36.39999999936938
agent-3: 36.39999999936938
agent-4: 30.399999999369157
agent-5: 33.39999999936937
Extrinsic Rewards:
4
6
6
0
3
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.3157894736842105
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-44-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 248.3932235524292
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 522
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 9.207
    learner:
      cur_lr: 0.0011861739913001657
      grad_gnorm: 40.00000762939453
      policy_entropy: 22.946264266967773
      policy_loss: -4.713216781616211
      var_gnorm: 22.34975814819336
      vf_explained_var: 0.0
      vf_loss: 1.248233675956726
    num_steps_sampled: 2615000
    num_steps_trained: 2615000
    wait_time_ms: 73.392
  iterations_since_restore: 523
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4551.074405908585
  time_this_iter_s: 8.551283597946167
  time_total_s: 4551.074405908585
  timestamp: 1594853059
  timesteps_since_restore: 2615000
  timesteps_this_iter: 5000
  timesteps_total: 2615000
  training_iteration: 523
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4551 s, 523 iter, 2615000 ts, 248 rew

agent-1: 86.3999994809939
agent-2: 78.39999948099388
agent-3: 74.39999948099393
agent-4: 79.39999948099387
agent-5: 77.3999994809939
Extrinsic Rewards:
16
8
4
9
7
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 4
Max Reward: 16
Gini Coefficient: 0.23636363636363636
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-44-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 252.3532235264789
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 523
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.679
    dispatch_time_ms: 5.865
    learner:
      cur_lr: 0.0011858410434797406
      grad_gnorm: 40.0
      policy_entropy: 34.39714050292969
      policy_loss: 37.398494720458984
      var_gnorm: 22.339431762695312
      vf_explained_var: 0.0
      vf_loss: 38.32749557495117
    num_steps_sampled: 2620000
    num_steps_trained: 2620000
    wait_time_ms: 78.905
  iterations_since_restore: 524
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4559.631960630417
  time_this_iter_s: 8.557554721832275
  time_total_s: 4559.631960630417
  timestamp: 1594853068
  timesteps_since_restore: 2620000
  timesteps_this_iter: 5000
  timesteps_total: 2620000
  training_iteration: 524
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4559 s, 524 iter, 2620000 ts, 252 rew

agent-1: 56.79999998758005
agent-2: 60.79999998758005
agent-3: 56.79999998758005
agent-4: 62.79999998758005
agent-5: 59.79999998758005
Extrinsic Rewards:
4
8
4
10
7
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 4
Max Reward: 10
Gini Coefficient: 0.19393939393939394
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-44-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 255.32322352585786
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 524
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.399
    dispatch_time_ms: 7.77
    learner:
      cur_lr: 0.0011855079792439938
      grad_gnorm: 8.663156509399414
      policy_entropy: 34.61342239379883
      policy_loss: -1.7163820266723633
      var_gnorm: 22.338302612304688
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0571778267621994
    num_steps_sampled: 2625000
    num_steps_trained: 2625000
    wait_time_ms: 73.183
  iterations_since_restore: 525
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4568.186947107315
  time_this_iter_s: 8.554986476898193
  time_total_s: 4568.186947107315
  timestamp: 1594853077
  timesteps_since_restore: 2625000
  timesteps_this_iter: 5000
  timesteps_total: 2625000
  training_iteration: 525
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4568 s, 525 iter, 2625000 ts, 255 rew

agent-1: 41.79999999792905
agent-2: 43.799999997929056
agent-3: 37.799999997929056
agent-4: 44.799999997929056
agent-5: 38.799999997929056
Extrinsic Rewards:
5
7
1
8
2
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.33043478260869563
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-44-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 257.3932235257543
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 525
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.561
    dispatch_time_ms: 8.018
    learner:
      cur_lr: 0.0011851750314235687
      grad_gnorm: 8.900609970092773
      policy_entropy: 33.62223815917969
      policy_loss: -1.0438467264175415
      var_gnorm: 22.338977813720703
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.055444009602069855
    num_steps_sampled: 2630000
    num_steps_trained: 2630000
    wait_time_ms: 74.783
  iterations_since_restore: 526
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4576.6679146289825
  time_this_iter_s: 8.48096752166748
  time_total_s: 4576.6679146289825
  timestamp: 1594853085
  timesteps_since_restore: 2630000
  timesteps_this_iter: 5000
  timesteps_total: 2630000
  training_iteration: 526
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4576 s, 526 iter, 2630000 ts, 257 rew

agent-1: 31.199999999482262
agent-2: 32.1999999994823
agent-3: 31.199999999482262
agent-4: 28.199999999482262
agent-5: 30.199999999482262
Extrinsic Rewards:
4
5
4
1
3
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 5
Gini Coefficient: 0.21176470588235294
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-44-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 258.9232235257285
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 526
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.404
    dispatch_time_ms: 10.082
    learner:
      cur_lr: 0.0011848419671878219
      grad_gnorm: 20.7008056640625
      policy_entropy: 20.57280921936035
      policy_loss: -2.3683218955993652
      var_gnorm: 22.33884048461914
      vf_explained_var: 0.0
      vf_loss: 0.32676175236701965
    num_steps_sampled: 2635000
    num_steps_trained: 2635000
    wait_time_ms: 71.678
  iterations_since_restore: 527
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4585.091333389282
  time_this_iter_s: 8.423418760299683
  time_total_s: 4585.091333389282
  timestamp: 1594853094
  timesteps_since_restore: 2635000
  timesteps_this_iter: 5000
  timesteps_total: 2635000
  training_iteration: 527
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4585 s, 527 iter, 2635000 ts, 259 rew

agent-1: 57.999999985122024
agent-2: 69.99999998512223
agent-3: 60.999999985122024
agent-4: 58.999999985122024
agent-5: 66.99999998512222
Extrinsic Rewards:
2
14
5
3
11
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.3657142857142857
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-45-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 262.07322352498454
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 527
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.586
    dispatch_time_ms: 5.992
    learner:
      cur_lr: 0.0011845090193673968
      grad_gnorm: 40.0
      policy_entropy: 31.194067001342773
      policy_loss: 19.42613983154297
      var_gnorm: 22.337743759155273
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.61212158203125
    num_steps_sampled: 2640000
    num_steps_trained: 2640000
    wait_time_ms: 72.88
  iterations_since_restore: 528
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4593.444265365601
  time_this_iter_s: 8.35293197631836
  time_total_s: 4593.444265365601
  timestamp: 1594853102
  timesteps_since_restore: 2640000
  timesteps_this_iter: 5000
  timesteps_total: 2640000
  training_iteration: 528
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4593 s, 528 iter, 2640000 ts, 262 rew

agent-1: 62.99999992487581
agent-2: 63.99999992487581
agent-3: 61.99999992487581
agent-4: 57.999999924875794
agent-5: 67.99999992487564
Extrinsic Rewards:
7
8
6
2
12
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.25142857142857145
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-45-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 265.22322352122836
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 528
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.576
    dispatch_time_ms: 10.408
    learner:
      cur_lr: 0.00118417595513165
      grad_gnorm: 19.77803611755371
      policy_entropy: 34.605003356933594
      policy_loss: -4.151926040649414
      var_gnorm: 22.336772918701172
      vf_explained_var: 0.0
      vf_loss: 0.2731427550315857
    num_steps_sampled: 2645000
    num_steps_trained: 2645000
    wait_time_ms: 72.471
  iterations_since_restore: 529
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4601.925031661987
  time_this_iter_s: 8.480766296386719
  time_total_s: 4601.925031661987
  timestamp: 1594853110
  timesteps_since_restore: 2645000
  timesteps_this_iter: 5000
  timesteps_total: 2645000
  training_iteration: 529
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4601 s, 529 iter, 2645000 ts, 265 rew

agent-1: 33.59999999884186
agent-2: 25.59999999884184
agent-3: 29.59999999884184
agent-4: 25.59999999884184
agent-5: 29.59999999884184
Extrinsic Rewards:
8
0
4
0
4
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.5
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-45-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 266.6632235211705
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 529
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.985
    dispatch_time_ms: 7.196
    learner:
      cur_lr: 0.001183843007311225
      grad_gnorm: 9.129412651062012
      policy_entropy: 34.090858459472656
      policy_loss: -0.5788450241088867
      var_gnorm: 22.337539672851562
      vf_explained_var: 0.0
      vf_loss: 0.06343590468168259
    num_steps_sampled: 2650000
    num_steps_trained: 2650000
    wait_time_ms: 74.387
  iterations_since_restore: 530
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4610.404783010483
  time_this_iter_s: 8.479751348495483
  time_total_s: 4610.404783010483
  timestamp: 1594853119
  timesteps_since_restore: 2650000
  timesteps_this_iter: 5000
  timesteps_total: 2650000
  training_iteration: 530
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4610 s, 530 iter, 2650000 ts, 267 rew

agent-1: 65.1999999877692
agent-2: 68.19999998776925
agent-3: 68.19999998776925
agent-4: 67.19999998776925
agent-5: 64.19999998776923
Extrinsic Rewards:
6
9
9
8
5
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 5
Max Reward: 9
Gini Coefficient: 0.11891891891891893
20:20 Ratio: 1.8
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-45-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 269.99322352055896
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 530
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.556
    dispatch_time_ms: 7.036
    learner:
      cur_lr: 0.001183509943075478
      grad_gnorm: 40.0
      policy_entropy: 9.085983276367188
      policy_loss: -1.3550235033035278
      var_gnorm: 22.340173721313477
      vf_explained_var: 0.0
      vf_loss: 1.2712167501449585
    num_steps_sampled: 2655000
    num_steps_trained: 2655000
    wait_time_ms: 78.578
  iterations_since_restore: 531
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4619.130138158798
  time_this_iter_s: 8.72535514831543
  time_total_s: 4619.130138158798
  timestamp: 1594853128
  timesteps_since_restore: 2655000
  timesteps_this_iter: 5000
  timesteps_total: 2655000
  training_iteration: 531
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4619 s, 531 iter, 2655000 ts, 270 rew

agent-1: 76.59999997274146
agent-2: 76.59999997274146
agent-3: 88.5999999727415
agent-4: 87.59999997274151
agent-5: 84.59999997274151
Extrinsic Rewards:
3
3
15
14
11
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 3
Max Reward: 15
Gini Coefficient: 0.30434782608695654
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-45-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 274.133223519196
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 531
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 6.971
    learner:
      cur_lr: 0.001183176995255053
      grad_gnorm: 8.07503604888916
      policy_entropy: 7.801979064941406
      policy_loss: -0.24677515029907227
      var_gnorm: 22.336685180664062
      vf_explained_var: 0.0
      vf_loss: 0.0504990816116333
    num_steps_sampled: 2660000
    num_steps_trained: 2660000
    wait_time_ms: 72.662
  iterations_since_restore: 532
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4627.7935309410095
  time_this_iter_s: 8.663392782211304
  time_total_s: 4627.7935309410095
  timestamp: 1594853136
  timesteps_since_restore: 2660000
  timesteps_this_iter: 5000
  timesteps_total: 2660000
  training_iteration: 532
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4627 s, 532 iter, 2660000 ts, 274 rew

agent-1: 91.1999997408172
agent-2: 96.1999997408172
agent-3: 87.1999997408172
agent-4: 98.1999997408172
agent-5: 95.19999974081723
Extrinsic Rewards:
8
13
4
15
12
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 4
Max Reward: 15
Gini Coefficient: 0.2076923076923077
20:20 Ratio: 3.75
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-45-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 278.81322350623685
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 532
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 6.024
    learner:
      cur_lr: 0.001182844047434628
      grad_gnorm: 40.0
      policy_entropy: 34.62645721435547
      policy_loss: -13.265253067016602
      var_gnorm: 22.351293563842773
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.302852630615234
    num_steps_sampled: 2665000
    num_steps_trained: 2665000
    wait_time_ms: 81.499
  iterations_since_restore: 533
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4636.503526926041
  time_this_iter_s: 8.709995985031128
  time_total_s: 4636.503526926041
  timestamp: 1594853145
  timesteps_since_restore: 2665000
  timesteps_this_iter: 5000
  timesteps_total: 2665000
  training_iteration: 533
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4636 s, 533 iter, 2665000 ts, 279 rew

agent-1: 123.39995249029901
agent-2: 127.39995249029904
agent-3: 125.39995249029901
agent-4: 122.39995249029901
agent-5: 122.39995249029901
Extrinsic Rewards:
13
17
15
12
12
Sum Reward: 69
Avg Reward: 13.8
Min Reward: 12
Max Reward: 17
Gini Coefficient: 0.07536231884057971
20:20 Ratio: 1.4166666666666667
Max-min Ratio: 1.4166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-45-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 285.0232211307518
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 533
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 6.614
    learner:
      cur_lr: 0.0011825109831988811
      grad_gnorm: 8.29904556274414
      policy_entropy: 9.34310245513916
      policy_loss: -0.26903051137924194
      var_gnorm: 22.33832359313965
      vf_explained_var: 0.0
      vf_loss: 0.05334002524614334
    num_steps_sampled: 2670000
    num_steps_trained: 2670000
    wait_time_ms: 80.746
  iterations_since_restore: 534
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4645.202504873276
  time_this_iter_s: 8.698977947235107
  time_total_s: 4645.202504873276
  timestamp: 1594853154
  timesteps_since_restore: 2670000
  timesteps_this_iter: 5000
  timesteps_total: 2670000
  training_iteration: 534
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4645 s, 534 iter, 2670000 ts, 285 rew

agent-1: 61.59999997746794
agent-2: 63.59999997746794
agent-3: 68.59999997746795
agent-4: 61.599999977467924
agent-5: 68.59999997746796
Extrinsic Rewards:
4
6
11
4
11
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 4
Max Reward: 11
Gini Coefficient: 0.23333333333333334
20:20 Ratio: 2.75
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-46-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 288.2632211296252
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 534
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.655
    dispatch_time_ms: 6.969
    learner:
      cur_lr: 0.0011821780353784561
      grad_gnorm: 40.0
      policy_entropy: 12.210450172424316
      policy_loss: 42.45474624633789
      var_gnorm: 22.35146141052246
      vf_explained_var: 0.0
      vf_loss: 176.0709228515625
    num_steps_sampled: 2675000
    num_steps_trained: 2675000
    wait_time_ms: 73.706
  iterations_since_restore: 535
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4653.846742391586
  time_this_iter_s: 8.644237518310547
  time_total_s: 4653.846742391586
  timestamp: 1594853163
  timesteps_since_restore: 2675000
  timesteps_this_iter: 5000
  timesteps_total: 2675000
  training_iteration: 535
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4653 s, 535 iter, 2675000 ts, 288 rew

agent-1: 181.39224914820048
agent-2: 168.39224914820045
agent-3: 177.39224914820048
agent-4: 184.3922491482005
agent-5: 179.39224914820045
Extrinsic Rewards:
23
10
19
26
21
Sum Reward: 99
Avg Reward: 19.8
Min Reward: 10
Max Reward: 26
Gini Coefficient: 0.14545454545454545
20:20 Ratio: 2.6
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-46-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 297.17283358703526
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 535
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 8.509
    learner:
      cur_lr: 0.0011818449711427093
      grad_gnorm: 29.9713077545166
      policy_entropy: 24.909259796142578
      policy_loss: -3.317006826400757
      var_gnorm: 22.338279724121094
      vf_explained_var: 0.0
      vf_loss: 0.6912628412246704
    num_steps_sampled: 2680000
    num_steps_trained: 2680000
    wait_time_ms: 77.389
  iterations_since_restore: 536
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4662.526733875275
  time_this_iter_s: 8.679991483688354
  time_total_s: 4662.526733875275
  timestamp: 1594853171
  timesteps_since_restore: 2680000
  timesteps_this_iter: 5000
  timesteps_total: 2680000
  training_iteration: 536
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4662 s, 536 iter, 2680000 ts, 297 rew

agent-1: 60.79999998716488
agent-2: 69.79999998716507
agent-3: 76.79999998716504
agent-4: 69.79999998716507
agent-5: 64.79999998716511
Extrinsic Rewards:
0
9
16
9
4
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 0
Max Reward: 16
Gini Coefficient: 0.3894736842105263
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-46-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 300.5928335863935
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 536
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.594
    dispatch_time_ms: 8.886
    learner:
      cur_lr: 0.0011815120233222842
      grad_gnorm: 16.86130714416504
      policy_entropy: 34.471534729003906
      policy_loss: -2.8296377658843994
      var_gnorm: 22.33843994140625
      vf_explained_var: 0.0
      vf_loss: 0.21688611805438995
    num_steps_sampled: 2685000
    num_steps_trained: 2685000
    wait_time_ms: 76.256
  iterations_since_restore: 537
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4671.200269937515
  time_this_iter_s: 8.6735360622406
  time_total_s: 4671.200269937515
  timestamp: 1594853180
  timesteps_since_restore: 2685000
  timesteps_this_iter: 5000
  timesteps_total: 2685000
  training_iteration: 537
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4671 s, 537 iter, 2685000 ts, 301 rew

agent-1: 58.39999999555094
agent-2: 61.39999999555095
agent-3: 64.3999999955511
agent-4: 57.39999999555095
agent-5: 64.3999999955511
Extrinsic Rewards:
4
7
10
3
10
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.23529411764705882
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-46-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 303.6528335861711
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 537
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.765
    dispatch_time_ms: 26.884
    learner:
      cur_lr: 0.0011811789590865374
      grad_gnorm: 9.001763343811035
      policy_entropy: 20.543731689453125
      policy_loss: -0.5099101662635803
      var_gnorm: 22.339784622192383
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.06274913996458054
    num_steps_sampled: 2690000
    num_steps_trained: 2690000
    wait_time_ms: 52.712
  iterations_since_restore: 538
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4680.023139715195
  time_this_iter_s: 8.822869777679443
  time_total_s: 4680.023139715195
  timestamp: 1594853189
  timesteps_since_restore: 2690000
  timesteps_this_iter: 5000
  timesteps_total: 2690000
  training_iteration: 538
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4680 s, 538 iter, 2690000 ts, 304 rew

agent-1: 60.799999998051014
agent-2: 63.79999999805101
agent-3: 58.79999999805102
agent-4: 54.79999999805102
agent-5: 58.799999998051014
Extrinsic Rewards:
8
11
6
2
6
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.24242424242424243
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-46-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 306.6228335860736
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 538
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.477
    dispatch_time_ms: 27.054
    learner:
      cur_lr: 0.0011808460112661123
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.134897232055664
      policy_loss: -6.02957010269165
      var_gnorm: 22.339738845825195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.100093126296997
    num_steps_sampled: 2695000
    num_steps_trained: 2695000
    wait_time_ms: 57.764
  iterations_since_restore: 539
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4689.127251625061
  time_this_iter_s: 9.104111909866333
  time_total_s: 4689.127251625061
  timestamp: 1594853198
  timesteps_since_restore: 2695000
  timesteps_this_iter: 5000
  timesteps_total: 2695000
  training_iteration: 539
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4689 s, 539 iter, 2695000 ts, 307 rew

agent-1: 73.79999923552954
agent-2: 73.79999923552954
agent-3: 85.79999923552953
agent-4: 82.79999923552953
agent-5: 70.79999923552955
Extrinsic Rewards:
5
5
17
14
2
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 2
Max Reward: 17
Gini Coefficient: 0.3627906976744186
20:20 Ratio: 8.5
Max-min Ratio: 8.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-46-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 310.49283354785007
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 539
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.264
    dispatch_time_ms: 26.043
    learner:
      cur_lr: 0.0011805129470303655
      grad_gnorm: 40.0
      policy_entropy: 34.578556060791016
      policy_loss: 32.48151397705078
      var_gnorm: 22.3417911529541
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 27.24335479736328
    num_steps_sampled: 2700000
    num_steps_trained: 2700000
    wait_time_ms: 63.544
  iterations_since_restore: 540
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4699.161408662796
  time_this_iter_s: 10.034157037734985
  time_total_s: 4699.161408662796
  timestamp: 1594853208
  timesteps_since_restore: 2700000
  timesteps_this_iter: 5000
  timesteps_total: 2700000
  training_iteration: 540
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4699 s, 540 iter, 2700000 ts, 310 rew

agent-1: 188.19196875740914
agent-2: 186.1919687574092
agent-3: 187.19196875740911
agent-4: 179.1919687574092
agent-5: 177.1919687574092
Extrinsic Rewards:
25
23
24
16
14
Sum Reward: 102
Avg Reward: 20.4
Min Reward: 14
Max Reward: 25
Gini Coefficient: 0.11764705882352941
20:20 Ratio: 1.7857142857142858
Max-min Ratio: 1.7857142857142858
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-46-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 319.6724319857205
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 540
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.436
    dispatch_time_ms: 14.389
    learner:
      cur_lr: 0.0011801799992099404
      grad_gnorm: 40.0
      policy_entropy: 7.368253707885742
      policy_loss: -1.8714406490325928
      var_gnorm: 22.33991241455078
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.8801730871200562
    num_steps_sampled: 2705000
    num_steps_trained: 2705000
    wait_time_ms: 73.689
  iterations_since_restore: 541
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4708.141632795334
  time_this_iter_s: 8.980224132537842
  time_total_s: 4708.141632795334
  timestamp: 1594853217
  timesteps_since_restore: 2705000
  timesteps_this_iter: 5000
  timesteps_total: 2705000
  training_iteration: 541
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4708 s, 541 iter, 2705000 ts, 320 rew

agent-1: 59.59999990797611
agent-2: 67.59999990797617
agent-3: 67.5999999079762
agent-4: 62.59999990797612
agent-5: 66.59999990797617
Extrinsic Rewards:
2
10
10
5
9
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.23333333333333334
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-47-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 322.9124319811193
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 541
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 31.57
    learner:
      cur_lr: 0.0011798470513895154
      grad_gnorm: 40.0
      policy_entropy: 5.270895957946777
      policy_loss: 0.6759317517280579
      var_gnorm: 22.334535598754883
      vf_explained_var: 0.0
      vf_loss: 10.261672973632812
    num_steps_sampled: 2710000
    num_steps_trained: 2710000
    wait_time_ms: 62.625
  iterations_since_restore: 542
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4717.408618211746
  time_this_iter_s: 9.266985416412354
  time_total_s: 4717.408618211746
  timestamp: 1594853226
  timesteps_since_restore: 2710000
  timesteps_this_iter: 5000
  timesteps_total: 2710000
  training_iteration: 542
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4717 s, 542 iter, 2710000 ts, 323 rew

agent-1: 45.19999999503794
agent-2: 50.19999999503794
agent-3: 48.199999995037956
agent-4: 50.19999999503794
agent-5: 49.199999995037956
Extrinsic Rewards:
2
7
5
7
6
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.17777777777777778
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-47-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 325.3424319808712
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 542
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 28.994
    learner:
      cur_lr: 0.0011795139871537685
      grad_gnorm: 40.0
      policy_entropy: 18.185888290405273
      policy_loss: 35.36613082885742
      var_gnorm: 22.349319458007812
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 99.26396179199219
    num_steps_sampled: 2715000
    num_steps_trained: 2715000
    wait_time_ms: 67.477
  iterations_since_restore: 543
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4726.464313745499
  time_this_iter_s: 9.055695533752441
  time_total_s: 4726.464313745499
  timestamp: 1594853236
  timesteps_since_restore: 2715000
  timesteps_this_iter: 5000
  timesteps_total: 2715000
  training_iteration: 543
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4726 s, 543 iter, 2715000 ts, 325 rew

agent-1: 100.1999405288192
agent-2: 93.1999405288192
agent-3: 90.1999405288192
agent-4: 93.19994052881921
agent-5: 91.1999405288192
Extrinsic Rewards:
17
10
7
10
8
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 7
Max Reward: 17
Gini Coefficient: 0.16923076923076924
20:20 Ratio: 2.4285714285714284
Max-min Ratio: 2.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-47-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 330.02242900731216
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 543
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.873
    dispatch_time_ms: 31.576
    learner:
      cur_lr: 0.0011791810393333435
      grad_gnorm: 40.0
      policy_entropy: 1.5146596431732178
      policy_loss: 2.137061357498169
      var_gnorm: 22.34113883972168
      vf_explained_var: 0.0
      vf_loss: 7.721701145172119
    num_steps_sampled: 2720000
    num_steps_trained: 2720000
    wait_time_ms: 57.849
  iterations_since_restore: 544
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4735.56796336174
  time_this_iter_s: 9.103649616241455
  time_total_s: 4735.56796336174
  timestamp: 1594853245
  timesteps_since_restore: 2720000
  timesteps_this_iter: 5000
  timesteps_total: 2720000
  training_iteration: 544
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4735 s, 544 iter, 2720000 ts, 330 rew

agent-1: 130.99999495863415
agent-2: 148.99999495863418
agent-3: 138.9999949586342
agent-4: 125.99999495863462
agent-5: 129.99999495863412
Extrinsic Rewards:
11
29
19
6
10
Sum Reward: 75
Avg Reward: 15.0
Min Reward: 6
Max Reward: 29
Gini Coefficient: 0.29333333333333333
20:20 Ratio: 4.833333333333333
Max-min Ratio: 4.833333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-47-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 336.7724287552438
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 544
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.534
    dispatch_time_ms: 38.287
    learner:
      cur_lr: 0.0011788479750975966
      grad_gnorm: 39.999996185302734
      policy_entropy: 7.845083236694336
      policy_loss: 13.81964111328125
      var_gnorm: 22.348785400390625
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 50.96747589111328
    num_steps_sampled: 2725000
    num_steps_trained: 2725000
    wait_time_ms: 59.421
  iterations_since_restore: 545
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4744.579200029373
  time_this_iter_s: 9.011236667633057
  time_total_s: 4744.579200029373
  timestamp: 1594853254
  timesteps_since_restore: 2725000
  timesteps_this_iter: 5000
  timesteps_total: 2725000
  training_iteration: 545
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4744 s, 545 iter, 2725000 ts, 337 rew

agent-1: 151.3494460794703
agent-2: 150.3494460794703
agent-3: 158.3494460794703
agent-4: 166.34944607947037
agent-5: 169.34944607947037
Extrinsic Rewards:
11
10
18
26
29
Sum Reward: 94
Avg Reward: 18.8
Min Reward: 10
Max Reward: 29
Gini Coefficient: 0.225531914893617
20:20 Ratio: 2.9
Max-min Ratio: 2.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-47-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9964060380878
  episode_reward_mean: 344.72990105921735
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 545
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.123
    dispatch_time_ms: 22.571
    learner:
      cur_lr: 0.0011785150272771716
      grad_gnorm: 17.14154815673828
      policy_entropy: 14.847821235656738
      policy_loss: 3.0110692977905273
      var_gnorm: 22.40606117248535
      vf_explained_var: 0.0
      vf_loss: 0.735758900642395
    num_steps_sampled: 2730000
    num_steps_trained: 2730000
    wait_time_ms: 40.432
  iterations_since_restore: 546
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4761.3514630794525
  time_this_iter_s: 16.772263050079346
  time_total_s: 4761.3514630794525
  timestamp: 1594853271
  timesteps_since_restore: 2730000
  timesteps_this_iter: 5000
  timesteps_total: 2730000
  training_iteration: 546
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4761 s, 546 iter, 2730000 ts, 345 rew

agent-1: 205.4813312053979
agent-2: 208.48133120539785
agent-3: 215.4813312053979
agent-4: 218.4813312053979
agent-5: 219.48133120539785
Extrinsic Rewards:
16
19
26
29
30
Sum Reward: 120
Avg Reward: 24.0
Min Reward: 16
Max Reward: 30
Gini Coefficient: 0.12666666666666668
20:20 Ratio: 1.875
Max-min Ratio: 1.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-48-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 355.4039676194873
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 546
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 37.795
    learner:
      cur_lr: 0.0011781819630414248
      grad_gnorm: 40.0
      policy_entropy: 14.064491271972656
      policy_loss: -11.035577774047852
      var_gnorm: 22.386150360107422
      vf_explained_var: 0.0
      vf_loss: 9.382896423339844
    num_steps_sampled: 2735000
    num_steps_trained: 2735000
    wait_time_ms: 67.97
  iterations_since_restore: 547
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4770.497685670853
  time_this_iter_s: 9.146222591400146
  time_total_s: 4770.497685670853
  timestamp: 1594853280
  timesteps_since_restore: 2735000
  timesteps_this_iter: 5000
  timesteps_total: 2735000
  training_iteration: 547
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4770 s, 547 iter, 2735000 ts, 355 rew

agent-1: 101.59999992579714
agent-2: 100.59999992579709
agent-3: 97.59999992579709
agent-4: 97.59999992579714
agent-5: 106.59999992579709
Extrinsic Rewards:
12
11
8
8
17
Sum Reward: 56
Avg Reward: 11.2
Min Reward: 8
Max Reward: 17
Gini Coefficient: 0.15714285714285714
20:20 Ratio: 2.125
Max-min Ratio: 2.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-48-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 360.4439676157771
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 547
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.068
    dispatch_time_ms: 22.224
    learner:
      cur_lr: 0.0011778490152209997
      grad_gnorm: 35.725624084472656
      policy_entropy: 0.9676492810249329
      policy_loss: -0.04660666733980179
      var_gnorm: 22.33905792236328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.9882345199584961
    num_steps_sampled: 2740000
    num_steps_trained: 2740000
    wait_time_ms: 57.779
  iterations_since_restore: 548
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4779.29754281044
  time_this_iter_s: 8.799857139587402
  time_total_s: 4779.29754281044
  timestamp: 1594853289
  timesteps_since_restore: 2740000
  timesteps_this_iter: 5000
  timesteps_total: 2740000
  training_iteration: 548
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4779 s, 548 iter, 2740000 ts, 360 rew

agent-1: 28.199999999559378
agent-2: 29.19999999955938
agent-3: 31.19999999955938
agent-4: 31.19999999955938
agent-5: 33.199999999559274
Extrinsic Rewards:
1
2
4
4
6
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.2823529411764706
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-48-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 361.97396761575504
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 548
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.639
    dispatch_time_ms: 33.629
    learner:
      cur_lr: 0.0011775159509852529
      grad_gnorm: 5.311375617980957
      policy_entropy: 0.974658727645874
      policy_loss: -0.005689381156116724
      var_gnorm: 22.335559844970703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.021844005212187767
    num_steps_sampled: 2745000
    num_steps_trained: 2745000
    wait_time_ms: 51.91
  iterations_since_restore: 549
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4788.109862804413
  time_this_iter_s: 8.812319993972778
  time_total_s: 4788.109862804413
  timestamp: 1594853297
  timesteps_since_restore: 2745000
  timesteps_this_iter: 5000
  timesteps_total: 2745000
  training_iteration: 549
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4788 s, 549 iter, 2745000 ts, 362 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-48-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 361.9739676157551
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 549
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 28.32
    learner:
      cur_lr: 0.0011771830031648278
      grad_gnorm: 0.30325406789779663
      policy_entropy: 1.030076026916504
      policy_loss: -0.0004526985576376319
      var_gnorm: 22.335426330566406
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.111307058949023e-05
    num_steps_sampled: 2750000
    num_steps_trained: 2750000
    wait_time_ms: 57.495
  iterations_since_restore: 550
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4796.651968717575
  time_this_iter_s: 8.542105913162231
  time_total_s: 4796.651968717575
  timestamp: 1594853306
  timesteps_since_restore: 2750000
  timesteps_this_iter: 5000
  timesteps_total: 2750000
  training_iteration: 550
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4796 s, 550 iter, 2750000 ts, 362 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-48-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 361.9739676157551
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 550
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.312
    dispatch_time_ms: 27.696
    learner:
      cur_lr: 0.0011768500553444028
      grad_gnorm: 4.170835971832275
      policy_entropy: 1.8908882141113281
      policy_loss: -0.0029431660659611225
      var_gnorm: 22.334135055541992
      vf_explained_var: 0.0
      vf_loss: 0.01346830278635025
    num_steps_sampled: 2755000
    num_steps_trained: 2755000
    wait_time_ms: 55.83
  iterations_since_restore: 551
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4805.32611489296
  time_this_iter_s: 8.674146175384521
  time_total_s: 4805.32611489296
  timestamp: 1594853315
  timesteps_since_restore: 2755000
  timesteps_this_iter: 5000
  timesteps_total: 2755000
  training_iteration: 551
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4805 s, 551 iter, 2755000 ts, 362 rew

agent-1: 20.345937249783045
agent-2: 16.345937249783052
agent-3: 25.345937249783056
agent-4: 16.345937249783052
agent-5: 17.345937249783052
Extrinsic Rewards:
4
0
9
0
1
Sum Reward: 14
Avg Reward: 2.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.6285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-48-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 362.93126447824426
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 551
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.92
    dispatch_time_ms: 42.896
    learner:
      cur_lr: 0.001176516991108656
      grad_gnorm: 39.999996185302734
      policy_entropy: 34.57949447631836
      policy_loss: 43.394474029541016
      var_gnorm: 22.33693504333496
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 33.782508850097656
    num_steps_sampled: 2760000
    num_steps_trained: 2760000
    wait_time_ms: 50.029
  iterations_since_restore: 552
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4814.134205818176
  time_this_iter_s: 8.808090925216675
  time_total_s: 4814.134205818176
  timestamp: 1594853324
  timesteps_since_restore: 2760000
  timesteps_this_iter: 5000
  timesteps_total: 2760000
  training_iteration: 552
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4814 s, 552 iter, 2760000 ts, 363 rew

agent-1: 74.80534405806652
agent-2: 73.8053440580665
agent-3: 76.8053440580665
agent-4: 66.80534405806644
agent-5: 66.80534405806644
Extrinsic Rewards:
11
10
13
3
3
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.28
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-48-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 366.5215316811476
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 552
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.507
    dispatch_time_ms: 27.358
    learner:
      cur_lr: 0.001176184043288231
      grad_gnorm: 40.0
      policy_entropy: 0.43582862615585327
      policy_loss: -1.5222500562667847
      var_gnorm: 22.34351348876953
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.8418872356414795
    num_steps_sampled: 2765000
    num_steps_trained: 2765000
    wait_time_ms: 60.961
  iterations_since_restore: 553
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4823.093211889267
  time_this_iter_s: 8.959006071090698
  time_total_s: 4823.093211889267
  timestamp: 1594853333
  timesteps_since_restore: 2765000
  timesteps_this_iter: 5000
  timesteps_total: 2765000
  training_iteration: 553
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4823 s, 553 iter, 2765000 ts, 367 rew

agent-1: 60.99999995732108
agent-2: 64.99999995732117
agent-3: 58.999999957321094
agent-4: 63.99999995732108
agent-5: 65.99999995732115
Extrinsic Rewards:
5
9
3
8
10
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.2057142857142857
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-49-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 369.6715316790137
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 553
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.976
    dispatch_time_ms: 35.74
    learner:
      cur_lr: 0.001175850979052484
      grad_gnorm: 6.458054542541504
      policy_entropy: 0.09296755492687225
      policy_loss: -0.00040150972199626267
      var_gnorm: 22.341291427612305
      vf_explained_var: 0.0
      vf_loss: 0.03230000659823418
    num_steps_sampled: 2770000
    num_steps_trained: 2770000
    wait_time_ms: 55.801
  iterations_since_restore: 554
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4832.322137355804
  time_this_iter_s: 9.228925466537476
  time_total_s: 4832.322137355804
  timestamp: 1594853342
  timesteps_since_restore: 2770000
  timesteps_this_iter: 5000
  timesteps_total: 2770000
  training_iteration: 554
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4832 s, 554 iter, 2770000 ts, 370 rew

agent-1: 39.199999998669504
agent-2: 42.199999998669504
agent-3: 36.19999999866949
agent-4: 39.19999999866949
agent-5: 41.199999998669504
Extrinsic Rewards:
4
7
1
4
6
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-49-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 371.65153167894715
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 554
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.49
    dispatch_time_ms: 8.496
    learner:
      cur_lr: 0.001175518031232059
      grad_gnorm: 3.726114273071289
      policy_entropy: 0.09212047606706619
      policy_loss: -0.00020720106840599328
      var_gnorm: 22.34123992919922
      vf_explained_var: 0.0
      vf_loss: 0.010748760774731636
    num_steps_sampled: 2775000
    num_steps_trained: 2775000
    wait_time_ms: 70.83
  iterations_since_restore: 555
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4840.629373550415
  time_this_iter_s: 8.307236194610596
  time_total_s: 4840.629373550415
  timestamp: 1594853350
  timesteps_since_restore: 2775000
  timesteps_this_iter: 5000
  timesteps_total: 2775000
  training_iteration: 555
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4840 s, 555 iter, 2775000 ts, 372 rew

agent-1: 3.1999999999664004
agent-2: 3.1999999999664004
agent-3: 5.199999999966401
agent-4: 3.1999999999664004
agent-5: 3.1999999999664004
Extrinsic Rewards:
0
0
2
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-49-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 371.83153167894557
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 555
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.485
    dispatch_time_ms: 9.221
    learner:
      cur_lr: 0.0011751849669963121
      grad_gnorm: 5.3972015380859375
      policy_entropy: 0.09177732467651367
      policy_loss: -0.0002570177603047341
      var_gnorm: 22.341421127319336
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.02231341041624546
    num_steps_sampled: 2780000
    num_steps_trained: 2780000
    wait_time_ms: 72.025
  iterations_since_restore: 556
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4849.024077415466
  time_this_iter_s: 8.39470386505127
  time_total_s: 4849.024077415466
  timestamp: 1594853359
  timesteps_since_restore: 2780000
  timesteps_this_iter: 5000
  timesteps_total: 2780000
  training_iteration: 556
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4849 s, 556 iter, 2780000 ts, 372 rew

agent-1: 10.99999999991536
agent-2: 7.999999999915366
agent-3: 7.999999999915366
agent-4: 9.999999999915364
agent-5: 7.999999999915366
Extrinsic Rewards:
3
0
0
2
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-49-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 372.28153167894123
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 556
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.398
    dispatch_time_ms: 9.362
    learner:
      cur_lr: 0.001174852019175887
      grad_gnorm: 0.16640222072601318
      policy_entropy: 0.0923551470041275
      policy_loss: 1.0771025699796155e-05
      var_gnorm: 22.341196060180664
      vf_explained_var: 0.0
      vf_loss: 2.1444668163894676e-05
    num_steps_sampled: 2785000
    num_steps_trained: 2785000
    wait_time_ms: 70.363
  iterations_since_restore: 557
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4857.354447603226
  time_this_iter_s: 8.3303701877594
  time_total_s: 4857.354447603226
  timestamp: 1594853367
  timesteps_since_restore: 2785000
  timesteps_this_iter: 5000
  timesteps_total: 2785000
  training_iteration: 557
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4857 s, 557 iter, 2785000 ts, 372 rew

agent-1: 6.399999999932382
agent-2: 7.399999999932382
agent-3: 9.399999999932376
agent-4: 6.399999999932382
agent-5: 6.399999999932382
Extrinsic Rewards:
0
1
3
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.7
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-49-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 370.5715326977845
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 557
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.036
    dispatch_time_ms: 6.721
    learner:
      cur_lr: 0.0011745189549401402
      grad_gnorm: 6.924005031585693
      policy_entropy: 0.09199977666139603
      policy_loss: -0.42158231139183044
      var_gnorm: 22.341506958007812
      vf_explained_var: 0.0
      vf_loss: 0.036580510437488556
    num_steps_sampled: 2790000
    num_steps_trained: 2790000
    wait_time_ms: 73.974
  iterations_since_restore: 558
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4865.7939875125885
  time_this_iter_s: 8.439539909362793
  time_total_s: 4865.7939875125885
  timestamp: 1594853376
  timesteps_since_restore: 2790000
  timesteps_this_iter: 5000
  timesteps_total: 2790000
  training_iteration: 558
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4865 s, 558 iter, 2790000 ts, 371 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-49-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 367.15153270370496
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 558
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.654
    dispatch_time_ms: 9.841
    learner:
      cur_lr: 0.0011741860071197152
      grad_gnorm: 4.070680618286133
      policy_entropy: 0.09081196039915085
      policy_loss: -0.00021039247803855687
      var_gnorm: 22.34132194519043
      vf_explained_var: 0.0
      vf_loss: 0.012833145447075367
    num_steps_sampled: 2795000
    num_steps_trained: 2795000
    wait_time_ms: 70.784
  iterations_since_restore: 559
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4874.186365842819
  time_this_iter_s: 8.392378330230713
  time_total_s: 4874.186365842819
  timestamp: 1594853384
  timesteps_since_restore: 2795000
  timesteps_this_iter: 5000
  timesteps_total: 2795000
  training_iteration: 559
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4874 s, 559 iter, 2795000 ts, 367 rew

agent-1: 9.999999999915364
agent-2: 10.99999999991536
agent-3: 7.999999999915366
agent-4: 7.999999999915366
agent-5: 7.999999999915366
Extrinsic Rewards:
2
3
0
0
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-49-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 364.54153277774907
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 559
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.507
    dispatch_time_ms: 6.357
    learner:
      cur_lr: 0.0011738529428839684
      grad_gnorm: 11.75747299194336
      policy_entropy: 0.12305361032485962
      policy_loss: -0.0008318019099533558
      var_gnorm: 22.34076499938965
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.10691577941179276
    num_steps_sampled: 2800000
    num_steps_trained: 2800000
    wait_time_ms: 71.207
  iterations_since_restore: 560
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4882.525624990463
  time_this_iter_s: 8.339259147644043
  time_total_s: 4882.525624990463
  timestamp: 1594853392
  timesteps_since_restore: 2800000
  timesteps_this_iter: 5000
  timesteps_total: 2800000
  training_iteration: 560
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4882 s, 560 iter, 2800000 ts, 365 rew

agent-1: 16.39967762397079
agent-2: 14.399677623970762
agent-3: 18.399677623970796
agent-4: 17.39967762397079
agent-5: 14.399677623970762
Extrinsic Rewards:
2
0
4
3
0
Sum Reward: 9
Avg Reward: 1.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.4888888888888889
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-50-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 362.5615166611073
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 560
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.475
    dispatch_time_ms: 7.605
    learner:
      cur_lr: 0.0011735199950635433
      grad_gnorm: 5.813313961029053
      policy_entropy: 0.13331221044063568
      policy_loss: -0.00042002522968687117
      var_gnorm: 22.340145111083984
      vf_explained_var: 0.0
      vf_loss: 0.026152489706873894
    num_steps_sampled: 2805000
    num_steps_trained: 2805000
    wait_time_ms: 73.352
  iterations_since_restore: 561
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4890.949264764786
  time_this_iter_s: 8.42363977432251
  time_total_s: 4890.949264764786
  timestamp: 1594853401
  timesteps_since_restore: 2805000
  timesteps_this_iter: 5000
  timesteps_total: 2805000
  training_iteration: 561
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4890 s, 561 iter, 2805000 ts, 363 rew

agent-1: 3.1999999999664004
agent-2: 3.1999999999664004
agent-3: 3.1999999999664004
agent-4: 3.1999999999664004
agent-5: 5.199999999966401
Extrinsic Rewards:
0
0
0
0
2
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-50-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 357.25153075429495
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 561
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.357
    dispatch_time_ms: 8.321
    learner:
      cur_lr: 0.0011731870472431183
      grad_gnorm: 6.403443336486816
      policy_entropy: 0.13290083408355713
      policy_loss: -0.0004931946168653667
      var_gnorm: 22.340272903442383
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.03153572604060173
    num_steps_sampled: 2810000
    num_steps_trained: 2810000
    wait_time_ms: 72.723
  iterations_since_restore: 562
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4899.325212717056
  time_this_iter_s: 8.375947952270508
  time_total_s: 4899.325212717056
  timestamp: 1594853409
  timesteps_since_restore: 2810000
  timesteps_this_iter: 5000
  timesteps_total: 2810000
  training_iteration: 562
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4899 s, 562 iter, 2810000 ts, 357 rew

agent-1: 11.999999999629573
agent-2: 7.9999999996295825
agent-3: 8.999999999629575
agent-4: 7.9999999996295825
agent-5: 7.9999999996295825
Extrinsic Rewards:
4
0
1
0
0
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.72
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-50-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 351.40177779927006
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 562
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 8.251
    learner:
      cur_lr: 0.0011728539830073714
      grad_gnorm: 1.0984119176864624
      policy_entropy: 0.18748612701892853
      policy_loss: -0.00016872244304977357
      var_gnorm: 22.338987350463867
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0009339380194433033
    num_steps_sampled: 2815000
    num_steps_trained: 2815000
    wait_time_ms: 75.751
  iterations_since_restore: 563
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4907.600032329559
  time_this_iter_s: 8.274819612503052
  time_total_s: 4907.600032329559
  timestamp: 1594853418
  timesteps_since_restore: 2815000
  timesteps_this_iter: 5000
  timesteps_total: 2815000
  training_iteration: 563
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4907 s, 563 iter, 2815000 ts, 351 rew

agent-1: 17.199999994583198
agent-2: 11.199999994583237
agent-3: 12.199999994583234
agent-4: 11.199999994583237
agent-5: 11.199999994583237
Extrinsic Rewards:
6
0
1
0
0
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.7428571428571429
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-50-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 348.1617778008253
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 563
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.778
    dispatch_time_ms: 6.558
    learner:
      cur_lr: 0.0011725210351869464
      grad_gnorm: 9.750161170959473
      policy_entropy: 0.18591803312301636
      policy_loss: -0.00106532359495759
      var_gnorm: 22.339313507080078
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.07362423837184906
    num_steps_sampled: 2820000
    num_steps_trained: 2820000
    wait_time_ms: 75.699
  iterations_since_restore: 564
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4915.946823120117
  time_this_iter_s: 8.346790790557861
  time_total_s: 4915.946823120117
  timestamp: 1594853426
  timesteps_since_restore: 2820000
  timesteps_this_iter: 5000
  timesteps_total: 2820000
  training_iteration: 564
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4915 s, 564 iter, 2820000 ts, 348 rew

agent-1: 5.199999999966401
agent-2: 3.1999999999664004
agent-3: 3.1999999999664004
agent-4: 3.1999999999664004
agent-5: 3.1999999999664004
Extrinsic Rewards:
2
0
0
0
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-50-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 346.09177780090073
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 564
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 8.691
    learner:
      cur_lr: 0.0011721879709511995
      grad_gnorm: 3.5618720054626465
      policy_entropy: 0.18632985651493073
      policy_loss: -0.00037522465572692454
      var_gnorm: 22.339059829711914
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.009825488552451134
    num_steps_sampled: 2825000
    num_steps_trained: 2825000
    wait_time_ms: 73.287
  iterations_since_restore: 565
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4924.340194940567
  time_this_iter_s: 8.393371820449829
  time_total_s: 4924.340194940567
  timestamp: 1594853434
  timesteps_since_restore: 2825000
  timesteps_this_iter: 5000
  timesteps_total: 2825000
  training_iteration: 565
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4924 s, 565 iter, 2825000 ts, 346 rew

agent-1: 6.399999999932382
agent-2: 8.399999999932367
agent-3: 8.399999999932367
agent-4: 6.399999999932382
agent-5: 6.399999999932382
Extrinsic Rewards:
0
2
2
0
0
Sum Reward: 4
Avg Reward: 0.8
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-50-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 344.1117778009975
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 565
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 8.118
    learner:
      cur_lr: 0.0011718550231307745
      grad_gnorm: 7.005443572998047
      policy_entropy: 0.18628016114234924
      policy_loss: -0.0008697339799255133
      var_gnorm: 22.339290618896484
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.03776400908827782
    num_steps_sampled: 2830000
    num_steps_trained: 2830000
    wait_time_ms: 72.025
  iterations_since_restore: 566
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4932.70023560524
  time_this_iter_s: 8.360040664672852
  time_total_s: 4932.70023560524
  timestamp: 1594853443
  timesteps_since_restore: 2830000
  timesteps_this_iter: 5000
  timesteps_total: 2830000
  training_iteration: 566
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4932 s, 566 iter, 2830000 ts, 344 rew

agent-1: 16.99024689048751
agent-2: 12.990246890487507
agent-3: 14.990246890487505
agent-4: 15.990246890487509
agent-5: 12.990246890487507
Extrinsic Rewards:
4
0
2
3
0
Sum Reward: 9
Avg Reward: 1.8
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.4888888888888889
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-50-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 337.0215826633584
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 566
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.575
    dispatch_time_ms: 9.529
    learner:
      cur_lr: 0.0011715219588950276
      grad_gnorm: 8.511765480041504
      policy_entropy: 0.46880650520324707
      policy_loss: -0.002508140867576003
      var_gnorm: 22.33661460876465
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.056107040494680405
    num_steps_sampled: 2835000
    num_steps_trained: 2835000
    wait_time_ms: 71.911
  iterations_since_restore: 567
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4941.143651485443
  time_this_iter_s: 8.443415880203247
  time_total_s: 4941.143651485443
  timestamp: 1594853451
  timesteps_since_restore: 2835000
  timesteps_this_iter: 5000
  timesteps_total: 2835000
  training_iteration: 567
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4941 s, 567 iter, 2835000 ts, 337 rew

agent-1: 7.999946581620292
agent-2: 7.999946581620292
agent-3: 9.999946581620282
agent-4: 7.999946581620292
agent-5: 10.999946581620282
Extrinsic Rewards:
0
0
2
0
3
Sum Reward: 5
Avg Reward: 1.0
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.64
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-51-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 333.96157999462224
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 567
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.48
    dispatch_time_ms: 8.893
    learner:
      cur_lr: 0.0011711890110746026
      grad_gnorm: 21.297388076782227
      policy_entropy: 2.2096049785614014
      policy_loss: -0.038205910474061966
      var_gnorm: 22.334251403808594
      vf_explained_var: 0.0
      vf_loss: 0.3505922257900238
    num_steps_sampled: 2840000
    num_steps_trained: 2840000
    wait_time_ms: 72.055
  iterations_since_restore: 568
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4949.46194934845
  time_this_iter_s: 8.318297863006592
  time_total_s: 4949.46194934845
  timestamp: 1594853460
  timesteps_since_restore: 2840000
  timesteps_this_iter: 5000
  timesteps_total: 2840000
  training_iteration: 568
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4949 s, 568 iter, 2840000 ts, 334 rew

agent-1: 34.733898944497405
agent-2: 32.733898944497405
agent-3: 30.73389894449741
agent-4: 28.733898944497415
agent-5: 32.73389894449742
Extrinsic Rewards:
8
6
4
2
6
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2153846153846154
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-51-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 333.84827494191745
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 568
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.127
    dispatch_time_ms: 7.216
    learner:
      cur_lr: 0.0011708559468388557
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.925152778625488
      policy_loss: -3.841330051422119
      var_gnorm: 22.346473693847656
      vf_explained_var: 0.0
      vf_loss: 4.622129917144775
    num_steps_sampled: 2845000
    num_steps_trained: 2845000
    wait_time_ms: 75.872
  iterations_since_restore: 569
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4958.024383068085
  time_this_iter_s: 8.56243371963501
  time_total_s: 4958.024383068085
  timestamp: 1594853468
  timesteps_since_restore: 2845000
  timesteps_this_iter: 5000
  timesteps_total: 2845000
  training_iteration: 569
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4958 s, 569 iter, 2845000 ts, 334 rew

agent-1: 76.19998155591081
agent-2: 91.19998155591084
agent-3: 91.19998155591084
agent-4: 79.19998155591082
agent-5: 85.19998155591084
Extrinsic Rewards:
1
16
16
4
10
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 1
Max Reward: 16
Gini Coefficient: 0.3574468085106383
20:20 Ratio: 16.0
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-51-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 335.5582740199459
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 569
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 10.908
    learner:
      cur_lr: 0.0011705229990184307
      grad_gnorm: 14.153136253356934
      policy_entropy: 20.918163299560547
      policy_loss: -1.246262788772583
      var_gnorm: 22.329748153686523
      vf_explained_var: 0.0
      vf_loss: 0.15449322760105133
    num_steps_sampled: 2850000
    num_steps_trained: 2850000
    wait_time_ms: 72.902
  iterations_since_restore: 570
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4966.659632444382
  time_this_iter_s: 8.635249376296997
  time_total_s: 4966.659632444382
  timestamp: 1594853477
  timesteps_since_restore: 2850000
  timesteps_this_iter: 5000
  timesteps_total: 2850000
  training_iteration: 570
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4966 s, 570 iter, 2850000 ts, 336 rew

agent-1: 45.599999997847114
agent-2: 43.59999999784713
agent-3: 59.5999999978471
agent-4: 42.59999999784713
agent-5: 42.59999999784713
Extrinsic Rewards:
4
2
18
1
1
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 18
Gini Coefficient: 0.5692307692307692
20:20 Ratio: 18.0
Max-min Ratio: 18.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-51-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 328.77348810042173
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 570
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 8.796
    learner:
      cur_lr: 0.0011701900511980057
      grad_gnorm: 16.88570213317871
      policy_entropy: 34.335426330566406
      policy_loss: -3.389909267425537
      var_gnorm: 22.329442977905273
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.21851025521755219
    num_steps_sampled: 2855000
    num_steps_trained: 2855000
    wait_time_ms: 73.255
  iterations_since_restore: 571
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4975.306183576584
  time_this_iter_s: 8.646551132202148
  time_total_s: 4975.306183576584
  timestamp: 1594853486
  timesteps_since_restore: 2855000
  timesteps_this_iter: 5000
  timesteps_total: 2855000
  training_iteration: 571
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4975 s, 571 iter, 2855000 ts, 329 rew

agent-1: 42.999999999112255
agent-2: 43.999999999112255
agent-3: 41.99999999911225
agent-4: 46.99999999911226
agent-5: 48.99999999911227
Extrinsic Rewards:
3
4
2
7
9
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.288
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-51-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 328.14348810166683
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 571
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.835
    dispatch_time_ms: 7.0
    learner:
      cur_lr: 0.0011698569869622588
      grad_gnorm: 15.281575202941895
      policy_entropy: 32.3502197265625
      policy_loss: -2.4653353691101074
      var_gnorm: 22.32962417602539
      vf_explained_var: 0.0
      vf_loss: 0.18081040680408478
    num_steps_sampled: 2860000
    num_steps_trained: 2860000
    wait_time_ms: 77.812
  iterations_since_restore: 572
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4983.938526630402
  time_this_iter_s: 8.632343053817749
  time_total_s: 4983.938526630402
  timestamp: 1594853494
  timesteps_since_restore: 2860000
  timesteps_this_iter: 5000
  timesteps_total: 2860000
  training_iteration: 572
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4983 s, 572 iter, 2860000 ts, 328 rew

agent-1: 53.99999999463354
agent-2: 53.99999999463354
agent-3: 51.99999999463354
agent-4: 55.99999999463354
agent-5: 53.99999999463354
Extrinsic Rewards:
6
6
4
8
6
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 4
Max Reward: 8
Gini Coefficient: 0.10666666666666667
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-51-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 329.2234881014341
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 572
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.498
    dispatch_time_ms: 6.329
    learner:
      cur_lr: 0.0011695240391418338
      grad_gnorm: 24.07049560546875
      policy_entropy: 34.553855895996094
      policy_loss: -3.929170846939087
      var_gnorm: 22.330949783325195
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.36231470108032227
    num_steps_sampled: 2865000
    num_steps_trained: 2865000
    wait_time_ms: 76.36
  iterations_since_restore: 573
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 4992.475690603256
  time_this_iter_s: 8.537163972854614
  time_total_s: 4992.475690603256
  timestamp: 1594853503
  timesteps_since_restore: 2865000
  timesteps_this_iter: 5000
  timesteps_total: 2865000
  training_iteration: 573
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 4992 s, 573 iter, 2865000 ts, 329 rew

agent-1: 51.99999996108758
agent-2: 56.99999996108758
agent-3: 57.99999996108758
agent-4: 51.99999996108757
agent-5: 50.99999996108757
Extrinsic Rewards:
4
9
10
4
3
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.25333333333333335
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-51-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 330.21348809956197
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 573
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.949
    dispatch_time_ms: 9.773
    learner:
      cur_lr: 0.001169190974906087
      grad_gnorm: 12.615853309631348
      policy_entropy: 28.869033813476562
      policy_loss: -0.8359116911888123
      var_gnorm: 22.33014678955078
      vf_explained_var: 0.0
      vf_loss: 0.11663208156824112
    num_steps_sampled: 2870000
    num_steps_trained: 2870000
    wait_time_ms: 72.485
  iterations_since_restore: 574
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5000.973551988602
  time_this_iter_s: 8.497861385345459
  time_total_s: 5000.973551988602
  timestamp: 1594853511
  timesteps_since_restore: 2870000
  timesteps_this_iter: 5000
  timesteps_total: 2870000
  training_iteration: 574
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5000 s, 574 iter, 2870000 ts, 330 rew

agent-1: 59.79999997893109
agent-2: 59.799999978931076
agent-3: 56.7999999789311
agent-4: 52.79999997893109
agent-5: 67.79999997893098
Extrinsic Rewards:
7
7
4
0
15
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 0
Max Reward: 15
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-52-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 331.20348809855
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 574
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.37
    dispatch_time_ms: 9.307
    learner:
      cur_lr: 0.0011688580270856619
      grad_gnorm: 40.0
      policy_entropy: 34.20753479003906
      policy_loss: -13.609474182128906
      var_gnorm: 22.341949462890625
      vf_explained_var: 0.0
      vf_loss: 4.011688232421875
    num_steps_sampled: 2875000
    num_steps_trained: 2875000
    wait_time_ms: 74.59
  iterations_since_restore: 575
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5009.864303827286
  time_this_iter_s: 8.890751838684082
  time_total_s: 5009.864303827286
  timestamp: 1594853520
  timesteps_since_restore: 2875000
  timesteps_this_iter: 5000
  timesteps_total: 2875000
  training_iteration: 575
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5009 s, 575 iter, 2875000 ts, 331 rew

agent-1: 120.39987505843382
agent-2: 111.39987505843386
agent-3: 122.39987505843388
agent-4: 111.39987505843385
agent-5: 110.39987505843389
Extrinsic Rewards:
18
9
20
9
8
Sum Reward: 64
Avg Reward: 12.8
Min Reward: 8
Max Reward: 20
Gini Coefficient: 0.20625
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-52-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 331.4734846762666
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 575
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 5.749
    learner:
      cur_lr: 0.001168524962849915
      grad_gnorm: 12.89747142791748
      policy_entropy: 3.9775922298431396
      policy_loss: -0.04218197241425514
      var_gnorm: 22.331825256347656
      vf_explained_var: 0.0
      vf_loss: 0.12863154709339142
    num_steps_sampled: 2880000
    num_steps_trained: 2880000
    wait_time_ms: 81.638
  iterations_since_restore: 576
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5018.59034204483
  time_this_iter_s: 8.726038217544556
  time_total_s: 5018.59034204483
  timestamp: 1594853529
  timesteps_since_restore: 2880000
  timesteps_this_iter: 5000
  timesteps_total: 2880000
  training_iteration: 576
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5018 s, 576 iter, 2880000 ts, 331 rew

agent-1: 46.59999999608627
agent-2: 48.59999999608627
agent-3: 48.59999999608627
agent-4: 41.59999999608627
agent-5: 48.59999999608627
Extrinsic Rewards:
5
7
7
0
7
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.24615384615384617
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-52-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 331.293484685453
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 576
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 10.661
    learner:
      cur_lr: 0.00116819201502949
      grad_gnorm: 37.44583511352539
      policy_entropy: 34.546180725097656
      policy_loss: -8.749624252319336
      var_gnorm: 22.332351684570312
      vf_explained_var: 0.0
      vf_loss: 1.0847415924072266
    num_steps_sampled: 2885000
    num_steps_trained: 2885000
    wait_time_ms: 73.727
  iterations_since_restore: 577
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5027.132665634155
  time_this_iter_s: 8.542323589324951
  time_total_s: 5027.132665634155
  timestamp: 1594853538
  timesteps_since_restore: 2885000
  timesteps_this_iter: 5000
  timesteps_total: 2885000
  training_iteration: 577
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5027 s, 577 iter, 2885000 ts, 331 rew

agent-1: 72.79999395043315
agent-2: 76.79999395043315
agent-3: 83.79999395043312
agent-4: 84.7999939504331
agent-5: 68.79999395043313
Extrinsic Rewards:
4
8
15
16
0
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 0
Max Reward: 16
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-52-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 329.2247077798513
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 577
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 7.619
    learner:
      cur_lr: 0.0011678589507937431
      grad_gnorm: 40.0
      policy_entropy: 31.805072784423828
      policy_loss: 72.29342651367188
      var_gnorm: 22.331205368041992
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 152.0674285888672
    num_steps_sampled: 2890000
    num_steps_trained: 2890000
    wait_time_ms: 72.1
  iterations_since_restore: 578
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5035.5989818573
  time_this_iter_s: 8.466316223144531
  time_total_s: 5035.5989818573
  timestamp: 1594853546
  timesteps_since_restore: 2890000
  timesteps_this_iter: 5000
  timesteps_total: 2890000
  training_iteration: 578
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5035 s, 578 iter, 2890000 ts, 329 rew

agent-1: 36.1999999986921
agent-2: 35.1999999986921
agent-3: 44.19999999869208
agent-4: 39.19999999869209
agent-5: 43.19999999869209
Extrinsic Rewards:
1
0
9
4
8
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.45454545454545453
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-52-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.4066560269878
  episode_reward_mean: 325.6247091622024
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 578
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 5.725
    learner:
      cur_lr: 0.001167526002973318
      grad_gnorm: 40.0
      policy_entropy: 24.991634368896484
      policy_loss: 34.47172164916992
      var_gnorm: 22.356704711914062
      vf_explained_var: 0.0
      vf_loss: 106.33543395996094
    num_steps_sampled: 2895000
    num_steps_trained: 2895000
    wait_time_ms: 75.995
  iterations_since_restore: 579
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5044.058753967285
  time_this_iter_s: 8.459772109985352
  time_total_s: 5044.058753967285
  timestamp: 1594853555
  timesteps_since_restore: 2895000
  timesteps_this_iter: 5000
  timesteps_total: 2895000
  training_iteration: 579
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5044 s, 579 iter, 2895000 ts, 326 rew

agent-1: 200.39530310709185
agent-2: 202.39530310709188
agent-3: 221.3953031070919
agent-4: 211.39530310709188
agent-5: 235.3953031070918
Extrinsic Rewards:
10
12
31
21
45
Sum Reward: 119
Avg Reward: 23.8
Min Reward: 10
Max Reward: 45
Gini Coefficient: 0.2991596638655462
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-52-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 332.46447437557225
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 579
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.651
    dispatch_time_ms: 8.092
    learner:
      cur_lr: 0.001167193055152893
      grad_gnorm: 40.0
      policy_entropy: 24.877622604370117
      policy_loss: -7.813456058502197
      var_gnorm: 22.34488868713379
      vf_explained_var: 0.0
      vf_loss: 4.804214000701904
    num_steps_sampled: 2900000
    num_steps_trained: 2900000
    wait_time_ms: 75.103
  iterations_since_restore: 580
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5052.602369785309
  time_this_iter_s: 8.543615818023682
  time_total_s: 5052.602369785309
  timestamp: 1594853563
  timesteps_since_restore: 2900000
  timesteps_this_iter: 5000
  timesteps_total: 2900000
  training_iteration: 580
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5052 s, 580 iter, 2900000 ts, 332 rew

agent-1: 140.59999407316081
agent-2: 138.59999407316081
agent-3: 130.59999407316067
agent-4: 139.5999940731608
agent-5: 134.59999407316081
Extrinsic Rewards:
19
17
9
18
13
Sum Reward: 76
Avg Reward: 15.2
Min Reward: 9
Max Reward: 19
Gini Coefficient: 0.13157894736842105
20:20 Ratio: 2.111111111111111
Max-min Ratio: 2.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-52-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 333.09447410765364
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 580
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.014
    dispatch_time_ms: 7.193
    learner:
      cur_lr: 0.0011668599909171462
      grad_gnorm: 31.244407653808594
      policy_entropy: 6.137042045593262
      policy_loss: -1.501153826713562
      var_gnorm: 22.333694458007812
      vf_explained_var: 0.0
      vf_loss: 0.7541491985321045
    num_steps_sampled: 2905000
    num_steps_trained: 2905000
    wait_time_ms: 75.982
  iterations_since_restore: 581
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5061.089962244034
  time_this_iter_s: 8.487592458724976
  time_total_s: 5061.089962244034
  timestamp: 1594853572
  timesteps_since_restore: 2905000
  timesteps_this_iter: 5000
  timesteps_total: 2905000
  training_iteration: 581
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5061 s, 581 iter, 2905000 ts, 333 rew

agent-1: 54.79999999491671
agent-2: 52.799999994916696
agent-3: 44.79999999491669
agent-4: 46.79999999491669
agent-5: 52.79999999491669
Extrinsic Rewards:
10
8
0
2
8
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.37142857142857144
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-53-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 331.7444741446533
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 581
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 8.154
    learner:
      cur_lr: 0.0011665270430967212
      grad_gnorm: 40.0
      policy_entropy: 5.742264270782471
      policy_loss: 4.620728492736816
      var_gnorm: 22.332380294799805
      vf_explained_var: 0.0
      vf_loss: 8.000568389892578
    num_steps_sampled: 2910000
    num_steps_trained: 2910000
    wait_time_ms: 71.842
  iterations_since_restore: 582
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5069.573895454407
  time_this_iter_s: 8.483933210372925
  time_total_s: 5069.573895454407
  timestamp: 1594853580
  timesteps_since_restore: 2910000
  timesteps_this_iter: 5000
  timesteps_total: 2910000
  training_iteration: 582
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5069 s, 582 iter, 2910000 ts, 332 rew

agent-1: 58.199999996282706
agent-2: 56.199999996282706
agent-3: 54.199999996282706
agent-4: 57.19999999628272
agent-5: 62.199999996282706
Extrinsic Rewards:
7
5
3
6
11
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.225
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-53-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 332.46447414456486
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 582
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.92
    dispatch_time_ms: 9.221
    learner:
      cur_lr: 0.0011661939788609743
      grad_gnorm: 40.0
      policy_entropy: 30.30078887939453
      policy_loss: 55.48996353149414
      var_gnorm: 22.34480094909668
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 89.88553619384766
    num_steps_sampled: 2915000
    num_steps_trained: 2915000
    wait_time_ms: 69.464
  iterations_since_restore: 583
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5077.981205940247
  time_this_iter_s: 8.407310485839844
  time_total_s: 5077.981205940247
  timestamp: 1594853589
  timesteps_since_restore: 2915000
  timesteps_this_iter: 5000
  timesteps_total: 2915000
  training_iteration: 583
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5077 s, 583 iter, 2915000 ts, 332 rew

agent-1: 125.799943856301
agent-2: 114.799943856301
agent-3: 131.79994385630093
agent-4: 117.79994385630103
agent-5: 121.799943856301
Extrinsic Rewards:
17
6
23
9
13
Sum Reward: 68
Avg Reward: 13.6
Min Reward: 6
Max Reward: 23
Gini Coefficient: 0.24705882352941178
20:20 Ratio: 3.8333333333333335
Max-min Ratio: 3.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-53-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 331.1144724285847
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 583
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.979
    dispatch_time_ms: 6.804
    learner:
      cur_lr: 0.0011658610310405493
      grad_gnorm: 39.999996185302734
      policy_entropy: 31.617319107055664
      policy_loss: 43.800662994384766
      var_gnorm: 22.336950302124023
      vf_explained_var: 0.0
      vf_loss: 54.90581130981445
    num_steps_sampled: 2920000
    num_steps_trained: 2920000
    wait_time_ms: 76.071
  iterations_since_restore: 584
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5086.414793014526
  time_this_iter_s: 8.433587074279785
  time_total_s: 5086.414793014526
  timestamp: 1594853597
  timesteps_since_restore: 2920000
  timesteps_this_iter: 5000
  timesteps_total: 2920000
  training_iteration: 584
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5086 s, 584 iter, 2920000 ts, 331 rew

agent-1: 144.9999576278449
agent-2: 145.999957627845
agent-3: 141.999957627845
agent-4: 151.99995762784488
agent-5: 134.99995762784508
Extrinsic Rewards:
17
18
14
24
7
Sum Reward: 80
Avg Reward: 16.0
Min Reward: 7
Max Reward: 24
Gini Coefficient: 0.19
20:20 Ratio: 3.4285714285714284
Max-min Ratio: 3.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-53-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 334.44447031552517
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 584
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.309
    dispatch_time_ms: 11.514
    learner:
      cur_lr: 0.0011655279668048024
      grad_gnorm: 25.237367630004883
      policy_entropy: 24.767650604248047
      policy_loss: -3.9142708778381348
      var_gnorm: 22.33413314819336
      vf_explained_var: 0.0
      vf_loss: 0.47000062465667725
    num_steps_sampled: 2925000
    num_steps_trained: 2925000
    wait_time_ms: 72.195
  iterations_since_restore: 585
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5094.8389184474945
  time_this_iter_s: 8.42412543296814
  time_total_s: 5094.8389184474945
  timestamp: 1594853606
  timesteps_since_restore: 2925000
  timesteps_this_iter: 5000
  timesteps_total: 2925000
  training_iteration: 585
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5094 s, 585 iter, 2925000 ts, 334 rew

agent-1: 69.59999986604284
agent-2: 68.59999986604281
agent-3: 77.59999986604278
agent-4: 76.59999986604278
agent-5: 76.59999986604281
Extrinsic Rewards:
4
3
12
11
11
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.24390243902439024
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-53-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 336.1544703088946
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 585
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.236
    dispatch_time_ms: 8.285
    learner:
      cur_lr: 0.0011651950189843774
      grad_gnorm: 40.0
      policy_entropy: 15.272647857666016
      policy_loss: 11.786165237426758
      var_gnorm: 22.33481788635254
      vf_explained_var: 0.0
      vf_loss: 13.03515625
    num_steps_sampled: 2930000
    num_steps_trained: 2930000
    wait_time_ms: 78.09
  iterations_since_restore: 586
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5103.3059368133545
  time_this_iter_s: 8.467018365859985
  time_total_s: 5103.3059368133545
  timestamp: 1594853614
  timesteps_since_restore: 2930000
  timesteps_this_iter: 5000
  timesteps_total: 2930000
  training_iteration: 586
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5103 s, 586 iter, 2930000 ts, 336 rew

agent-1: 27.19999999942428
agent-2: 30.19999999942427
agent-3: 33.19999999942432
agent-4: 30.19999999942427
agent-5: 32.19999999942433
Extrinsic Rewards:
0
3
6
3
5
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.32941176470588235
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-53-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 334.35447030945704
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 586
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.874
    dispatch_time_ms: 8.866
    learner:
      cur_lr: 0.0011648619547486305
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.14736270904541
      policy_loss: 0.6680000424385071
      var_gnorm: 22.33556365966797
      vf_explained_var: 0.0
      vf_loss: 2.7830581665039062
    num_steps_sampled: 2935000
    num_steps_trained: 2935000
    wait_time_ms: 75.885
  iterations_since_restore: 587
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5111.869631052017
  time_this_iter_s: 8.56369423866272
  time_total_s: 5111.869631052017
  timestamp: 1594853623
  timesteps_since_restore: 2935000
  timesteps_this_iter: 5000
  timesteps_total: 2935000
  training_iteration: 587
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5111 s, 587 iter, 2935000 ts, 334 rew

agent-1: 78.7999998598507
agent-2: 77.79999985985069
agent-3: 74.79999985985069
agent-4: 79.7999998598507
agent-5: 75.79999985985069
Extrinsic Rewards:
10
9
6
11
7
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 6
Max Reward: 11
Gini Coefficient: 0.12093023255813953
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-53-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 332.46447204954694
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 587
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.773
    dispatch_time_ms: 7.81
    learner:
      cur_lr: 0.0011645290069282055
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.33063316345215
      policy_loss: 8.465879440307617
      var_gnorm: 22.33949089050293
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.816242218017578
    num_steps_sampled: 2940000
    num_steps_trained: 2940000
    wait_time_ms: 76.134
  iterations_since_restore: 588
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5120.544905900955
  time_this_iter_s: 8.675274848937988
  time_total_s: 5120.544905900955
  timestamp: 1594853631
  timesteps_since_restore: 2940000
  timesteps_this_iter: 5000
  timesteps_total: 2940000
  training_iteration: 588
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5120 s, 588 iter, 2940000 ts, 332 rew

agent-1: 179.36448556179622
agent-2: 184.36448556179627
agent-3: 166.3644855617964
agent-4: 183.3644855617963
agent-5: 177.3644855617964
Extrinsic Rewards:
21
26
8
25
19
Sum Reward: 99
Avg Reward: 19.8
Min Reward: 8
Max Reward: 26
Gini Coefficient: 0.1696969696969697
20:20 Ratio: 3.25
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-54-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 332.2426880544816
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 588
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.448
    dispatch_time_ms: 8.958
    learner:
      cur_lr: 0.0011641959426924586
      grad_gnorm: 40.000003814697266
      policy_entropy: 34.229862213134766
      policy_loss: -14.038785934448242
      var_gnorm: 22.345943450927734
      vf_explained_var: 0.0
      vf_loss: 4.819278717041016
    num_steps_sampled: 2945000
    num_steps_trained: 2945000
    wait_time_ms: 73.251
  iterations_since_restore: 589
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5129.1906015872955
  time_this_iter_s: 8.645695686340332
  time_total_s: 5129.1906015872955
  timestamp: 1594853640
  timesteps_since_restore: 2945000
  timesteps_this_iter: 5000
  timesteps_total: 2945000
  training_iteration: 589
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5129 s, 589 iter, 2945000 ts, 332 rew

agent-1: 119.9999910670121
agent-2: 119.99999106701209
agent-3: 117.9999910670121
agent-4: 112.99999106701213
agent-5: 113.99999106701212
Extrinsic Rewards:
16
16
14
9
10
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 9
Max Reward: 16
Gini Coefficient: 0.12307692307692308
20:20 Ratio: 1.7777777777777777
Max-min Ratio: 1.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-54-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 334.312687621163
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 589
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.013
    dispatch_time_ms: 5.379
    learner:
      cur_lr: 0.0011638629948720336
      grad_gnorm: 40.0
      policy_entropy: 4.770608425140381
      policy_loss: 0.4283236265182495
      var_gnorm: 22.336345672607422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.11372184753418
    num_steps_sampled: 2950000
    num_steps_trained: 2950000
    wait_time_ms: 75.006
  iterations_since_restore: 590
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5137.760825395584
  time_this_iter_s: 8.570223808288574
  time_total_s: 5137.760825395584
  timestamp: 1594853649
  timesteps_since_restore: 2950000
  timesteps_this_iter: 5000
  timesteps_total: 2950000
  training_iteration: 590
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5137 s, 590 iter, 2950000 ts, 334 rew

agent-1: 50.599999995772045
agent-2: 49.599999995772045
agent-3: 52.599999995772045
agent-4: 61.59999999577206
agent-5: 64.59999999577194
Extrinsic Rewards:
1
0
3
12
15
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 0
Max Reward: 15
Gini Coefficient: 0.5290322580645161
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-54-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 335.6626876209714
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 590
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.644
    dispatch_time_ms: 8.761
    learner:
      cur_lr: 0.0011635300470516086
      grad_gnorm: 39.999996185302734
      policy_entropy: 11.404584884643555
      policy_loss: 9.980727195739746
      var_gnorm: 22.34506607055664
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 20.66293716430664
    num_steps_sampled: 2955000
    num_steps_trained: 2955000
    wait_time_ms: 73.342
  iterations_since_restore: 591
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5146.280913352966
  time_this_iter_s: 8.520087957382202
  time_total_s: 5146.280913352966
  timestamp: 1594853657
  timesteps_since_restore: 2955000
  timesteps_this_iter: 5000
  timesteps_total: 2955000
  training_iteration: 591
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5146 s, 591 iter, 2955000 ts, 336 rew

agent-1: 134.23958735350828
agent-2: 153.23958735350823
agent-3: 146.23958735350817
agent-4: 137.23958735350828
agent-5: 139.23958735350823
Extrinsic Rewards:
8
27
20
11
13
Sum Reward: 79
Avg Reward: 15.8
Min Reward: 8
Max Reward: 27
Gini Coefficient: 0.2379746835443038
20:20 Ratio: 3.375
Max-min Ratio: 3.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-54-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 340.87466698869133
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 591
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.81
    dispatch_time_ms: 7.712
    learner:
      cur_lr: 0.0011631969828158617
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.20445442199707
      policy_loss: -9.47650146484375
      var_gnorm: 22.34745979309082
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.1177592277526855
    num_steps_sampled: 2960000
    num_steps_trained: 2960000
    wait_time_ms: 76.507
  iterations_since_restore: 592
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5154.895045995712
  time_this_iter_s: 8.614132642745972
  time_total_s: 5154.895045995712
  timestamp: 1594853666
  timesteps_since_restore: 2960000
  timesteps_this_iter: 5000
  timesteps_total: 2960000
  training_iteration: 592
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5154 s, 592 iter, 2960000 ts, 341 rew

agent-1: 100.19999556532524
agent-2: 88.19999556532528
agent-3: 95.19999556532525
agent-4: 94.19999556532524
agent-5: 90.19999556532528
Extrinsic Rewards:
17
5
12
11
7
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 5
Max Reward: 17
Gini Coefficient: 0.2230769230769231
20:20 Ratio: 3.4
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-54-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 342.40466677461745
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 592
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.102
    dispatch_time_ms: 10.573
    learner:
      cur_lr: 0.0011628640349954367
      grad_gnorm: 23.55341911315918
      policy_entropy: 26.346933364868164
      policy_loss: -2.9594337940216064
      var_gnorm: 22.34600257873535
      vf_explained_var: 0.0
      vf_loss: 0.4186237156391144
    num_steps_sampled: 2965000
    num_steps_trained: 2965000
    wait_time_ms: 73.545
  iterations_since_restore: 593
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5163.517945051193
  time_this_iter_s: 8.622899055480957
  time_total_s: 5163.517945051193
  timestamp: 1594853675
  timesteps_since_restore: 2965000
  timesteps_this_iter: 5000
  timesteps_total: 2965000
  training_iteration: 593
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5163 s, 593 iter, 2965000 ts, 342 rew

agent-1: 37.19999999905897
agent-2: 46.199999999058996
agent-3: 37.19999999905897
agent-4: 42.19999999905899
agent-5: 35.19999999905898
Extrinsic Rewards:
2
11
2
7
0
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.4909090909090909
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-54-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 341.59466677515564
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 593
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.892
    dispatch_time_ms: 8.85
    learner:
      cur_lr: 0.0011625309707596898
      grad_gnorm: 40.0
      policy_entropy: 8.497014999389648
      policy_loss: 0.7931389212608337
      var_gnorm: 22.712440490722656
      vf_explained_var: 0.0
      vf_loss: 4.742447853088379
    num_steps_sampled: 2970000
    num_steps_trained: 2970000
    wait_time_ms: 71.319
  iterations_since_restore: 594
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5172.125834226608
  time_this_iter_s: 8.607889175415039
  time_total_s: 5172.125834226608
  timestamp: 1594853683
  timesteps_since_restore: 2970000
  timesteps_this_iter: 5000
  timesteps_total: 2970000
  training_iteration: 594
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.5/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5172 s, 594 iter, 2970000 ts, 342 rew

agent-1: 36.79999999829095
agent-2: 39.799999998290964
agent-3: 48.799999998290964
agent-4: 44.79999999829096
agent-5: 36.79999999829095
Extrinsic Rewards:
0
3
12
8
0
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.5565217391304348
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-54-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 339.2546667778833
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 594
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.647
    dispatch_time_ms: 8.646
    learner:
      cur_lr: 0.0011621980229392648
      grad_gnorm: 6.170012950897217
      policy_entropy: 53.84645462036133
      policy_loss: 1.6850208044052124
      var_gnorm: 22.721040725708008
      vf_explained_var: 0.0
      vf_loss: 0.03909953683614731
    num_steps_sampled: 2975000
    num_steps_trained: 2975000
    wait_time_ms: 76.108
  iterations_since_restore: 595
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5180.7399826049805
  time_this_iter_s: 8.614148378372192
  time_total_s: 5180.7399826049805
  timestamp: 1594853692
  timesteps_since_restore: 2975000
  timesteps_this_iter: 5000
  timesteps_total: 2975000
  training_iteration: 595
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5180 s, 595 iter, 2975000 ts, 339 rew

agent-1: 106.99872864312967
agent-2: 117.99872864312967
agent-3: 117.99872864312967
agent-4: 117.99872864312967
agent-5: 123.99872864312967
Extrinsic Rewards:
3
14
14
14
20
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 3
Max Reward: 20
Gini Coefficient: 0.20923076923076922
20:20 Ratio: 6.666666666666667
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-55-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 343.3946032100923
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 595
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 5.638
    learner:
      cur_lr: 0.001161864958703518
      grad_gnorm: 40.0
      policy_entropy: 32.97245407104492
      policy_loss: 64.20634460449219
      var_gnorm: 22.66487693786621
      vf_explained_var: 0.0
      vf_loss: 88.04119110107422
    num_steps_sampled: 2980000
    num_steps_trained: 2980000
    wait_time_ms: 77.115
  iterations_since_restore: 596
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5189.34246301651
  time_this_iter_s: 8.602480411529541
  time_total_s: 5189.34246301651
  timestamp: 1594853701
  timesteps_since_restore: 2980000
  timesteps_this_iter: 5000
  timesteps_total: 2980000
  training_iteration: 596
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5189 s, 596 iter, 2980000 ts, 343 rew

agent-1: 54.99999999265615
agent-2: 59.99999999265616
agent-3: 55.99999999265614
agent-4: 50.99999999265612
agent-5: 47.99999999265612
Extrinsic Rewards:
7
12
8
3
0
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.38666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-55-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 342.9446032100511
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 596
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 6.479
    learner:
      cur_lr: 0.0011615320108830929
      grad_gnorm: 18.19314193725586
      policy_entropy: 47.10742950439453
      policy_loss: -4.090323448181152
      var_gnorm: 22.673259735107422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.2526353895664215
    num_steps_sampled: 2985000
    num_steps_trained: 2985000
    wait_time_ms: 76.611
  iterations_since_restore: 597
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5198.014025688171
  time_this_iter_s: 8.671562671661377
  time_total_s: 5198.014025688171
  timestamp: 1594853709
  timesteps_since_restore: 2985000
  timesteps_this_iter: 5000
  timesteps_total: 2985000
  training_iteration: 597
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5198 s, 597 iter, 2985000 ts, 343 rew

agent-1: 90.59999986783285
agent-2: 77.59999986783285
agent-3: 82.59999986783284
agent-4: 82.59999986783284
agent-5: 80.59999986783285
Extrinsic Rewards:
17
4
9
9
7
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 4
Max Reward: 17
Gini Coefficient: 0.24347826086956523
20:20 Ratio: 4.25
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-55-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 342.94460320548023
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 597
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.661
    dispatch_time_ms: 6.394
    learner:
      cur_lr: 0.001161198946647346
      grad_gnorm: 14.360548973083496
      policy_entropy: 64.29756164550781
      policy_loss: -3.1899466514587402
      var_gnorm: 22.691530227661133
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.1341792494058609
    num_steps_sampled: 2990000
    num_steps_trained: 2990000
    wait_time_ms: 79.782
  iterations_since_restore: 598
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5206.77894949913
  time_this_iter_s: 8.764923810958862
  time_total_s: 5206.77894949913
  timestamp: 1594853718
  timesteps_since_restore: 2990000
  timesteps_this_iter: 5000
  timesteps_total: 2990000
  training_iteration: 598
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5206 s, 598 iter, 2990000 ts, 343 rew

agent-1: 27.199999999539383
agent-2: 29.199999999539383
agent-3: 27.199999999539383
agent-4: 38.19999999953939
agent-5: 31.199999999539376
Extrinsic Rewards:
0
2
0
11
4
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.611764705882353
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-55-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 339.52460424649985
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 598
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 6.776
    learner:
      cur_lr: 0.001160865998826921
      grad_gnorm: 14.02175235748291
      policy_entropy: 55.98843002319336
      policy_loss: -4.234927654266357
      var_gnorm: 22.69191551208496
      vf_explained_var: 0.0
      vf_loss: 0.1485038697719574
    num_steps_sampled: 2995000
    num_steps_trained: 2995000
    wait_time_ms: 77.523
  iterations_since_restore: 599
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5215.437365055084
  time_this_iter_s: 8.65841555595398
  time_total_s: 5215.437365055084
  timestamp: 1594853727
  timesteps_since_restore: 2995000
  timesteps_this_iter: 5000
  timesteps_total: 2995000
  training_iteration: 599
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5215 s, 599 iter, 2995000 ts, 340 rew

agent-1: 38.399999998214234
agent-2: 40.39999999821425
agent-3: 54.39999999821424
agent-4: 40.39999999821425
agent-5: 42.399999998214255
Extrinsic Rewards:
0
2
16
2
4
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 16
Gini Coefficient: 0.5666666666666667
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-55-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 338.62460424678943
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 599
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.512
    dispatch_time_ms: 7.897
    learner:
      cur_lr: 0.001160533051006496
      grad_gnorm: 14.836089134216309
      policy_entropy: 46.347599029541016
      policy_loss: -2.753103017807007
      var_gnorm: 22.692628860473633
      vf_explained_var: 0.0
      vf_loss: 0.1693553626537323
    num_steps_sampled: 3000000
    num_steps_trained: 3000000
    wait_time_ms: 75.335
  iterations_since_restore: 600
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5224.099452257156
  time_this_iter_s: 8.662087202072144
  time_total_s: 5224.099452257156
  timestamp: 1594853735
  timesteps_since_restore: 3000000
  timesteps_this_iter: 5000
  timesteps_total: 3000000
  training_iteration: 600
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5224 s, 600 iter, 3000000 ts, 339 rew

agent-1: 26.599999998739218
agent-2: 32.59999999873932
agent-3: 29.599999998739214
agent-4: 26.59999999873922
agent-5: 28.599999998739218
Extrinsic Rewards:
1
7
4
1
3
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.375
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-55-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 338.35460424675364
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 600
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 7.76
    learner:
      cur_lr: 0.001160199986770749
      grad_gnorm: 16.91984748840332
      policy_entropy: 67.3368148803711
      policy_loss: -5.360990047454834
      var_gnorm: 22.684528350830078
      vf_explained_var: 0.0
      vf_loss: 0.20759868621826172
    num_steps_sampled: 3005000
    num_steps_trained: 3005000
    wait_time_ms: 76.414
  iterations_since_restore: 601
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5232.765167951584
  time_this_iter_s: 8.66571569442749
  time_total_s: 5232.765167951584
  timestamp: 1594853744
  timesteps_since_restore: 3005000
  timesteps_this_iter: 5000
  timesteps_total: 3005000
  training_iteration: 601
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5232 s, 601 iter, 3005000 ts, 338 rew

agent-1: 50.19999999783633
agent-2: 49.19999999783632
agent-3: 47.19999999783633
agent-4: 50.19999999783632
agent-5: 46.19999999783632
Extrinsic Rewards:
7
6
4
7
3
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.16296296296296298
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-55-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 339.1646042466699
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 601
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.145
    dispatch_time_ms: 8.496
    learner:
      cur_lr: 0.001159867038950324
      grad_gnorm: 15.082930564880371
      policy_entropy: 64.82135772705078
      policy_loss: -4.282872676849365
      var_gnorm: 22.69478988647461
      vf_explained_var: 0.0
      vf_loss: 0.16088935732841492
    num_steps_sampled: 3010000
    num_steps_trained: 3010000
    wait_time_ms: 74.54
  iterations_since_restore: 602
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5241.40465593338
  time_this_iter_s: 8.639487981796265
  time_total_s: 5241.40465593338
  timestamp: 1594853753
  timesteps_since_restore: 3010000
  timesteps_this_iter: 5000
  timesteps_total: 3010000
  training_iteration: 602
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5241 s, 602 iter, 3010000 ts, 339 rew

agent-1: 39.3999999984437
agent-2: 38.399999998443704
agent-3: 42.39999999844371
agent-4: 42.39999999844371
agent-5: 53.399999998443704
Extrinsic Rewards:
1
0
4
4
15
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 15
Gini Coefficient: 0.55
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-56-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 338.1746042471036
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 602
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.085
    dispatch_time_ms: 10.492
    learner:
      cur_lr: 0.0011595339747145772
      grad_gnorm: 13.634832382202148
      policy_entropy: 59.88302993774414
      policy_loss: -3.8681857585906982
      var_gnorm: 22.696969985961914
      vf_explained_var: 0.0
      vf_loss: 0.11874578148126602
    num_steps_sampled: 3015000
    num_steps_trained: 3015000
    wait_time_ms: 74.068
  iterations_since_restore: 603
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5250.491396188736
  time_this_iter_s: 9.086740255355835
  time_total_s: 5250.491396188736
  timestamp: 1594853762
  timesteps_since_restore: 3015000
  timesteps_this_iter: 5000
  timesteps_total: 3015000
  training_iteration: 603
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5250 s, 603 iter, 3015000 ts, 338 rew

agent-1: 34.39999999914207
agent-2: 34.39999999914207
agent-3: 39.39999999914208
agent-4: 32.39999999914208
agent-5: 30.399999999142054
Extrinsic Rewards:
4
4
9
2
0
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.42105263157894735
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-56-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 337.99460424710566
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 603
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.897
    dispatch_time_ms: 8.413
    learner:
      cur_lr: 0.0011592010268941522
      grad_gnorm: 37.320491790771484
      policy_entropy: 59.34757614135742
      policy_loss: 10.173717498779297
      var_gnorm: 22.70583152770996
      vf_explained_var: 0.0
      vf_loss: 1.0797926187515259
    num_steps_sampled: 3020000
    num_steps_trained: 3020000
    wait_time_ms: 74.8
  iterations_since_restore: 604
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5259.179329633713
  time_this_iter_s: 8.687933444976807
  time_total_s: 5259.179329633713
  timestamp: 1594853771
  timesteps_since_restore: 3020000
  timesteps_this_iter: 5000
  timesteps_total: 3020000
  training_iteration: 604
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5259 s, 604 iter, 3020000 ts, 338 rew

agent-1: 42.19999999925224
agent-2: 38.199999999252235
agent-3: 35.19999999925221
agent-4: 35.19999999925221
agent-5: 47.19999999925222
Extrinsic Rewards:
7
3
0
0
12
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.5636363636363636
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-56-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 336.91460424756406
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 604
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 8.642
    learner:
      cur_lr: 0.0011588679626584053
      grad_gnorm: 11.656503677368164
      policy_entropy: 37.90214157104492
      policy_loss: -2.022815704345703
      var_gnorm: 22.69969940185547
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.10105828940868378
    num_steps_sampled: 3025000
    num_steps_trained: 3025000
    wait_time_ms: 75.991
  iterations_since_restore: 605
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5267.829034805298
  time_this_iter_s: 8.649705171585083
  time_total_s: 5267.829034805298
  timestamp: 1594853779
  timesteps_since_restore: 3025000
  timesteps_this_iter: 5000
  timesteps_total: 3025000
  training_iteration: 605
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5267 s, 605 iter, 3025000 ts, 337 rew

agent-1: 54.99999999718977
agent-2: 48.999999997189754
agent-3: 53.99999999718977
agent-4: 54.999999997189754
agent-5: 56.99999999718977
Extrinsic Rewards:
7
1
6
7
9
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.22666666666666666
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-56-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 332.50460506353323
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 605
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.717
    dispatch_time_ms: 7.387
    learner:
      cur_lr: 0.0011585350148379803
      grad_gnorm: 40.0
      policy_entropy: 35.476993560791016
      policy_loss: 60.46684646606445
      var_gnorm: 22.698047637939453
      vf_explained_var: 0.0
      vf_loss: 113.51245880126953
    num_steps_sampled: 3030000
    num_steps_trained: 3030000
    wait_time_ms: 74.547
  iterations_since_restore: 606
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5276.492105007172
  time_this_iter_s: 8.66307020187378
  time_total_s: 5276.492105007172
  timestamp: 1594853788
  timesteps_since_restore: 3030000
  timesteps_this_iter: 5000
  timesteps_total: 3030000
  training_iteration: 606
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5276 s, 606 iter, 3030000 ts, 333 rew

agent-1: 33.79999999930212
agent-2: 35.79999999930215
agent-3: 33.79999999930213
agent-4: 29.79999999930198
agent-5: 28.799999999301985
Extrinsic Rewards:
5
7
5
1
0
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-56-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 332.4146050635521
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 606
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.463
    dispatch_time_ms: 7.922
    learner:
      cur_lr: 0.0011582019506022334
      grad_gnorm: 40.0
      policy_entropy: 27.742229461669922
      policy_loss: -8.16584300994873
      var_gnorm: 22.885374069213867
      vf_explained_var: 0.0
      vf_loss: 4.550658702850342
    num_steps_sampled: 3035000
    num_steps_trained: 3035000
    wait_time_ms: 76.028
  iterations_since_restore: 607
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5285.098051786423
  time_this_iter_s: 8.605946779251099
  time_total_s: 5285.098051786423
  timestamp: 1594853797
  timesteps_since_restore: 3035000
  timesteps_this_iter: 5000
  timesteps_total: 3035000
  training_iteration: 607
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5285 s, 607 iter, 3035000 ts, 332 rew

agent-1: 162.19969164722542
agent-2: 153.19969164722536
agent-3: 152.19969164722542
agent-4: 158.19969164722542
agent-5: 157.19969164722542
Extrinsic Rewards:
23
14
13
19
18
Sum Reward: 87
Avg Reward: 17.4
Min Reward: 13
Max Reward: 23
Gini Coefficient: 0.11494252873563218
20:20 Ratio: 1.7692307692307692
Max-min Ratio: 1.7692307692307692
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-56-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 338.084589646048
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 607
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.734
    dispatch_time_ms: 8.725
    learner:
      cur_lr: 0.0011578690027818084
      grad_gnorm: 27.055538177490234
      policy_entropy: 20.94428253173828
      policy_loss: -0.8166895508766174
      var_gnorm: 22.920555114746094
      vf_explained_var: 0.0
      vf_loss: 0.5440739393234253
    num_steps_sampled: 3040000
    num_steps_trained: 3040000
    wait_time_ms: 72.806
  iterations_since_restore: 608
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5293.735570907593
  time_this_iter_s: 8.637519121170044
  time_total_s: 5293.735570907593
  timestamp: 1594853805
  timesteps_since_restore: 3040000
  timesteps_this_iter: 5000
  timesteps_total: 3040000
  training_iteration: 608
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5293 s, 608 iter, 3040000 ts, 338 rew

agent-1: 68.9999999734627
agent-2: 68.9999999734627
agent-3: 79.99999997346272
agent-4: 73.99999997346279
agent-5: 67.9999999734627
Extrinsic Rewards:
5
5
16
10
4
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 4
Max Reward: 16
Gini Coefficient: 0.29
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-56-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 339.43458964484654
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 608
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.841
    dispatch_time_ms: 8.161
    learner:
      cur_lr: 0.0011575360549613833
      grad_gnorm: 40.0
      policy_entropy: 43.00345993041992
      policy_loss: -11.626742362976074
      var_gnorm: 22.933732986450195
      vf_explained_var: 0.0
      vf_loss: 2.7389590740203857
    num_steps_sampled: 3045000
    num_steps_trained: 3045000
    wait_time_ms: 78.235
  iterations_since_restore: 609
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5302.367442846298
  time_this_iter_s: 8.631871938705444
  time_total_s: 5302.367442846298
  timestamp: 1594853814
  timesteps_since_restore: 3045000
  timesteps_this_iter: 5000
  timesteps_total: 3045000
  training_iteration: 609
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5302 s, 609 iter, 3045000 ts, 339 rew

agent-1: 123.59972776412678
agent-2: 123.59972776412678
agent-3: 131.59972776412675
agent-4: 121.59972776412678
agent-5: 138.59972776412678
Extrinsic Rewards:
10
10
18
8
25
Sum Reward: 71
Avg Reward: 14.2
Min Reward: 8
Max Reward: 25
Gini Coefficient: 0.23661971830985915
20:20 Ratio: 3.125
Max-min Ratio: 3.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-57-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 343.75457603407676
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 609
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.645
    dispatch_time_ms: 6.138
    learner:
      cur_lr: 0.0011572029907256365
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.50864028930664
      policy_loss: 53.52997970581055
      var_gnorm: 22.91498374938965
      vf_explained_var: 0.0
      vf_loss: 80.0134048461914
    num_steps_sampled: 3050000
    num_steps_trained: 3050000
    wait_time_ms: 79.422
  iterations_since_restore: 610
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5311.039629936218
  time_this_iter_s: 8.672187089920044
  time_total_s: 5311.039629936218
  timestamp: 1594853823
  timesteps_since_restore: 3050000
  timesteps_this_iter: 5000
  timesteps_total: 3050000
  training_iteration: 610
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5311 s, 610 iter, 3050000 ts, 344 rew

agent-1: 63.99999999042149
agent-2: 57.99999999042151
agent-3: 70.99999999042167
agent-4: 56.99999999042149
agent-5: 64.99999999042157
Extrinsic Rewards:
8
2
15
1
9
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 1
Max Reward: 15
Gini Coefficient: 0.4
20:20 Ratio: 15.0
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-57-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 339.79458506019347
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 610
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.108
    dispatch_time_ms: 7.006
    learner:
      cur_lr: 0.0011568700429052114
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.95102310180664
      policy_loss: -8.084056854248047
      var_gnorm: 22.920347213745117
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 2.869793176651001
    num_steps_sampled: 3055000
    num_steps_trained: 3055000
    wait_time_ms: 77.782
  iterations_since_restore: 611
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5319.640286445618
  time_this_iter_s: 8.600656509399414
  time_total_s: 5319.640286445618
  timestamp: 1594853831
  timesteps_since_restore: 3055000
  timesteps_this_iter: 5000
  timesteps_total: 3055000
  training_iteration: 611
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5319 s, 611 iter, 3055000 ts, 340 rew

agent-1: 127.99997376519585
agent-2: 126.99997376519585
agent-3: 121.99997376519582
agent-4: 118.99997376519582
agent-5: 133.99997376519613
Extrinsic Rewards:
16
15
10
7
22
Sum Reward: 70
Avg Reward: 14.0
Min Reward: 7
Max Reward: 22
Gini Coefficient: 0.2057142857142857
20:20 Ratio: 3.142857142857143
Max-min Ratio: 3.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-57-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 337.76870564063825
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 611
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.87
    dispatch_time_ms: 9.478
    learner:
      cur_lr: 0.0011565369786694646
      grad_gnorm: 39.999996185302734
      policy_entropy: 53.06740188598633
      policy_loss: -16.612606048583984
      var_gnorm: 22.92293930053711
      vf_explained_var: 0.0
      vf_loss: 3.7125320434570312
    num_steps_sampled: 3060000
    num_steps_trained: 3060000
    wait_time_ms: 75.083
  iterations_since_restore: 612
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5328.248866319656
  time_this_iter_s: 8.608579874038696
  time_total_s: 5328.248866319656
  timestamp: 1594853840
  timesteps_since_restore: 3060000
  timesteps_this_iter: 5000
  timesteps_total: 3060000
  training_iteration: 612
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5328 s, 612 iter, 3060000 ts, 338 rew

agent-1: 141.99969977939847
agent-2: 151.99969977939836
agent-3: 143.99969977939844
agent-4: 166.99969977939836
agent-5: 159.99969977939836
Extrinsic Rewards:
6
16
8
31
24
Sum Reward: 85
Avg Reward: 17.0
Min Reward: 6
Max Reward: 31
Gini Coefficient: 0.31058823529411766
20:20 Ratio: 5.166666666666667
Max-min Ratio: 5.166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-57-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 341.0986907582654
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 612
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.458
    dispatch_time_ms: 7.292
    learner:
      cur_lr: 0.0011562040308490396
      grad_gnorm: 16.18427085876465
      policy_entropy: 30.66991424560547
      policy_loss: -2.775219678878784
      var_gnorm: 22.913354873657227
      vf_explained_var: 0.0
      vf_loss: 0.20167045295238495
    num_steps_sampled: 3065000
    num_steps_trained: 3065000
    wait_time_ms: 77.878
  iterations_since_restore: 613
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5336.912403821945
  time_this_iter_s: 8.663537502288818
  time_total_s: 5336.912403821945
  timestamp: 1594853849
  timesteps_since_restore: 3065000
  timesteps_this_iter: 5000
  timesteps_total: 3065000
  training_iteration: 613
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5336 s, 613 iter, 3065000 ts, 341 rew

agent-1: 59.39999999504799
agent-2: 63.39999999504799
agent-3: 58.39999999504799
agent-4: 59.39999999504799
agent-5: 65.39999999504815
Extrinsic Rewards:
5
9
4
5
11
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 4
Max Reward: 11
Gini Coefficient: 0.21176470588235294
20:20 Ratio: 2.75
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-57-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 342.2686907580853
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 613
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.24
    dispatch_time_ms: 6.88
    learner:
      cur_lr: 0.0011558709666132927
      grad_gnorm: 3.6891987323760986
      policy_entropy: 49.431819915771484
      policy_loss: -0.6894122362136841
      var_gnorm: 22.913076400756836
      vf_explained_var: 0.0
      vf_loss: 0.009463981725275517
    num_steps_sampled: 3070000
    num_steps_trained: 3070000
    wait_time_ms: 77.482
  iterations_since_restore: 614
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5345.623612880707
  time_this_iter_s: 8.711209058761597
  time_total_s: 5345.623612880707
  timestamp: 1594853857
  timesteps_since_restore: 3070000
  timesteps_this_iter: 5000
  timesteps_total: 3070000
  training_iteration: 614
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5345 s, 614 iter, 3070000 ts, 342 rew

agent-1: 26.599999999589024
agent-2: 28.599999999589024
agent-3: 27.599999999589024
agent-4: 30.599999999589024
agent-5: 30.599999999589024
Extrinsic Rewards:
1
3
2
5
5
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 1
Max Reward: 5
Gini Coefficient: 0.275
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-57-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 341.908690758109
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 614
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.466
    dispatch_time_ms: 9.033
    learner:
      cur_lr: 0.0011555380187928677
      grad_gnorm: 10.430180549621582
      policy_entropy: 17.12484359741211
      policy_loss: -1.0331158638000488
      var_gnorm: 22.915475845336914
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.08327820897102356
    num_steps_sampled: 3075000
    num_steps_trained: 3075000
    wait_time_ms: 73.727
  iterations_since_restore: 615
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5354.29608798027
  time_this_iter_s: 8.672475099563599
  time_total_s: 5354.29608798027
  timestamp: 1594853866
  timesteps_since_restore: 3075000
  timesteps_this_iter: 5000
  timesteps_total: 3075000
  training_iteration: 615
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5354 s, 615 iter, 3075000 ts, 342 rew

agent-1: 32.99999999931894
agent-2: 36.99999999931895
agent-3: 40.99999999931893
agent-4: 36.999999999318945
agent-5: 31.99999999931896
Extrinsic Rewards:
1
5
9
5
0
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.44
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-57-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 337.9842934952721
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 615
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.882
    dispatch_time_ms: 7.33
    learner:
      cur_lr: 0.0011552049545571208
      grad_gnorm: 39.999996185302734
      policy_entropy: 16.31169891357422
      policy_loss: 33.39945983886719
      var_gnorm: 22.916183471679688
      vf_explained_var: 0.0
      vf_loss: 49.938575744628906
    num_steps_sampled: 3080000
    num_steps_trained: 3080000
    wait_time_ms: 75.824
  iterations_since_restore: 616
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5362.964550256729
  time_this_iter_s: 8.66846227645874
  time_total_s: 5362.964550256729
  timestamp: 1594853875
  timesteps_since_restore: 3080000
  timesteps_this_iter: 5000
  timesteps_total: 3080000
  training_iteration: 616
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5362 s, 616 iter, 3080000 ts, 338 rew

agent-1: 35.199999999505806
agent-2: 30.199999999505778
agent-3: 29.199999999505778
agent-4: 28.19999999950578
agent-5: 30.19999999950578
Extrinsic Rewards:
8
3
2
1
3
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.35294117647058826
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-58-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 335.0143071692774
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 616
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.235
    dispatch_time_ms: 9.519
    learner:
      cur_lr: 0.0011548720067366958
      grad_gnorm: 36.76882553100586
      policy_entropy: 31.827835083007812
      policy_loss: -5.491825580596924
      var_gnorm: 22.920934677124023
      vf_explained_var: 0.0
      vf_loss: 1.0420628786087036
    num_steps_sampled: 3085000
    num_steps_trained: 3085000
    wait_time_ms: 74.982
  iterations_since_restore: 617
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5371.622277498245
  time_this_iter_s: 8.657727241516113
  time_total_s: 5371.622277498245
  timestamp: 1594853884
  timesteps_since_restore: 3085000
  timesteps_this_iter: 5000
  timesteps_total: 3085000
  training_iteration: 617
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5371 s, 617 iter, 3085000 ts, 335 rew

agent-1: 117.19999095136407
agent-2: 104.19999095136407
agent-3: 116.19999095136407
agent-4: 110.19999095136407
agent-5: 110.1999909513641
Extrinsic Rewards:
18
5
17
11
11
Sum Reward: 62
Avg Reward: 12.4
Min Reward: 5
Max Reward: 18
Gini Coefficient: 0.2064516129032258
20:20 Ratio: 3.6
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-58-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 336.8143067183872
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 617
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 8.107
    learner:
      cur_lr: 0.001154538942500949
      grad_gnorm: 9.946130752563477
      policy_entropy: 6.110694408416748
      policy_loss: -0.6559024453163147
      var_gnorm: 22.91762351989746
      vf_explained_var: 0.0
      vf_loss: 0.07616568356752396
    num_steps_sampled: 3090000
    num_steps_trained: 3090000
    wait_time_ms: 75.183
  iterations_since_restore: 618
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5380.2707505226135
  time_this_iter_s: 8.648473024368286
  time_total_s: 5380.2707505226135
  timestamp: 1594853892
  timesteps_since_restore: 3090000
  timesteps_this_iter: 5000
  timesteps_total: 3090000
  training_iteration: 618
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5380 s, 618 iter, 3090000 ts, 337 rew

agent-1: 37.99999999894623
agent-2: 38.99999999894622
agent-3: 35.999999998946215
agent-4: 33.99999999894621
agent-5: 32.99999999894621
Extrinsic Rewards:
6
7
4
2
1
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.32
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-58-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 336.18430671853866
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 618
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.494
    dispatch_time_ms: 12.01
    learner:
      cur_lr: 0.0011542059946805239
      grad_gnorm: 39.999996185302734
      policy_entropy: 24.091615676879883
      policy_loss: 24.56844139099121
      var_gnorm: 22.93555450439453
      vf_explained_var: 0.0
      vf_loss: 45.780235290527344
    num_steps_sampled: 3095000
    num_steps_trained: 3095000
    wait_time_ms: 68.941
  iterations_since_restore: 619
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5388.764653921127
  time_this_iter_s: 8.493903398513794
  time_total_s: 5388.764653921127
  timestamp: 1594853901
  timesteps_since_restore: 3095000
  timesteps_this_iter: 5000
  timesteps_total: 3095000
  training_iteration: 619
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5388 s, 619 iter, 3095000 ts, 336 rew

agent-1: 136.98840188994475
agent-2: 135.98840188994475
agent-3: 128.98840188994464
agent-4: 141.98840188994467
agent-5: 130.98840188994473
Extrinsic Rewards:
17
16
9
22
11
Sum Reward: 75
Avg Reward: 15.0
Min Reward: 9
Max Reward: 22
Gini Coefficient: 0.17066666666666666
20:20 Ratio: 2.4444444444444446
Max-min Ratio: 2.4444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-58-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 339.96372682143783
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 619
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.95
    dispatch_time_ms: 9.022
    learner:
      cur_lr: 0.0011538730468600988
      grad_gnorm: 35.96485137939453
      policy_entropy: 12.312983512878418
      policy_loss: -5.1709675788879395
      var_gnorm: 22.92211151123047
      vf_explained_var: 0.0
      vf_loss: 0.9563199281692505
    num_steps_sampled: 3100000
    num_steps_trained: 3100000
    wait_time_ms: 73.013
  iterations_since_restore: 620
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5397.282995939255
  time_this_iter_s: 8.518342018127441
  time_total_s: 5397.282995939255
  timestamp: 1594853909
  timesteps_since_restore: 3100000
  timesteps_this_iter: 5000
  timesteps_total: 3100000
  training_iteration: 620
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5397 s, 620 iter, 3100000 ts, 340 rew

agent-1: 120.7999981125367
agent-2: 119.7999981125367
agent-3: 104.79999811253673
agent-4: 109.79999811253673
agent-5: 111.7999981125367
Extrinsic Rewards:
20
19
4
9
11
Sum Reward: 63
Avg Reward: 12.6
Min Reward: 4
Max Reward: 20
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-58-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 343.9237267270968
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 620
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 6.091
    learner:
      cur_lr: 0.001153539982624352
      grad_gnorm: 30.013813018798828
      policy_entropy: 54.64829635620117
      policy_loss: -7.8825483322143555
      var_gnorm: 22.930694580078125
      vf_explained_var: 0.0
      vf_loss: 0.6730746030807495
    num_steps_sampled: 3105000
    num_steps_trained: 3105000
    wait_time_ms: 80.271
  iterations_since_restore: 621
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5405.696645021439
  time_this_iter_s: 8.413649082183838
  time_total_s: 5405.696645021439
  timestamp: 1594853918
  timesteps_since_restore: 3105000
  timesteps_this_iter: 5000
  timesteps_total: 3105000
  training_iteration: 621
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5405 s, 621 iter, 3105000 ts, 344 rew

agent-1: 93.19902277951192
agent-2: 75.19902277951195
agent-3: 84.19902277951195
agent-4: 88.19902277951192
agent-5: 82.19902277951195
Extrinsic Rewards:
18
0
9
13
7
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 0
Max Reward: 18
Gini Coefficient: 0.3574468085106383
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-58-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 338.88371380569146
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 621
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.535
    dispatch_time_ms: 9.471
    learner:
      cur_lr: 0.001153207034803927
      grad_gnorm: 15.13302230834961
      policy_entropy: 30.736087799072266
      policy_loss: -1.3509503602981567
      var_gnorm: 22.927949905395508
      vf_explained_var: 0.0
      vf_loss: 0.1765238493680954
    num_steps_sampled: 3110000
    num_steps_trained: 3110000
    wait_time_ms: 76.102
  iterations_since_restore: 622
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5414.227066755295
  time_this_iter_s: 8.530421733856201
  time_total_s: 5414.227066755295
  timestamp: 1594853926
  timesteps_since_restore: 3110000
  timesteps_this_iter: 5000
  timesteps_total: 3110000
  training_iteration: 622
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5414 s, 622 iter, 3110000 ts, 339 rew

agent-1: 38.79999999613684
agent-2: 41.79999999613684
agent-3: 44.799999996136854
agent-4: 38.79999999613684
agent-5: 42.79999999613684
Extrinsic Rewards:
2
5
8
2
6
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2782608695652174
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-58-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 339.24371380552986
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 622
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 7.674
    learner:
      cur_lr: 0.00115287397056818
      grad_gnorm: 40.0
      policy_entropy: 40.12269973754883
      policy_loss: -10.397372245788574
      var_gnorm: 22.941082000732422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.930446982383728
    num_steps_sampled: 3115000
    num_steps_trained: 3115000
    wait_time_ms: 75.895
  iterations_since_restore: 623
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5422.827283143997
  time_this_iter_s: 8.600216388702393
  time_total_s: 5422.827283143997
  timestamp: 1594853935
  timesteps_since_restore: 3115000
  timesteps_this_iter: 5000
  timesteps_total: 3115000
  training_iteration: 623
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5422 s, 623 iter, 3115000 ts, 339 rew

agent-1: 100.7999409985319
agent-2: 99.79994099853185
agent-3: 90.79994099853185
agent-4: 94.79994099853187
agent-5: 90.79994099853185
Extrinsic Rewards:
16
15
6
10
6
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 6
Max Reward: 16
Gini Coefficient: 0.2188679245283019
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-59-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 340.0537108814068
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 623
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.426
    dispatch_time_ms: 9.27
    learner:
      cur_lr: 0.001152541022747755
      grad_gnorm: 17.340091705322266
      policy_entropy: 50.136680603027344
      policy_loss: -3.729304313659668
      var_gnorm: 22.94856071472168
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.23149830102920532
    num_steps_sampled: 3120000
    num_steps_trained: 3120000
    wait_time_ms: 74.986
  iterations_since_restore: 624
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5431.315580368042
  time_this_iter_s: 8.4882972240448
  time_total_s: 5431.315580368042
  timestamp: 1594853943
  timesteps_since_restore: 3120000
  timesteps_this_iter: 5000
  timesteps_total: 3120000
  training_iteration: 624
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5431 s, 624 iter, 3120000 ts, 340 rew

agent-1: 57.59999999767337
agent-2: 52.599999997673365
agent-3: 58.59999999767337
agent-4: 51.599999997673365
agent-5: 58.59999999767337
Extrinsic Rewards:
8
3
9
2
9
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.25806451612903225
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-59-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 339.87371088191145
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 624
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.717
    dispatch_time_ms: 8.404
    learner:
      cur_lr: 0.0011522079585120082
      grad_gnorm: 28.06821632385254
      policy_entropy: 46.05358123779297
      policy_loss: -5.446658134460449
      var_gnorm: 22.9532413482666
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.5763941407203674
    num_steps_sampled: 3125000
    num_steps_trained: 3125000
    wait_time_ms: 73.736
  iterations_since_restore: 625
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5439.895674467087
  time_this_iter_s: 8.5800940990448
  time_total_s: 5439.895674467087
  timestamp: 1594853952
  timesteps_since_restore: 3125000
  timesteps_this_iter: 5000
  timesteps_total: 3125000
  training_iteration: 625
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5439 s, 625 iter, 3125000 ts, 340 rew

agent-1: 76.1999998666908
agent-2: 72.19999986669077
agent-3: 73.19999986669077
agent-4: 85.19999986669077
agent-5: 71.19999986669077
Extrinsic Rewards:
9
5
6
18
4
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 4
Max Reward: 18
Gini Coefficient: 0.3047619047619048
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-59-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 341.58371087534965
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 625
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.06
    dispatch_time_ms: 8.106
    learner:
      cur_lr: 0.0011518750106915832
      grad_gnorm: 10.180973052978516
      policy_entropy: 14.748186111450195
      policy_loss: 0.711428165435791
      var_gnorm: 22.967065811157227
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.08624396473169327
    num_steps_sampled: 3130000
    num_steps_trained: 3130000
    wait_time_ms: 75.005
  iterations_since_restore: 626
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5448.465605020523
  time_this_iter_s: 8.56993055343628
  time_total_s: 5448.465605020523
  timestamp: 1594853961
  timesteps_since_restore: 3130000
  timesteps_this_iter: 5000
  timesteps_total: 3130000
  training_iteration: 626
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5448 s, 626 iter, 3130000 ts, 342 rew

agent-1: 65.79999984127397
agent-2: 71.799999841274
agent-3: 67.79999984127399
agent-4: 68.799999841274
agent-5: 67.79999984127399
Extrinsic Rewards:
5
11
7
8
7
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 5
Max Reward: 11
Gini Coefficient: 0.1368421052631579
20:20 Ratio: 2.2
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-59-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 343.47371086743914
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 626
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.746
    dispatch_time_ms: 6.848
    learner:
      cur_lr: 0.0011515419464558363
      grad_gnorm: 25.54812240600586
      policy_entropy: 22.972055435180664
      policy_loss: -1.2095050811767578
      var_gnorm: 22.966615676879883
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.4714953899383545
    num_steps_sampled: 3135000
    num_steps_trained: 3135000
    wait_time_ms: 79.548
  iterations_since_restore: 627
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5457.204359292984
  time_this_iter_s: 8.738754272460938
  time_total_s: 5457.204359292984
  timestamp: 1594853969
  timesteps_since_restore: 3135000
  timesteps_this_iter: 5000
  timesteps_total: 3135000
  training_iteration: 627
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5457 s, 627 iter, 3135000 ts, 343 rew

agent-1: 75.59974002862806
agent-2: 74.59974002862806
agent-3: 71.59974002862812
agent-4: 74.59974002862806
agent-5: 72.59974002862809
Extrinsic Rewards:
10
9
6
9
7
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 6
Max Reward: 10
Gini Coefficient: 0.0975609756097561
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-59-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 344.0136978696145
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 627
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 6.177
    learner:
      cur_lr: 0.0011512089986354113
      grad_gnorm: 18.99785614013672
      policy_entropy: 28.2642879486084
      policy_loss: -3.303779363632202
      var_gnorm: 22.961015701293945
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.27195537090301514
    num_steps_sampled: 3140000
    num_steps_trained: 3140000
    wait_time_ms: 80.574
  iterations_since_restore: 628
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5465.940255403519
  time_this_iter_s: 8.735896110534668
  time_total_s: 5465.940255403519
  timestamp: 1594853978
  timesteps_since_restore: 3140000
  timesteps_this_iter: 5000
  timesteps_total: 3140000
  training_iteration: 628
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5465 s, 628 iter, 3140000 ts, 344 rew

agent-1: 46.399999994415914
agent-2: 38.3999999944159
agent-3: 41.399999994415914
agent-4: 50.39999999441593
agent-5: 39.3999999944159
Extrinsic Rewards:
8
0
3
12
1
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.5166666666666667
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-59-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 343.0236978730915
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 628
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 9.621
    learner:
      cur_lr: 0.0011508760508149862
      grad_gnorm: 24.84916114807129
      policy_entropy: 33.05915451049805
      policy_loss: -3.219363212585449
      var_gnorm: 22.950422286987305
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.46271809935569763
    num_steps_sampled: 3145000
    num_steps_trained: 3145000
    wait_time_ms: 72.423
  iterations_since_restore: 629
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5474.498288154602
  time_this_iter_s: 8.558032751083374
  time_total_s: 5474.498288154602
  timestamp: 1594853987
  timesteps_since_restore: 3145000
  timesteps_this_iter: 5000
  timesteps_total: 3145000
  training_iteration: 629
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5474 s, 629 iter, 3145000 ts, 343 rew

agent-1: 83.39999987704311
agent-2: 91.39999987704311
agent-3: 90.39999987704313
agent-4: 86.39999987704313
agent-5: 89.39999987704311
Extrinsic Rewards:
5
13
12
8
11
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 5
Max Reward: 13
Gini Coefficient: 0.16326530612244897
20:20 Ratio: 2.6
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_18-59-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 345.9936978670015
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 629
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 8.747
    learner:
      cur_lr: 0.0011505429865792394
      grad_gnorm: 16.67214584350586
      policy_entropy: 42.582855224609375
      policy_loss: 3.6098711490631104
      var_gnorm: 22.9517879486084
      vf_explained_var: 0.0
      vf_loss: 0.22499585151672363
    num_steps_sampled: 3150000
    num_steps_trained: 3150000
    wait_time_ms: 75.892
  iterations_since_restore: 630
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5483.052729129791
  time_this_iter_s: 8.554440975189209
  time_total_s: 5483.052729129791
  timestamp: 1594853995
  timesteps_since_restore: 3150000
  timesteps_this_iter: 5000
  timesteps_total: 3150000
  training_iteration: 630
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5483 s, 630 iter, 3150000 ts, 346 rew

agent-1: 38.199999996221905
agent-2: 42.1999999962219
agent-3: 39.19999999622189
agent-4: 42.1999999962219
agent-5: 36.1999999962219
Extrinsic Rewards:
3
7
4
7
1
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.2909090909090909
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-00-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 344.6436978674242
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 630
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 9.505
    learner:
      cur_lr: 0.0011502100387588143
      grad_gnorm: 17.796348571777344
      policy_entropy: 47.74369812011719
      policy_loss: -3.090125799179077
      var_gnorm: 22.952756881713867
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.23812951147556305
    num_steps_sampled: 3155000
    num_steps_trained: 3155000
    wait_time_ms: 73.816
  iterations_since_restore: 631
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5499.573020935059
  time_this_iter_s: 16.520291805267334
  time_total_s: 5499.573020935059
  timestamp: 1594854012
  timesteps_since_restore: 3155000
  timesteps_this_iter: 5000
  timesteps_total: 3155000
  training_iteration: 631
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5499 s, 631 iter, 3155000 ts, 345 rew

agent-1: 39.799999994880665
agent-2: 43.799999994880665
agent-3: 39.79999999488066
agent-4: 46.79999999488068
agent-5: 36.79999999488066
Extrinsic Rewards:
3
7
3
10
0
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.41739130434782606
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-00-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 342.57369786853116
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 631
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 7.001
    learner:
      cur_lr: 0.0011498769745230675
      grad_gnorm: 11.409379959106445
      policy_entropy: 51.283241271972656
      policy_loss: 3.3370375633239746
      var_gnorm: 22.952516555786133
      vf_explained_var: 0.0
      vf_loss: 0.10148563235998154
    num_steps_sampled: 3160000
    num_steps_trained: 3160000
    wait_time_ms: 76.986
  iterations_since_restore: 632
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5508.1941068172455
  time_this_iter_s: 8.62108588218689
  time_total_s: 5508.1941068172455
  timestamp: 1594854021
  timesteps_since_restore: 3160000
  timesteps_this_iter: 5000
  timesteps_total: 3160000
  training_iteration: 632
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5508 s, 632 iter, 3160000 ts, 343 rew

agent-1: 81.79999988167269
agent-2: 75.79999988167263
agent-3: 79.79999988167269
agent-4: 68.79999988167259
agent-5: 80.79999988167269
Extrinsic Rewards:
13
7
11
0
12
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.28837209302325584
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-00-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 341.76369787557394
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 632
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 9.489
    learner:
      cur_lr: 0.0011495440267026424
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.944957733154297
      policy_loss: 44.63368225097656
      var_gnorm: 22.94918441772461
      vf_explained_var: 0.0
      vf_loss: 45.539798736572266
    num_steps_sampled: 3165000
    num_steps_trained: 3165000
    wait_time_ms: 69.725
  iterations_since_restore: 633
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5516.6593997478485
  time_this_iter_s: 8.465292930603027
  time_total_s: 5516.6593997478485
  timestamp: 1594854029
  timesteps_since_restore: 3165000
  timesteps_this_iter: 5000
  timesteps_total: 3165000
  training_iteration: 633
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5516 s, 633 iter, 3165000 ts, 342 rew

agent-1: 39.99999999640293
agent-2: 48.99999999640296
agent-3: 41.99999999640294
agent-4: 43.999999996402956
agent-5: 49.99999999640297
Extrinsic Rewards:
0
9
2
4
10
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.432
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-00-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 337.80370025087905
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 633
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.478
    dispatch_time_ms: 5.257
    learner:
      cur_lr: 0.0011492109624668956
      grad_gnorm: 39.999996185302734
      policy_entropy: 38.35174560546875
      policy_loss: 17.69610023498535
      var_gnorm: 22.963146209716797
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.838950157165527
    num_steps_sampled: 3170000
    num_steps_trained: 3170000
    wait_time_ms: 79.2
  iterations_since_restore: 634
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5524.900270462036
  time_this_iter_s: 8.240870714187622
  time_total_s: 5524.900270462036
  timestamp: 1594854037
  timesteps_since_restore: 3170000
  timesteps_this_iter: 5000
  timesteps_total: 3170000
  training_iteration: 634
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5524 s, 634 iter, 3170000 ts, 338 rew

agent-1: 161.21627697797507
agent-2: 161.21627697797507
agent-3: 146.21627697797493
agent-4: 178.21627697797507
agent-5: 153.21627697797496
Extrinsic Rewards:
19
19
4
36
11
Sum Reward: 89
Avg Reward: 17.8
Min Reward: 4
Max Reward: 36
Gini Coefficient: 0.3235955056179775
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-00-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 342.56451410090443
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 634
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.787
    dispatch_time_ms: 38.872
    learner:
      cur_lr: 0.0011488780146464705
      grad_gnorm: 40.000003814697266
      policy_entropy: 31.671695709228516
      policy_loss: -9.076678276062012
      var_gnorm: 22.9583683013916
      vf_explained_var: 0.0
      vf_loss: 1.633409023284912
    num_steps_sampled: 3175000
    num_steps_trained: 3175000
    wait_time_ms: 52.885
  iterations_since_restore: 635
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5533.544443368912
  time_this_iter_s: 8.64417290687561
  time_total_s: 5533.544443368912
  timestamp: 1594854046
  timesteps_since_restore: 3175000
  timesteps_this_iter: 5000
  timesteps_total: 3175000
  training_iteration: 635
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5533 s, 635 iter, 3175000 ts, 343 rew

agent-1: 47.79999999033512
agent-2: 46.7999999903351
agent-3: 49.79999999033512
agent-4: 56.79999999033512
agent-5: 50.79999999033512
Extrinsic Rewards:
3
2
5
12
6
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.32857142857142857
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-00-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 336.1749016430111
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 635
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.922
    dispatch_time_ms: 29.504
    learner:
      cur_lr: 0.0011485449504107237
      grad_gnorm: 2.9032301902770996
      policy_entropy: 1.273624062538147
      policy_loss: -0.0030957781709730625
      var_gnorm: 22.951475143432617
      vf_explained_var: 0.0
      vf_loss: 0.006526703480631113
    num_steps_sampled: 3180000
    num_steps_trained: 3180000
    wait_time_ms: 99.838
  iterations_since_restore: 636
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5542.69913482666
  time_this_iter_s: 9.154691457748413
  time_total_s: 5542.69913482666
  timestamp: 1594854055
  timesteps_since_restore: 3180000
  timesteps_this_iter: 5000
  timesteps_total: 3180000
  training_iteration: 636
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5542 s, 636 iter, 3180000 ts, 336 rew

agent-1: 42.9999999978625
agent-2: 50.999999997862524
agent-3: 42.9999999978625
agent-4: 41.999999997862496
agent-5: 45.9999999978625
Extrinsic Rewards:
3
11
3
2
6
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.336
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-01-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 335.004901643546
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 636
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.932
    dispatch_time_ms: 27.979
    learner:
      cur_lr: 0.0011482120025902987
      grad_gnorm: 40.0
      policy_entropy: 1.2801376581192017
      policy_loss: 8.60248851776123
      var_gnorm: 22.951473236083984
      vf_explained_var: 0.0
      vf_loss: 3.3118762969970703
    num_steps_sampled: 3185000
    num_steps_trained: 3185000
    wait_time_ms: 39.735
  iterations_since_restore: 637
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5550.97433423996
  time_this_iter_s: 8.27519941329956
  time_total_s: 5550.97433423996
  timestamp: 1594854064
  timesteps_since_restore: 3185000
  timesteps_this_iter: 5000
  timesteps_total: 3185000
  training_iteration: 637
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5550 s, 637 iter, 3185000 ts, 335 rew

agent-1: 1.5840426768569638
agent-2: 2.584042676856964
agent-3: 1.5840426768569638
agent-4: 1.5840426768569638
agent-5: 1.5840426768569638
Extrinsic Rewards:
0
1
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-01-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 332.03410377761134
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 637
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.927
    dispatch_time_ms: 24.305
    learner:
      cur_lr: 0.0011478790547698736
      grad_gnorm: 40.0
      policy_entropy: 4.570876121520996
      policy_loss: 1.114469289779663
      var_gnorm: 22.95680046081543
      vf_explained_var: 0.0
      vf_loss: 1.576409101486206
    num_steps_sampled: 3190000
    num_steps_trained: 3190000
    wait_time_ms: 51.136
  iterations_since_restore: 638
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5559.366302013397
  time_this_iter_s: 8.3919677734375
  time_total_s: 5559.366302013397
  timestamp: 1594854072
  timesteps_since_restore: 3190000
  timesteps_this_iter: 5000
  timesteps_total: 3190000
  training_iteration: 638
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5559 s, 638 iter, 3190000 ts, 332 rew

agent-1: 11.758993036091741
agent-2: 13.758993036091741
agent-3: 13.75899303609174
agent-4: 10.758993036091736
agent-5: 11.758993036091736
Extrinsic Rewards:
1
3
3
0
1
Sum Reward: 8
Avg Reward: 1.6
Min Reward: 0
Max Reward: 3
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-01-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 329.6820534295133
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 638
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.054
    dispatch_time_ms: 39.31
    learner:
      cur_lr: 0.0011475459905341268
      grad_gnorm: 40.0
      policy_entropy: 39.442543029785156
      policy_loss: 36.01679992675781
      var_gnorm: 22.98844337463379
      vf_explained_var: 0.0
      vf_loss: 45.0153923034668
    num_steps_sampled: 3195000
    num_steps_trained: 3195000
    wait_time_ms: 46.959
  iterations_since_restore: 639
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5567.901117324829
  time_this_iter_s: 8.534815311431885
  time_total_s: 5567.901117324829
  timestamp: 1594854081
  timesteps_since_restore: 3195000
  timesteps_this_iter: 5000
  timesteps_total: 3195000
  training_iteration: 639
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5567 s, 639 iter, 3195000 ts, 330 rew

agent-1: 100.78530392843754
agent-2: 103.78530392843751
agent-3: 110.78530392843754
agent-4: 103.78530392843753
agent-5: 102.78530392843753
Extrinsic Rewards:
8
11
18
11
10
Sum Reward: 58
Avg Reward: 11.6
Min Reward: 8
Max Reward: 18
Gini Coefficient: 0.14482758620689656
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-01-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 331.03131866415873
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 639
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.684
    dispatch_time_ms: 23.586
    learner:
      cur_lr: 0.0011472130427137017
      grad_gnorm: 40.00000762939453
      policy_entropy: 30.23479461669922
      policy_loss: 59.45265197753906
      var_gnorm: 23.01997184753418
      vf_explained_var: 0.0
      vf_loss: 76.78228759765625
    num_steps_sampled: 3200000
    num_steps_trained: 3200000
    wait_time_ms: 69.531
  iterations_since_restore: 640
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5576.8051035404205
  time_this_iter_s: 8.90398621559143
  time_total_s: 5576.8051035404205
  timestamp: 1594854089
  timesteps_since_restore: 3200000
  timesteps_this_iter: 5000
  timesteps_total: 3200000
  training_iteration: 640
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5576 s, 640 iter, 3200000 ts, 331 rew

agent-1: 114.59699318356195
agent-2: 124.59699318356196
agent-3: 124.59699318356196
agent-4: 114.59699318356195
agent-5: 115.59699318356193
Extrinsic Rewards:
9
19
19
9
10
Sum Reward: 66
Avg Reward: 13.2
Min Reward: 9
Max Reward: 19
Gini Coefficient: 0.18181818181818182
20:20 Ratio: 2.111111111111111
Max-min Ratio: 2.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-01-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 327.7915698854664
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 640
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 18.342
    learner:
      cur_lr: 0.0011468799784779549
      grad_gnorm: 40.0
      policy_entropy: 32.88394546508789
      policy_loss: -15.702628135681152
      var_gnorm: 22.991891860961914
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.709804058074951
    num_steps_sampled: 3205000
    num_steps_trained: 3205000
    wait_time_ms: 66.162
  iterations_since_restore: 641
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5585.731931447983
  time_this_iter_s: 8.926827907562256
  time_total_s: 5585.731931447983
  timestamp: 1594854098
  timesteps_since_restore: 3205000
  timesteps_this_iter: 5000
  timesteps_total: 3205000
  training_iteration: 641
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5585 s, 641 iter, 3205000 ts, 328 rew

agent-1: 72.39999991758361
agent-2: 76.39999991758356
agent-3: 84.39999991758357
agent-4: 75.39999991758359
agent-5: 87.39999991758359
Extrinsic Rewards:
2
6
14
5
17
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 2
Max Reward: 17
Gini Coefficient: 0.35454545454545455
20:20 Ratio: 8.5
Max-min Ratio: 8.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-01-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 328.51156988594676
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 641
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.798
    dispatch_time_ms: 30.085
    learner:
      cur_lr: 0.0011465470306575298
      grad_gnorm: 17.737930297851562
      policy_entropy: 12.240506172180176
      policy_loss: -0.574073851108551
      var_gnorm: 22.9685001373291
      vf_explained_var: 0.0
      vf_loss: 0.2436448484659195
    num_steps_sampled: 3210000
    num_steps_trained: 3210000
    wait_time_ms: 47.328
  iterations_since_restore: 642
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5594.514353752136
  time_this_iter_s: 8.782422304153442
  time_total_s: 5594.514353752136
  timestamp: 1594854107
  timesteps_since_restore: 3210000
  timesteps_this_iter: 5000
  timesteps_total: 3210000
  training_iteration: 642
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5594 s, 642 iter, 3210000 ts, 329 rew

agent-1: 55.399999995513795
agent-2: 51.399999995513795
agent-3: 52.3999999955138
agent-4: 51.399999995513795
agent-5: 50.3999999955138
Extrinsic Rewards:
9
5
6
5
4
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.15172413793103448
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-01-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 328.6915698859706
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 642
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 8.874
    learner:
      cur_lr: 0.001146213966421783
      grad_gnorm: 40.0
      policy_entropy: 40.511741638183594
      policy_loss: 9.690903663635254
      var_gnorm: 22.987117767333984
      vf_explained_var: 0.0
      vf_loss: 4.498624324798584
    num_steps_sampled: 3215000
    num_steps_trained: 3215000
    wait_time_ms: 74.125
  iterations_since_restore: 643
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5603.017048835754
  time_this_iter_s: 8.502695083618164
  time_total_s: 5603.017048835754
  timestamp: 1594854116
  timesteps_since_restore: 3215000
  timesteps_this_iter: 5000
  timesteps_total: 3215000
  training_iteration: 643
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5603 s, 643 iter, 3215000 ts, 329 rew

agent-1: 110.5926014633457
agent-2: 119.5926014633457
agent-3: 117.5926014633457
agent-4: 124.5926014633457
agent-5: 121.5926014633457
Extrinsic Rewards:
5
14
12
19
16
Sum Reward: 66
Avg Reward: 13.2
Min Reward: 5
Max Reward: 19
Gini Coefficient: 0.19393939393939394
20:20 Ratio: 3.8
Max-min Ratio: 3.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-02-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 329.95120293269684
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 643
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.059
    dispatch_time_ms: 8.827
    learner:
      cur_lr: 0.001145881018601358
      grad_gnorm: 1.403310775756836
      policy_entropy: 45.422786712646484
      policy_loss: 0.21677933633327484
      var_gnorm: 22.98227882385254
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0050307693891227245
    num_steps_sampled: 3220000
    num_steps_trained: 3220000
    wait_time_ms: 73.806
  iterations_since_restore: 644
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5611.5340530872345
  time_this_iter_s: 8.517004251480103
  time_total_s: 5611.5340530872345
  timestamp: 1594854124
  timesteps_since_restore: 3220000
  timesteps_this_iter: 5000
  timesteps_total: 3220000
  training_iteration: 644
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5611 s, 644 iter, 3220000 ts, 330 rew

agent-1: 100.79999918135822
agent-2: 90.79999918135816
agent-3: 99.79999918135823
agent-4: 93.7999991813582
agent-5: 91.79999918135817
Extrinsic Rewards:
16
6
15
9
7
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 6
Max Reward: 16
Gini Coefficient: 0.21132075471698114
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-02-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 327.97120314383307
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 644
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.308
    dispatch_time_ms: 6.548
    learner:
      cur_lr: 0.001145547954365611
      grad_gnorm: 17.759843826293945
      policy_entropy: 43.21491622924805
      policy_loss: -4.2844319343566895
      var_gnorm: 22.978961944580078
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.21865935623645782
    num_steps_sampled: 3225000
    num_steps_trained: 3225000
    wait_time_ms: 76.671
  iterations_since_restore: 645
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5620.16199016571
  time_this_iter_s: 8.627937078475952
  time_total_s: 5620.16199016571
  timestamp: 1594854133
  timesteps_since_restore: 3225000
  timesteps_this_iter: 5000
  timesteps_total: 3225000
  training_iteration: 645
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5620 s, 645 iter, 3225000 ts, 328 rew

agent-1: 57.399999994663936
agent-2: 63.39999999466395
agent-3: 72.39999999466396
agent-4: 57.399999994663936
agent-5: 55.399999994663936
Extrinsic Rewards:
3
9
18
3
1
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 1
Max Reward: 18
Gini Coefficient: 0.47058823529411764
20:20 Ratio: 18.0
Max-min Ratio: 18.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-02-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 323.07373083959266
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 645
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.61
    dispatch_time_ms: 10.507
    learner:
      cur_lr: 0.001145215006545186
      grad_gnorm: 2.3934149742126465
      policy_entropy: 46.20499038696289
      policy_loss: -0.18731354176998138
      var_gnorm: 22.9792537689209
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0037738822866231203
    num_steps_sampled: 3230000
    num_steps_trained: 3230000
    wait_time_ms: 75.315
  iterations_since_restore: 646
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5628.814143896103
  time_this_iter_s: 8.652153730392456
  time_total_s: 5628.814143896103
  timestamp: 1594854142
  timesteps_since_restore: 3230000
  timesteps_this_iter: 5000
  timesteps_total: 3230000
  training_iteration: 646
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5628 s, 646 iter, 3230000 ts, 323 rew

agent-1: 35.799999999264024
agent-2: 33.799999999264024
agent-3: 34.799999999264
agent-4: 28.799999999263953
agent-5: 28.799999999263953
Extrinsic Rewards:
7
5
6
0
0
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4444444444444444
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-02-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 314.01966427928596
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 646
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.853
    dispatch_time_ms: 9.272
    learner:
      cur_lr: 0.0011448819423094392
      grad_gnorm: 12.196393966674805
      policy_entropy: 45.296485900878906
      policy_loss: -2.022024154663086
      var_gnorm: 22.975921630859375
      vf_explained_var: 0.0
      vf_loss: 0.08326629549264908
    num_steps_sampled: 3235000
    num_steps_trained: 3235000
    wait_time_ms: 80.761
  iterations_since_restore: 647
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5637.4810090065
  time_this_iter_s: 8.666865110397339
  time_total_s: 5637.4810090065
  timestamp: 1594854150
  timesteps_since_restore: 3235000
  timesteps_this_iter: 5000
  timesteps_total: 3235000
  training_iteration: 647
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5637 s, 647 iter, 3235000 ts, 314 rew

agent-1: 43.59999999892737
agent-2: 44.59999999892737
agent-3: 45.59999999892738
agent-4: 53.59999999892738
agent-5: 46.59999999892737
Extrinsic Rewards:
2
3
4
12
5
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.3384615384615385
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-02-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 311.3196642829425
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 647
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 9.159
    learner:
      cur_lr: 0.0011445489944890141
      grad_gnorm: 16.725364685058594
      policy_entropy: 41.42035675048828
      policy_loss: -2.910393714904785
      var_gnorm: 22.9766788482666
      vf_explained_var: 0.0
      vf_loss: 0.21428577601909637
    num_steps_sampled: 3240000
    num_steps_trained: 3240000
    wait_time_ms: 73.834
  iterations_since_restore: 648
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5646.014225244522
  time_this_iter_s: 8.53321623802185
  time_total_s: 5646.014225244522
  timestamp: 1594854159
  timesteps_since_restore: 3240000
  timesteps_this_iter: 5000
  timesteps_total: 3240000
  training_iteration: 648
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5646 s, 648 iter, 3240000 ts, 311 rew

agent-1: 28.799999999462543
agent-2: 34.79999999946227
agent-3: 34.79999999946227
agent-4: 34.79999999946227
agent-5: 28.799999999462543
Extrinsic Rewards:
0
6
6
6
0
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-02-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 311.4096642829377
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 648
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.443
    dispatch_time_ms: 8.791
    learner:
      cur_lr: 0.0011442160466685891
      grad_gnorm: 18.952253341674805
      policy_entropy: 45.373748779296875
      policy_loss: -4.352566719055176
      var_gnorm: 22.96645164489746
      vf_explained_var: 0.0
      vf_loss: 0.27620816230773926
    num_steps_sampled: 3245000
    num_steps_trained: 3245000
    wait_time_ms: 72.173
  iterations_since_restore: 649
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5654.576234817505
  time_this_iter_s: 8.562009572982788
  time_total_s: 5654.576234817505
  timestamp: 1594854168
  timesteps_since_restore: 3245000
  timesteps_this_iter: 5000
  timesteps_total: 3245000
  training_iteration: 649
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5654 s, 649 iter, 3245000 ts, 311 rew

agent-1: 45.39999999727532
agent-2: 43.39999999727532
agent-3: 40.39999999727533
agent-4: 48.39999999727534
agent-5: 38.39999999727534
Extrinsic Rewards:
7
5
2
10
0
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.4166666666666667
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-02-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 313.5696642828014
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 649
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.23
    dispatch_time_ms: 9.84
    learner:
      cur_lr: 0.0011438829824328423
      grad_gnorm: 16.436222076416016
      policy_entropy: 36.39867401123047
      policy_loss: -2.7627129554748535
      var_gnorm: 22.967010498046875
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.20701180398464203
    num_steps_sampled: 3250000
    num_steps_trained: 3250000
    wait_time_ms: 75.234
  iterations_since_restore: 650
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5663.132513523102
  time_this_iter_s: 8.556278705596924
  time_total_s: 5663.132513523102
  timestamp: 1594854176
  timesteps_since_restore: 3250000
  timesteps_this_iter: 5000
  timesteps_total: 3250000
  training_iteration: 650
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5663 s, 650 iter, 3250000 ts, 314 rew

agent-1: 33.59999999627581
agent-2: 39.5999999962758
agent-3: 39.5999999962758
agent-4: 36.5999999962758
agent-5: 39.5999999962758
Extrinsic Rewards:
0
6
6
3
6
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.2857142857142857
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-03-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 315.4596642826152
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 650
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.039
    dispatch_time_ms: 8.379
    learner:
      cur_lr: 0.0011435500346124172
      grad_gnorm: 21.24217414855957
      policy_entropy: 42.587059020996094
      policy_loss: -3.4610438346862793
      var_gnorm: 22.96959114074707
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.3307674527168274
    num_steps_sampled: 3255000
    num_steps_trained: 3255000
    wait_time_ms: 73.028
  iterations_since_restore: 651
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5671.621916294098
  time_this_iter_s: 8.489402770996094
  time_total_s: 5671.621916294098
  timestamp: 1594854185
  timesteps_since_restore: 3255000
  timesteps_this_iter: 5000
  timesteps_total: 3255000
  training_iteration: 651
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5671 s, 651 iter, 3255000 ts, 315 rew

agent-1: 45.9999999975276
agent-2: 31.999999997527727
agent-3: 32.999999997527645
agent-4: 36.99999999752763
agent-5: 31.999999997527727
Extrinsic Rewards:
14
0
1
5
0
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.66
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-03-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 316.3023674200024
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 651
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.012
    dispatch_time_ms: 10.54
    learner:
      cur_lr: 0.0011432169703766704
      grad_gnorm: 40.0
      policy_entropy: 44.55644989013672
      policy_loss: 66.4825439453125
      var_gnorm: 22.970609664916992
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 67.55419921875
    num_steps_sampled: 3260000
    num_steps_trained: 3260000
    wait_time_ms: 72.831
  iterations_since_restore: 652
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5680.217648029327
  time_this_iter_s: 8.595731735229492
  time_total_s: 5680.217648029327
  timestamp: 1594854193
  timesteps_since_restore: 3260000
  timesteps_this_iter: 5000
  timesteps_total: 3260000
  training_iteration: 652
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5680 s, 652 iter, 3260000 ts, 316 rew

agent-1: 94.3999992754599
agent-2: 97.39999927545993
agent-3: 99.39999927545993
agent-4: 97.39999927545993
agent-5: 97.39999927545988
Extrinsic Rewards:
8
11
13
11
11
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 8
Max Reward: 13
Gini Coefficient: 0.07407407407407407
20:20 Ratio: 1.625
Max-min Ratio: 1.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-03-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 317.5721001808721
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 652
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 9.034
    learner:
      cur_lr: 0.0011428840225562453
      grad_gnorm: 19.63749122619629
      policy_entropy: 31.73011589050293
      policy_loss: -1.9915452003479004
      var_gnorm: 22.984806060791016
      vf_explained_var: 0.0
      vf_loss: 0.25607749819755554
    num_steps_sampled: 3265000
    num_steps_trained: 3265000
    wait_time_ms: 74.408
  iterations_since_restore: 653
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5688.772047758102
  time_this_iter_s: 8.554399728775024
  time_total_s: 5688.772047758102
  timestamp: 1594854202
  timesteps_since_restore: 3265000
  timesteps_this_iter: 5000
  timesteps_total: 3265000
  training_iteration: 653
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5688 s, 653 iter, 3265000 ts, 318 rew

agent-1: 70.19999979975947
agent-2: 71.19999979975948
agent-3: 84.19999979975945
agent-4: 80.19999979975942
agent-5: 72.19999979975945
Extrinsic Rewards:
3
4
17
13
5
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 3
Max Reward: 17
Gini Coefficient: 0.3523809523809524
20:20 Ratio: 5.666666666666667
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-03-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 318.20210017299405
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 653
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.545
    dispatch_time_ms: 5.975
    learner:
      cur_lr: 0.0011425509583204985
      grad_gnorm: 18.30109214782715
      policy_entropy: 41.952125549316406
      policy_loss: -3.1854124069213867
      var_gnorm: 22.976205825805664
      vf_explained_var: 0.0
      vf_loss: 0.24390079081058502
    num_steps_sampled: 3270000
    num_steps_trained: 3270000
    wait_time_ms: 77.48
  iterations_since_restore: 654
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5697.384039878845
  time_this_iter_s: 8.611992120742798
  time_total_s: 5697.384039878845
  timestamp: 1594854211
  timesteps_since_restore: 3270000
  timesteps_this_iter: 5000
  timesteps_total: 3270000
  training_iteration: 654
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5697 s, 654 iter, 3270000 ts, 318 rew

agent-1: 35.39999999892225
agent-2: 33.39999999892225
agent-3: 34.399999998922254
agent-4: 32.399999998922254
agent-5: 35.39999999892224
Extrinsic Rewards:
5
3
4
2
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.16842105263157894
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-03-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 317.9321001730067
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 654
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.019
    dispatch_time_ms: 6.106
    learner:
      cur_lr: 0.0011422180105000734
      grad_gnorm: 20.76537322998047
      policy_entropy: 42.32001495361328
      policy_loss: -3.5192761421203613
      var_gnorm: 22.980981826782227
      vf_explained_var: 0.0
      vf_loss: 0.3251786231994629
    num_steps_sampled: 3275000
    num_steps_trained: 3275000
    wait_time_ms: 73.799
  iterations_since_restore: 655
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5705.932732105255
  time_this_iter_s: 8.548692226409912
  time_total_s: 5705.932732105255
  timestamp: 1594854219
  timesteps_since_restore: 3275000
  timesteps_this_iter: 5000
  timesteps_total: 3275000
  training_iteration: 655
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5705 s, 655 iter, 3275000 ts, 318 rew

agent-1: 47.59999999749632
agent-2: 41.59999999749633
agent-3: 51.599999997496305
agent-4: 47.59999999749632
agent-5: 45.59999999749632
Extrinsic Rewards:
6
0
10
6
4
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.3384615384615385
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-03-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 320.0921001728832
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 655
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.836
    dispatch_time_ms: 8.862
    learner:
      cur_lr: 0.0011418849462643266
      grad_gnorm: 17.812944412231445
      policy_entropy: 42.48468780517578
      policy_loss: -3.748136043548584
      var_gnorm: 22.983253479003906
      vf_explained_var: 0.0
      vf_loss: 0.24180585145950317
    num_steps_sampled: 3280000
    num_steps_trained: 3280000
    wait_time_ms: 75.873
  iterations_since_restore: 656
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5714.551332950592
  time_this_iter_s: 8.618600845336914
  time_total_s: 5714.551332950592
  timestamp: 1594854228
  timesteps_since_restore: 3280000
  timesteps_this_iter: 5000
  timesteps_total: 3280000
  training_iteration: 656
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5714 s, 656 iter, 3280000 ts, 320 rew

agent-1: 56.79999999401829
agent-2: 45.799999994018314
agent-3: 49.79999999401829
agent-4: 46.799999994018314
agent-5: 52.79999999401829
Extrinsic Rewards:
12
1
5
2
8
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.4
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-03-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 322.16210017258834
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 656
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.023
    dispatch_time_ms: 7.692
    learner:
      cur_lr: 0.0011415519984439015
      grad_gnorm: 12.773059844970703
      policy_entropy: 31.887447357177734
      policy_loss: -2.1289494037628174
      var_gnorm: 22.985872268676758
      vf_explained_var: 0.0
      vf_loss: 0.12540894746780396
    num_steps_sampled: 3285000
    num_steps_trained: 3285000
    wait_time_ms: 76.654
  iterations_since_restore: 657
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5723.302644491196
  time_this_iter_s: 8.751311540603638
  time_total_s: 5723.302644491196
  timestamp: 1594854237
  timesteps_since_restore: 3285000
  timesteps_this_iter: 5000
  timesteps_total: 3285000
  training_iteration: 657
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5723 s, 657 iter, 3285000 ts, 322 rew

agent-1: 45.9999999981303
agent-2: 42.999999998130285
agent-3: 45.9999999981303
agent-4: 46.999999998130285
agent-5: 42.999999998130285
Extrinsic Rewards:
6
3
6
7
3
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.176
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-04-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 324.0521001724982
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 657
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.301
    dispatch_time_ms: 8.895
    learner:
      cur_lr: 0.0011412190506234765
      grad_gnorm: 19.684524536132812
      policy_entropy: 31.68132781982422
      policy_loss: -3.2077317237854004
      var_gnorm: 22.98836898803711
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.2966962456703186
    num_steps_sampled: 3290000
    num_steps_trained: 3290000
    wait_time_ms: 74.592
  iterations_since_restore: 658
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5731.86980175972
  time_this_iter_s: 8.56715726852417
  time_total_s: 5731.86980175972
  timestamp: 1594854245
  timesteps_since_restore: 3290000
  timesteps_this_iter: 5000
  timesteps_total: 3290000
  training_iteration: 658
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5731 s, 658 iter, 3290000 ts, 324 rew

agent-1: 33.19999999883858
agent-2: 29.199999998838607
agent-3: 32.19999999883859
agent-4: 31.199999998838607
agent-5: 27.199999998838607
Extrinsic Rewards:
6
2
5
4
0
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.35294117647058826
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-04-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 325.58210017244016
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 658
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.619
    dispatch_time_ms: 9.763
    learner:
      cur_lr: 0.0011408859863877296
      grad_gnorm: 4.586822509765625
      policy_entropy: 46.216461181640625
      policy_loss: -3.1709365844726562
      var_gnorm: 22.97916603088379
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.04411424323916435
    num_steps_sampled: 3295000
    num_steps_trained: 3295000
    wait_time_ms: 1060.895
  iterations_since_restore: 659
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5750.467491865158
  time_this_iter_s: 18.597690105438232
  time_total_s: 5750.467491865158
  timestamp: 1594854264
  timesteps_since_restore: 3295000
  timesteps_this_iter: 5000
  timesteps_total: 3295000
  training_iteration: 659
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5750 s, 659 iter, 3295000 ts, 326 rew

agent-1: 78.79999996093665
agent-2: 79.79999996093665
agent-3: 71.79999996093665
agent-4: 82.79999996093665
agent-5: 73.79999996093666
Extrinsic Rewards:
10
11
3
14
5
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.26046511627906976
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-04-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 329.0021001704912
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 659
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.601
    dispatch_time_ms: 9.509
    learner:
      cur_lr: 0.0011405530385673046
      grad_gnorm: 6.576695442199707
      policy_entropy: 57.117366790771484
      policy_loss: -1.786831021308899
      var_gnorm: 22.98027801513672
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.029880011454224586
    num_steps_sampled: 3300000
    num_steps_trained: 3300000
    wait_time_ms: 74.363
  iterations_since_restore: 660
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5758.450259208679
  time_this_iter_s: 7.982767343521118
  time_total_s: 5758.450259208679
  timestamp: 1594854272
  timesteps_since_restore: 3300000
  timesteps_this_iter: 5000
  timesteps_total: 3300000
  training_iteration: 660
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5758 s, 660 iter, 3300000 ts, 329 rew

agent-1: 34.79999999931616
agent-2: 33.79999999931615
agent-3: 29.79999999931624
agent-4: 31.799999999316245
agent-5: 31.799999999316245
Extrinsic Rewards:
6
5
1
3
3
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-04-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 329.8121162892585
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 660
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.63
    dispatch_time_ms: 5.763
    learner:
      cur_lr: 0.0011402199743315578
      grad_gnorm: 12.521498680114746
      policy_entropy: 43.5848274230957
      policy_loss: -2.924121618270874
      var_gnorm: 22.98522186279297
      vf_explained_var: 0.0
      vf_loss: 0.11761204153299332
    num_steps_sampled: 3305000
    num_steps_trained: 3305000
    wait_time_ms: 75.461
  iterations_since_restore: 661
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5767.0186269283295
  time_this_iter_s: 8.568367719650269
  time_total_s: 5767.0186269283295
  timestamp: 1594854280
  timesteps_since_restore: 3305000
  timesteps_this_iter: 5000
  timesteps_total: 3305000
  training_iteration: 661
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5767 s, 661 iter, 3305000 ts, 330 rew

agent-1: 38.99999999885749
agent-2: 35.99999999885748
agent-3: 35.99999999885748
agent-4: 33.999999998857476
agent-5: 34.99999999885748
Extrinsic Rewards:
7
4
4
2
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.22
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-04-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 331.43211628920295
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 661
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.568
    dispatch_time_ms: 7.323
    learner:
      cur_lr: 0.0011398870265111327
      grad_gnorm: 19.632568359375
      policy_entropy: 48.84419250488281
      policy_loss: -4.1241984367370605
      var_gnorm: 22.986541748046875
      vf_explained_var: 0.0
      vf_loss: 0.27660393714904785
    num_steps_sampled: 3310000
    num_steps_trained: 3310000
    wait_time_ms: 78.934
  iterations_since_restore: 662
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5775.748483657837
  time_this_iter_s: 8.729856729507446
  time_total_s: 5775.748483657837
  timestamp: 1594854289
  timesteps_since_restore: 3310000
  timesteps_this_iter: 5000
  timesteps_total: 3310000
  training_iteration: 662
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5775 s, 662 iter, 3310000 ts, 331 rew

agent-1: 47.19999999841416
agent-2: 52.199999998414164
agent-3: 51.19999999841416
agent-4: 44.19999999841416
agent-5: 48.199999998414164
Extrinsic Rewards:
4
9
8
1
5
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.2962962962962963
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-04-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 333.4121162891422
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 662
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.32
    dispatch_time_ms: 8.63
    learner:
      cur_lr: 0.0011395539622753859
      grad_gnorm: 8.006896018981934
      policy_entropy: 42.8304443359375
      policy_loss: -1.7538433074951172
      var_gnorm: 22.98333740234375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0466618686914444
    num_steps_sampled: 3315000
    num_steps_trained: 3315000
    wait_time_ms: 73.673
  iterations_since_restore: 663
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5784.353196382523
  time_this_iter_s: 8.604712724685669
  time_total_s: 5784.353196382523
  timestamp: 1594854298
  timesteps_since_restore: 3315000
  timesteps_this_iter: 5000
  timesteps_total: 3315000
  training_iteration: 663
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5784 s, 663 iter, 3315000 ts, 333 rew

agent-1: 41.399999998166834
agent-2: 38.39999999816683
agent-3: 45.39999999816685
agent-4: 50.399999998166855
agent-5: 40.399999998166834
Extrinsic Rewards:
3
0
7
12
2
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.48333333333333334
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-05-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 334.9421162893214
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 663
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.158
    dispatch_time_ms: 7.126
    learner:
      cur_lr: 0.0011392210144549608
      grad_gnorm: 39.999996185302734
      policy_entropy: 43.79792022705078
      policy_loss: 57.5888671875
      var_gnorm: 22.9809513092041
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 41.55769348144531
    num_steps_sampled: 3320000
    num_steps_trained: 3320000
    wait_time_ms: 74.564
  iterations_since_restore: 664
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5792.898501873016
  time_this_iter_s: 8.545305490493774
  time_total_s: 5792.898501873016
  timestamp: 1594854306
  timesteps_since_restore: 3320000
  timesteps_this_iter: 5000
  timesteps_total: 3320000
  training_iteration: 664
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5792 s, 664 iter, 3320000 ts, 335 rew

agent-1: 64.19999999571533
agent-2: 52.199999995715366
agent-3: 63.199999995715366
agent-4: 54.199999995715366
agent-5: 54.19999999571537
Extrinsic Rewards:
13
1
12
3
3
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.4125
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-05-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 337.6421162891088
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 664
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.144
    dispatch_time_ms: 8.969
    learner:
      cur_lr: 0.001138887950219214
      grad_gnorm: 21.35627555847168
      policy_entropy: 42.2650260925293
      policy_loss: -5.6950225830078125
      var_gnorm: 22.980920791625977
      vf_explained_var: 0.0
      vf_loss: 0.33597999811172485
    num_steps_sampled: 3325000
    num_steps_trained: 3325000
    wait_time_ms: 73.857
  iterations_since_restore: 665
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5801.4818477630615
  time_this_iter_s: 8.583345890045166
  time_total_s: 5801.4818477630615
  timestamp: 1594854315
  timesteps_since_restore: 3325000
  timesteps_this_iter: 5000
  timesteps_total: 3325000
  training_iteration: 665
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5801 s, 665 iter, 3325000 ts, 338 rew

agent-1: 56.79999984639517
agent-2: 57.79999984639517
agent-3: 62.79999984639517
agent-4: 58.79999984639517
agent-5: 60.79999984639517
Extrinsic Rewards:
4
5
10
6
8
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 4
Max Reward: 10
Gini Coefficient: 0.18181818181818182
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-05-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 340.25211628143205
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 665
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.91
    dispatch_time_ms: 7.159
    learner:
      cur_lr: 0.001138555002398789
      grad_gnorm: 20.713539123535156
      policy_entropy: 59.57548522949219
      policy_loss: -6.460762023925781
      var_gnorm: 22.98903465270996
      vf_explained_var: 0.0
      vf_loss: 0.32212841510772705
    num_steps_sampled: 3330000
    num_steps_trained: 3330000
    wait_time_ms: 77.222
  iterations_since_restore: 666
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5810.077199935913
  time_this_iter_s: 8.595352172851562
  time_total_s: 5810.077199935913
  timestamp: 1594854324
  timesteps_since_restore: 3330000
  timesteps_this_iter: 5000
  timesteps_total: 3330000
  training_iteration: 666
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5810 s, 666 iter, 3330000 ts, 340 rew

agent-1: 31.399999998805825
agent-2: 40.39999999880589
agent-3: 31.399999998805832
agent-4: 35.3999999988059
agent-5: 32.39999999880587
Extrinsic Rewards:
1
10
1
5
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.4631578947368421
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-05-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 341.222603936848
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 666
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 8.069
    learner:
      cur_lr: 0.001138222054578364
      grad_gnorm: 22.433677673339844
      policy_entropy: 54.0968132019043
      policy_loss: -6.765513896942139
      var_gnorm: 22.987773895263672
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.36559948325157166
    num_steps_sampled: 3335000
    num_steps_trained: 3335000
    wait_time_ms: 77.148
  iterations_since_restore: 667
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5818.738141536713
  time_this_iter_s: 8.66094160079956
  time_total_s: 5818.738141536713
  timestamp: 1594854332
  timesteps_since_restore: 3335000
  timesteps_this_iter: 5000
  timesteps_total: 3335000
  training_iteration: 667
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5818 s, 667 iter, 3335000 ts, 341 rew

agent-1: 72.79999999289554
agent-2: 63.799999992895664
agent-3: 68.79999999289555
agent-4: 69.79999999289556
agent-5: 66.79999999289555
Extrinsic Rewards:
12
3
8
9
6
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.22105263157894736
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-05-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 344.1926066074117
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 667
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.268
    dispatch_time_ms: 10.245
    learner:
      cur_lr: 0.001137888990342617
      grad_gnorm: 40.000003814697266
      policy_entropy: 36.28684997558594
      policy_loss: 39.61481475830078
      var_gnorm: 22.983022689819336
      vf_explained_var: 0.0
      vf_loss: 17.77056312561035
    num_steps_sampled: 3340000
    num_steps_trained: 3340000
    wait_time_ms: 73.075
  iterations_since_restore: 668
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5827.233031988144
  time_this_iter_s: 8.494890451431274
  time_total_s: 5827.233031988144
  timestamp: 1594854341
  timesteps_since_restore: 3340000
  timesteps_this_iter: 5000
  timesteps_total: 3340000
  training_iteration: 668
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5827 s, 668 iter, 3340000 ts, 344 rew

agent-1: 45.19999999578427
agent-2: 55.19999999578427
agent-3: 43.19999999578427
agent-4: 50.19999999578427
agent-5: 49.19999999578425
Extrinsic Rewards:
2
12
0
7
6
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.42962962962962964
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-05-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 345.02591165997603
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 668
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.002
    dispatch_time_ms: 7.591
    learner:
      cur_lr: 0.001137556042522192
      grad_gnorm: 40.000003814697266
      policy_entropy: 50.30313491821289
      policy_loss: 25.673429489135742
      var_gnorm: 23.009748458862305
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 8.568282127380371
    num_steps_sampled: 3345000
    num_steps_trained: 3345000
    wait_time_ms: 74.455
  iterations_since_restore: 669
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5835.717621088028
  time_this_iter_s: 8.484589099884033
  time_total_s: 5835.717621088028
  timestamp: 1594854349
  timesteps_since_restore: 3345000
  timesteps_this_iter: 5000
  timesteps_total: 3345000
  training_iteration: 669
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5835 s, 669 iter, 3345000 ts, 345 rew

agent-1: 155.7886509363848
agent-2: 149.78865093638484
agent-3: 143.7886509363848
agent-4: 145.7886509363848
agent-5: 151.7886509363848
Extrinsic Rewards:
23
17
11
13
19
Sum Reward: 83
Avg Reward: 16.6
Min Reward: 11
Max Reward: 23
Gini Coefficient: 0.14457831325301204
20:20 Ratio: 2.090909090909091
Max-min Ratio: 2.090909090909091
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-05-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 348.2653451289997
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 669
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 7.771
    learner:
      cur_lr: 0.0011372229782864451
      grad_gnorm: 40.0
      policy_entropy: 52.19989776611328
      policy_loss: 55.106849670410156
      var_gnorm: 22.99903678894043
      vf_explained_var: 0.0
      vf_loss: 44.851863861083984
    num_steps_sampled: 3350000
    num_steps_trained: 3350000
    wait_time_ms: 77.808
  iterations_since_restore: 670
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5844.255695343018
  time_this_iter_s: 8.538074254989624
  time_total_s: 5844.255695343018
  timestamp: 1594854358
  timesteps_since_restore: 3350000
  timesteps_this_iter: 5000
  timesteps_total: 3350000
  training_iteration: 670
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5844 s, 670 iter, 3350000 ts, 348 rew

agent-1: 48.799999954297405
agent-2: 55.799999954297384
agent-3: 45.79999995429741
agent-4: 55.79999995429739
agent-5: 45.79999995429741
Extrinsic Rewards:
4
11
1
11
1
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.42857142857142855
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-06-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 348.4453451268222
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 670
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.727
    dispatch_time_ms: 11.335
    learner:
      cur_lr: 0.00113689003046602
      grad_gnorm: 25.86627769470215
      policy_entropy: 63.59060287475586
      policy_loss: -8.46755599975586
      var_gnorm: 23.00005340576172
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.50016188621521
    num_steps_sampled: 3355000
    num_steps_trained: 3355000
    wait_time_ms: 74.903
  iterations_since_restore: 671
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5852.776480436325
  time_this_iter_s: 8.520785093307495
  time_total_s: 5852.776480436325
  timestamp: 1594854367
  timesteps_since_restore: 3355000
  timesteps_this_iter: 5000
  timesteps_total: 3355000
  training_iteration: 671
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5852 s, 671 iter, 3355000 ts, 348 rew

agent-1: 88.79999944775062
agent-2: 78.79999944775062
agent-3: 83.7999994477506
agent-4: 86.79999944775062
agent-5: 93.79999944775057
Extrinsic Rewards:
12
2
7
10
17
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 2
Max Reward: 17
Gini Coefficient: 0.2916666666666667
20:20 Ratio: 8.5
Max-min Ratio: 8.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-06-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 350.5153450992541
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 671
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.42
    dispatch_time_ms: 9.484
    learner:
      cur_lr: 0.0011365569662302732
      grad_gnorm: 10.748767852783203
      policy_entropy: 60.140846252441406
      policy_loss: -2.875199794769287
      var_gnorm: 23.000547409057617
      vf_explained_var: 0.0
      vf_loss: 0.08434942364692688
    num_steps_sampled: 3360000
    num_steps_trained: 3360000
    wait_time_ms: 74.634
  iterations_since_restore: 672
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5861.373824596405
  time_this_iter_s: 8.597344160079956
  time_total_s: 5861.373824596405
  timestamp: 1594854375
  timesteps_since_restore: 3360000
  timesteps_this_iter: 5000
  timesteps_total: 3360000
  training_iteration: 672
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5861 s, 672 iter, 3360000 ts, 351 rew

agent-1: 35.199999998401104
agent-2: 44.19999999840109
agent-3: 37.199999998401104
agent-4: 39.19999999840109
agent-5: 42.199999998401104
Extrinsic Rewards:
0
9
2
4
7
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.41818181818181815
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-06-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 349.7953450994425
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 672
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 6.807
    learner:
      cur_lr: 0.0011362240184098482
      grad_gnorm: 15.699146270751953
      policy_entropy: 62.23421096801758
      policy_loss: -4.7466206550598145
      var_gnorm: 22.997455596923828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.16656287014484406
    num_steps_sampled: 3365000
    num_steps_trained: 3365000
    wait_time_ms: 72.741
  iterations_since_restore: 673
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5870.100482940674
  time_this_iter_s: 8.726658344268799
  time_total_s: 5870.100482940674
  timestamp: 1594854384
  timesteps_since_restore: 3365000
  timesteps_this_iter: 5000
  timesteps_total: 3365000
  training_iteration: 673
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5870 s, 673 iter, 3365000 ts, 350 rew

agent-1: 28.79999999930528
agent-2: 29.79999999930528
agent-3: 36.79999999930522
agent-4: 32.7999999993052
agent-5: 33.799999999305214
Extrinsic Rewards:
0
1
8
4
5
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4444444444444444
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-06-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 348.71534510135336
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 673
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.293
    dispatch_time_ms: 8.858
    learner:
      cur_lr: 0.0011358909541741014
      grad_gnorm: 10.298762321472168
      policy_entropy: 59.39654541015625
      policy_loss: -2.9115591049194336
      var_gnorm: 22.99785804748535
      vf_explained_var: 0.0
      vf_loss: 0.07821300625801086
    num_steps_sampled: 3370000
    num_steps_trained: 3370000
    wait_time_ms: 75.366
  iterations_since_restore: 674
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5878.714130163193
  time_this_iter_s: 8.613647222518921
  time_total_s: 5878.714130163193
  timestamp: 1594854393
  timesteps_since_restore: 3370000
  timesteps_this_iter: 5000
  timesteps_total: 3370000
  training_iteration: 674
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5878 s, 674 iter, 3370000 ts, 349 rew

agent-1: 40.19999999929252
agent-2: 41.199999999292515
agent-3: 37.199999999292544
agent-4: 37.199999999292544
agent-5: 42.199999999292515
Extrinsic Rewards:
5
6
2
2
7
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-06-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 347.7253451023715
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 674
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.887
    dispatch_time_ms: 5.807
    learner:
      cur_lr: 0.0011355580063536763
      grad_gnorm: 16.55499839782715
      policy_entropy: 24.55072021484375
      policy_loss: -1.5986409187316895
      var_gnorm: 22.99053955078125
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.20963522791862488
    num_steps_sampled: 3375000
    num_steps_trained: 3375000
    wait_time_ms: 76.388
  iterations_since_restore: 675
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5887.203814506531
  time_this_iter_s: 8.489684343338013
  time_total_s: 5887.203814506531
  timestamp: 1594854401
  timesteps_since_restore: 3375000
  timesteps_this_iter: 5000
  timesteps_total: 3375000
  training_iteration: 675
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5887 s, 675 iter, 3375000 ts, 348 rew

agent-1: 49.799999996068635
agent-2: 47.799999996068635
agent-3: 47.799999996068635
agent-4: 46.799999996068635
agent-5: 59.79999999606865
Extrinsic Rewards:
5
3
3
2
15
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.4
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-06-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 344.48535134925316
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 675
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.902
    dispatch_time_ms: 7.135
    learner:
      cur_lr: 0.0011352249421179295
      grad_gnorm: 40.000003814697266
      policy_entropy: 53.19618225097656
      policy_loss: 41.556949615478516
      var_gnorm: 23.001134872436523
      vf_explained_var: 0.0
      vf_loss: 22.450634002685547
    num_steps_sampled: 3380000
    num_steps_trained: 3380000
    wait_time_ms: 76.276
  iterations_since_restore: 676
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5895.688991308212
  time_this_iter_s: 8.485176801681519
  time_total_s: 5895.688991308212
  timestamp: 1594854410
  timesteps_since_restore: 3380000
  timesteps_this_iter: 5000
  timesteps_total: 3380000
  training_iteration: 676
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5895 s, 676 iter, 3380000 ts, 344 rew

agent-1: 97.99999192557846
agent-2: 105.99999192557848
agent-3: 100.99999192557847
agent-4: 96.99999192557847
agent-5: 92.99999192557844
Extrinsic Rewards:
10
18
13
9
5
Sum Reward: 55
Avg Reward: 11.0
Min Reward: 5
Max Reward: 18
Gini Coefficient: 0.21818181818181817
20:20 Ratio: 3.6
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-06-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 347.09535094572783
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 676
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.558
    dispatch_time_ms: 7.783
    learner:
      cur_lr: 0.0011348919942975044
      grad_gnorm: 20.823814392089844
      policy_entropy: 54.734619140625
      policy_loss: -5.493663787841797
      var_gnorm: 22.998151779174805
      vf_explained_var: 0.0
      vf_loss: 0.3194272816181183
    num_steps_sampled: 3385000
    num_steps_trained: 3385000
    wait_time_ms: 72.973
  iterations_since_restore: 677
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5904.318648576736
  time_this_iter_s: 8.62965726852417
  time_total_s: 5904.318648576736
  timestamp: 1594854418
  timesteps_since_restore: 3385000
  timesteps_this_iter: 5000
  timesteps_total: 3385000
  training_iteration: 677
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5904 s, 677 iter, 3385000 ts, 347 rew

agent-1: 73.39999991939082
agent-2: 77.39999991939086
agent-3: 63.39999991939096
agent-4: 70.3999999193908
agent-5: 66.39999991939078
Extrinsic Rewards:
11
15
1
8
4
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 1
Max Reward: 15
Gini Coefficient: 0.358974358974359
20:20 Ratio: 15.0
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-07-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 346.7353512441758
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 677
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 8.023
    learner:
      cur_lr: 0.0011345590464770794
      grad_gnorm: 12.127617835998535
      policy_entropy: 52.872920989990234
      policy_loss: -3.0203301906585693
      var_gnorm: 22.999536514282227
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.11029234528541565
    num_steps_sampled: 3390000
    num_steps_trained: 3390000
    wait_time_ms: 75.934
  iterations_since_restore: 678
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5912.972448587418
  time_this_iter_s: 8.653800010681152
  time_total_s: 5912.972448587418
  timestamp: 1594854427
  timesteps_since_restore: 3390000
  timesteps_this_iter: 5000
  timesteps_total: 3390000
  training_iteration: 678
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5912 s, 678 iter, 3390000 ts, 347 rew

agent-1: 49.39999999776857
agent-2: 52.39999999776857
agent-3: 54.39999999776857
agent-4: 46.39999999776858
agent-5: 58.39999999776857
Extrinsic Rewards:
3
6
8
0
12
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-07-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1070.9765155354546
  episode_reward_mean: 347.36535124412956
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 678
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 6.575
    learner:
      cur_lr: 0.0011342259822413325
      grad_gnorm: 6.200011730194092
      policy_entropy: 57.101890563964844
      policy_loss: 1.9818726778030396
      var_gnorm: 23.000686645507812
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.03247637674212456
    num_steps_sampled: 3395000
    num_steps_trained: 3395000
    wait_time_ms: 77.451
  iterations_since_restore: 679
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5921.568474054337
  time_this_iter_s: 8.596025466918945
  time_total_s: 5921.568474054337
  timestamp: 1594854436
  timesteps_since_restore: 3395000
  timesteps_this_iter: 5000
  timesteps_total: 3395000
  training_iteration: 679
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5921 s, 679 iter, 3395000 ts, 347 rew

agent-1: 35.59999999926359
agent-2: 40.59999999926361
agent-3: 36.59999999926359
agent-4: 37.599999999263595
agent-5: 38.5999999992636
Extrinsic Rewards:
2
7
3
4
5
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.22857142857142856
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-07-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 890.8224278089792
  episode_reward_mean: 338.5455860887383
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 679
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.248
    dispatch_time_ms: 5.693
    learner:
      cur_lr: 0.0011338930344209075
      grad_gnorm: 9.206952095031738
      policy_entropy: 62.3786735534668
      policy_loss: -2.7586374282836914
      var_gnorm: 23.004446029663086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.061121657490730286
    num_steps_sampled: 3400000
    num_steps_trained: 3400000
    wait_time_ms: 76.2
  iterations_since_restore: 680
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5930.164443969727
  time_this_iter_s: 8.595969915390015
  time_total_s: 5930.164443969727
  timestamp: 1594854444
  timesteps_since_restore: 3400000
  timesteps_this_iter: 5000
  timesteps_total: 3400000
  training_iteration: 680
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5930 s, 680 iter, 3400000 ts, 339 rew

agent-1: 50.999999997220165
agent-2: 40.99999999722017
agent-3: 44.99999999722017
agent-4: 45.99999999722017
agent-5: 41.99999999722017
Extrinsic Rewards:
11
1
5
6
2
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.384
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-07-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 890.8224278089792
  episode_reward_mean: 333.95558638494117
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 680
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.478
    dispatch_time_ms: 30.885
    learner:
      cur_lr: 0.0011335599701851606
      grad_gnorm: 39.999996185302734
      policy_entropy: 54.457401275634766
      policy_loss: 22.99822425842285
      var_gnorm: 23.004940032958984
      vf_explained_var: 0.0
      vf_loss: 5.8433518409729
    num_steps_sampled: 3405000
    num_steps_trained: 3405000
    wait_time_ms: 55.219
  iterations_since_restore: 681
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5939.094984292984
  time_this_iter_s: 8.930540323257446
  time_total_s: 5939.094984292984
  timestamp: 1594854453
  timesteps_since_restore: 3405000
  timesteps_this_iter: 5000
  timesteps_total: 3405000
  training_iteration: 681
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5939 s, 681 iter, 3405000 ts, 334 rew

agent-1: 42.99999999681652
agent-2: 43.99999999681651
agent-3: 47.99999999681653
agent-4: 41.99999999681651
agent-5: 47.99999999681651
Extrinsic Rewards:
3
4
8
2
8
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.272
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-07-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 890.8224278089792
  episode_reward_mean: 333.68558638503623
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 681
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 34.103
    learner:
      cur_lr: 0.0011332270223647356
      grad_gnorm: 33.15182876586914
      policy_entropy: 15.215129852294922
      policy_loss: -1.0928032398223877
      var_gnorm: 23.005111694335938
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.7547521591186523
    num_steps_sampled: 3410000
    num_steps_trained: 3410000
    wait_time_ms: 65.83
  iterations_since_restore: 682
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5948.19965839386
  time_this_iter_s: 9.104674100875854
  time_total_s: 5948.19965839386
  timestamp: 1594854462
  timesteps_since_restore: 3410000
  timesteps_this_iter: 5000
  timesteps_total: 3410000
  training_iteration: 682
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5948 s, 682 iter, 3410000 ts, 334 rew

agent-1: 65.59999998463405
agent-2: 69.59999998463405
agent-3: 59.5999999846341
agent-4: 67.59999998463408
agent-5: 61.5999999846341
Extrinsic Rewards:
8
12
2
10
4
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.28888888888888886
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-07-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 890.8224278089792
  episode_reward_mean: 334.04558638445377
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 682
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.37
    dispatch_time_ms: 39.615
    learner:
      cur_lr: 0.0011328939581289887
      grad_gnorm: 40.0
      policy_entropy: 31.101469039916992
      policy_loss: -9.543089866638184
      var_gnorm: 23.013700485229492
      vf_explained_var: 0.0
      vf_loss: 2.603914737701416
    num_steps_sampled: 3415000
    num_steps_trained: 3415000
    wait_time_ms: 38.011
  iterations_since_restore: 683
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5957.21693944931
  time_this_iter_s: 9.01728105545044
  time_total_s: 5957.21693944931
  timestamp: 1594854471
  timesteps_since_restore: 3415000
  timesteps_this_iter: 5000
  timesteps_total: 3415000
  training_iteration: 683
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5957 s, 683 iter, 3415000 ts, 334 rew

agent-1: 143.9990967009494
agent-2: 140.9990967009494
agent-3: 140.99909670094937
agent-4: 147.99909670094937
agent-5: 145.99909670094937
Extrinsic Rewards:
16
13
13
20
18
Sum Reward: 80
Avg Reward: 16.0
Min Reward: 13
Max Reward: 20
Gini Coefficient: 0.095
20:20 Ratio: 1.5384615384615385
Max-min Ratio: 1.5384615384615385
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-08-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 890.8224278089792
  episode_reward_mean: 335.1255440266861
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 683
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.649
    dispatch_time_ms: 16.138
    learner:
      cur_lr: 0.0011325610103085637
      grad_gnorm: 4.070584774017334
      policy_entropy: 0.08534616231918335
      policy_loss: -0.0004323924658820033
      var_gnorm: 23.015518188476562
      vf_explained_var: 0.0
      vf_loss: 0.012832488864660263
    num_steps_sampled: 3420000
    num_steps_trained: 3420000
    wait_time_ms: 70.287
  iterations_since_restore: 684
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5970.747873783112
  time_this_iter_s: 13.53093433380127
  time_total_s: 5970.747873783112
  timestamp: 1594854485
  timesteps_since_restore: 3420000
  timesteps_this_iter: 5000
  timesteps_total: 3420000
  training_iteration: 684
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5970 s, 684 iter, 3420000 ts, 335 rew

agent-1: 56.59999999634678
agent-2: 59.59999999634677
agent-3: 52.59999999634678
agent-4: 56.59999999634678
agent-5: 53.59999999634678
Extrinsic Rewards:
7
10
3
7
4
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.21935483870967742
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-08-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 890.8224278089792
  episode_reward_mean: 330.7155461451112
  episode_reward_min: 8.920213384284745
  episodes_this_iter: 1
  episodes_total: 684
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.078
    dispatch_time_ms: 21.786
    learner:
      cur_lr: 0.0011322279460728168
      grad_gnorm: 0.02258857525885105
      policy_entropy: 0.08556093275547028
      policy_loss: 1.637252921682375e-06
      var_gnorm: 23.01548194885254
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.9531335005449364e-07
    num_steps_sampled: 3425000
    num_steps_trained: 3425000
    wait_time_ms: 58.446
  iterations_since_restore: 685
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5979.1803550720215
  time_this_iter_s: 8.432481288909912
  time_total_s: 5979.1803550720215
  timestamp: 1594854493
  timesteps_since_restore: 3425000
  timesteps_this_iter: 5000
  timesteps_total: 3425000
  training_iteration: 685
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5979 s, 685 iter, 3425000 ts, 331 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-08-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 890.8224278089792
  episode_reward_mean: 327.025546151809
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 685
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 24.618
    learner:
      cur_lr: 0.0011318949982523918
      grad_gnorm: 0.005625367630273104
      policy_entropy: 0.08568522334098816
      policy_loss: 1.0305984687875025e-07
      var_gnorm: 23.015485763549805
      vf_explained_var: 0.0
      vf_loss: 2.436037505049171e-08
    num_steps_sampled: 3430000
    num_steps_trained: 3430000
    wait_time_ms: 36.714
  iterations_since_restore: 686
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5987.692619800568
  time_this_iter_s: 8.512264728546143
  time_total_s: 5987.692619800568
  timestamp: 1594854502
  timesteps_since_restore: 3430000
  timesteps_this_iter: 5000
  timesteps_total: 3430000
  training_iteration: 686
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5987 s, 686 iter, 3430000 ts, 327 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-08-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 890.8224278089792
  episode_reward_mean: 325.49554615183786
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 686
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.004
    dispatch_time_ms: 45.33
    learner:
      cur_lr: 0.0011315620504319668
      grad_gnorm: 0.009221862070262432
      policy_entropy: 0.08581847697496414
      policy_loss: 9.145428521151189e-07
      var_gnorm: 23.015491485595703
      vf_explained_var: 0.0
      vf_loss: 9.033811920744483e-08
    num_steps_sampled: 3435000
    num_steps_trained: 3435000
    wait_time_ms: 48.474
  iterations_since_restore: 687
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 5996.1863832473755
  time_this_iter_s: 8.493763446807861
  time_total_s: 5996.1863832473755
  timestamp: 1594854510
  timesteps_since_restore: 3435000
  timesteps_this_iter: 5000
  timesteps_total: 3435000
  training_iteration: 687
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 5996 s, 687 iter, 3435000 ts, 325 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-08-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 890.8224278089792
  episode_reward_mean: 321.6255461588452
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 687
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.12
    dispatch_time_ms: 8.821
    learner:
      cur_lr: 0.00113122898619622
      grad_gnorm: 0.0035916909109801054
      policy_entropy: 0.0859549269080162
      policy_loss: 2.8522327966129524e-07
      var_gnorm: 23.01549530029297
      vf_explained_var: 0.0
      vf_loss: 9.710299231358022e-09
    num_steps_sampled: 3440000
    num_steps_trained: 3440000
    wait_time_ms: 68.091
  iterations_since_restore: 688
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6004.418236017227
  time_this_iter_s: 8.231852769851685
  time_total_s: 6004.418236017227
  timestamp: 1594854519
  timesteps_since_restore: 3440000
  timesteps_this_iter: 5000
  timesteps_total: 3440000
  training_iteration: 688
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6004 s, 688 iter, 3440000 ts, 322 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-08-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 312.71732188075543
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 688
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.702
    dispatch_time_ms: 9.464
    learner:
      cur_lr: 0.0011308960383757949
      grad_gnorm: 0.010635728016495705
      policy_entropy: 0.08609592914581299
      policy_loss: 5.205675392971898e-07
      var_gnorm: 23.0154972076416
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 8.751828772801673e-08
    num_steps_sampled: 3445000
    num_steps_trained: 3445000
    wait_time_ms: 71.409
  iterations_since_restore: 689
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6012.3698263168335
  time_this_iter_s: 7.951590299606323
  time_total_s: 6012.3698263168335
  timestamp: 1594854527
  timesteps_since_restore: 3445000
  timesteps_this_iter: 5000
  timesteps_total: 3445000
  training_iteration: 689
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6012 s, 689 iter, 3445000 ts, 313 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-08-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 306.8673223274049
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 689
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.174
    dispatch_time_ms: 9.298
    learner:
      cur_lr: 0.001130562974140048
      grad_gnorm: 0.0030523529276251793
      policy_entropy: 0.08624778687953949
      policy_loss: 2.241906287281381e-07
      var_gnorm: 23.015501022338867
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.989706147209063e-09
    num_steps_sampled: 3450000
    num_steps_trained: 3450000
    wait_time_ms: 67.93
  iterations_since_restore: 690
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6020.278737068176
  time_this_iter_s: 7.908910751342773
  time_total_s: 6020.278737068176
  timestamp: 1594854535
  timesteps_since_restore: 3450000
  timesteps_this_iter: 5000
  timesteps_total: 3450000
  training_iteration: 690
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6020 s, 690 iter, 3450000 ts, 307 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-09-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 304.0773223276163
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 690
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.825
    dispatch_time_ms: 8.725
    learner:
      cur_lr: 0.001130230026319623
      grad_gnorm: 0.010161115787923336
      policy_entropy: 0.0864122211933136
      policy_loss: 5.162813181414094e-07
      var_gnorm: 23.0155086517334
      vf_explained_var: 0.0
      vf_loss: 7.986686512140295e-08
    num_steps_sampled: 3455000
    num_steps_trained: 3455000
    wait_time_ms: 69.046
  iterations_since_restore: 691
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6028.221653699875
  time_this_iter_s: 7.942916631698608
  time_total_s: 6028.221653699875
  timestamp: 1594854543
  timesteps_since_restore: 3455000
  timesteps_this_iter: 5000
  timesteps_total: 3455000
  training_iteration: 691
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6028 s, 691 iter, 3455000 ts, 304 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-09-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 296.9753429599409
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 691
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.733
    dispatch_time_ms: 5.964
    learner:
      cur_lr: 0.0011298969620838761
      grad_gnorm: 0.002022381639108062
      policy_entropy: 0.08658301085233688
      policy_loss: 1.8399343559849513e-07
      var_gnorm: 23.015514373779297
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.914178010016144e-09
    num_steps_sampled: 3460000
    num_steps_trained: 3460000
    wait_time_ms: 70.11
  iterations_since_restore: 692
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6036.180533647537
  time_this_iter_s: 7.9588799476623535
  time_total_s: 6036.180533647537
  timestamp: 1594854551
  timesteps_since_restore: 3460000
  timesteps_this_iter: 5000
  timesteps_total: 3460000
  training_iteration: 692
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6036 s, 692 iter, 3460000 ts, 297 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-09-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 292.29534318167464
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 692
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 8.691
    learner:
      cur_lr: 0.001129564014263451
      grad_gnorm: 0.010156124830245972
      policy_entropy: 0.08676718175411224
      policy_loss: 5.354120276024332e-07
      var_gnorm: 23.015518188476562
      vf_explained_var: 0.0
      vf_loss: 7.966882975551925e-08
    num_steps_sampled: 3465000
    num_steps_trained: 3465000
    wait_time_ms: 68.23
  iterations_since_restore: 693
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6044.145218610764
  time_this_iter_s: 7.964684963226318
  time_total_s: 6044.145218610764
  timestamp: 1594854559
  timesteps_since_restore: 3465000
  timesteps_this_iter: 5000
  timesteps_total: 3465000
  training_iteration: 693
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6044 s, 693 iter, 3465000 ts, 292 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-09-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 290.31534318172163
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 693
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.934
    dispatch_time_ms: 8.477
    learner:
      cur_lr: 0.0011292309500277042
      grad_gnorm: 0.0005388115532696247
      policy_entropy: 0.0869511067867279
      policy_loss: 4.539113618307056e-08
      var_gnorm: 23.015522003173828
      vf_explained_var: 0.0
      vf_loss: 4.89821377902544e-12
    num_steps_sampled: 3470000
    num_steps_trained: 3470000
    wait_time_ms: 67.988
  iterations_since_restore: 694
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6052.0773339271545
  time_this_iter_s: 7.932115316390991
  time_total_s: 6052.0773339271545
  timestamp: 1594854567
  timesteps_since_restore: 3470000
  timesteps_this_iter: 5000
  timesteps_total: 3470000
  training_iteration: 694
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6052 s, 694 iter, 3470000 ts, 290 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-09-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 288.24534318180713
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 694
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.747
    dispatch_time_ms: 7.261
    learner:
      cur_lr: 0.0011288980022072792
      grad_gnorm: 0.008329521864652634
      policy_entropy: 0.08714505285024643
      policy_loss: 4.0575594084657496e-07
      var_gnorm: 23.01552963256836
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.34833795029499e-08
    num_steps_sampled: 3475000
    num_steps_trained: 3475000
    wait_time_ms: 68.343
  iterations_since_restore: 695
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6059.985236644745
  time_this_iter_s: 7.907902717590332
  time_total_s: 6059.985236644745
  timestamp: 1594854575
  timesteps_since_restore: 3475000
  timesteps_this_iter: 5000
  timesteps_total: 3475000
  training_iteration: 695
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6059 s, 695 iter, 3475000 ts, 288 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-09-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 282.39540674965065
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 695
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 8.761
    learner:
      cur_lr: 0.0011285650543868542
      grad_gnorm: 0.0013297547120600939
      policy_entropy: 0.08735056221485138
      policy_loss: -1.741450539327616e-08
      var_gnorm: 23.015535354614258
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.1669293309424233e-09
    num_steps_sampled: 3480000
    num_steps_trained: 3480000
    wait_time_ms: 67.791
  iterations_since_restore: 696
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6067.919200897217
  time_this_iter_s: 7.933964252471924
  time_total_s: 6067.919200897217
  timestamp: 1594854582
  timesteps_since_restore: 3480000
  timesteps_this_iter: 5000
  timesteps_total: 3480000
  training_iteration: 696
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6067 s, 696 iter, 3480000 ts, 282 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-09-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 279.6954067500178
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 696
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.157
    dispatch_time_ms: 7.838
    learner:
      cur_lr: 0.0011282319901511073
      grad_gnorm: 0.007759378757327795
      policy_entropy: 0.0875755101442337
      policy_loss: 6.190414865159255e-07
      var_gnorm: 23.015541076660156
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.644095596972875e-08
    num_steps_sampled: 3485000
    num_steps_trained: 3485000
    wait_time_ms: 69.136
  iterations_since_restore: 697
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6076.019803285599
  time_this_iter_s: 8.100602388381958
  time_total_s: 6076.019803285599
  timestamp: 1594854591
  timesteps_since_restore: 3485000
  timesteps_this_iter: 5000
  timesteps_total: 3485000
  training_iteration: 697
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6076 s, 697 iter, 3485000 ts, 280 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-09-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 275.55540675662616
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 697
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.954
    dispatch_time_ms: 5.658
    learner:
      cur_lr: 0.0011278990423306823
      grad_gnorm: 0.002696393523365259
      policy_entropy: 0.08780957013368607
      policy_loss: -8.447345578588283e-08
      var_gnorm: 23.015548706054688
      vf_explained_var: 0.0
      vf_loss: 5.355651477856327e-09
    num_steps_sampled: 3490000
    num_steps_trained: 3490000
    wait_time_ms: 73.207
  iterations_since_restore: 698
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6084.0719203948975
  time_this_iter_s: 8.052117109298706
  time_total_s: 6084.0719203948975
  timestamp: 1594854599
  timesteps_since_restore: 3490000
  timesteps_this_iter: 5000
  timesteps_total: 3490000
  training_iteration: 698
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6084 s, 698 iter, 3490000 ts, 276 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-10-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 274.02540675664915
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 698
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.468
    dispatch_time_ms: 5.944
    learner:
      cur_lr: 0.0011275659780949354
      grad_gnorm: 0.006029470358043909
      policy_entropy: 0.0880536437034607
      policy_loss: 2.503982443613495e-07
      var_gnorm: 23.01555633544922
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.802534559975811e-08
    num_steps_sampled: 3495000
    num_steps_trained: 3495000
    wait_time_ms: 71.364
  iterations_since_restore: 699
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6092.148483753204
  time_this_iter_s: 8.076563358306885
  time_total_s: 6092.148483753204
  timestamp: 1594854607
  timesteps_since_restore: 3495000
  timesteps_this_iter: 5000
  timesteps_total: 3495000
  training_iteration: 699
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6092 s, 699 iter, 3495000 ts, 274 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-10-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 271.8654067567384
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 699
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.336
    dispatch_time_ms: 7.332
    learner:
      cur_lr: 0.0011272330302745104
      grad_gnorm: 0.003894463647156954
      policy_entropy: 0.088310606777668
      policy_loss: -1.5739068714992754e-07
      var_gnorm: 23.01556396484375
      vf_explained_var: 0.0
      vf_loss: 1.1459047932760313e-08
    num_steps_sampled: 3500000
    num_steps_trained: 3500000
    wait_time_ms: 71.56
  iterations_since_restore: 700
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6100.2811625003815
  time_this_iter_s: 8.132678747177124
  time_total_s: 6100.2811625003815
  timestamp: 1594854615
  timesteps_since_restore: 3500000
  timesteps_this_iter: 5000
  timesteps_total: 3500000
  training_iteration: 700
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6100 s, 700 iter, 3500000 ts, 272 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-10-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 270.4254067568015
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 700
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 9.102
    learner:
      cur_lr: 0.0011268999660387635
      grad_gnorm: 0.005062234587967396
      policy_entropy: 0.08859870582818985
      policy_loss: 3.9869547663329286e-07
      var_gnorm: 23.01557159423828
      vf_explained_var: 0.0
      vf_loss: 1.9660939543086897e-08
    num_steps_sampled: 3505000
    num_steps_trained: 3505000
    wait_time_ms: 70.564
  iterations_since_restore: 701
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6108.2928721904755
  time_this_iter_s: 8.011709690093994
  time_total_s: 6108.2928721904755
  timestamp: 1594854623
  timesteps_since_restore: 3505000
  timesteps_this_iter: 5000
  timesteps_total: 3505000
  training_iteration: 701
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6108 s, 701 iter, 3505000 ts, 270 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-10-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 267.9954067569097
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 701
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.755
    dispatch_time_ms: 8.549
    learner:
      cur_lr: 0.0011265670182183385
      grad_gnorm: 0.00473066046833992
      policy_entropy: 0.08888674527406693
      policy_loss: -2.063372193106261e-07
      var_gnorm: 23.015581130981445
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.702831120553583e-08
    num_steps_sampled: 3510000
    num_steps_trained: 3510000
    wait_time_ms: 68.012
  iterations_since_restore: 702
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6116.35239481926
  time_this_iter_s: 8.05952262878418
  time_total_s: 6116.35239481926
  timestamp: 1594854631
  timesteps_since_restore: 3510000
  timesteps_this_iter: 5000
  timesteps_total: 3510000
  training_iteration: 702
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6116 s, 702 iter, 3510000 ts, 268 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-10-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 265.8354067569875
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 702
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 7.944
    learner:
      cur_lr: 0.0011262339539825916
      grad_gnorm: 0.003916403744369745
      policy_entropy: 0.08920138329267502
      policy_loss: 4.7209533704517526e-07
      var_gnorm: 23.015588760375977
      vf_explained_var: 0.0
      vf_loss: 1.1651792419797857e-08
    num_steps_sampled: 3515000
    num_steps_trained: 3515000
    wait_time_ms: 69.209
  iterations_since_restore: 703
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6124.412333488464
  time_this_iter_s: 8.059938669204712
  time_total_s: 6124.412333488464
  timestamp: 1594854639
  timesteps_since_restore: 3515000
  timesteps_this_iter: 5000
  timesteps_total: 3515000
  training_iteration: 703
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6124 s, 703 iter, 3515000 ts, 266 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-10-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 264.1254067570304
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 703
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.23
    dispatch_time_ms: 8.905
    learner:
      cur_lr: 0.0011259010061621666
      grad_gnorm: 0.004767338279634714
      policy_entropy: 0.08951960504055023
      policy_loss: -2.220262871333034e-07
      var_gnorm: 23.015600204467773
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 1.7459209189496505e-08
    num_steps_sampled: 3520000
    num_steps_trained: 3520000
    wait_time_ms: 64.881
  iterations_since_restore: 704
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6132.511151075363
  time_this_iter_s: 8.098817586898804
  time_total_s: 6132.511151075363
  timestamp: 1594854647
  timesteps_since_restore: 3520000
  timesteps_this_iter: 5000
  timesteps_total: 3520000
  training_iteration: 704
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6132 s, 704 iter, 3520000 ts, 264 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-10-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 262.1454067570678
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 704
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.316
    dispatch_time_ms: 7.677
    learner:
      cur_lr: 0.0011255679419264197
      grad_gnorm: 0.0005575967370532453
      policy_entropy: 0.08986733108758926
      policy_loss: 9.404461565054589e-08
      var_gnorm: 23.015609741210938
      vf_explained_var: 0.0
      vf_loss: 9.004265215384333e-12
    num_steps_sampled: 3525000
    num_steps_trained: 3525000
    wait_time_ms: 70.144
  iterations_since_restore: 705
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6140.5969977378845
  time_this_iter_s: 8.085846662521362
  time_total_s: 6140.5969977378845
  timestamp: 1594854655
  timesteps_since_restore: 3525000
  timesteps_this_iter: 5000
  timesteps_total: 3525000
  training_iteration: 705
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6140 s, 705 iter, 3525000 ts, 262 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-11-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 259.4454067572083
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 705
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.62
    dispatch_time_ms: 9.934
    learner:
      cur_lr: 0.0011252349941059947
      grad_gnorm: 0.004525110591202974
      policy_entropy: 0.0902392789721489
      policy_loss: -1.9255560346209677e-07
      var_gnorm: 23.0156192779541
      vf_explained_var: 0.0
      vf_loss: 1.5620351234701957e-08
    num_steps_sampled: 3530000
    num_steps_trained: 3530000
    wait_time_ms: 71.825
  iterations_since_restore: 706
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6148.6620326042175
  time_this_iter_s: 8.065034866333008
  time_total_s: 6148.6620326042175
  timestamp: 1594854664
  timesteps_since_restore: 3530000
  timesteps_this_iter: 5000
  timesteps_total: 3530000
  training_iteration: 706
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.3/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6148 s, 706 iter, 3530000 ts, 259 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-11-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 257.8254067572432
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 706
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.283
    dispatch_time_ms: 8.231
    learner:
      cur_lr: 0.0011249020462855697
      grad_gnorm: 0.002105000661686063
      policy_entropy: 0.090618796646595
      policy_loss: -8.741225343555925e-08
      var_gnorm: 23.0156307220459
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.1925770915819385e-09
    num_steps_sampled: 3535000
    num_steps_trained: 3535000
    wait_time_ms: 70.464
  iterations_since_restore: 707
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6156.7256853580475
  time_this_iter_s: 8.063652753829956
  time_total_s: 6156.7256853580475
  timestamp: 1594854672
  timesteps_since_restore: 3535000
  timesteps_this_iter: 5000
  timesteps_total: 3535000
  training_iteration: 707
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6156 s, 707 iter, 3535000 ts, 258 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-11-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 249.9954221748819
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 707
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.339
    dispatch_time_ms: 8.15
    learner:
      cur_lr: 0.0011245689820498228
      grad_gnorm: 0.004629520699381828
      policy_entropy: 0.09103767573833466
      policy_loss: -2.8603264468074485e-07
      var_gnorm: 23.01564598083496
      vf_explained_var: 0.0
      vf_loss: 1.6355624410380187e-08
    num_steps_sampled: 3540000
    num_steps_trained: 3540000
    wait_time_ms: 68.522
  iterations_since_restore: 708
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6164.793771982193
  time_this_iter_s: 8.068086624145508
  time_total_s: 6164.793771982193
  timestamp: 1594854680
  timesteps_since_restore: 3540000
  timesteps_this_iter: 5000
  timesteps_total: 3540000
  training_iteration: 708
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6164 s, 708 iter, 3540000 ts, 250 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-11-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 246.39542217620877
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 708
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.86
    dispatch_time_ms: 8.245
    learner:
      cur_lr: 0.0011242360342293978
      grad_gnorm: 0.0067931353114545345
      policy_entropy: 0.09146468341350555
      policy_loss: -9.077097473664253e-08
      var_gnorm: 23.01565933227539
      vf_explained_var: 0.0
      vf_loss: 3.544289484125329e-08
    num_steps_sampled: 3545000
    num_steps_trained: 3545000
    wait_time_ms: 71.641
  iterations_since_restore: 709
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6172.851650953293
  time_this_iter_s: 8.057878971099854
  time_total_s: 6172.851650953293
  timestamp: 1594854688
  timesteps_since_restore: 3545000
  timesteps_this_iter: 5000
  timesteps_total: 3545000
  training_iteration: 709
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6172 s, 709 iter, 3545000 ts, 246 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-11-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 240.00543578800244
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 709
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.9
    dispatch_time_ms: 8.399
    learner:
      cur_lr: 0.001123902969993651
      grad_gnorm: 0.003962086513638496
      policy_entropy: 0.09199731051921844
      policy_loss: -2.837824411017209e-07
      var_gnorm: 23.015676498413086
      vf_explained_var: 0.0
      vf_loss: 1.1864224269686474e-08
    num_steps_sampled: 3550000
    num_steps_trained: 3550000
    wait_time_ms: 70.217
  iterations_since_restore: 710
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6180.954587936401
  time_this_iter_s: 8.10293698310852
  time_total_s: 6180.954587936401
  timestamp: 1594854696
  timesteps_since_restore: 3550000
  timesteps_this_iter: 5000
  timesteps_total: 3550000
  training_iteration: 710
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6180 s, 710 iter, 3550000 ts, 240 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-11-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 236.8554357884814
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 710
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 7.481
    learner:
      cur_lr: 0.0011235700221732259
      grad_gnorm: 0.009459972381591797
      policy_entropy: 0.0924939289689064
      policy_loss: -2.017524849406982e-07
      var_gnorm: 23.01569175720215
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.913031569411032e-08
    num_steps_sampled: 3555000
    num_steps_trained: 3555000
    wait_time_ms: 72.049
  iterations_since_restore: 711
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6189.021667480469
  time_this_iter_s: 8.067079544067383
  time_total_s: 6189.021667480469
  timestamp: 1594854704
  timesteps_since_restore: 3555000
  timesteps_this_iter: 5000
  timesteps_total: 3555000
  training_iteration: 711
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6189 s, 711 iter, 3555000 ts, 237 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-11-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 230.5554371002216
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 711
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.189
    dispatch_time_ms: 10.018
    learner:
      cur_lr: 0.001123236957937479
      grad_gnorm: 0.002171505242586136
      policy_entropy: 0.09302181750535965
      policy_loss: -3.594832946873794e-07
      var_gnorm: 23.015708923339844
      vf_explained_var: 0.0
      vf_loss: 3.3896243589737196e-09
    num_steps_sampled: 3560000
    num_steps_trained: 3560000
    wait_time_ms: 68.346
  iterations_since_restore: 712
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6197.090854406357
  time_this_iter_s: 8.069186925888062
  time_total_s: 6197.090854406357
  timestamp: 1594854712
  timesteps_since_restore: 3560000
  timesteps_this_iter: 5000
  timesteps_total: 3560000
  training_iteration: 712
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6197 s, 712 iter, 3560000 ts, 231 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-12-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 222.9054521112516
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 712
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.01
    dispatch_time_ms: 8.026
    learner:
      cur_lr: 0.001122904010117054
      grad_gnorm: 0.014069588854908943
      policy_entropy: 0.09358210116624832
      policy_loss: -4.944332658851636e-07
      var_gnorm: 23.01572608947754
      vf_explained_var: 0.0
      vf_loss: 1.5266894592969038e-07
    num_steps_sampled: 3565000
    num_steps_trained: 3565000
    wait_time_ms: 70.521
  iterations_since_restore: 713
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6205.2272799015045
  time_this_iter_s: 8.136425495147705
  time_total_s: 6205.2272799015045
  timestamp: 1594854720
  timesteps_since_restore: 3565000
  timesteps_this_iter: 5000
  timesteps_total: 3565000
  training_iteration: 713
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6205 s, 713 iter, 3565000 ts, 223 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-12-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 219.84545211149924
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 713
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 10.378
    learner:
      cur_lr: 0.0011225709458813071
      grad_gnorm: 0.001745457062497735
      policy_entropy: 0.09416400641202927
      policy_loss: 7.400841894877885e-08
      var_gnorm: 23.015745162963867
      vf_explained_var: 0.0
      vf_loss: 2.115742692154754e-09
    num_steps_sampled: 3570000
    num_steps_trained: 3570000
    wait_time_ms: 67.385
  iterations_since_restore: 714
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6213.260869026184
  time_this_iter_s: 8.033589124679565
  time_total_s: 6213.260869026184
  timestamp: 1594854728
  timesteps_since_restore: 3570000
  timesteps_this_iter: 5000
  timesteps_total: 3570000
  training_iteration: 714
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6213 s, 714 iter, 3570000 ts, 220 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-12-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 218.40545211151985
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 714
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.301
    dispatch_time_ms: 7.082
    learner:
      cur_lr: 0.001122237998060882
      grad_gnorm: 0.016632655635476112
      policy_entropy: 0.09482208639383316
      policy_loss: -6.405941235243517e-07
      var_gnorm: 23.015766143798828
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.1443536013521225e-07
    num_steps_sampled: 3575000
    num_steps_trained: 3575000
    wait_time_ms: 72.483
  iterations_since_restore: 715
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6221.348218202591
  time_this_iter_s: 8.08734917640686
  time_total_s: 6221.348218202591
  timestamp: 1594854737
  timesteps_since_restore: 3575000
  timesteps_this_iter: 5000
  timesteps_total: 3575000
  training_iteration: 715
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6221 s, 715 iter, 3575000 ts, 218 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-12-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 216.6054521115539
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 715
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.051
    dispatch_time_ms: 8.224
    learner:
      cur_lr: 0.001121905050240457
      grad_gnorm: 0.004753434099256992
      policy_entropy: 0.09548206627368927
      policy_loss: 2.56022474331985e-07
      var_gnorm: 23.015783309936523
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.7310261668512794e-08
    num_steps_sampled: 3580000
    num_steps_trained: 3580000
    wait_time_ms: 70.113
  iterations_since_restore: 716
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6239.163685321808
  time_this_iter_s: 17.81546711921692
  time_total_s: 6239.163685321808
  timestamp: 1594854754
  timesteps_since_restore: 3580000
  timesteps_this_iter: 5000
  timesteps_total: 3580000
  training_iteration: 716
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6239 s, 716 iter, 3580000 ts, 217 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-12-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 215.07545211157858
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 716
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 8.139
    learner:
      cur_lr: 0.0011215719860047102
      grad_gnorm: 0.019868789240717888
      policy_entropy: 0.09622931480407715
      policy_loss: -9.486068393016467e-07
      var_gnorm: 23.015806198120117
      vf_explained_var: 0.0
      vf_loss: 3.054550461456529e-07
    num_steps_sampled: 3585000
    num_steps_trained: 3585000
    wait_time_ms: 68.764
  iterations_since_restore: 717
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6247.189222574234
  time_this_iter_s: 8.025537252426147
  time_total_s: 6247.189222574234
  timestamp: 1594854763
  timesteps_since_restore: 3585000
  timesteps_this_iter: 5000
  timesteps_total: 3585000
  training_iteration: 717
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6247 s, 717 iter, 3585000 ts, 215 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-12-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 209.4954525640105
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 717
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 5.556
    learner:
      cur_lr: 0.0011212390381842852
      grad_gnorm: 0.007108935154974461
      policy_entropy: 0.09699534624814987
      policy_loss: 2.69672625563544e-07
      var_gnorm: 23.015827178955078
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.8868449792062165e-08
    num_steps_sampled: 3590000
    num_steps_trained: 3590000
    wait_time_ms: 76.036
  iterations_since_restore: 718
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6255.303616762161
  time_this_iter_s: 8.114394187927246
  time_total_s: 6255.303616762161
  timestamp: 1594854771
  timesteps_since_restore: 3590000
  timesteps_this_iter: 5000
  timesteps_total: 3590000
  training_iteration: 718
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6255 s, 718 iter, 3590000 ts, 209 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-12-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 207.69545256406317
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 718
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.47
    dispatch_time_ms: 9.497
    learner:
      cur_lr: 0.0011209059739485383
      grad_gnorm: 0.017685310915112495
      policy_entropy: 0.0978335291147232
      policy_loss: -8.287956347885483e-07
      var_gnorm: 23.015853881835938
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.4201105475185614e-07
    num_steps_sampled: 3595000
    num_steps_trained: 3595000
    wait_time_ms: 72.282
  iterations_since_restore: 719
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6263.373069763184
  time_this_iter_s: 8.069453001022339
  time_total_s: 6263.373069763184
  timestamp: 1594854779
  timesteps_since_restore: 3595000
  timesteps_this_iter: 5000
  timesteps_total: 3595000
  training_iteration: 719
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6263 s, 719 iter, 3595000 ts, 208 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-13-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 200.94603246956592
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 719
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.847
    dispatch_time_ms: 8.738
    learner:
      cur_lr: 0.0011205730261281133
      grad_gnorm: 0.00884421169757843
      policy_entropy: 0.09870771318674088
      policy_loss: 4.176681329681742e-07
      var_gnorm: 23.015878677368164
      vf_explained_var: 0.0
      vf_loss: 6.033382504710971e-08
    num_steps_sampled: 3600000
    num_steps_trained: 3600000
    wait_time_ms: 69.475
  iterations_since_restore: 720
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6271.435761928558
  time_this_iter_s: 8.062692165374756
  time_total_s: 6271.435761928558
  timestamp: 1594854787
  timesteps_since_restore: 3600000
  timesteps_this_iter: 5000
  timesteps_total: 3600000
  training_iteration: 720
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6271 s, 720 iter, 3600000 ts, 201 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-13-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 195.27603256393914
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 720
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.809
    dispatch_time_ms: 7.888
    learner:
      cur_lr: 0.0011202399618923664
      grad_gnorm: 0.018532514572143555
      policy_entropy: 0.09966487437486649
      policy_loss: -1.6360928611902636e-06
      var_gnorm: 23.015907287597656
      vf_explained_var: 0.0
      vf_loss: 2.657594677657471e-07
    num_steps_sampled: 3605000
    num_steps_trained: 3605000
    wait_time_ms: 71.925
  iterations_since_restore: 721
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6279.517303705215
  time_this_iter_s: 8.081541776657104
  time_total_s: 6279.517303705215
  timestamp: 1594854795
  timesteps_since_restore: 3605000
  timesteps_this_iter: 5000
  timesteps_total: 3605000
  training_iteration: 721
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6279 s, 721 iter, 3605000 ts, 195 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-13-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 191.04608142496355
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 721
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.741
    dispatch_time_ms: 5.884
    learner:
      cur_lr: 0.0011199070140719414
      grad_gnorm: 0.010125582106411457
      policy_entropy: 0.10069514811038971
      policy_loss: 5.912217488912574e-07
      var_gnorm: 23.01593589782715
      vf_explained_var: 0.0
      vf_loss: 7.919327771332973e-08
    num_steps_sampled: 3610000
    num_steps_trained: 3610000
    wait_time_ms: 71.858
  iterations_since_restore: 722
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6287.555743217468
  time_this_iter_s: 8.038439512252808
  time_total_s: 6287.555743217468
  timestamp: 1594854803
  timesteps_since_restore: 3610000
  timesteps_this_iter: 5000
  timesteps_total: 3610000
  training_iteration: 722
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6287 s, 722 iter, 3610000 ts, 191 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-13-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 188.97608142515674
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 722
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.843
    dispatch_time_ms: 7.857
    learner:
      cur_lr: 0.0011195739498361945
      grad_gnorm: 0.018950413912534714
      policy_entropy: 0.10176947712898254
      policy_loss: -1.6746408846302074e-06
      var_gnorm: 23.015966415405273
      vf_explained_var: 0.0
      vf_loss: 2.778792804747354e-07
    num_steps_sampled: 3615000
    num_steps_trained: 3615000
    wait_time_ms: 70.449
  iterations_since_restore: 723
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6295.610304355621
  time_this_iter_s: 8.054561138153076
  time_total_s: 6295.610304355621
  timestamp: 1594854811
  timesteps_since_restore: 3615000
  timesteps_this_iter: 5000
  timesteps_total: 3615000
  training_iteration: 723
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6295 s, 723 iter, 3615000 ts, 189 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-13-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 184.20608437523012
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 723
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.861
    dispatch_time_ms: 8.213
    learner:
      cur_lr: 0.0011192410020157695
      grad_gnorm: 0.008377415128052235
      policy_entropy: 0.10293307900428772
      policy_loss: 1.0313528946426231e-06
      var_gnorm: 23.01599884033203
      vf_explained_var: 0.0
      vf_loss: 5.408762149272661e-08
    num_steps_sampled: 3620000
    num_steps_trained: 3620000
    wait_time_ms: 70.174
  iterations_since_restore: 724
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6303.6910445690155
  time_this_iter_s: 8.080740213394165
  time_total_s: 6303.6910445690155
  timestamp: 1594854819
  timesteps_since_restore: 3620000
  timesteps_this_iter: 5000
  timesteps_total: 3620000
  training_iteration: 724
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6303 s, 724 iter, 3620000 ts, 184 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-13-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 181.4160843753465
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 724
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.888
    dispatch_time_ms: 7.191
    learner:
      cur_lr: 0.0011189080541953444
      grad_gnorm: 0.014296128414571285
      policy_entropy: 0.10418183356523514
      policy_loss: -1.4862949910821044e-06
      var_gnorm: 23.01603126525879
      vf_explained_var: 0.0
      vf_loss: 1.5812031506357016e-07
    num_steps_sampled: 3625000
    num_steps_trained: 3625000
    wait_time_ms: 69.388
  iterations_since_restore: 725
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6311.770988225937
  time_this_iter_s: 8.079943656921387
  time_total_s: 6311.770988225937
  timestamp: 1594854827
  timesteps_since_restore: 3625000
  timesteps_this_iter: 5000
  timesteps_total: 3625000
  training_iteration: 725
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6311 s, 725 iter, 3625000 ts, 181 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-13-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 177.63608438201192
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 725
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.056
    dispatch_time_ms: 9.859
    learner:
      cur_lr: 0.0011185749899595976
      grad_gnorm: 0.0012269223807379603
      policy_entropy: 0.10554124414920807
      policy_loss: 2.5773982770260773e-07
      var_gnorm: 23.016069412231445
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 8.377621374400235e-10
    num_steps_sampled: 3630000
    num_steps_trained: 3630000
    wait_time_ms: 69.638
  iterations_since_restore: 726
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6319.945411205292
  time_this_iter_s: 8.174422979354858
  time_total_s: 6319.945411205292
  timestamp: 1594854836
  timesteps_since_restore: 3630000
  timesteps_this_iter: 5000
  timesteps_total: 3630000
  training_iteration: 726
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6319 s, 726 iter, 3630000 ts, 178 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-14-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 174.21608438994818
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 726
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 10.864
    learner:
      cur_lr: 0.0011182420421391726
      grad_gnorm: 0.007403583265841007
      policy_entropy: 0.10698901861906052
      policy_loss: -2.2517176603287226e-06
      var_gnorm: 23.016109466552734
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 4.1925709126644506e-08
    num_steps_sampled: 3635000
    num_steps_trained: 3635000
    wait_time_ms: 67.326
  iterations_since_restore: 727
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6327.982634067535
  time_this_iter_s: 8.037222862243652
  time_total_s: 6327.982634067535
  timestamp: 1594854844
  timesteps_since_restore: 3635000
  timesteps_this_iter: 5000
  timesteps_total: 3635000
  training_iteration: 727
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6327 s, 727 iter, 3635000 ts, 174 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-14-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 170.52609738851675
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 727
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.667
    dispatch_time_ms: 6.762
    learner:
      cur_lr: 0.0011179089779034257
      grad_gnorm: 0.00323881465010345
      policy_entropy: 0.10854700207710266
      policy_loss: 2.6876546144194435e-07
      var_gnorm: 23.01615333557129
      vf_explained_var: 0.0
      vf_loss: 7.79787878713023e-09
    num_steps_sampled: 3640000
    num_steps_trained: 3640000
    wait_time_ms: 73.698
  iterations_since_restore: 728
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6336.076690912247
  time_this_iter_s: 8.094056844711304
  time_total_s: 6336.076690912247
  timestamp: 1594854852
  timesteps_since_restore: 3640000
  timesteps_this_iter: 5000
  timesteps_total: 3640000
  training_iteration: 728
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6336 s, 728 iter, 3640000 ts, 171 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-14-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 168.36609738879596
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 728
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.923
    dispatch_time_ms: 9.072
    learner:
      cur_lr: 0.0011175760300830007
      grad_gnorm: 0.0026315529830753803
      policy_entropy: 0.11023029685020447
      policy_loss: -1.0031551482825307e-06
      var_gnorm: 23.016199111938477
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.0009969498887585e-09
    num_steps_sampled: 3645000
    num_steps_trained: 3645000
    wait_time_ms: 69.944
  iterations_since_restore: 729
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6344.141927719116
  time_this_iter_s: 8.065236806869507
  time_total_s: 6344.141927719116
  timestamp: 1594854860
  timesteps_since_restore: 3645000
  timesteps_this_iter: 5000
  timesteps_total: 3645000
  training_iteration: 729
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6344 s, 729 iter, 3645000 ts, 168 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-14-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 163.95609739494384
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 729
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 7.139
    learner:
      cur_lr: 0.0011172429658472538
      grad_gnorm: 0.009340524673461914
      policy_entropy: 0.11205039918422699
      policy_loss: -3.5038971191170276e-07
      var_gnorm: 23.016246795654297
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.716498290870732e-08
    num_steps_sampled: 3650000
    num_steps_trained: 3650000
    wait_time_ms: 73.847
  iterations_since_restore: 730
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6352.1796770095825
  time_this_iter_s: 8.037749290466309
  time_total_s: 6352.1796770095825
  timestamp: 1594854868
  timesteps_since_restore: 3650000
  timesteps_this_iter: 5000
  timesteps_total: 3650000
  training_iteration: 730
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6352 s, 730 iter, 3650000 ts, 164 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-14-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 161.97609739513274
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 730
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.789
    dispatch_time_ms: 8.767
    learner:
      cur_lr: 0.0011169100180268288
      grad_gnorm: 0.005385956726968288
      policy_entropy: 0.11402227729558945
      policy_loss: -1.0096113101099036e-06
      var_gnorm: 23.016300201416016
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.2058229021126863e-08
    num_steps_sampled: 3655000
    num_steps_trained: 3655000
    wait_time_ms: 67.585
  iterations_since_restore: 731
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6360.216832399368
  time_this_iter_s: 8.037155389785767
  time_total_s: 6360.216832399368
  timestamp: 1594854876
  timesteps_since_restore: 3655000
  timesteps_this_iter: 5000
  timesteps_total: 3655000
  training_iteration: 731
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6360 s, 731 iter, 3655000 ts, 162 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-14-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 159.90609739538868
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 731
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.521
    dispatch_time_ms: 8.991
    learner:
      cur_lr: 0.001116576953791082
      grad_gnorm: 0.01595829240977764
      policy_entropy: 0.11621034890413284
      policy_loss: -9.052230325323762e-07
      var_gnorm: 23.016355514526367
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.969522855915784e-07
    num_steps_sampled: 3660000
    num_steps_trained: 3660000
    wait_time_ms: 70.324
  iterations_since_restore: 732
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6368.372699260712
  time_this_iter_s: 8.155866861343384
  time_total_s: 6368.372699260712
  timestamp: 1594854884
  timesteps_since_restore: 3660000
  timesteps_this_iter: 5000
  timesteps_total: 3660000
  training_iteration: 732
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6368 s, 732 iter, 3660000 ts, 160 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-14-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 156.0360974013051
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 732
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.337
    dispatch_time_ms: 7.099
    learner:
      cur_lr: 0.0011162440059706569
      grad_gnorm: 0.008478316478431225
      policy_entropy: 0.11853831261396408
      policy_loss: -1.3394512734521413e-06
      var_gnorm: 23.016414642333984
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.51829408834692e-08
    num_steps_sampled: 3665000
    num_steps_trained: 3665000
    wait_time_ms: 69.178
  iterations_since_restore: 733
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6376.3685212135315
  time_this_iter_s: 7.995821952819824
  time_total_s: 6376.3685212135315
  timestamp: 1594854892
  timesteps_since_restore: 3665000
  timesteps_this_iter: 5000
  timesteps_total: 3665000
  training_iteration: 733
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6376 s, 733 iter, 3665000 ts, 156 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-15-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 800.0813848898749
  episode_reward_mean: 153.78609740148497
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 733
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.989
    dispatch_time_ms: 9.393
    learner:
      cur_lr: 0.0011159110581502318
      grad_gnorm: 0.012862271629273891
      policy_entropy: 0.1216864064335823
      policy_loss: -1.0540672974457266e-06
      var_gnorm: 23.016483306884766
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.2753596934089728e-07
    num_steps_sampled: 3670000
    num_steps_trained: 3670000
    wait_time_ms: 69.977
  iterations_since_restore: 734
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6384.4436955451965
  time_this_iter_s: 8.075174331665039
  time_total_s: 6384.4436955451965
  timestamp: 1594854900
  timesteps_since_restore: 3670000
  timesteps_this_iter: 5000
  timesteps_total: 3670000
  training_iteration: 734
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6384 s, 734 iter, 3670000 ts, 154 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-15-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 145.7852835525862
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 734
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.691
    dispatch_time_ms: 7.164
    learner:
      cur_lr: 0.001115577993914485
      grad_gnorm: 0.038776759058237076
      policy_entropy: 0.1245821863412857
      policy_loss: 1.0198376685366384e-06
      var_gnorm: 23.01655387878418
      vf_explained_var: 0.0
      vf_loss: 1.1637688430710114e-06
    num_steps_sampled: 3675000
    num_steps_trained: 3675000
    wait_time_ms: 70.319
  iterations_since_restore: 735
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6392.489329099655
  time_this_iter_s: 8.045633554458618
  time_total_s: 6392.489329099655
  timestamp: 1594854908
  timesteps_since_restore: 3675000
  timesteps_this_iter: 5000
  timesteps_total: 3675000
  training_iteration: 735
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6392 s, 735 iter, 3675000 ts, 146 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-15-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 143.26528355306945
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 735
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 27.26
    learner:
      cur_lr: 0.00111524504609406
      grad_gnorm: 0.031953874975442886
      policy_entropy: 0.12773023545742035
      policy_loss: 1.0065399465020164e-06
      var_gnorm: 23.01662826538086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.903030336819938e-07
    num_steps_sampled: 3680000
    num_steps_trained: 3680000
    wait_time_ms: 57.857
  iterations_since_restore: 736
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6400.909815788269
  time_this_iter_s: 8.420486688613892
  time_total_s: 6400.909815788269
  timestamp: 1594854917
  timesteps_since_restore: 3680000
  timesteps_this_iter: 5000
  timesteps_total: 3680000
  training_iteration: 736
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6400 s, 736 iter, 3680000 ts, 143 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-15-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 141.01528355317632
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 736
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.818
    dispatch_time_ms: 36.924
    learner:
      cur_lr: 0.001114911981858313
      grad_gnorm: 0.12254949659109116
      policy_entropy: 0.13102635741233826
      policy_loss: -1.1965030353167094e-05
      var_gnorm: 23.016708374023438
      vf_explained_var: 0.0
      vf_loss: 1.1631887900875881e-05
    num_steps_sampled: 3685000
    num_steps_trained: 3685000
    wait_time_ms: 51.545
  iterations_since_restore: 737
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6409.376069068909
  time_this_iter_s: 8.466253280639648
  time_total_s: 6409.376069068909
  timestamp: 1594854925
  timesteps_since_restore: 3685000
  timesteps_this_iter: 5000
  timesteps_total: 3685000
  training_iteration: 737
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6409 s, 737 iter, 3685000 ts, 141 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-15-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 140.92608141933346
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 737
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.838
    dispatch_time_ms: 32.78
    learner:
      cur_lr: 0.001114579034037888
      grad_gnorm: 1.5989294052124023
      policy_entropy: 0.13285380601882935
      policy_loss: 0.00038991490146145225
      var_gnorm: 23.016801834106445
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0019799266010522842
    num_steps_sampled: 3690000
    num_steps_trained: 3690000
    wait_time_ms: 52.273
  iterations_since_restore: 738
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6417.95646739006
  time_this_iter_s: 8.580398321151733
  time_total_s: 6417.95646739006
  timestamp: 1594854934
  timesteps_since_restore: 3690000
  timesteps_this_iter: 5000
  timesteps_total: 3690000
  training_iteration: 738
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6417 s, 738 iter, 3690000 ts, 141 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-15-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 140.30813176752886
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 738
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.247
    dispatch_time_ms: 16.25
    learner:
      cur_lr: 0.0011142459698021412
      grad_gnorm: 0.40022188425064087
      policy_entropy: 0.10999180376529694
      policy_loss: 4.421075209393166e-05
      var_gnorm: 23.015287399291992
      vf_explained_var: 0.0
      vf_loss: 0.00012405090092215687
    num_steps_sampled: 3695000
    num_steps_trained: 3695000
    wait_time_ms: 65.375
  iterations_since_restore: 739
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6426.574786901474
  time_this_iter_s: 8.618319511413574
  time_total_s: 6426.574786901474
  timestamp: 1594854943
  timesteps_since_restore: 3695000
  timesteps_this_iter: 5000
  timesteps_total: 3695000
  training_iteration: 739
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6426 s, 739 iter, 3695000 ts, 140 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-15-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 135.08886657110702
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 739
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.939
    dispatch_time_ms: 28.297
    learner:
      cur_lr: 0.0011139130219817162
      grad_gnorm: 0.0007491952273994684
      policy_entropy: 0.11256150156259537
      policy_loss: 1.1751516240110504e-06
      var_gnorm: 23.015344619750977
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.142511582181044e-11
    num_steps_sampled: 3700000
    num_steps_trained: 3700000
    wait_time_ms: 61.256
  iterations_since_restore: 740
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6435.090136051178
  time_this_iter_s: 8.51534914970398
  time_total_s: 6435.090136051178
  timestamp: 1594854951
  timesteps_since_restore: 3700000
  timesteps_this_iter: 5000
  timesteps_total: 3700000
  training_iteration: 740
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6435 s, 740 iter, 3700000 ts, 135 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-16-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 129.14901691192892
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 740
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.893
    dispatch_time_ms: 32.799
    learner:
      cur_lr: 0.0011135799577459693
      grad_gnorm: 0.02648906409740448
      policy_entropy: 0.115943044424057
      policy_loss: 4.017085757368477e-07
      var_gnorm: 23.015419006347656
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.435339289761032e-07
    num_steps_sampled: 3705000
    num_steps_trained: 3705000
    wait_time_ms: 52.111
  iterations_since_restore: 741
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6443.939866304398
  time_this_iter_s: 8.849730253219604
  time_total_s: 6443.939866304398
  timestamp: 1594854960
  timesteps_since_restore: 3705000
  timesteps_this_iter: 5000
  timesteps_total: 3705000
  training_iteration: 741
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6443 s, 741 iter, 3705000 ts, 129 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-16-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 125.18901691604977
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 741
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 32.119
    learner:
      cur_lr: 0.0011132470099255443
      grad_gnorm: 0.0008046322036534548
      policy_entropy: 0.11961769312620163
      policy_loss: 2.060832748895791e-08
      var_gnorm: 23.0154972076416
      vf_explained_var: 0.0
      vf_loss: 7.064171470005931e-11
    num_steps_sampled: 3710000
    num_steps_trained: 3710000
    wait_time_ms: 48.233
  iterations_since_restore: 742
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6452.392795801163
  time_this_iter_s: 8.452929496765137
  time_total_s: 6452.392795801163
  timestamp: 1594854969
  timesteps_since_restore: 3710000
  timesteps_this_iter: 5000
  timesteps_total: 3710000
  training_iteration: 742
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6452 s, 742 iter, 3710000 ts, 125 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-16-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 122.57901691627404
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 742
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.291
    dispatch_time_ms: 28.728
    learner:
      cur_lr: 0.0011129139456897974
      grad_gnorm: 0.15095089375972748
      policy_entropy: 0.12605167925357819
      policy_loss: -1.6438771126559004e-05
      var_gnorm: 23.01559829711914
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.660686707007699e-05
    num_steps_sampled: 3715000
    num_steps_trained: 3715000
    wait_time_ms: 58.799
  iterations_since_restore: 743
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6460.954978942871
  time_this_iter_s: 8.562183141708374
  time_total_s: 6460.954978942871
  timestamp: 1594854977
  timesteps_since_restore: 3715000
  timesteps_this_iter: 5000
  timesteps_total: 3715000
  training_iteration: 743
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6460 s, 743 iter, 3715000 ts, 123 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-16-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 116.63938684310679
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 743
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.581
    dispatch_time_ms: 6.446
    learner:
      cur_lr: 0.0011125809978693724
      grad_gnorm: 0.0020668823271989822
      policy_entropy: 0.1157202273607254
      policy_loss: -3.074967480642954e-07
      var_gnorm: 23.015609741210938
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.9026641090723615e-09
    num_steps_sampled: 3720000
    num_steps_trained: 3720000
    wait_time_ms: 33.93
  iterations_since_restore: 744
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6469.693046569824
  time_this_iter_s: 8.738067626953125
  time_total_s: 6469.693046569824
  timestamp: 1594854986
  timesteps_since_restore: 3720000
  timesteps_this_iter: 5000
  timesteps_total: 3720000
  training_iteration: 744
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6469 s, 744 iter, 3720000 ts, 117 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-16-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 111.86938688403895
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 744
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.821
    dispatch_time_ms: 8.22
    learner:
      cur_lr: 0.0011122480500489473
      grad_gnorm: 0.01623103767633438
      policy_entropy: 0.12001611292362213
      policy_loss: -1.703684347376111e-06
      var_gnorm: 23.015705108642578
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 2.0358400831810286e-07
    num_steps_sampled: 3725000
    num_steps_trained: 3725000
    wait_time_ms: 68.922
  iterations_since_restore: 745
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6477.700109004974
  time_this_iter_s: 8.007062435150146
  time_total_s: 6477.700109004974
  timestamp: 1594854994
  timesteps_since_restore: 3725000
  timesteps_this_iter: 5000
  timesteps_total: 3725000
  training_iteration: 745
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6477 s, 745 iter, 3725000 ts, 112 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-16-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 108.80938688430575
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 745
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.096
    dispatch_time_ms: 9.656
    learner:
      cur_lr: 0.0011119149858132005
      grad_gnorm: 0.008833996020257473
      policy_entropy: 0.124957375228405
      policy_loss: -8.594067821832141e-07
      var_gnorm: 23.015811920166016
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 6.000176000497959e-08
    num_steps_sampled: 3730000
    num_steps_trained: 3730000
    wait_time_ms: 67.092
  iterations_since_restore: 746
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6485.555547475815
  time_this_iter_s: 7.855438470840454
  time_total_s: 6485.555547475815
  timestamp: 1594855002
  timesteps_since_restore: 3730000
  timesteps_this_iter: 5000
  timesteps_total: 3730000
  training_iteration: 746
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6485 s, 746 iter, 3730000 ts, 109 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-16-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 107.18938688434253
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 746
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.892
    dispatch_time_ms: 6.979
    learner:
      cur_lr: 0.0011115820379927754
      grad_gnorm: 0.012582776136696339
      policy_entropy: 0.13055512309074402
      policy_loss: -8.156679882631579e-07
      var_gnorm: 23.015926361083984
      vf_explained_var: 0.0
      vf_loss: 1.222017402824349e-07
    num_steps_sampled: 3735000
    num_steps_trained: 3735000
    wait_time_ms: 67.803
  iterations_since_restore: 747
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6493.486278533936
  time_this_iter_s: 7.9307310581207275
  time_total_s: 6493.486278533936
  timestamp: 1594855010
  timesteps_since_restore: 3735000
  timesteps_this_iter: 5000
  timesteps_total: 3735000
  training_iteration: 747
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6493 s, 747 iter, 3735000 ts, 107 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-16-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 104.8493868843962
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 747
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.986
    dispatch_time_ms: 7.69
    learner:
      cur_lr: 0.0011112489737570286
      grad_gnorm: 0.0017886502901092172
      policy_entropy: 0.13709291815757751
      policy_loss: -2.602424729047925e-06
      var_gnorm: 23.016056060791016
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.889032041901828e-09
    num_steps_sampled: 3740000
    num_steps_trained: 3740000
    wait_time_ms: 68.795
  iterations_since_restore: 748
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6501.4144542217255
  time_this_iter_s: 7.928175687789917
  time_total_s: 6501.4144542217255
  timestamp: 1594855018
  timesteps_since_restore: 3740000
  timesteps_this_iter: 5000
  timesteps_total: 3740000
  training_iteration: 748
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6501 s, 748 iter, 3740000 ts, 105 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-17-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 103.22938688442305
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 748
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.613
    dispatch_time_ms: 7.206
    learner:
      cur_lr: 0.0011109160259366035
      grad_gnorm: 0.0012582367053255439
      policy_entropy: 0.14453932642936707
      policy_loss: -5.277038326312322e-06
      var_gnorm: 23.016199111938477
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.318906426410308e-10
    num_steps_sampled: 3745000
    num_steps_trained: 3745000
    wait_time_ms: 69.058
  iterations_since_restore: 749
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6509.328130245209
  time_this_iter_s: 7.913676023483276
  time_total_s: 6509.328130245209
  timestamp: 1594855026
  timesteps_since_restore: 3745000
  timesteps_this_iter: 5000
  timesteps_total: 3745000
  training_iteration: 749
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6509 s, 749 iter, 3745000 ts, 103 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-17-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 101.06938688455928
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 749
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.39
    dispatch_time_ms: 8.773
    learner:
      cur_lr: 0.0011105829617008567
      grad_gnorm: 0.008608908392488956
      policy_entropy: 0.1533653736114502
      policy_loss: -3.298746946711617e-07
      var_gnorm: 23.016357421875
      vf_explained_var: 0.0
      vf_loss: 5.689958371135617e-08
    num_steps_sampled: 3750000
    num_steps_trained: 3750000
    wait_time_ms: 67.467
  iterations_since_restore: 750
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6517.26225566864
  time_this_iter_s: 7.9341254234313965
  time_total_s: 6517.26225566864
  timestamp: 1594855034
  timesteps_since_restore: 3750000
  timesteps_this_iter: 5000
  timesteps_total: 3750000
  training_iteration: 750
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6517 s, 750 iter, 3750000 ts, 101 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-17-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 99.17938688474547
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 750
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.725
    dispatch_time_ms: 7.816
    learner:
      cur_lr: 0.0011102500138804317
      grad_gnorm: 0.006190417800098658
      policy_entropy: 0.16416601836681366
      policy_loss: -1.0082269909617025e-05
      var_gnorm: 23.016538619995117
      vf_explained_var: 0.0
      vf_loss: 2.8693813547420177e-08
    num_steps_sampled: 3755000
    num_steps_trained: 3755000
    wait_time_ms: 68.844
  iterations_since_restore: 751
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6525.200553417206
  time_this_iter_s: 7.938297748565674
  time_total_s: 6525.200553417206
  timestamp: 1594855042
  timesteps_since_restore: 3755000
  timesteps_this_iter: 5000
  timesteps_total: 3755000
  training_iteration: 751
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6525 s, 751 iter, 3755000 ts, 99.2 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-17-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 97.37938688486912
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 751
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.4
    dispatch_time_ms: 8.868
    learner:
      cur_lr: 0.0011099169496446848
      grad_gnorm: 0.014325535856187344
      policy_entropy: 0.173390194773674
      policy_loss: 3.7881289927099715e-07
      var_gnorm: 23.016727447509766
      vf_explained_var: 0.0
      vf_loss: 1.580025781322547e-07
    num_steps_sampled: 3760000
    num_steps_trained: 3760000
    wait_time_ms: 67.986
  iterations_since_restore: 752
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6533.162187576294
  time_this_iter_s: 7.961634159088135
  time_total_s: 6533.162187576294
  timestamp: 1594855050
  timesteps_since_restore: 3760000
  timesteps_this_iter: 5000
  timesteps_total: 3760000
  training_iteration: 752
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6533 s, 752 iter, 3760000 ts, 97.4 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-17-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 92.5193869210961
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 752
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.924
    dispatch_time_ms: 8.792
    learner:
      cur_lr: 0.0011095840018242598
      grad_gnorm: 0.015639927238225937
      policy_entropy: 0.1883789747953415
      policy_loss: 1.5289778048099834e-06
      var_gnorm: 23.016958236694336
      vf_explained_var: 0.0
      vf_loss: 1.8872557916438382e-07
    num_steps_sampled: 3765000
    num_steps_trained: 3765000
    wait_time_ms: 68.056
  iterations_since_restore: 753
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6541.09809589386
  time_this_iter_s: 7.935908317565918
  time_total_s: 6541.09809589386
  timestamp: 1594855058
  timesteps_since_restore: 3765000
  timesteps_this_iter: 5000
  timesteps_total: 3765000
  training_iteration: 753
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6541 s, 753 iter, 3765000 ts, 92.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-17-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 88.73938693110813
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 753
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.79
    dispatch_time_ms: 7.953
    learner:
      cur_lr: 0.0011092510540038347
      grad_gnorm: 0.0028699194081127644
      policy_entropy: 0.20726561546325684
      policy_loss: 4.2443139136594255e-07
      var_gnorm: 23.017229080200195
      vf_explained_var: 0.0
      vf_loss: 5.135829983515805e-09
    num_steps_sampled: 3770000
    num_steps_trained: 3770000
    wait_time_ms: 71.852
  iterations_since_restore: 754
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6549.053205490112
  time_this_iter_s: 7.955109596252441
  time_total_s: 6549.053205490112
  timestamp: 1594855066
  timesteps_since_restore: 3770000
  timesteps_this_iter: 5000
  timesteps_total: 3770000
  training_iteration: 754
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6549 s, 754 iter, 3770000 ts, 88.7 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-17-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 87.02938693116202
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 754
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.176
    dispatch_time_ms: 7.792
    learner:
      cur_lr: 0.0011089179897680879
      grad_gnorm: 0.035177458077669144
      policy_entropy: 0.23166416585445404
      policy_loss: 4.350339168013306e-06
      var_gnorm: 23.017549514770508
      vf_explained_var: 0.0
      vf_loss: 9.5687926204846e-07
    num_steps_sampled: 3775000
    num_steps_trained: 3775000
    wait_time_ms: 71.152
  iterations_since_restore: 755
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6557.213686466217
  time_this_iter_s: 8.160480976104736
  time_total_s: 6557.213686466217
  timestamp: 1594855074
  timesteps_since_restore: 3775000
  timesteps_this_iter: 5000
  timesteps_total: 3775000
  training_iteration: 755
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6557 s, 755 iter, 3775000 ts, 87 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-18-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 84.68938693128719
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 755
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.931
    dispatch_time_ms: 7.877
    learner:
      cur_lr: 0.0011085850419476628
      grad_gnorm: 0.002343308413401246
      policy_entropy: 0.27798447012901306
      policy_loss: 1.9700451048265677e-06
      var_gnorm: 23.018001556396484
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 2.0555777080488724e-09
    num_steps_sampled: 3780000
    num_steps_trained: 3780000
    wait_time_ms: 69.916
  iterations_since_restore: 756
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6565.328586339951
  time_this_iter_s: 8.11489987373352
  time_total_s: 6565.328586339951
  timestamp: 1594855082
  timesteps_since_restore: 3780000
  timesteps_this_iter: 5000
  timesteps_total: 3780000
  training_iteration: 756
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6565 s, 756 iter, 3780000 ts, 84.7 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-18-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 82.1693869315863
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 756
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.201
    dispatch_time_ms: 7.508
    learner:
      cur_lr: 0.001108251977711916
      grad_gnorm: 0.01752893626689911
      policy_entropy: 0.32880517840385437
      policy_loss: -7.070511855999939e-06
      var_gnorm: 23.018495559692383
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.347655509993274e-07
    num_steps_sampled: 3785000
    num_steps_trained: 3785000
    wait_time_ms: 70.888
  iterations_since_restore: 757
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6573.361930608749
  time_this_iter_s: 8.033344268798828
  time_total_s: 6573.361930608749
  timestamp: 1594855090
  timesteps_since_restore: 3785000
  timesteps_this_iter: 5000
  timesteps_total: 3785000
  training_iteration: 757
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6573 s, 757 iter, 3785000 ts, 82.2 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-18-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 79.9193869316798
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 757
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 10.844
    learner:
      cur_lr: 0.001107919029891491
      grad_gnorm: 0.032706696540117264
      policy_entropy: 0.4030190110206604
      policy_loss: 7.582115358673036e-06
      var_gnorm: 23.019054412841797
      vf_explained_var: 0.0
      vf_loss: 8.242458306995104e-07
    num_steps_sampled: 3790000
    num_steps_trained: 3790000
    wait_time_ms: 68.786
  iterations_since_restore: 758
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6581.505202293396
  time_this_iter_s: 8.143271684646606
  time_total_s: 6581.505202293396
  timestamp: 1594855098
  timesteps_since_restore: 3790000
  timesteps_this_iter: 5000
  timesteps_total: 3790000
  training_iteration: 758
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6581 s, 758 iter, 3790000 ts, 79.9 rew

agent-1: 7.0260257861325135
agent-2: 8.02602578613251
agent-3: 9.026025786132513
agent-4: 10.02602578613251
agent-5: 7.02602578613251
Extrinsic Rewards:
1
2
3
4
1
Sum Reward: 11
Avg Reward: 2.2
Min Reward: 1
Max Reward: 4
Gini Coefficient: 0.2909090909090909
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-18-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 78.80068822104448
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 758
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.516
    dispatch_time_ms: 7.188
    learner:
      cur_lr: 0.001107585965655744
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.580658912658691
      policy_loss: -2.6747851371765137
      var_gnorm: 23.0345401763916
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.1858668327331543
    num_steps_sampled: 3795000
    num_steps_trained: 3795000
    wait_time_ms: 78.809
  iterations_since_restore: 759
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6589.703981399536
  time_this_iter_s: 8.198779106140137
  time_total_s: 6589.703981399536
  timestamp: 1594855107
  timesteps_since_restore: 3795000
  timesteps_this_iter: 5000
  timesteps_total: 3795000
  training_iteration: 759
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6589 s, 759 iter, 3795000 ts, 78.8 rew

agent-1: 46.13606667925015
agent-2: 47.13606667925015
agent-3: 53.13606667925016
agent-4: 49.13606667925015
agent-5: 47.13606667925015
Extrinsic Rewards:
3
4
10
6
4
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.23703703703703705
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-18-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 77.35749155696016
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 759
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.314
    dispatch_time_ms: 9.178
    learner:
      cur_lr: 0.001107253017835319
      grad_gnorm: 40.000003814697266
      policy_entropy: 3.9961233139038086
      policy_loss: -0.4984210133552551
      var_gnorm: 22.98797607421875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.17755651473999
    num_steps_sampled: 3800000
    num_steps_trained: 3800000
    wait_time_ms: 73.966
  iterations_since_restore: 760
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6598.277474164963
  time_this_iter_s: 8.573492765426636
  time_total_s: 6598.277474164963
  timestamp: 1594855115
  timesteps_since_restore: 3800000
  timesteps_this_iter: 5000
  timesteps_total: 3800000
  training_iteration: 760
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6598 s, 760 iter, 3800000 ts, 77.4 rew

agent-1: 107.99999829379641
agent-2: 112.99999829379641
agent-3: 103.99999829379641
agent-4: 108.99999829379641
agent-5: 105.99999829379641
Extrinsic Rewards:
12
17
8
13
10
Sum Reward: 60
Avg Reward: 12.0
Min Reward: 8
Max Reward: 17
Gini Coefficient: 0.14
20:20 Ratio: 2.125
Max-min Ratio: 2.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-18-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 81.13749147168419
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 760
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.724
    dispatch_time_ms: 6.292
    learner:
      cur_lr: 0.0011069199535995722
      grad_gnorm: 0.8782605528831482
      policy_entropy: 0.9707543849945068
      policy_loss: -0.03753470256924629
      var_gnorm: 22.968305587768555
      vf_explained_var: 0.0
      vf_loss: 0.0005946828750893474
    num_steps_sampled: 3805000
    num_steps_trained: 3805000
    wait_time_ms: 79.558
  iterations_since_restore: 761
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6606.7500286102295
  time_this_iter_s: 8.472554445266724
  time_total_s: 6606.7500286102295
  timestamp: 1594855124
  timesteps_since_restore: 3805000
  timesteps_this_iter: 5000
  timesteps_total: 3805000
  training_iteration: 761
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6606 s, 761 iter, 3805000 ts, 81.1 rew

agent-1: 42.5999999991026
agent-2: 34.59999999910262
agent-3: 40.59999999910261
agent-4: 34.59999999910263
agent-5: 36.5999999991026
Extrinsic Rewards:
9
1
7
1
3
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.41904761904761906
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-18-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 81.22749147169645
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 761
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 9.473
    learner:
      cur_lr: 0.0011065870057791471
      grad_gnorm: 4.8672685623168945
      policy_entropy: 1.584802269935608
      policy_loss: -0.004786284174770117
      var_gnorm: 22.9674072265625
      vf_explained_var: 0.0
      vf_loss: 0.018343999981880188
    num_steps_sampled: 3810000
    num_steps_trained: 3810000
    wait_time_ms: 67.526
  iterations_since_restore: 762
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6614.8905873298645
  time_this_iter_s: 8.14055871963501
  time_total_s: 6614.8905873298645
  timestamp: 1594855132
  timesteps_since_restore: 3810000
  timesteps_this_iter: 5000
  timesteps_total: 3810000
  training_iteration: 762
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6614 s, 762 iter, 3810000 ts, 81.2 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-19-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 78.79749147177577
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 762
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.622
    dispatch_time_ms: 5.989
    learner:
      cur_lr: 0.0011062540579587221
      grad_gnorm: 0.12338046729564667
      policy_entropy: 2.1542437076568604
      policy_loss: -0.0002480669063515961
      var_gnorm: 22.96706199645996
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.1575388271012343e-05
    num_steps_sampled: 3815000
    num_steps_trained: 3815000
    wait_time_ms: 73.189
  iterations_since_restore: 763
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6622.969739437103
  time_this_iter_s: 8.07915210723877
  time_total_s: 6622.969739437103
  timestamp: 1594855140
  timesteps_since_restore: 3815000
  timesteps_this_iter: 5000
  timesteps_total: 3815000
  training_iteration: 763
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6622 s, 763 iter, 3815000 ts, 78.8 rew

agent-1: 1.59999998739561
agent-2: 1.59999998739561
agent-3: 1.59999998739561
agent-4: 2.5999999873956083
agent-5: 1.59999998739561
Extrinsic Rewards:
0
0
0
1
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-19-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 76.72749147123722
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 763
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 8.281
    learner:
      cur_lr: 0.0011059209937229753
      grad_gnorm: 40.0
      policy_entropy: 35.84834289550781
      policy_loss: -14.843735694885254
      var_gnorm: 23.012901306152344
      vf_explained_var: 0.0
      vf_loss: 5.832521438598633
    num_steps_sampled: 3820000
    num_steps_trained: 3820000
    wait_time_ms: 75.807
  iterations_since_restore: 764
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6631.364538669586
  time_this_iter_s: 8.39479923248291
  time_total_s: 6631.364538669586
  timestamp: 1594855148
  timesteps_since_restore: 3820000
  timesteps_this_iter: 5000
  timesteps_total: 3820000
  training_iteration: 764
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6631 s, 764 iter, 3820000 ts, 76.7 rew

agent-1: 55.599994653918536
agent-2: 50.59999465391853
agent-3: 53.59999465391855
agent-4: 58.599994653918536
agent-5: 60.599994653918536
Extrinsic Rewards:
6
1
4
9
11
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.3225806451612903
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-19-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 76.6374912041474
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 764
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 8.071
    learner:
      cur_lr: 0.0011055880459025502
      grad_gnorm: 10.718684196472168
      policy_entropy: 0.8525445461273193
      policy_loss: -0.0068186563439667225
      var_gnorm: 22.980512619018555
      vf_explained_var: 0.0
      vf_loss: 0.08897270262241364
    num_steps_sampled: 3825000
    num_steps_trained: 3825000
    wait_time_ms: 74.109
  iterations_since_restore: 765
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6655.614023447037
  time_this_iter_s: 24.24948477745056
  time_total_s: 6655.614023447037
  timestamp: 1594855173
  timesteps_since_restore: 3825000
  timesteps_this_iter: 5000
  timesteps_total: 3825000
  training_iteration: 765
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6655 s, 765 iter, 3825000 ts, 76.6 rew

agent-1: 110.79999976775774
agent-2: 102.79999976775774
agent-3: 100.79999976775773
agent-4: 107.79999976775773
agent-5: 99.79999976775773
Extrinsic Rewards:
18
10
8
15
7
Sum Reward: 58
Avg Reward: 11.6
Min Reward: 7
Max Reward: 18
Gini Coefficient: 0.2
20:20 Ratio: 2.5714285714285716
Max-min Ratio: 2.5714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-19-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 78.88749120021552
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 765
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.638
    dispatch_time_ms: 7.32
    learner:
      cur_lr: 0.0011052549816668034
      grad_gnorm: 5.655797958374023
      policy_entropy: 1.4891183376312256
      policy_loss: -0.005344650708138943
      var_gnorm: 22.979284286499023
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.024769632145762444
    num_steps_sampled: 3830000
    num_steps_trained: 3830000
    wait_time_ms: 74.725
  iterations_since_restore: 766
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6663.976078748703
  time_this_iter_s: 8.36205530166626
  time_total_s: 6663.976078748703
  timestamp: 1594855181
  timesteps_since_restore: 3830000
  timesteps_this_iter: 5000
  timesteps_total: 3830000
  training_iteration: 766
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6663 s, 766 iter, 3830000 ts, 78.9 rew

agent-1: 57.290853731144736
agent-2: 59.29085373114477
agent-3: 57.29085373114475
agent-4: 59.290853731144765
agent-5: 52.290853731144765
Extrinsic Rewards:
8
10
8
10
3
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.1641025641025641
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-19-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 80.03203388683247
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 766
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.741
    dispatch_time_ms: 7.281
    learner:
      cur_lr: 0.0011049220338463783
      grad_gnorm: 40.0
      policy_entropy: 26.420223236083984
      policy_loss: 22.398902893066406
      var_gnorm: 23.002904891967773
      vf_explained_var: 0.0
      vf_loss: 24.79701805114746
    num_steps_sampled: 3835000
    num_steps_trained: 3835000
    wait_time_ms: 73.694
  iterations_since_restore: 767
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6672.38508272171
  time_this_iter_s: 8.409003973007202
  time_total_s: 6672.38508272171
  timestamp: 1594855190
  timesteps_since_restore: 3835000
  timesteps_this_iter: 5000
  timesteps_total: 3835000
  training_iteration: 767
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6672 s, 767 iter, 3835000 ts, 80 rew

agent-1: 121.64542413111259
agent-2: 113.64542413111259
agent-3: 106.64542413111256
agent-4: 120.64542413111259
agent-5: 110.64542413111256
Extrinsic Rewards:
20
12
5
19
9
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 5
Max Reward: 20
Gini Coefficient: 0.24615384615384617
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-19-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 82.3443050937433
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 767
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.431
    dispatch_time_ms: 8.35
    learner:
      cur_lr: 0.0011045889696106315
      grad_gnorm: 40.0
      policy_entropy: 10.235346794128418
      policy_loss: -7.027115345001221
      var_gnorm: 23.000333786010742
      vf_explained_var: 0.0
      vf_loss: 11.137218475341797
    num_steps_sampled: 3840000
    num_steps_trained: 3840000
    wait_time_ms: 76.266
  iterations_since_restore: 768
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6680.955857038498
  time_this_iter_s: 8.57077431678772
  time_total_s: 6680.955857038498
  timestamp: 1594855198
  timesteps_since_restore: 3840000
  timesteps_this_iter: 5000
  timesteps_total: 3840000
  training_iteration: 768
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6680 s, 768 iter, 3840000 ts, 82.3 rew

agent-1: 92.99999926415447
agent-2: 95.99999926415447
agent-3: 87.9999992641545
agent-4: 84.99999926415447
agent-5: 87.9999992641545
Extrinsic Rewards:
13
16
8
5
8
Sum Reward: 50
Avg Reward: 10.0
Min Reward: 5
Max Reward: 16
Gini Coefficient: 0.216
20:20 Ratio: 3.2
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-20-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 746.9432546819222
  episode_reward_mean: 84.4143050571618
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 768
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 6.809
    learner:
      cur_lr: 0.0011042560217902064
      grad_gnorm: 40.0
      policy_entropy: 5.851845741271973
      policy_loss: 1.2871031761169434
      var_gnorm: 22.96095085144043
      vf_explained_var: 0.0
      vf_loss: 8.236682891845703
    num_steps_sampled: 3845000
    num_steps_trained: 3845000
    wait_time_ms: 70.748
  iterations_since_restore: 769
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6689.639726161957
  time_this_iter_s: 8.683869123458862
  time_total_s: 6689.639726161957
  timestamp: 1594855207
  timesteps_since_restore: 3845000
  timesteps_this_iter: 5000
  timesteps_total: 3845000
  training_iteration: 769
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6689 s, 769 iter, 3845000 ts, 84.4 rew

agent-1: 46.59999999613959
agent-2: 44.5999999961396
agent-3: 46.59999999613959
agent-4: 48.59999999613959
agent-5: 47.59999999613959
Extrinsic Rewards:
5
3
5
7
6
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.13846153846153847
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-20-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 719.9954835047427
  episode_reward_mean: 79.28487251014957
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 769
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.627
    dispatch_time_ms: 8.802
    learner:
      cur_lr: 0.0011039229575544596
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.8693904876709
      policy_loss: -6.125349044799805
      var_gnorm: 22.979232788085938
      vf_explained_var: 0.0
      vf_loss: 2.9627509117126465
    num_steps_sampled: 3850000
    num_steps_trained: 3850000
    wait_time_ms: 77.216
  iterations_since_restore: 770
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6698.200400590897
  time_this_iter_s: 8.56067442893982
  time_total_s: 6698.200400590897
  timestamp: 1594855215
  timesteps_since_restore: 3850000
  timesteps_this_iter: 5000
  timesteps_total: 3850000
  training_iteration: 770
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6698 s, 770 iter, 3850000 ts, 79.3 rew

agent-1: 111.39986304200127
agent-2: 112.39986304200127
agent-3: 101.39986304200127
agent-4: 99.39986304200131
agent-5: 106.39986304200127
Extrinsic Rewards:
17
18
7
5
12
Sum Reward: 59
Avg Reward: 11.8
Min Reward: 5
Max Reward: 18
Gini Coefficient: 0.2440677966101695
20:20 Ratio: 3.6
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-20-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 719.9954835047427
  episode_reward_mean: 82.07486566453471
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 770
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 8.132
    learner:
      cur_lr: 0.0011035900097340345
      grad_gnorm: 40.0
      policy_entropy: 21.926923751831055
      policy_loss: -8.422259330749512
      var_gnorm: 22.96707534790039
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.528294563293457
    num_steps_sampled: 3855000
    num_steps_trained: 3855000
    wait_time_ms: 75.427
  iterations_since_restore: 771
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6706.875998973846
  time_this_iter_s: 8.675598382949829
  time_total_s: 6706.875998973846
  timestamp: 1594855224
  timesteps_since_restore: 3855000
  timesteps_this_iter: 5000
  timesteps_total: 3855000
  training_iteration: 771
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6706 s, 771 iter, 3855000 ts, 82.1 rew

agent-1: 116.39990533025932
agent-2: 114.39990533025934
agent-3: 110.39990533025937
agent-4: 116.39990533025937
agent-5: 118.39990533025934
Extrinsic Rewards:
14
12
8
14
16
Sum Reward: 64
Avg Reward: 12.8
Min Reward: 8
Max Reward: 16
Gini Coefficient: 0.1125
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-20-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 719.9954835047427
  episode_reward_mean: 83.51486095866012
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 771
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.508
    dispatch_time_ms: 6.299
    learner:
      cur_lr: 0.0011032569454982877
      grad_gnorm: 40.0
      policy_entropy: 16.7049617767334
      policy_loss: 16.003679275512695
      var_gnorm: 22.96432113647461
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 74.41181945800781
    num_steps_sampled: 3860000
    num_steps_trained: 3860000
    wait_time_ms: 73.79
  iterations_since_restore: 772
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6715.416652917862
  time_this_iter_s: 8.540653944015503
  time_total_s: 6715.416652917862
  timestamp: 1594855233
  timesteps_since_restore: 3860000
  timesteps_this_iter: 5000
  timesteps_total: 3860000
  training_iteration: 772
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6715 s, 772 iter, 3860000 ts, 83.5 rew

agent-1: 59.79999999608569
agent-2: 62.79999999608569
agent-3: 58.799999996085674
agent-4: 57.799999996085674
agent-5: 57.799999996085674
Extrinsic Rewards:
7
10
6
5
5
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 5
Max Reward: 10
Gini Coefficient: 0.14545454545454545
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-20-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 719.9954835047427
  episode_reward_mean: 84.50486095854434
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 772
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.902
    dispatch_time_ms: 25.639
    learner:
      cur_lr: 0.0011029239976778626
      grad_gnorm: 27.862720489501953
      policy_entropy: 8.158975601196289
      policy_loss: -0.6016196012496948
      var_gnorm: 22.96866226196289
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.5998125672340393
    num_steps_sampled: 3865000
    num_steps_trained: 3865000
    wait_time_ms: 67.117
  iterations_since_restore: 773
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6728.427062749863
  time_this_iter_s: 13.010409832000732
  time_total_s: 6728.427062749863
  timestamp: 1594855246
  timesteps_since_restore: 3865000
  timesteps_this_iter: 5000
  timesteps_total: 3865000
  training_iteration: 773
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6728 s, 773 iter, 3865000 ts, 84.5 rew

agent-1: 191.19988075830085
agent-2: 177.19988075830082
agent-3: 178.1998807583008
agent-4: 186.19988075830085
agent-5: 185.1998807583008
Extrinsic Rewards:
28
14
15
23
22
Sum Reward: 102
Avg Reward: 20.4
Min Reward: 14
Max Reward: 28
Gini Coefficient: 0.1411764705882353
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-20-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 917.9994037915058
  episode_reward_mean: 92.06485499649412
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 773
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.245
    dispatch_time_ms: 32.443
    learner:
      cur_lr: 0.0011025910498574376
      grad_gnorm: 40.000003814697266
      policy_entropy: 9.807723999023438
      policy_loss: -1.8924577236175537
      var_gnorm: 22.979164123535156
      vf_explained_var: 0.0
      vf_loss: 2.5901975631713867
    num_steps_sampled: 3870000
    num_steps_trained: 3870000
    wait_time_ms: 46.018
  iterations_since_restore: 774
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6737.432329177856
  time_this_iter_s: 9.005266427993774
  time_total_s: 6737.432329177856
  timestamp: 1594855255
  timesteps_since_restore: 3870000
  timesteps_this_iter: 5000
  timesteps_total: 3870000
  training_iteration: 774
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6737 s, 774 iter, 3870000 ts, 92.1 rew

agent-1: 200.4621450015325
agent-2: 219.46214500153255
agent-3: 205.46214500153246
agent-4: 212.4621450015325
agent-5: 205.46214500153255
Extrinsic Rewards:
15
34
20
27
20
Sum Reward: 116
Avg Reward: 23.2
Min Reward: 15
Max Reward: 34
Gini Coefficient: 0.15517241379310345
20:20 Ratio: 2.2666666666666666
Max-min Ratio: 2.2666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-21-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 100.51796224660616
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 774
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.21
    dispatch_time_ms: 20.438
    learner:
      cur_lr: 0.0011022579856216908
      grad_gnorm: 40.000003814697266
      policy_entropy: 33.831111907958984
      policy_loss: 54.19892120361328
      var_gnorm: 22.962181091308594
      vf_explained_var: 0.0
      vf_loss: 78.21690368652344
    num_steps_sampled: 3875000
    num_steps_trained: 3875000
    wait_time_ms: 67.119
  iterations_since_restore: 775
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6746.504130125046
  time_this_iter_s: 9.071800947189331
  time_total_s: 6746.504130125046
  timestamp: 1594855264
  timesteps_since_restore: 3875000
  timesteps_this_iter: 5000
  timesteps_total: 3875000
  training_iteration: 775
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6746 s, 775 iter, 3875000 ts, 101 rew

agent-1: 70.59999992629675
agent-2: 76.59999992629676
agent-3: 71.59999992629676
agent-4: 78.59999992629676
agent-5: 71.59999992629676
Extrinsic Rewards:
5
11
6
13
6
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 5
Max Reward: 13
Gini Coefficient: 0.2048780487804878
20:20 Ratio: 2.6
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-21-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 101.68796224311758
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 775
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.406
    dispatch_time_ms: 8.485
    learner:
      cur_lr: 0.0011019250378012657
      grad_gnorm: 17.32900047302246
      policy_entropy: 33.98347473144531
      policy_loss: -2.794034004211426
      var_gnorm: 22.963953018188477
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.21021871268749237
    num_steps_sampled: 3880000
    num_steps_trained: 3880000
    wait_time_ms: 77.773
  iterations_since_restore: 776
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6755.453323602676
  time_this_iter_s: 8.949193477630615
  time_total_s: 6755.453323602676
  timestamp: 1594855273
  timesteps_since_restore: 3880000
  timesteps_this_iter: 5000
  timesteps_total: 3880000
  training_iteration: 776
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6755 s, 776 iter, 3880000 ts, 102 rew

agent-1: 58.399999994342636
agent-2: 63.39999999434265
agent-3: 59.399999994342636
agent-4: 60.39999999434262
agent-5: 64.39999999434278
Extrinsic Rewards:
4
9
5
6
10
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 4
Max Reward: 10
Gini Coefficient: 0.18823529411764706
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-21-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 99.79796264655577
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 776
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 8.473
    learner:
      cur_lr: 0.0011015919735655189
      grad_gnorm: 9.227388381958008
      policy_entropy: 26.696182250976562
      policy_loss: -0.9656996726989746
      var_gnorm: 22.972288131713867
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.06448422372341156
    num_steps_sampled: 3885000
    num_steps_trained: 3885000
    wait_time_ms: 76.49
  iterations_since_restore: 777
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6764.082868337631
  time_this_iter_s: 8.629544734954834
  time_total_s: 6764.082868337631
  timestamp: 1594855282
  timesteps_since_restore: 3885000
  timesteps_this_iter: 5000
  timesteps_total: 3885000
  training_iteration: 777
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6764 s, 777 iter, 3885000 ts, 99.8 rew

agent-1: 25.599999999568325
agent-2: 27.59999999956833
agent-3: 32.59999999956847
agent-4: 26.59999999956833
agent-5: 31.599999999568332
Extrinsic Rewards:
0
2
7
1
6
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.475
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-21-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 97.72796265056463
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 777
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.809
    dispatch_time_ms: 6.816
    learner:
      cur_lr: 0.0011012590257450938
      grad_gnorm: 14.564507484436035
      policy_entropy: 27.06904411315918
      policy_loss: -2.6215529441833496
      var_gnorm: 22.96805763244629
      vf_explained_var: 0.0
      vf_loss: 0.1376664787530899
    num_steps_sampled: 3890000
    num_steps_trained: 3890000
    wait_time_ms: 77.229
  iterations_since_restore: 778
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6772.712045431137
  time_this_iter_s: 8.62917709350586
  time_total_s: 6772.712045431137
  timestamp: 1594855290
  timesteps_since_restore: 3890000
  timesteps_this_iter: 5000
  timesteps_total: 3890000
  training_iteration: 778
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6772 s, 778 iter, 3890000 ts, 97.7 rew

agent-1: 52.99999999856802
agent-2: 41.99999999856801
agent-3: 44.99999999856801
agent-4: 40.99999999856802
agent-5: 43.99999999856801
Extrinsic Rewards:
13
2
5
1
4
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.432
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-21-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 97.36796265060462
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 778
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.01
    dispatch_time_ms: 9.189
    learner:
      cur_lr: 0.001100925961509347
      grad_gnorm: 9.830022811889648
      policy_entropy: 31.318349838256836
      policy_loss: -1.1214114427566528
      var_gnorm: 22.968292236328125
      vf_explained_var: 0.0
      vf_loss: 0.07017405331134796
    num_steps_sampled: 3895000
    num_steps_trained: 3895000
    wait_time_ms: 73.745
  iterations_since_restore: 779
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6781.264746427536
  time_this_iter_s: 8.552700996398926
  time_total_s: 6781.264746427536
  timestamp: 1594855299
  timesteps_since_restore: 3895000
  timesteps_this_iter: 5000
  timesteps_total: 3895000
  training_iteration: 779
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6781 s, 779 iter, 3895000 ts, 97.4 rew

agent-1: 50.399999998246585
agent-2: 55.39999999824656
agent-3: 51.39999999824657
agent-4: 52.39999999824657
agent-5: 51.39999999824657
Extrinsic Rewards:
4
9
5
6
5
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.15172413793103448
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-21-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 98.08796265055372
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 779
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.675
    dispatch_time_ms: 9.263
    learner:
      cur_lr: 0.001100593013688922
      grad_gnorm: 40.0
      policy_entropy: 23.701631546020508
      policy_loss: 2.345827102661133
      var_gnorm: 22.979108810424805
      vf_explained_var: 0.0
      vf_loss: 2.3045148849487305
    num_steps_sampled: 3900000
    num_steps_trained: 3900000
    wait_time_ms: 75.131
  iterations_since_restore: 780
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6789.927990436554
  time_this_iter_s: 8.663244009017944
  time_total_s: 6789.927990436554
  timestamp: 1594855308
  timesteps_since_restore: 3900000
  timesteps_this_iter: 5000
  timesteps_total: 3900000
  training_iteration: 780
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6789 s, 780 iter, 3900000 ts, 98.1 rew

agent-1: 74.39999969967462
agent-2: 87.3999996996746
agent-3: 76.39999969967461
agent-4: 84.3999996996746
agent-5: 73.39999969967462
Extrinsic Rewards:
4
17
6
14
3
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 3
Max Reward: 17
Gini Coefficient: 0.34545454545454546
20:20 Ratio: 5.666666666666667
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-21-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 99.79796263567646
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 780
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.915
    dispatch_time_ms: 10.518
    learner:
      cur_lr: 0.001100259949453175
      grad_gnorm: 13.786836624145508
      policy_entropy: 22.66035270690918
      policy_loss: -1.6922621726989746
      var_gnorm: 22.975360870361328
      vf_explained_var: 0.0
      vf_loss: 0.1434362232685089
    num_steps_sampled: 3905000
    num_steps_trained: 3905000
    wait_time_ms: 70.984
  iterations_since_restore: 781
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6798.5411212444305
  time_this_iter_s: 8.613130807876587
  time_total_s: 6798.5411212444305
  timestamp: 1594855316
  timesteps_since_restore: 3905000
  timesteps_this_iter: 5000
  timesteps_total: 3905000
  training_iteration: 781
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6798 s, 781 iter, 3905000 ts, 99.8 rew

agent-1: 78.19999872992621
agent-2: 91.19999872992622
agent-3: 93.19999872992625
agent-4: 78.1999987299262
agent-5: 82.19999872992621
Extrinsic Rewards:
3
16
18
3
7
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 3
Max Reward: 18
Gini Coefficient: 0.3659574468085106
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-22-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 101.77796257233199
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 781
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 9.722
    learner:
      cur_lr: 0.00109992700163275
      grad_gnorm: 40.0
      policy_entropy: 21.48255157470703
      policy_loss: -6.124999046325684
      var_gnorm: 22.974525451660156
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.9072178602218628
    num_steps_sampled: 3910000
    num_steps_trained: 3910000
    wait_time_ms: 75.16
  iterations_since_restore: 782
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6807.181065559387
  time_this_iter_s: 8.639944314956665
  time_total_s: 6807.181065559387
  timestamp: 1594855325
  timesteps_since_restore: 3910000
  timesteps_this_iter: 5000
  timesteps_total: 3910000
  training_iteration: 782
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6807 s, 782 iter, 3910000 ts, 102 rew

agent-1: 100.59999570989645
agent-2: 95.59999570989643
agent-3: 100.5999957098964
agent-4: 101.5999957098964
agent-5: 105.59999570989638
Extrinsic Rewards:
11
6
11
12
16
Sum Reward: 56
Avg Reward: 11.2
Min Reward: 6
Max Reward: 16
Gini Coefficient: 0.15
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-22-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 103.57796235859509
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 782
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 5.767
    learner:
      cur_lr: 0.001099594053812325
      grad_gnorm: 11.42875862121582
      policy_entropy: 13.273420333862305
      policy_loss: -0.5317598581314087
      var_gnorm: 22.95761489868164
      vf_explained_var: 0.0
      vf_loss: 0.10033297538757324
    num_steps_sampled: 3915000
    num_steps_trained: 3915000
    wait_time_ms: 81.183
  iterations_since_restore: 783
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6815.930637836456
  time_this_iter_s: 8.749572277069092
  time_total_s: 6815.930637836456
  timestamp: 1594855334
  timesteps_since_restore: 3915000
  timesteps_this_iter: 5000
  timesteps_total: 3915000
  training_iteration: 783
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6815 s, 783 iter, 3915000 ts, 104 rew

agent-1: 70.39999997616262
agent-2: 69.39999997616259
agent-3: 66.39999997616259
agent-4: 70.39999997616259
agent-5: 74.39999997616259
Extrinsic Rewards:
8
7
4
8
12
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.17435897435897435
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-22-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 99.88800752235582
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 783
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.546
    dispatch_time_ms: 6.303
    learner:
      cur_lr: 0.0010992609895765781
      grad_gnorm: 38.0797004699707
      policy_entropy: 33.79908752441406
      policy_loss: -6.971490383148193
      var_gnorm: 22.960779190063477
      vf_explained_var: 0.0
      vf_loss: 1.1224313974380493
    num_steps_sampled: 3920000
    num_steps_trained: 3920000
    wait_time_ms: 76.703
  iterations_since_restore: 784
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6824.551509618759
  time_this_iter_s: 8.620871782302856
  time_total_s: 6824.551509618759
  timestamp: 1594855342
  timesteps_since_restore: 3920000
  timesteps_this_iter: 5000
  timesteps_total: 3920000
  training_iteration: 784
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6824 s, 784 iter, 3920000 ts, 99.9 rew

agent-1: 126.39999587530687
agent-2: 117.39999587530687
agent-3: 127.39999587530687
agent-4: 124.39999587530687
agent-5: 125.39999587530687
Extrinsic Rewards:
16
7
17
14
15
Sum Reward: 69
Avg Reward: 13.8
Min Reward: 7
Max Reward: 17
Gini Coefficient: 0.12753623188405797
20:20 Ratio: 2.4285714285714284
Max-min Ratio: 2.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-22-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 103.30800731630384
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 784
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 6.705
    learner:
      cur_lr: 0.001098928041756153
      grad_gnorm: 40.0
      policy_entropy: 31.482229232788086
      policy_loss: 5.954158782958984
      var_gnorm: 22.95098114013672
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.3597332239151
    num_steps_sampled: 3925000
    num_steps_trained: 3925000
    wait_time_ms: 81.329
  iterations_since_restore: 785
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6833.206111192703
  time_this_iter_s: 8.654601573944092
  time_total_s: 6833.206111192703
  timestamp: 1594855351
  timesteps_since_restore: 3925000
  timesteps_this_iter: 5000
  timesteps_total: 3925000
  training_iteration: 785
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6833 s, 785 iter, 3925000 ts, 103 rew

agent-1: 49.99999999834314
agent-2: 52.99999999834313
agent-3: 53.99999999834314
agent-4: 57.99999999834313
agent-5: 54.99999999834313
Extrinsic Rewards:
2
5
6
10
7
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.24
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-22-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 106.00800731622103
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 785
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.908
    dispatch_time_ms: 11.474
    learner:
      cur_lr: 0.0010985949775204062
      grad_gnorm: 25.221141815185547
      policy_entropy: 32.79259490966797
      policy_loss: -4.286957263946533
      var_gnorm: 22.950536727905273
      vf_explained_var: 0.0
      vf_loss: 0.4821373522281647
    num_steps_sampled: 3930000
    num_steps_trained: 3930000
    wait_time_ms: 68.027
  iterations_since_restore: 786
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6841.862552165985
  time_this_iter_s: 8.65644097328186
  time_total_s: 6841.862552165985
  timestamp: 1594855360
  timesteps_since_restore: 3930000
  timesteps_this_iter: 5000
  timesteps_total: 3930000
  training_iteration: 786
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6841 s, 786 iter, 3930000 ts, 106 rew

agent-1: 35.59999999899179
agent-2: 42.599999998991805
agent-3: 34.599999998991805
agent-4: 35.59999999899179
agent-5: 40.59999999899181
Extrinsic Rewards:
2
9
1
2
7
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-22-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 107.8980073161706
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 786
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 8.842
    learner:
      cur_lr: 0.0010982620296999812
      grad_gnorm: 10.241703987121582
      policy_entropy: 33.5580940246582
      policy_loss: -1.3570345640182495
      var_gnorm: 22.952272415161133
      vf_explained_var: 0.0
      vf_loss: 0.0797320082783699
    num_steps_sampled: 3935000
    num_steps_trained: 3935000
    wait_time_ms: 74.383
  iterations_since_restore: 787
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6850.41784286499
  time_this_iter_s: 8.555290699005127
  time_total_s: 6850.41784286499
  timestamp: 1594855368
  timesteps_since_restore: 3935000
  timesteps_this_iter: 5000
  timesteps_total: 3935000
  training_iteration: 787
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6850 s, 787 iter, 3935000 ts, 108 rew

agent-1: 79.59999996967329
agent-2: 75.59999996967329
agent-3: 88.59999996967325
agent-4: 88.59999996967326
agent-5: 81.59999996967328
Extrinsic Rewards:
6
2
15
15
8
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.30434782608695654
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-22-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 112.03800731465427
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 787
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.12
    dispatch_time_ms: 7.919
    learner:
      cur_lr: 0.0010979289654642344
      grad_gnorm: 16.123231887817383
      policy_entropy: 29.01668930053711
      policy_loss: -3.0319175720214844
      var_gnorm: 22.948806762695312
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.200824573636055
    num_steps_sampled: 3940000
    num_steps_trained: 3940000
    wait_time_ms: 77.868
  iterations_since_restore: 788
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6859.055409193039
  time_this_iter_s: 8.637566328048706
  time_total_s: 6859.055409193039
  timestamp: 1594855377
  timesteps_since_restore: 3940000
  timesteps_this_iter: 5000
  timesteps_total: 3940000
  training_iteration: 788
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6859 s, 788 iter, 3940000 ts, 112 rew

agent-1: 43.19999999825878
agent-2: 39.199999998258804
agent-3: 40.199999998258804
agent-4: 38.199999998258804
agent-5: 37.199999998258804
Extrinsic Rewards:
8
4
5
3
2
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-23-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 114.01800731456719
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 788
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.622
    dispatch_time_ms: 9.285
    learner:
      cur_lr: 0.0010975960176438093
      grad_gnorm: 23.217792510986328
      policy_entropy: 34.61903762817383
      policy_loss: 4.199316024780273
      var_gnorm: 22.94890785217285
      vf_explained_var: 0.0
      vf_loss: 0.3784584105014801
    num_steps_sampled: 3945000
    num_steps_trained: 3945000
    wait_time_ms: 73.854
  iterations_since_restore: 789
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6867.683105230331
  time_this_iter_s: 8.62769603729248
  time_total_s: 6867.683105230331
  timestamp: 1594855386
  timesteps_since_restore: 3945000
  timesteps_this_iter: 5000
  timesteps_total: 3945000
  training_iteration: 789
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6867 s, 789 iter, 3945000 ts, 114 rew

agent-1: 53.999999996271384
agent-2: 57.999999996271384
agent-3: 52.999999996271384
agent-4: 52.999999996271384
agent-5: 51.999999996271384
Extrinsic Rewards:
6
10
5
5
4
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 4
Max Reward: 10
Gini Coefficient: 0.17333333333333334
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-23-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 116.71800731438074
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 789
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.35
    dispatch_time_ms: 7.916
    learner:
      cur_lr: 0.0010972629534080625
      grad_gnorm: 9.286357879638672
      policy_entropy: 27.930965423583984
      policy_loss: -1.2676392793655396
      var_gnorm: 22.949298858642578
      vf_explained_var: 0.0
      vf_loss: 0.06592545658349991
    num_steps_sampled: 3950000
    num_steps_trained: 3950000
    wait_time_ms: 74.897
  iterations_since_restore: 790
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6876.378304243088
  time_this_iter_s: 8.695199012756348
  time_total_s: 6876.378304243088
  timestamp: 1594855394
  timesteps_since_restore: 3950000
  timesteps_this_iter: 5000
  timesteps_total: 3950000
  training_iteration: 790
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6876 s, 790 iter, 3950000 ts, 117 rew

agent-1: 28.5999999995119
agent-2: 26.599999999511894
agent-3: 27.5999999995119
agent-4: 31.5999999995119
agent-5: 29.5999999995119
Extrinsic Rewards:
3
1
2
6
4
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.3
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-23-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 118.15800731435633
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 790
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.305
    dispatch_time_ms: 9.976
    learner:
      cur_lr: 0.0010969300055876374
      grad_gnorm: 11.275101661682129
      policy_entropy: 32.93843460083008
      policy_loss: -1.2498903274536133
      var_gnorm: 22.949975967407227
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.09387707710266113
    num_steps_sampled: 3955000
    num_steps_trained: 3955000
    wait_time_ms: 75.484
  iterations_since_restore: 791
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6884.980839729309
  time_this_iter_s: 8.602535486221313
  time_total_s: 6884.980839729309
  timestamp: 1594855403
  timesteps_since_restore: 3955000
  timesteps_this_iter: 5000
  timesteps_total: 3955000
  training_iteration: 791
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6884 s, 791 iter, 3955000 ts, 118 rew

agent-1: 31.999999999381057
agent-2: 44.999999999381096
agent-3: 34.999999999381096
agent-4: 31.999999999381057
agent-5: 35.999999999381096
Extrinsic Rewards:
0
13
3
0
4
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-23-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 119.95800731432536
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 791
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.59
    dispatch_time_ms: 7.133
    learner:
      cur_lr: 0.0010965970577672124
      grad_gnorm: 30.86362075805664
      policy_entropy: 22.355680465698242
      policy_loss: -3.5973644256591797
      var_gnorm: 22.95755386352539
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.7375178933143616
    num_steps_sampled: 3960000
    num_steps_trained: 3960000
    wait_time_ms: 77.966
  iterations_since_restore: 792
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6893.663263559341
  time_this_iter_s: 8.682423830032349
  time_total_s: 6893.663263559341
  timestamp: 1594855412
  timesteps_since_restore: 3960000
  timesteps_this_iter: 5000
  timesteps_total: 3960000
  training_iteration: 792
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6893 s, 792 iter, 3960000 ts, 120 rew

agent-1: 61.39999995721126
agent-2: 65.3999999572113
agent-3: 62.39999995721127
agent-4: 58.39999995721127
agent-5: 58.39999995721127
Extrinsic Rewards:
7
11
8
4
4
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 4
Max Reward: 11
Gini Coefficient: 0.21176470588235294
20:20 Ratio: 2.75
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-23-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 123.01800731218593
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 792
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.762
    dispatch_time_ms: 7.22
    learner:
      cur_lr: 0.0010962639935314655
      grad_gnorm: 40.0
      policy_entropy: 21.88081932067871
      policy_loss: 8.135048866271973
      var_gnorm: 22.959871292114258
      vf_explained_var: 0.0
      vf_loss: 3.3366219997406006
    num_steps_sampled: 3965000
    num_steps_trained: 3965000
    wait_time_ms: 80.492
  iterations_since_restore: 793
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6902.349720954895
  time_this_iter_s: 8.686457395553589
  time_total_s: 6902.349720954895
  timestamp: 1594855420
  timesteps_since_restore: 3965000
  timesteps_this_iter: 5000
  timesteps_total: 3965000
  training_iteration: 793
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6902 s, 793 iter, 3965000 ts, 123 rew

agent-1: 60.599999985739665
agent-2: 71.59999998573979
agent-3: 64.59999998573981
agent-4: 63.59999998573965
agent-5: 63.59999998573965
Extrinsic Rewards:
3
14
7
6
6
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.25555555555555554
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-23-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 126.25800731147291
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 793
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.656
    dispatch_time_ms: 7.065
    learner:
      cur_lr: 0.0010959310457110405
      grad_gnorm: 8.783736228942871
      policy_entropy: 28.513641357421875
      policy_loss: -1.5791711807250977
      var_gnorm: 22.950881958007812
      vf_explained_var: 0.0
      vf_loss: 0.05748988687992096
    num_steps_sampled: 3970000
    num_steps_trained: 3970000
    wait_time_ms: 77.389
  iterations_since_restore: 794
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6911.022376298904
  time_this_iter_s: 8.6726553440094
  time_total_s: 6911.022376298904
  timestamp: 1594855429
  timesteps_since_restore: 3970000
  timesteps_this_iter: 5000
  timesteps_total: 3970000
  training_iteration: 794
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6911 s, 794 iter, 3970000 ts, 126 rew

agent-1: 47.99999999886208
agent-2: 41.999999998862066
agent-3: 41.999999998862066
agent-4: 46.99999999886206
agent-5: 45.99999999886207
Extrinsic Rewards:
8
2
2
7
6
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.272
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-23-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 128.50800731141604
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 794
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 6.999
    learner:
      cur_lr: 0.0010955979814752936
      grad_gnorm: 40.000003814697266
      policy_entropy: 34.71527862548828
      policy_loss: 8.480032920837402
      var_gnorm: 22.950159072875977
      vf_explained_var: 0.0
      vf_loss: 1.928315281867981
    num_steps_sampled: 3975000
    num_steps_trained: 3975000
    wait_time_ms: 78.072
  iterations_since_restore: 795
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6919.719758987427
  time_this_iter_s: 8.697382688522339
  time_total_s: 6919.719758987427
  timestamp: 1594855438
  timesteps_since_restore: 3975000
  timesteps_this_iter: 5000
  timesteps_total: 3975000
  training_iteration: 795
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6919 s, 795 iter, 3975000 ts, 129 rew

agent-1: 31.799999999476622
agent-2: 31.799999999476622
agent-3: 32.799999999476626
agent-4: 31.799999999476622
agent-5: 33.79999999947662
Extrinsic Rewards:
3
3
4
3
5
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 3
Max Reward: 5
Gini Coefficient: 0.1111111111111111
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-24-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 130.1280073113899
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 795
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.703
    dispatch_time_ms: 7.455
    learner:
      cur_lr: 0.0010952650336548686
      grad_gnorm: 23.971233367919922
      policy_entropy: 33.934139251708984
      policy_loss: -3.790698528289795
      var_gnorm: 22.94829750061035
      vf_explained_var: 0.0
      vf_loss: 0.2528766691684723
    num_steps_sampled: 3980000
    num_steps_trained: 3980000
    wait_time_ms: 74.911
  iterations_since_restore: 796
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6928.295514822006
  time_this_iter_s: 8.575755834579468
  time_total_s: 6928.295514822006
  timestamp: 1594855446
  timesteps_since_restore: 3980000
  timesteps_this_iter: 5000
  timesteps_total: 3980000
  training_iteration: 796
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6928 s, 796 iter, 3980000 ts, 130 rew

agent-1: 33.99999999908699
agent-2: 35.99999999908697
agent-3: 37.99999999908697
agent-4: 34.999999999086974
agent-5: 36.99999999908698
Extrinsic Rewards:
2
4
6
3
5
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.2
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-24-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 131.92800731134423
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 796
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 9.283
    learner:
      cur_lr: 0.0010949319694191217
      grad_gnorm: 11.317737579345703
      policy_entropy: 32.89409637451172
      policy_loss: -1.5925471782684326
      var_gnorm: 22.941104888916016
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.09045339375734329
    num_steps_sampled: 3985000
    num_steps_trained: 3985000
    wait_time_ms: 75.045
  iterations_since_restore: 797
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6936.896477460861
  time_this_iter_s: 8.60096263885498
  time_total_s: 6936.896477460861
  timestamp: 1594855455
  timesteps_since_restore: 3985000
  timesteps_this_iter: 5000
  timesteps_total: 3985000
  training_iteration: 797
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6936 s, 797 iter, 3985000 ts, 132 rew

agent-1: 47.59999998924083
agent-2: 47.59999998924083
agent-3: 52.59999998924085
agent-4: 44.59999998924084
agent-5: 41.59999998924084
Extrinsic Rewards:
6
6
11
3
0
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.38461538461538464
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-24-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 134.2680073108063
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 797
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.371
    dispatch_time_ms: 7.557
    learner:
      cur_lr: 0.0010945990215986967
      grad_gnorm: 14.151442527770996
      policy_entropy: 25.39179229736328
      policy_loss: -1.5885472297668457
      var_gnorm: 22.939016342163086
      vf_explained_var: 0.0
      vf_loss: 0.1435532569885254
    num_steps_sampled: 3990000
    num_steps_trained: 3990000
    wait_time_ms: 73.686
  iterations_since_restore: 798
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6945.455670833588
  time_this_iter_s: 8.55919337272644
  time_total_s: 6945.455670833588
  timestamp: 1594855464
  timesteps_since_restore: 3990000
  timesteps_this_iter: 5000
  timesteps_total: 3990000
  training_iteration: 798
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6945 s, 798 iter, 3990000 ts, 134 rew

agent-1: 80.99999989695547
agent-2: 83.99999989695549
agent-3: 82.99999989695549
agent-4: 79.99999989695547
agent-5: 76.99999989695544
Extrinsic Rewards:
9
12
11
8
5
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 5
Max Reward: 12
Gini Coefficient: 0.1511111111111111
20:20 Ratio: 2.4
Max-min Ratio: 2.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-24-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 138.31800730565405
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 798
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.277
    dispatch_time_ms: 9.449
    learner:
      cur_lr: 0.0010942659573629498
      grad_gnorm: 12.73284912109375
      policy_entropy: 30.89535140991211
      policy_loss: -1.5078933238983154
      var_gnorm: 22.93895721435547
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.12433237582445145
    num_steps_sampled: 3995000
    num_steps_trained: 3995000
    wait_time_ms: 74.314
  iterations_since_restore: 799
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6954.0191304683685
  time_this_iter_s: 8.563459634780884
  time_total_s: 6954.0191304683685
  timestamp: 1594855472
  timesteps_since_restore: 3995000
  timesteps_this_iter: 5000
  timesteps_total: 3995000
  training_iteration: 799
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6954 s, 799 iter, 3995000 ts, 138 rew

agent-1: 28.99999999952132
agent-2: 24.999999999521325
agent-3: 25.99999999952133
agent-4: 27.999999999521325
agent-5: 26.99999999952132
Extrinsic Rewards:
5
1
2
4
3
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 1
Max Reward: 5
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-24-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 139.6680073056301
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 799
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.607
    dispatch_time_ms: 6.41
    learner:
      cur_lr: 0.0010939330095425248
      grad_gnorm: 35.30982208251953
      policy_entropy: 25.18096923828125
      policy_loss: -5.460258483886719
      var_gnorm: 22.93743133544922
      vf_explained_var: 0.0
      vf_loss: 0.9303297996520996
    num_steps_sampled: 4000000
    num_steps_trained: 4000000
    wait_time_ms: 72.958
  iterations_since_restore: 800
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6962.446439266205
  time_this_iter_s: 8.427308797836304
  time_total_s: 6962.446439266205
  timestamp: 1594855481
  timesteps_since_restore: 4000000
  timesteps_this_iter: 5000
  timesteps_total: 4000000
  training_iteration: 800
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6962 s, 800 iter, 4000000 ts, 140 rew

agent-1: 70.79999993381873
agent-2: 68.79999993381873
agent-3: 69.79999993381873
agent-4: 62.799999933818754
agent-5: 69.79999993381873
Extrinsic Rewards:
10
8
9
2
9
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.17894736842105263
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-24-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 143.08800730232107
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 800
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 9.295
    learner:
      cur_lr: 0.001093599945306778
      grad_gnorm: 12.657513618469238
      policy_entropy: 28.407482147216797
      policy_loss: -1.793736219406128
      var_gnorm: 22.936893463134766
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.12407509237527847
    num_steps_sampled: 4005000
    num_steps_trained: 4005000
    wait_time_ms: 73.108
  iterations_since_restore: 801
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6971.2813239097595
  time_this_iter_s: 8.834884643554688
  time_total_s: 6971.2813239097595
  timestamp: 1594855490
  timesteps_since_restore: 4005000
  timesteps_this_iter: 5000
  timesteps_total: 4005000
  training_iteration: 801
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6971 s, 801 iter, 4005000 ts, 143 rew

agent-1: 65.19999998109473
agent-2: 68.19999998109469
agent-3: 62.19999998109478
agent-4: 63.19999998109478
agent-5: 74.1999999810947
Extrinsic Rewards:
6
9
3
4
15
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 3
Max Reward: 15
Gini Coefficient: 0.31351351351351353
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-24-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 146.41800730137578
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 801
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.451
    dispatch_time_ms: 7.394
    learner:
      cur_lr: 0.001093266997486353
      grad_gnorm: 12.963095664978027
      policy_entropy: 34.678955078125
      policy_loss: -3.034074306488037
      var_gnorm: 22.936403274536133
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.118782177567482
    num_steps_sampled: 4010000
    num_steps_trained: 4010000
    wait_time_ms: 76.813
  iterations_since_restore: 802
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6979.715842008591
  time_this_iter_s: 8.434518098831177
  time_total_s: 6979.715842008591
  timestamp: 1594855498
  timesteps_since_restore: 4010000
  timesteps_this_iter: 5000
  timesteps_total: 4010000
  training_iteration: 802
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6979 s, 802 iter, 4010000 ts, 146 rew

agent-1: 40.19999999870337
agent-2: 40.19999999870337
agent-3: 41.199999998703355
agent-4: 39.19999999870337
agent-5: 37.19999999870338
Extrinsic Rewards:
5
5
6
4
2
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.16363636363636364
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-25-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 148.39800730131097
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 802
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 6.472
    learner:
      cur_lr: 0.0010929340496659279
      grad_gnorm: 26.938135147094727
      policy_entropy: 34.128170013427734
      policy_loss: 4.500187873840332
      var_gnorm: 22.937164306640625
      vf_explained_var: 0.0
      vf_loss: 0.5792786478996277
    num_steps_sampled: 4015000
    num_steps_trained: 4015000
    wait_time_ms: 74.996
  iterations_since_restore: 803
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6988.116492509842
  time_this_iter_s: 8.40065050125122
  time_total_s: 6988.116492509842
  timestamp: 1594855507
  timesteps_since_restore: 4015000
  timesteps_this_iter: 5000
  timesteps_total: 4015000
  training_iteration: 803
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6988 s, 803 iter, 4015000 ts, 148 rew

agent-1: 44.399999998680244
agent-2: 42.39999999868025
agent-3: 43.39999999868025
agent-4: 47.39999999868023
agent-5: 38.39999999868025
Extrinsic Rewards:
6
4
5
9
0
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.3333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-25-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 150.558007301245
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 803
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.59
    dispatch_time_ms: 8.382
    learner:
      cur_lr: 0.001092600985430181
      grad_gnorm: 11.201960563659668
      policy_entropy: 28.98272132873535
      policy_loss: -1.5127122402191162
      var_gnorm: 22.936445236206055
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.09347441047430038
    num_steps_sampled: 4020000
    num_steps_trained: 4020000
    wait_time_ms: 70.498
  iterations_since_restore: 804
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 6996.531193733215
  time_this_iter_s: 8.414701223373413
  time_total_s: 6996.531193733215
  timestamp: 1594855515
  timesteps_since_restore: 4020000
  timesteps_this_iter: 5000
  timesteps_total: 4020000
  training_iteration: 804
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 6996 s, 804 iter, 4020000 ts, 151 rew

agent-1: 35.79999999923199
agent-2: 33.799999999231986
agent-3: 30.799999999231858
agent-4: 28.79999999923186
agent-5: 32.79999999923197
Extrinsic Rewards:
7
5
2
0
4
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.37777777777777777
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-25-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 152.1780073012066
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 804
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.224
    dispatch_time_ms: 8.136
    learner:
      cur_lr: 0.001092268037609756
      grad_gnorm: 39.999996185302734
      policy_entropy: 24.472156524658203
      policy_loss: 29.436132431030273
      var_gnorm: 22.93802833557129
      vf_explained_var: 0.0
      vf_loss: 47.7197380065918
    num_steps_sampled: 4025000
    num_steps_trained: 4025000
    wait_time_ms: 73.273
  iterations_since_restore: 805
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7005.142441272736
  time_this_iter_s: 8.611247539520264
  time_total_s: 7005.142441272736
  timestamp: 1594855524
  timesteps_since_restore: 4025000
  timesteps_this_iter: 5000
  timesteps_total: 4025000
  training_iteration: 805
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7005 s, 805 iter, 4025000 ts, 152 rew

agent-1: 38.39999999884804
agent-2: 47.399999998848024
agent-3: 47.39999999884803
agent-4: 41.39999999884803
agent-5: 41.39999999884803
Extrinsic Rewards:
0
9
9
3
3
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-25-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 154.33800730114902
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 805
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.506
    dispatch_time_ms: 8.037
    learner:
      cur_lr: 0.0010919349733740091
      grad_gnorm: 12.945653915405273
      policy_entropy: 23.924346923828125
      policy_loss: -2.570073127746582
      var_gnorm: 22.937280654907227
      vf_explained_var: 0.0
      vf_loss: 0.11111468076705933
    num_steps_sampled: 4030000
    num_steps_trained: 4030000
    wait_time_ms: 74.619
  iterations_since_restore: 806
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7013.629339933395
  time_this_iter_s: 8.48689866065979
  time_total_s: 7013.629339933395
  timestamp: 1594855532
  timesteps_since_restore: 4030000
  timesteps_this_iter: 5000
  timesteps_total: 4030000
  training_iteration: 806
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7013 s, 806 iter, 4030000 ts, 154 rew

agent-1: 45.99999999676958
agent-2: 47.99999999676957
agent-3: 42.99999999676958
agent-4: 45.999999996769574
agent-5: 41.99999999676958
Extrinsic Rewards:
6
8
3
6
2
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.24
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-25-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 156.58800730098747
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 806
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 9.323
    learner:
      cur_lr: 0.001091602025553584
      grad_gnorm: 40.0
      policy_entropy: 22.922868728637695
      policy_loss: 8.067781448364258
      var_gnorm: 22.938337326049805
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.89017391204834
    num_steps_sampled: 4035000
    num_steps_trained: 4035000
    wait_time_ms: 75.579
  iterations_since_restore: 807
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7022.183630943298
  time_this_iter_s: 8.554291009902954
  time_total_s: 7022.183630943298
  timestamp: 1594855541
  timesteps_since_restore: 4035000
  timesteps_this_iter: 5000
  timesteps_total: 4035000
  training_iteration: 807
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7022 s, 807 iter, 4035000 ts, 157 rew

agent-1: 32.39999999860923
agent-2: 40.39999999860929
agent-3: 31.399999998609214
agent-4: 35.39999999860926
agent-5: 31.399999998609207
Extrinsic Rewards:
2
10
1
5
1
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.4631578947368421
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-25-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 158.29800730091793
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 807
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.001
    dispatch_time_ms: 8.504
    learner:
      cur_lr: 0.0010912689613178372
      grad_gnorm: 19.952043533325195
      policy_entropy: 15.203442573547363
      policy_loss: -1.7572884559631348
      var_gnorm: 22.936338424682617
      vf_explained_var: 0.0
      vf_loss: 0.30531391501426697
    num_steps_sampled: 4040000
    num_steps_trained: 4040000
    wait_time_ms: 76.536
  iterations_since_restore: 808
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7030.819427490234
  time_this_iter_s: 8.635796546936035
  time_total_s: 7030.819427490234
  timestamp: 1594855549
  timesteps_since_restore: 4040000
  timesteps_this_iter: 5000
  timesteps_total: 4040000
  training_iteration: 808
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7030 s, 808 iter, 4040000 ts, 158 rew

agent-1: 52.39999999856054
agent-2: 56.39999999856054
agent-3: 51.39999999856054
agent-4: 54.39999999856054
agent-5: 46.399999998560524
Extrinsic Rewards:
6
10
5
8
0
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.31724137931034485
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-25-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 160.90800730084595
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 808
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.457
    dispatch_time_ms: 8.074
    learner:
      cur_lr: 0.0010909360134974122
      grad_gnorm: 40.0
      policy_entropy: 8.146556854248047
      policy_loss: 2.4554283618927
      var_gnorm: 22.939908981323242
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 50.37208557128906
    num_steps_sampled: 4045000
    num_steps_trained: 4045000
    wait_time_ms: 78.449
  iterations_since_restore: 809
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7039.512062072754
  time_this_iter_s: 8.692634582519531
  time_total_s: 7039.512062072754
  timestamp: 1594855558
  timesteps_since_restore: 4045000
  timesteps_this_iter: 5000
  timesteps_total: 4045000
  training_iteration: 809
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7039 s, 809 iter, 4045000 ts, 161 rew

agent-1: 58.59999996820708
agent-2: 64.59999996820717
agent-3: 66.59999996820721
agent-4: 62.599999968207094
agent-5: 71.59999996820726
Extrinsic Rewards:
1
7
9
5
14
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.3333333333333333
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-26-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 164.14800729925636
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 809
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.746
    dispatch_time_ms: 7.221
    learner:
      cur_lr: 0.0010906029492616653
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.148427963256836
      policy_loss: -8.445446968078613
      var_gnorm: 22.941503524780273
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.394435167312622
    num_steps_sampled: 4050000
    num_steps_trained: 4050000
    wait_time_ms: 78.322
  iterations_since_restore: 810
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7048.204749107361
  time_this_iter_s: 8.692687034606934
  time_total_s: 7048.204749107361
  timestamp: 1594855567
  timesteps_since_restore: 4050000
  timesteps_this_iter: 5000
  timesteps_total: 4050000
  training_iteration: 810
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7048 s, 810 iter, 4050000 ts, 164 rew

agent-1: 73.39999716784975
agent-2: 78.39999716784979
agent-3: 81.3999971678498
agent-4: 82.3999971678498
agent-5: 80.3999971678498
Extrinsic Rewards:
3
8
11
12
10
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.19090909090909092
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-26-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 168.10800715764887
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 810
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.971
    dispatch_time_ms: 7.025
    learner:
      cur_lr: 0.0010902700014412403
      grad_gnorm: 40.000003814697266
      policy_entropy: 34.1766357421875
      policy_loss: 7.219786643981934
      var_gnorm: 22.937829971313477
      vf_explained_var: 0.0
      vf_loss: 1.4577990770339966
    num_steps_sampled: 4055000
    num_steps_trained: 4055000
    wait_time_ms: 76.174
  iterations_since_restore: 811
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7056.867112874985
  time_this_iter_s: 8.662363767623901
  time_total_s: 7056.867112874985
  timestamp: 1594855576
  timesteps_since_restore: 4055000
  timesteps_this_iter: 5000
  timesteps_total: 4055000
  training_iteration: 811
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7056 s, 811 iter, 4055000 ts, 168 rew

agent-1: 71.19999971090468
agent-2: 80.1999997109047
agent-3: 73.1999997109047
agent-4: 75.19999971090469
agent-5: 78.1999997109047
Extrinsic Rewards:
4
13
6
8
11
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 4
Max Reward: 13
Gini Coefficient: 0.21904761904761905
20:20 Ratio: 3.25
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-26-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 171.88800714319407
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 811
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 9.192
    learner:
      cur_lr: 0.0010899370536208153
      grad_gnorm: 23.52347183227539
      policy_entropy: 17.53270149230957
      policy_loss: -2.097599983215332
      var_gnorm: 22.934328079223633
      vf_explained_var: 0.0
      vf_loss: 0.4285104274749756
    num_steps_sampled: 4060000
    num_steps_trained: 4060000
    wait_time_ms: 77.349
  iterations_since_restore: 812
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7065.510461807251
  time_this_iter_s: 8.643348932266235
  time_total_s: 7065.510461807251
  timestamp: 1594855584
  timesteps_since_restore: 4060000
  timesteps_this_iter: 5000
  timesteps_total: 4060000
  training_iteration: 812
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7065 s, 812 iter, 4060000 ts, 172 rew

agent-1: 31.799999999382926
agent-2: 32.799999999382955
agent-3: 36.79999999938295
agent-4: 30.799999999382926
agent-5: 29.799999999382926
Extrinsic Rewards:
3
4
8
2
1
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.35555555555555557
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-26-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 173.50800714316318
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 812
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.026
    dispatch_time_ms: 7.168
    learner:
      cur_lr: 0.0010896039893850684
      grad_gnorm: 39.999996185302734
      policy_entropy: 28.737659454345703
      policy_loss: 25.80095100402832
      var_gnorm: 22.936079025268555
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 22.07921600341797
    num_steps_sampled: 4065000
    num_steps_trained: 4065000
    wait_time_ms: 78.231
  iterations_since_restore: 813
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7074.128116130829
  time_this_iter_s: 8.61765432357788
  time_total_s: 7074.128116130829
  timestamp: 1594855593
  timesteps_since_restore: 4065000
  timesteps_this_iter: 5000
  timesteps_total: 4065000
  training_iteration: 813
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7074 s, 813 iter, 4065000 ts, 174 rew

agent-1: 68.7999999804167
agent-2: 64.79999998041676
agent-3: 69.79999998041673
agent-4: 72.79999998041673
agent-5: 65.79999998041669
Extrinsic Rewards:
8
4
9
12
5
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.21052631578947367
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-26-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 176.92800714218407
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 813
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.327
    dispatch_time_ms: 9.63
    learner:
      cur_lr: 0.0010892710415646434
      grad_gnorm: 14.141118049621582
      policy_entropy: 11.566732406616211
      policy_loss: -0.497103214263916
      var_gnorm: 22.933977127075195
      vf_explained_var: 0.0
      vf_loss: 0.1522049456834793
    num_steps_sampled: 4070000
    num_steps_trained: 4070000
    wait_time_ms: 71.851
  iterations_since_restore: 814
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7082.78968834877
  time_this_iter_s: 8.661572217941284
  time_total_s: 7082.78968834877
  timestamp: 1594855602
  timesteps_since_restore: 4070000
  timesteps_this_iter: 5000
  timesteps_total: 4070000
  training_iteration: 814
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7082 s, 814 iter, 4070000 ts, 177 rew

agent-1: 54.59999999796205
agent-2: 45.59999999796205
agent-3: 45.59999999796205
agent-4: 44.59999999796204
agent-5: 43.59999999796204
Extrinsic Rewards:
13
4
4
3
2
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.35384615384615387
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-26-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 179.26800714208213
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 814
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.937
    dispatch_time_ms: 8.225
    learner:
      cur_lr: 0.0010889379773288965
      grad_gnorm: 10.300139427185059
      policy_entropy: 13.562434196472168
      policy_loss: -0.6501792073249817
      var_gnorm: 22.934534072875977
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.08203508704900742
    num_steps_sampled: 4075000
    num_steps_trained: 4075000
    wait_time_ms: 73.601
  iterations_since_restore: 815
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7091.498647451401
  time_this_iter_s: 8.708959102630615
  time_total_s: 7091.498647451401
  timestamp: 1594855610
  timesteps_since_restore: 4075000
  timesteps_this_iter: 5000
  timesteps_total: 4075000
  training_iteration: 815
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7091 s, 815 iter, 4075000 ts, 179 rew

agent-1: 43.99999999782955
agent-2: 44.99999999782956
agent-3: 41.99999999782956
agent-4: 50.99999999782956
agent-5: 42.99999999782956
Extrinsic Rewards:
4
5
2
11
3
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.32
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-26-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 181.51800714197364
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 815
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.321
    dispatch_time_ms: 7.28
    learner:
      cur_lr: 0.0010886050295084715
      grad_gnorm: 40.0
      policy_entropy: 22.48991584777832
      policy_loss: -7.011936664581299
      var_gnorm: 22.94226837158203
      vf_explained_var: 0.0
      vf_loss: 4.750355243682861
    num_steps_sampled: 4080000
    num_steps_trained: 4080000
    wait_time_ms: 75.618
  iterations_since_restore: 816
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7100.173010349274
  time_this_iter_s: 8.674362897872925
  time_total_s: 7100.173010349274
  timestamp: 1594855619
  timesteps_since_restore: 4080000
  timesteps_this_iter: 5000
  timesteps_total: 4080000
  training_iteration: 816
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7100 s, 816 iter, 4080000 ts, 182 rew

agent-1: 112.59999336748119
agent-2: 117.59999336748119
agent-3: 122.59999336748119
agent-4: 114.59999336748116
agent-5: 126.59999336748119
Extrinsic Rewards:
7
12
17
9
21
Sum Reward: 66
Avg Reward: 13.2
Min Reward: 7
Max Reward: 21
Gini Coefficient: 0.21818181818181817
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-27-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 187.45800681034763
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 816
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 8.866
    learner:
      cur_lr: 0.0010882719652727246
      grad_gnorm: 12.859064102172852
      policy_entropy: 20.5929012298584
      policy_loss: -1.8913960456848145
      var_gnorm: 22.93311882019043
      vf_explained_var: 0.0
      vf_loss: 0.11208402365446091
    num_steps_sampled: 4085000
    num_steps_trained: 4085000
    wait_time_ms: 74.141
  iterations_since_restore: 817
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7108.7505559921265
  time_this_iter_s: 8.577545642852783
  time_total_s: 7108.7505559921265
  timestamp: 1594855628
  timesteps_since_restore: 4085000
  timesteps_this_iter: 5000
  timesteps_total: 4085000
  training_iteration: 817
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7108 s, 817 iter, 4085000 ts, 187 rew

agent-1: 83.19999979783654
agent-2: 85.19999979783653
agent-3: 92.19999979783647
agent-4: 78.19999979783653
agent-5: 84.19999979783655
Extrinsic Rewards:
8
10
17
3
9
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 3
Max Reward: 17
Gini Coefficient: 0.2553191489361702
20:20 Ratio: 5.666666666666667
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-27-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 191.68800680023938
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 817
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 5.866
    learner:
      cur_lr: 0.0010879390174522996
      grad_gnorm: 40.0
      policy_entropy: 32.63378143310547
      policy_loss: -7.393023490905762
      var_gnorm: 22.933128356933594
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 1.2289739847183228
    num_steps_sampled: 4090000
    num_steps_trained: 4090000
    wait_time_ms: 79.766
  iterations_since_restore: 818
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7117.44738483429
  time_this_iter_s: 8.696828842163086
  time_total_s: 7117.44738483429
  timestamp: 1594855636
  timesteps_since_restore: 4090000
  timesteps_this_iter: 5000
  timesteps_total: 4090000
  training_iteration: 818
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7117 s, 818 iter, 4090000 ts, 192 rew

agent-1: 119.19999903150504
agent-2: 117.19999903150506
agent-3: 126.19999903150504
agent-4: 124.19999903150503
agent-5: 116.19999903150507
Extrinsic Rewards:
12
10
19
17
9
Sum Reward: 67
Avg Reward: 13.4
Min Reward: 9
Max Reward: 19
Gini Coefficient: 0.16119402985074627
20:20 Ratio: 2.111111111111111
Max-min Ratio: 2.111111111111111
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-27-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 197.71800675181464
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 818
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 9.128
    learner:
      cur_lr: 0.0010876059532165527
      grad_gnorm: 40.000003814697266
      policy_entropy: 31.79483413696289
      policy_loss: 15.68172550201416
      var_gnorm: 22.935548782348633
      vf_explained_var: 0.0
      vf_loss: 6.587992191314697
    num_steps_sampled: 4095000
    num_steps_trained: 4095000
    wait_time_ms: 75.173
  iterations_since_restore: 819
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7125.980750799179
  time_this_iter_s: 8.533365964889526
  time_total_s: 7125.980750799179
  timestamp: 1594855645
  timesteps_since_restore: 4095000
  timesteps_this_iter: 5000
  timesteps_total: 4095000
  training_iteration: 819
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7125 s, 819 iter, 4095000 ts, 198 rew

agent-1: 52.39999998785766
agent-2: 50.39999998785766
agent-3: 47.39999998785767
agent-4: 62.39999998785766
agent-5: 48.399999987857655
Extrinsic Rewards:
6
4
1
16
2
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 1
Max Reward: 16
Gini Coefficient: 0.4689655172413793
20:20 Ratio: 16.0
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-27-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 200.32800675120754
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 819
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.841
    dispatch_time_ms: 6.73
    learner:
      cur_lr: 0.0010872730053961277
      grad_gnorm: 39.999996185302734
      policy_entropy: 24.95286750793457
      policy_loss: 5.728059768676758
      var_gnorm: 22.931753158569336
      vf_explained_var: 0.0
      vf_loss: 1.8181437253952026
    num_steps_sampled: 4100000
    num_steps_trained: 4100000
    wait_time_ms: 76.152
  iterations_since_restore: 820
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7134.554301977158
  time_this_iter_s: 8.573551177978516
  time_total_s: 7134.554301977158
  timestamp: 1594855654
  timesteps_since_restore: 4100000
  timesteps_this_iter: 5000
  timesteps_total: 4100000
  training_iteration: 820
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7134 s, 820 iter, 4100000 ts, 200 rew

agent-1: 33.799999997593986
agent-2: 33.799999997593986
agent-3: 32.799999997594
agent-4: 32.799999997594
agent-5: 28.799999997593872
Extrinsic Rewards:
5
5
4
4
0
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 5
Gini Coefficient: 0.24444444444444444
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-27-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 201.94800675108723
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 820
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 6.298
    learner:
      cur_lr: 0.0010869400575757027
      grad_gnorm: 9.21878719329834
      policy_entropy: 31.565074920654297
      policy_loss: -1.1163711547851562
      var_gnorm: 22.93613052368164
      vf_explained_var: 0.0
      vf_loss: 0.06534194946289062
    num_steps_sampled: 4105000
    num_steps_trained: 4105000
    wait_time_ms: 75.99
  iterations_since_restore: 821
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7143.158522367477
  time_this_iter_s: 8.604220390319824
  time_total_s: 7143.158522367477
  timestamp: 1594855662
  timesteps_since_restore: 4105000
  timesteps_this_iter: 5000
  timesteps_total: 4105000
  training_iteration: 821
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7143 s, 821 iter, 4105000 ts, 202 rew

agent-1: 83.79999975933372
agent-2: 82.79999975933372
agent-3: 93.79999975933369
agent-4: 82.79999975933372
agent-5: 88.79999975933369
Extrinsic Rewards:
7
6
17
6
12
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 6
Max Reward: 17
Gini Coefficient: 0.23333333333333334
20:20 Ratio: 2.8333333333333335
Max-min Ratio: 2.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-27-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 206.26800673905393
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 821
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 9.19
    learner:
      cur_lr: 0.0010866069933399558
      grad_gnorm: 39.999996185302734
      policy_entropy: 29.241336822509766
      policy_loss: -10.383889198303223
      var_gnorm: 22.93377113342285
      vf_explained_var: 0.0
      vf_loss: 3.368074655532837
    num_steps_sampled: 4110000
    num_steps_trained: 4110000
    wait_time_ms: 75.459
  iterations_since_restore: 822
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7151.755028247833
  time_this_iter_s: 8.596505880355835
  time_total_s: 7151.755028247833
  timestamp: 1594855671
  timesteps_since_restore: 4110000
  timesteps_this_iter: 5000
  timesteps_total: 4110000
  training_iteration: 822
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7151 s, 822 iter, 4110000 ts, 206 rew

agent-1: 112.19999227032878
agent-2: 104.19999227032878
agent-3: 96.19999227032872
agent-4: 100.19999227032874
agent-5: 100.19999227032875
Extrinsic Rewards:
21
13
5
9
9
Sum Reward: 57
Avg Reward: 11.4
Min Reward: 5
Max Reward: 21
Gini Coefficient: 0.25263157894736843
20:20 Ratio: 4.2
Max-min Ratio: 4.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-28-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 211.39800635257038
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 822
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.186
    dispatch_time_ms: 7.48
    learner:
      cur_lr: 0.0010862740455195308
      grad_gnorm: 40.000003814697266
      policy_entropy: 8.622438430786133
      policy_loss: 9.708189010620117
      var_gnorm: 22.928253173828125
      vf_explained_var: 0.0
      vf_loss: 55.22148513793945
    num_steps_sampled: 4115000
    num_steps_trained: 4115000
    wait_time_ms: 78.34
  iterations_since_restore: 823
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7160.427401781082
  time_this_iter_s: 8.672373533248901
  time_total_s: 7160.427401781082
  timestamp: 1594855680
  timesteps_since_restore: 4115000
  timesteps_this_iter: 5000
  timesteps_total: 4115000
  training_iteration: 823
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7160 s, 823 iter, 4115000 ts, 211 rew

agent-1: 90.3999999611166
agent-2: 80.39999996111663
agent-3: 82.39999996111663
agent-4: 97.39999996111662
agent-5: 90.39999996111663
Extrinsic Rewards:
12
2
4
19
12
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 2
Max Reward: 19
Gini Coefficient: 0.34285714285714286
20:20 Ratio: 9.5
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-28-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 215.80800635062616
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 823
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 9.699
    learner:
      cur_lr: 0.001085940981283784
      grad_gnorm: 40.0
      policy_entropy: 15.673906326293945
      policy_loss: -6.071669101715088
      var_gnorm: 22.95813751220703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.046949863433838
    num_steps_sampled: 4120000
    num_steps_trained: 4120000
    wait_time_ms: 72.73
  iterations_since_restore: 824
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7169.056906223297
  time_this_iter_s: 8.629504442214966
  time_total_s: 7169.056906223297
  timestamp: 1594855688
  timesteps_since_restore: 4120000
  timesteps_this_iter: 5000
  timesteps_total: 4120000
  training_iteration: 824
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7169 s, 824 iter, 4120000 ts, 216 rew

agent-1: 115.1999816685782
agent-2: 115.19998166857822
agent-3: 131.19998166857815
agent-4: 122.19998166857822
agent-5: 119.1999816685782
Extrinsic Rewards:
8
8
24
15
12
Sum Reward: 67
Avg Reward: 13.4
Min Reward: 8
Max Reward: 24
Gini Coefficient: 0.23283582089552238
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-28-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 221.83800543405513
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 824
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 9.347
    learner:
      cur_lr: 0.0010856080334633589
      grad_gnorm: 40.0
      policy_entropy: 27.28806495666504
      policy_loss: 44.29127502441406
      var_gnorm: 22.9506778717041
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 99.32028198242188
    num_steps_sampled: 4125000
    num_steps_trained: 4125000
    wait_time_ms: 73.828
  iterations_since_restore: 825
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7177.769718885422
  time_this_iter_s: 8.712812662124634
  time_total_s: 7177.769718885422
  timestamp: 1594855697
  timesteps_since_restore: 4125000
  timesteps_this_iter: 5000
  timesteps_total: 4125000
  training_iteration: 825
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7177 s, 825 iter, 4125000 ts, 222 rew

agent-1: 95.99999990126281
agent-2: 88.99999990126281
agent-3: 90.99999990126281
agent-4: 88.99999990126281
agent-5: 84.99999990126284
Extrinsic Rewards:
16
9
11
9
5
Sum Reward: 50
Avg Reward: 10.0
Min Reward: 5
Max Reward: 16
Gini Coefficient: 0.192
20:20 Ratio: 3.2
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-28-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 226.33800542911828
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 825
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 9.139
    learner:
      cur_lr: 0.001085274969227612
      grad_gnorm: 19.393037796020508
      policy_entropy: 14.305978775024414
      policy_loss: -1.0339844226837158
      var_gnorm: 22.944005966186523
      vf_explained_var: 0.0
      vf_loss: 0.2878570556640625
    num_steps_sampled: 4130000
    num_steps_trained: 4130000
    wait_time_ms: 74.089
  iterations_since_restore: 826
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7186.380238771439
  time_this_iter_s: 8.610519886016846
  time_total_s: 7186.380238771439
  timestamp: 1594855706
  timesteps_since_restore: 4130000
  timesteps_this_iter: 5000
  timesteps_total: 4130000
  training_iteration: 826
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7186 s, 826 iter, 4130000 ts, 226 rew

agent-1: 77.9999999763098
agent-2: 64.99999997630978
agent-3: 68.99999997630977
agent-4: 69.99999997630977
agent-5: 77.9999999763098
Extrinsic Rewards:
14
1
5
6
14
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.35
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-28-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 229.93800542793375
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 826
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.539
    dispatch_time_ms: 6.816
    learner:
      cur_lr: 0.001084942021407187
      grad_gnorm: 40.0
      policy_entropy: 23.608585357666016
      policy_loss: 47.877296447753906
      var_gnorm: 22.948694229125977
      vf_explained_var: 0.0
      vf_loss: 70.845703125
    num_steps_sampled: 4135000
    num_steps_trained: 4135000
    wait_time_ms: 72.455
  iterations_since_restore: 827
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7194.8145978450775
  time_this_iter_s: 8.434359073638916
  time_total_s: 7194.8145978450775
  timestamp: 1594855714
  timesteps_since_restore: 4135000
  timesteps_this_iter: 5000
  timesteps_total: 4135000
  training_iteration: 827
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7194 s, 827 iter, 4135000 ts, 230 rew

agent-1: 49.99999999754643
agent-2: 49.99999999754643
agent-3: 60.99999999754641
agent-4: 50.99999999754643
agent-5: 57.99999999754643
Extrinsic Rewards:
2
2
13
3
10
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.4
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-28-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 232.63800542781112
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 827
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.477
    dispatch_time_ms: 5.746
    learner:
      cur_lr: 0.0010846089571714401
      grad_gnorm: 27.445663452148438
      policy_entropy: 16.922914505004883
      policy_loss: -3.998967409133911
      var_gnorm: 22.935312271118164
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.5520979166030884
    num_steps_sampled: 4140000
    num_steps_trained: 4140000
    wait_time_ms: 77.374
  iterations_since_restore: 828
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7203.453999519348
  time_this_iter_s: 8.63940167427063
  time_total_s: 7203.453999519348
  timestamp: 1594855723
  timesteps_since_restore: 4140000
  timesteps_this_iter: 5000
  timesteps_total: 4140000
  training_iteration: 828
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7203 s, 828 iter, 4140000 ts, 233 rew

agent-1: 75.79999789881418
agent-2: 79.79999789881415
agent-3: 74.7999978988142
agent-4: 82.79999789881417
agent-5: 73.7999978988142
Extrinsic Rewards:
7
11
6
14
5
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 5
Max Reward: 14
Gini Coefficient: 0.21395348837209302
20:20 Ratio: 2.8
Max-min Ratio: 2.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-29-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 236.50800532275179
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 828
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.875
    dispatch_time_ms: 9.321
    learner:
      cur_lr: 0.001084276009351015
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.065105438232422
      policy_loss: 40.3317985534668
      var_gnorm: 22.919950485229492
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 117.03388214111328
    num_steps_sampled: 4145000
    num_steps_trained: 4145000
    wait_time_ms: 75.394
  iterations_since_restore: 829
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7224.180565357208
  time_this_iter_s: 20.726565837860107
  time_total_s: 7224.180565357208
  timestamp: 1594855743
  timesteps_since_restore: 4145000
  timesteps_this_iter: 5000
  timesteps_total: 4145000
  training_iteration: 829
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7224 s, 829 iter, 4145000 ts, 237 rew

agent-1: 40.99999999920125
agent-2: 36.999999999201265
agent-3: 35.999999999201265
agent-4: 33.99999999920125
agent-5: 31.99999999920143
Extrinsic Rewards:
9
5
4
2
0
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.42
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-29-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 238.30800532271186
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 829
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.83
    dispatch_time_ms: 7.43
    learner:
      cur_lr: 0.0010839429451152682
      grad_gnorm: 40.0
      policy_entropy: 34.85248947143555
      policy_loss: -10.305388450622559
      var_gnorm: 22.944700241088867
      vf_explained_var: 0.0
      vf_loss: 2.495849847793579
    num_steps_sampled: 4150000
    num_steps_trained: 4150000
    wait_time_ms: 76.748
  iterations_since_restore: 830
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7232.730149507523
  time_this_iter_s: 8.549584150314331
  time_total_s: 7232.730149507523
  timestamp: 1594855752
  timesteps_since_restore: 4150000
  timesteps_this_iter: 5000
  timesteps_total: 4150000
  training_iteration: 830
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7232 s, 830 iter, 4150000 ts, 238 rew

agent-1: 159.39992648976664
agent-2: 168.3999264897666
agent-3: 184.39992648976664
agent-4: 162.39992648976664
agent-5: 171.39992648976664
Extrinsic Rewards:
9
18
34
12
21
Sum Reward: 94
Avg Reward: 18.8
Min Reward: 9
Max Reward: 34
Gini Coefficient: 0.251063829787234
20:20 Ratio: 3.7777777777777777
Max-min Ratio: 3.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-29-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 246.76800164720018
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 830
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.687
    dispatch_time_ms: 8.074
    learner:
      cur_lr: 0.0010836099972948432
      grad_gnorm: 40.0
      policy_entropy: 17.18355941772461
      policy_loss: 22.192853927612305
      var_gnorm: 22.92521858215332
      vf_explained_var: 0.0
      vf_loss: 29.535205841064453
    num_steps_sampled: 4155000
    num_steps_trained: 4155000
    wait_time_ms: 71.937
  iterations_since_restore: 831
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7241.240134239197
  time_this_iter_s: 8.509984731674194
  time_total_s: 7241.240134239197
  timestamp: 1594855761
  timesteps_since_restore: 4155000
  timesteps_this_iter: 5000
  timesteps_total: 4155000
  training_iteration: 831
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7241 s, 831 iter, 4155000 ts, 247 rew

agent-1: 69.99999998997714
agent-2: 59.99999998997703
agent-3: 63.99999998997702
agent-4: 64.99999998997716
agent-5: 55.999999989977
Extrinsic Rewards:
14
4
8
9
0
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.37714285714285717
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-29-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 249.91800164669905
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 831
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.664
    dispatch_time_ms: 9.82
    learner:
      cur_lr: 0.0010832770494744182
      grad_gnorm: 40.0
      policy_entropy: 34.16164779663086
      policy_loss: -8.749692916870117
      var_gnorm: 22.93047332763672
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.6334561109542847
    num_steps_sampled: 4160000
    num_steps_trained: 4160000
    wait_time_ms: 72.92
  iterations_since_restore: 832
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7249.708616018295
  time_this_iter_s: 8.46848177909851
  time_total_s: 7249.708616018295
  timestamp: 1594855769
  timesteps_since_restore: 4160000
  timesteps_this_iter: 5000
  timesteps_total: 4160000
  training_iteration: 832
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7249 s, 832 iter, 4160000 ts, 250 rew

agent-1: 87.5999964336368
agent-2: 76.59999643363685
agent-3: 91.59999643363678
agent-4: 76.59999643363685
agent-5: 81.59999643363683
Extrinsic Rewards:
14
3
18
3
8
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 3
Max Reward: 18
Gini Coefficient: 0.3565217391304348
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-29-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 254.0580014683809
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 832
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 8.842
    learner:
      cur_lr: 0.0010829439852386713
      grad_gnorm: 40.0
      policy_entropy: 27.041749954223633
      policy_loss: 31.98345375061035
      var_gnorm: 22.933000564575195
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 48.50047302246094
    num_steps_sampled: 4165000
    num_steps_trained: 4165000
    wait_time_ms: 73.981
  iterations_since_restore: 833
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7258.217080354691
  time_this_iter_s: 8.508464336395264
  time_total_s: 7258.217080354691
  timestamp: 1594855778
  timesteps_since_restore: 4165000
  timesteps_this_iter: 5000
  timesteps_total: 4165000
  training_iteration: 833
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7258 s, 833 iter, 4165000 ts, 254 rew

agent-1: 55.39999999336359
agent-2: 55.399999993363586
agent-3: 47.39999999336358
agent-4: 53.399999993363586
agent-5: 49.399999993363586
Extrinsic Rewards:
9
9
1
7
3
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.30344827586206896
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-29-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 256.66800146804906
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 833
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 9.633
    learner:
      cur_lr: 0.0010826110374182463
      grad_gnorm: 40.0
      policy_entropy: 12.445067405700684
      policy_loss: -2.225752830505371
      var_gnorm: 22.93012237548828
      vf_explained_var: 0.0
      vf_loss: 2.3711633682250977
    num_steps_sampled: 4170000
    num_steps_trained: 4170000
    wait_time_ms: 77.752
  iterations_since_restore: 834
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7266.791590690613
  time_this_iter_s: 8.574510335922241
  time_total_s: 7266.791590690613
  timestamp: 1594855786
  timesteps_since_restore: 4170000
  timesteps_this_iter: 5000
  timesteps_total: 4170000
  training_iteration: 834
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7266 s, 834 iter, 4170000 ts, 257 rew

agent-1: 112.59996364134163
agent-2: 118.59996364134166
agent-3: 118.59996364134169
agent-4: 123.59996364134169
agent-5: 120.59996364134169
Extrinsic Rewards:
7
13
13
18
15
Sum Reward: 66
Avg Reward: 13.2
Min Reward: 7
Max Reward: 18
Gini Coefficient: 0.14545454545454545
20:20 Ratio: 2.5714285714285716
Max-min Ratio: 2.5714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-29-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 262.60799965011614
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 834
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.702
    dispatch_time_ms: 7.819
    learner:
      cur_lr: 0.0010822779731824994
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.344924926757812
      policy_loss: 5.565844535827637
      var_gnorm: 22.91458511352539
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.251551151275635
    num_steps_sampled: 4175000
    num_steps_trained: 4175000
    wait_time_ms: 74.849
  iterations_since_restore: 835
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7275.512522697449
  time_this_iter_s: 8.720932006835938
  time_total_s: 7275.512522697449
  timestamp: 1594855795
  timesteps_since_restore: 4175000
  timesteps_this_iter: 5000
  timesteps_total: 4175000
  training_iteration: 835
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7275 s, 835 iter, 4175000 ts, 263 rew

agent-1: 41.599999993483635
agent-2: 54.59999999348363
agent-3: 46.59999999348363
agent-4: 44.59999999348363
agent-5: 46.59999999348364
Extrinsic Rewards:
0
13
5
3
5
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.4307692307692308
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-30-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 264.94799964979035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 835
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.077
    dispatch_time_ms: 8.82
    learner:
      cur_lr: 0.0010819450253620744
      grad_gnorm: 9.965119361877441
      policy_entropy: 26.102046966552734
      policy_loss: -1.1574580669403076
      var_gnorm: 22.927833557128906
      vf_explained_var: 0.0
      vf_loss: 0.0666484609246254
    num_steps_sampled: 4180000
    num_steps_trained: 4180000
    wait_time_ms: 75.53
  iterations_since_restore: 836
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7284.087473869324
  time_this_iter_s: 8.574951171875
  time_total_s: 7284.087473869324
  timestamp: 1594855804
  timesteps_since_restore: 4180000
  timesteps_this_iter: 5000
  timesteps_total: 4180000
  training_iteration: 836
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7284 s, 836 iter, 4180000 ts, 265 rew

agent-1: 148.99980668370443
agent-2: 158.9998066837044
agent-3: 159.99980668370443
agent-4: 147.9998066837044
agent-5: 148.9998066837044
Extrinsic Rewards:
13
23
24
12
13
Sum Reward: 85
Avg Reward: 17.0
Min Reward: 12
Max Reward: 24
Gini Coefficient: 0.16
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-30-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 272.5979899839756
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 836
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.247
    dispatch_time_ms: 9.699
    learner:
      cur_lr: 0.0010816119611263275
      grad_gnorm: 23.073200225830078
      policy_entropy: 28.051809310913086
      policy_loss: -3.590233325958252
      var_gnorm: 22.9152889251709
      vf_explained_var: 0.0
      vf_loss: 0.39379024505615234
    num_steps_sampled: 4185000
    num_steps_trained: 4185000
    wait_time_ms: 73.739
  iterations_since_restore: 837
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7292.7004153728485
  time_this_iter_s: 8.61294150352478
  time_total_s: 7292.7004153728485
  timestamp: 1594855812
  timesteps_since_restore: 4185000
  timesteps_this_iter: 5000
  timesteps_total: 4185000
  training_iteration: 837
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7292 s, 837 iter, 4185000 ts, 273 rew

agent-1: 81.99999986596619
agent-2: 78.9999998659662
agent-3: 83.99999986596619
agent-4: 79.9999998659662
agent-5: 79.9999998659662
Extrinsic Rewards:
10
7
12
8
8
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 7
Max Reward: 12
Gini Coefficient: 0.10666666666666667
20:20 Ratio: 1.7142857142857142
Max-min Ratio: 1.7142857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-30-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 276.6479899772739
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 837
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.098
    dispatch_time_ms: 8.596
    learner:
      cur_lr: 0.0010812790133059025
      grad_gnorm: 21.762128829956055
      policy_entropy: 22.308584213256836
      policy_loss: -2.8353617191314697
      var_gnorm: 22.909852981567383
      vf_explained_var: 0.0
      vf_loss: 0.364838182926178
    num_steps_sampled: 4190000
    num_steps_trained: 4190000
    wait_time_ms: 74.814
  iterations_since_restore: 838
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7301.320298910141
  time_this_iter_s: 8.61988353729248
  time_total_s: 7301.320298910141
  timestamp: 1594855821
  timesteps_since_restore: 4190000
  timesteps_this_iter: 5000
  timesteps_total: 4190000
  training_iteration: 838
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7301 s, 838 iter, 4190000 ts, 277 rew

agent-1: 52.39999998690512
agent-2: 56.39999998690511
agent-3: 48.399999986905165
agent-4: 48.399999986905165
agent-5: 55.39999998690516
Extrinsic Rewards:
6
10
2
2
9
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.31724137931034485
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-30-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 279.2579899766191
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 838
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.01
    dispatch_time_ms: 8.968
    learner:
      cur_lr: 0.0010809459490701556
      grad_gnorm: 8.392065048217773
      policy_entropy: 20.16796875
      policy_loss: -0.8526362180709839
      var_gnorm: 22.91075325012207
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.05441170558333397
    num_steps_sampled: 4195000
    num_steps_trained: 4195000
    wait_time_ms: 72.927
  iterations_since_restore: 839
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7309.997577190399
  time_this_iter_s: 8.677278280258179
  time_total_s: 7309.997577190399
  timestamp: 1594855830
  timesteps_since_restore: 4195000
  timesteps_this_iter: 5000
  timesteps_total: 4195000
  training_iteration: 839
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7309 s, 839 iter, 4195000 ts, 279 rew

agent-1: 49.19999999318728
agent-2: 48.19999999318728
agent-3: 50.19999999318728
agent-4: 47.19999999318729
agent-5: 48.19999999318728
Extrinsic Rewards:
6
5
7
4
5
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 4
Max Reward: 7
Gini Coefficient: 0.1037037037037037
20:20 Ratio: 1.75
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-30-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 281.68798997627846
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 839
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 8.177
    learner:
      cur_lr: 0.0010806130012497306
      grad_gnorm: 6.246160507202148
      policy_entropy: 19.1706485748291
      policy_loss: 0.3533421754837036
      var_gnorm: 22.912189483642578
      vf_explained_var: 0.0
      vf_loss: 0.035632021725177765
    num_steps_sampled: 4200000
    num_steps_trained: 4200000
    wait_time_ms: 75.374
  iterations_since_restore: 840
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7318.753722667694
  time_this_iter_s: 8.756145477294922
  time_total_s: 7318.753722667694
  timestamp: 1594855838
  timesteps_since_restore: 4200000
  timesteps_this_iter: 5000
  timesteps_total: 4200000
  training_iteration: 840
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7318 s, 840 iter, 4200000 ts, 282 rew

agent-1: 99.99999968005224
agent-2: 97.99999968005224
agent-3: 93.99999968005227
agent-4: 102.99999968005221
agent-5: 99.99999968005224
Extrinsic Rewards:
12
10
6
15
12
Sum Reward: 55
Avg Reward: 11.0
Min Reward: 6
Max Reward: 15
Gini Coefficient: 0.14545454545454545
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-30-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 286.63798996028106
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 840
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.192
    dispatch_time_ms: 23.016
    learner:
      cur_lr: 0.0010802800534293056
      grad_gnorm: 38.8527946472168
      policy_entropy: 19.212743759155273
      policy_loss: 8.112772941589355
      var_gnorm: 22.90519142150879
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.7677415609359741
    num_steps_sampled: 4205000
    num_steps_trained: 4205000
    wait_time_ms: 31.287
  iterations_since_restore: 841
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7327.886942863464
  time_this_iter_s: 9.133220195770264
  time_total_s: 7327.886942863464
  timestamp: 1594855848
  timesteps_since_restore: 4205000
  timesteps_this_iter: 5000
  timesteps_total: 4205000
  training_iteration: 841
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7327 s, 841 iter, 4205000 ts, 287 rew

agent-1: 78.39999988351535
agent-2: 62.39999988351532
agent-3: 68.39999988351535
agent-4: 76.39999988351536
agent-5: 65.39999988351532
Extrinsic Rewards:
16
0
6
14
3
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 0
Max Reward: 16
Gini Coefficient: 0.441025641025641
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-30-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 290.1479899544568
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 841
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 36.106
    learner:
      cur_lr: 0.0010799469891935587
      grad_gnorm: 25.45347785949707
      policy_entropy: 23.07102394104004
      policy_loss: -4.977355480194092
      var_gnorm: 22.90325927734375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.47740116715431213
    num_steps_sampled: 4210000
    num_steps_trained: 4210000
    wait_time_ms: 53.098
  iterations_since_restore: 842
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7336.880247592926
  time_this_iter_s: 8.99330472946167
  time_total_s: 7336.880247592926
  timestamp: 1594855857
  timesteps_since_restore: 4210000
  timesteps_this_iter: 5000
  timesteps_total: 4210000
  training_iteration: 842
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7336 s, 842 iter, 4210000 ts, 290 rew

agent-1: 49.599999989170435
agent-2: 43.59999998917043
agent-3: 44.599999989170435
agent-4: 43.59999998917043
agent-5: 52.59999998917045
Extrinsic Rewards:
8
2
3
2
11
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.36923076923076925
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-31-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 292.48798995391536
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 842
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.098
    dispatch_time_ms: 25.296
    learner:
      cur_lr: 0.0010796140413731337
      grad_gnorm: 10.290721893310547
      policy_entropy: 26.031036376953125
      policy_loss: -1.0536344051361084
      var_gnorm: 22.905975341796875
      vf_explained_var: 0.0
      vf_loss: 0.08119285851716995
    num_steps_sampled: 4215000
    num_steps_trained: 4215000
    wait_time_ms: 62.625
  iterations_since_restore: 843
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7346.117872238159
  time_this_iter_s: 9.237624645233154
  time_total_s: 7346.117872238159
  timestamp: 1594855866
  timesteps_since_restore: 4215000
  timesteps_this_iter: 5000
  timesteps_total: 4215000
  training_iteration: 843
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7346 s, 843 iter, 4215000 ts, 292 rew

agent-1: 88.99999998823473
agent-2: 82.99999998823473
agent-3: 74.99999998823478
agent-4: 80.99999998823475
agent-5: 76.99999998823476
Extrinsic Rewards:
17
11
3
9
5
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 3
Max Reward: 17
Gini Coefficient: 0.3022222222222222
20:20 Ratio: 5.666666666666667
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-31-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 296.53798995332716
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 843
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.82
    dispatch_time_ms: 37.331
    learner:
      cur_lr: 0.0010792809771373868
      grad_gnorm: 17.46803092956543
      policy_entropy: 31.373891830444336
      policy_loss: -5.261586666107178
      var_gnorm: 22.90428924560547
      vf_explained_var: 0.0
      vf_loss: 0.23484328389167786
    num_steps_sampled: 4220000
    num_steps_trained: 4220000
    wait_time_ms: 50.468
  iterations_since_restore: 844
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7355.196969032288
  time_this_iter_s: 9.079096794128418
  time_total_s: 7355.196969032288
  timestamp: 1594855875
  timesteps_since_restore: 4220000
  timesteps_this_iter: 5000
  timesteps_total: 4220000
  training_iteration: 844
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7355 s, 844 iter, 4220000 ts, 297 rew

agent-1: 69.19999999701427
agent-2: 68.19999999701427
agent-3: 68.19999999701426
agent-4: 67.19999999701426
agent-5: 60.199999997013954
Extrinsic Rewards:
10
9
9
8
1
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.20540540540540542
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-31-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 299.8679899531778
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 844
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.957
    dispatch_time_ms: 31.112
    learner:
      cur_lr: 0.0010789480293169618
      grad_gnorm: 33.25336837768555
      policy_entropy: 32.321258544921875
      policy_loss: 5.545176029205322
      var_gnorm: 22.9072322845459
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.788806140422821
    num_steps_sampled: 4225000
    num_steps_trained: 4225000
    wait_time_ms: 65.602
  iterations_since_restore: 845
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7364.457979440689
  time_this_iter_s: 9.26101040840149
  time_total_s: 7364.457979440689
  timestamp: 1594855884
  timesteps_since_restore: 4225000
  timesteps_this_iter: 5000
  timesteps_total: 4225000
  training_iteration: 845
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7364 s, 845 iter, 4225000 ts, 300 rew

agent-1: 53.59999999721436
agent-2: 59.59999999721439
agent-3: 54.59999999721436
agent-4: 53.59999999721437
agent-5: 57.59999999721438
Extrinsic Rewards:
4
10
5
4
8
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 4
Max Reward: 10
Gini Coefficient: 0.2064516129032258
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-31-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 302.65798995303857
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 845
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 17.233
    learner:
      cur_lr: 0.001078614965081215
      grad_gnorm: 14.861777305603027
      policy_entropy: 24.032978057861328
      policy_loss: -2.010774612426758
      var_gnorm: 22.90530776977539
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.1702456772327423
    num_steps_sampled: 4230000
    num_steps_trained: 4230000
    wait_time_ms: 60.043
  iterations_since_restore: 846
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7373.571452617645
  time_this_iter_s: 9.113473176956177
  time_total_s: 7373.571452617645
  timestamp: 1594855893
  timesteps_since_restore: 4230000
  timesteps_this_iter: 5000
  timesteps_total: 4230000
  training_iteration: 846
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7373 s, 846 iter, 4230000 ts, 303 rew

agent-1: 38.79999999917353
agent-2: 37.79999999917354
agent-3: 52.799999999173515
agent-4: 36.79999999917353
agent-5: 40.79999999917353
Extrinsic Rewards:
2
1
16
0
4
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 16
Gini Coefficient: 0.6086956521739131
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-31-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 304.7279899529973
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 846
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.741
    dispatch_time_ms: 26.71
    learner:
      cur_lr: 0.0010782820172607899
      grad_gnorm: 10.046103477478027
      policy_entropy: 19.999530792236328
      policy_loss: -0.03388114646077156
      var_gnorm: 22.90477180480957
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.07782364636659622
    num_steps_sampled: 4235000
    num_steps_trained: 4235000
    wait_time_ms: 58.84
  iterations_since_restore: 847
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7382.705302476883
  time_this_iter_s: 9.133849859237671
  time_total_s: 7382.705302476883
  timestamp: 1594855903
  timesteps_since_restore: 4235000
  timesteps_this_iter: 5000
  timesteps_total: 4235000
  training_iteration: 847
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7382 s, 847 iter, 4235000 ts, 305 rew

agent-1: 34.99999999784849
agent-2: 36.99999999784849
agent-3: 37.9999999978485
agent-4: 35.9999999978485
agent-5: 33.999999997848484
Extrinsic Rewards:
3
5
6
4
2
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.2
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-31-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 306.52798995288964
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 847
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.515
    dispatch_time_ms: 25.245
    learner:
      cur_lr: 0.001077948953025043
      grad_gnorm: 18.77747344970703
      policy_entropy: 14.519125938415527
      policy_loss: -1.836370825767517
      var_gnorm: 22.912456512451172
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2720358371734619
    num_steps_sampled: 4240000
    num_steps_trained: 4240000
    wait_time_ms: 65.935
  iterations_since_restore: 848
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7391.909558057785
  time_this_iter_s: 9.2042555809021
  time_total_s: 7391.909558057785
  timestamp: 1594855912
  timesteps_since_restore: 4240000
  timesteps_this_iter: 5000
  timesteps_total: 4240000
  training_iteration: 848
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7391 s, 848 iter, 4240000 ts, 307 rew

agent-1: 78.19999997601846
agent-2: 69.1999999760184
agent-3: 77.19999997601843
agent-4: 79.19999997601846
agent-5: 74.19999997601845
Extrinsic Rewards:
11
2
10
12
7
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.22857142857142856
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-32-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 310.30798995169056
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 848
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.634
    dispatch_time_ms: 18.887
    learner:
      cur_lr: 0.001077616005204618
      grad_gnorm: 10.133761405944824
      policy_entropy: 21.416183471679688
      policy_loss: -0.49448272585868835
      var_gnorm: 22.913808822631836
      vf_explained_var: 0.0
      vf_loss: 0.07945437729358673
    num_steps_sampled: 4245000
    num_steps_trained: 4245000
    wait_time_ms: 66.044
  iterations_since_restore: 849
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7401.104092597961
  time_this_iter_s: 9.194534540176392
  time_total_s: 7401.104092597961
  timestamp: 1594855921
  timesteps_since_restore: 4245000
  timesteps_this_iter: 5000
  timesteps_total: 4245000
  training_iteration: 849
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7401 s, 849 iter, 4245000 ts, 310 rew

agent-1: 35.19999999759719
agent-2: 37.199999997597175
agent-3: 42.199999997597175
agent-4: 41.19999999759717
agent-5: 42.199999997597175
Extrinsic Rewards:
0
2
7
6
7
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.34545454545454546
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-32-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 312.28798995157035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 849
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.863
    dispatch_time_ms: 36.387
    learner:
      cur_lr: 0.001077283057384193
      grad_gnorm: 40.000003814697266
      policy_entropy: 13.598732948303223
      policy_loss: 5.937216281890869
      var_gnorm: 22.923702239990234
      vf_explained_var: 0.0
      vf_loss: 1.6786869764328003
    num_steps_sampled: 4250000
    num_steps_trained: 4250000
    wait_time_ms: 50.622
  iterations_since_restore: 850
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7410.324306726456
  time_this_iter_s: 9.220214128494263
  time_total_s: 7410.324306726456
  timestamp: 1594855930
  timesteps_since_restore: 4250000
  timesteps_this_iter: 5000
  timesteps_total: 4250000
  training_iteration: 850
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7410 s, 850 iter, 4250000 ts, 312 rew

agent-1: 77.3999999585843
agent-2: 68.39999995858436
agent-3: 69.39999995858435
agent-4: 70.39999995858432
agent-5: 65.39999995858436
Extrinsic Rewards:
15
6
7
8
3
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 3
Max Reward: 15
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-32-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 315.7979899494996
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 850
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.535
    dispatch_time_ms: 31.154
    learner:
      cur_lr: 0.001076949993148446
      grad_gnorm: 40.000003814697266
      policy_entropy: 6.109282970428467
      policy_loss: 5.492636680603027
      var_gnorm: 22.926061630249023
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 13.479667663574219
    num_steps_sampled: 4255000
    num_steps_trained: 4255000
    wait_time_ms: 61.649
  iterations_since_restore: 851
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7419.455073356628
  time_this_iter_s: 9.13076663017273
  time_total_s: 7419.455073356628
  timestamp: 1594855940
  timesteps_since_restore: 4255000
  timesteps_this_iter: 5000
  timesteps_total: 4255000
  training_iteration: 851
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7419 s, 851 iter, 4255000 ts, 316 rew

agent-1: 119.99993955767552
agent-2: 129.99993955767573
agent-3: 133.99993955767565
agent-4: 124.99993955767555
agent-5: 120.99993955767555
Extrinsic Rewards:
8
18
22
13
9
Sum Reward: 70
Avg Reward: 14.0
Min Reward: 8
Max Reward: 22
Gini Coefficient: 0.21142857142857144
20:20 Ratio: 2.75
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-32-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 322.0979869273834
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 851
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 26.06
    learner:
      cur_lr: 0.001076617045328021
      grad_gnorm: 40.0
      policy_entropy: 33.014892578125
      policy_loss: -10.578898429870605
      var_gnorm: 22.91717529296875
      vf_explained_var: 0.0
      vf_loss: 2.243520498275757
    num_steps_sampled: 4260000
    num_steps_trained: 4260000
    wait_time_ms: 63.26
  iterations_since_restore: 852
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7428.568686723709
  time_this_iter_s: 9.113613367080688
  time_total_s: 7428.568686723709
  timestamp: 1594855949
  timesteps_since_restore: 4260000
  timesteps_this_iter: 5000
  timesteps_total: 4260000
  training_iteration: 852
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7428 s, 852 iter, 4260000 ts, 322 rew

agent-1: 132.59990740250748
agent-2: 134.59990740250745
agent-3: 137.5999074025075
agent-4: 140.59990740250748
agent-5: 138.5999074025075
Extrinsic Rewards:
11
13
16
19
17
Sum Reward: 76
Avg Reward: 15.2
Min Reward: 11
Max Reward: 19
Gini Coefficient: 0.10526315789473684
20:20 Ratio: 1.7272727272727273
Max-min Ratio: 1.7272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-32-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 328.93798229750877
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 852
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.577
    dispatch_time_ms: 30.202
    learner:
      cur_lr: 0.0010762839810922742
      grad_gnorm: 8.927395820617676
      policy_entropy: 0.23538850247859955
      policy_loss: -0.002287681680172682
      var_gnorm: 22.908109664916992
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.06172274053096771
    num_steps_sampled: 4265000
    num_steps_trained: 4265000
    wait_time_ms: 58.164
  iterations_since_restore: 853
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7437.419577360153
  time_this_iter_s: 8.850890636444092
  time_total_s: 7437.419577360153
  timestamp: 1594855958
  timesteps_since_restore: 4265000
  timesteps_this_iter: 5000
  timesteps_total: 4265000
  training_iteration: 853
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7437 s, 853 iter, 4265000 ts, 329 rew

agent-1: 52.39999999799311
agent-2: 49.3999999979931
agent-3: 51.3999999979931
agent-4: 58.3999999979931
agent-5: 49.3999999979931
Extrinsic Rewards:
6
3
5
12
3
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.2896551724137931
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-32-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 331.54798229740845
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 853
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.435
    dispatch_time_ms: 30.769
    learner:
      cur_lr: 0.0010759510332718492
      grad_gnorm: 0.9378671646118164
      policy_entropy: 0.22573116421699524
      policy_loss: -0.000183886440936476
      var_gnorm: 22.908174514770508
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0006811856874264777
    num_steps_sampled: 4270000
    num_steps_trained: 4270000
    wait_time_ms: 53.8
  iterations_since_restore: 854
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7445.917917728424
  time_this_iter_s: 8.498340368270874
  time_total_s: 7445.917917728424
  timestamp: 1594855966
  timesteps_since_restore: 4270000
  timesteps_this_iter: 5000
  timesteps_total: 4270000
  training_iteration: 854
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7445 s, 854 iter, 4270000 ts, 332 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-32-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 331.5479822974084
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 854
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.305
    dispatch_time_ms: 29.859
    learner:
      cur_lr: 0.0010756179690361023
      grad_gnorm: 0.04066995903849602
      policy_entropy: 0.22694353759288788
      policy_loss: -8.901195542421192e-06
      var_gnorm: 22.907970428466797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.2788324283974362e-06
    num_steps_sampled: 4275000
    num_steps_trained: 4275000
    wait_time_ms: 47.752
  iterations_since_restore: 855
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7454.394976377487
  time_this_iter_s: 8.47705864906311
  time_total_s: 7454.394976377487
  timestamp: 1594855975
  timesteps_since_restore: 4275000
  timesteps_this_iter: 5000
  timesteps_total: 4275000
  training_iteration: 855
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7454 s, 855 iter, 4275000 ts, 332 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-33-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 331.5479822974084
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 855
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.679
    dispatch_time_ms: 25.621
    learner:
      cur_lr: 0.0010752850212156773
      grad_gnorm: 0.004392409231513739
      policy_entropy: 0.22798258066177368
      policy_loss: 8.30817270980333e-07
      var_gnorm: 22.90802764892578
      vf_explained_var: 0.0
      vf_loss: 1.3123155007122023e-08
    num_steps_sampled: 4280000
    num_steps_trained: 4280000
    wait_time_ms: 52.316
  iterations_since_restore: 856
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7462.740372180939
  time_this_iter_s: 8.345395803451538
  time_total_s: 7462.740372180939
  timestamp: 1594855983
  timesteps_since_restore: 4280000
  timesteps_this_iter: 5000
  timesteps_total: 4280000
  training_iteration: 856
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7462 s, 856 iter, 4280000 ts, 332 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-33-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 331.5479822974084
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 856
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 30.003
    learner:
      cur_lr: 0.0010749519569799304
      grad_gnorm: 0.0076684788800776005
      policy_entropy: 0.22907795011997223
      policy_loss: 1.810583057704207e-06
      var_gnorm: 22.908084869384766
      vf_explained_var: 0.0
      vf_loss: 4.382795637525305e-08
    num_steps_sampled: 4285000
    num_steps_trained: 4285000
    wait_time_ms: 50.02
  iterations_since_restore: 857
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7471.208286762238
  time_this_iter_s: 8.467914581298828
  time_total_s: 7471.208286762238
  timestamp: 1594855992
  timesteps_since_restore: 4285000
  timesteps_this_iter: 5000
  timesteps_total: 4285000
  training_iteration: 857
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7471 s, 857 iter, 4285000 ts, 332 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-33-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 331.5479822974084
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 857
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 9.679
    learner:
      cur_lr: 0.0010746190091595054
      grad_gnorm: 0.0033634386491030455
      policy_entropy: 0.2302335500717163
      policy_loss: 6.508423098239291e-07
      var_gnorm: 22.90814971923828
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.774771854622941e-09
    num_steps_sampled: 4290000
    num_steps_trained: 4290000
    wait_time_ms: 66.978
  iterations_since_restore: 858
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7479.8248879909515
  time_this_iter_s: 8.61660122871399
  time_total_s: 7479.8248879909515
  timestamp: 1594856000
  timesteps_since_restore: 4290000
  timesteps_this_iter: 5000
  timesteps_total: 4290000
  training_iteration: 858
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7479 s, 858 iter, 4290000 ts, 332 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-33-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 331.1366810081018
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 858
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.275
    dispatch_time_ms: 12.874
    learner:
      cur_lr: 0.0010742859449237585
      grad_gnorm: 0.019147677347064018
      policy_entropy: 0.23145563900470734
      policy_loss: 3.5522677990229568e-06
      var_gnorm: 22.90821647644043
      vf_explained_var: 0.0
      vf_loss: 2.8191473688821134e-07
    num_steps_sampled: 4295000
    num_steps_trained: 4295000
    wait_time_ms: 63.57
  iterations_since_restore: 859
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7487.724471092224
  time_this_iter_s: 7.899583101272583
  time_total_s: 7487.724471092224
  timestamp: 1594856008
  timesteps_since_restore: 4295000
  timesteps_this_iter: 5000
  timesteps_total: 4295000
  training_iteration: 859
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7487 s, 859 iter, 4295000 ts, 331 rew

agent-1: 2.534127892155603
agent-2: 1.5341278921556023
agent-3: 1.5341278921556023
agent-4: 1.5341278921556023
agent-5: 1.5341278921556023
Extrinsic Rewards:
1
0
0
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-33-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 328.79658406874705
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 859
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.512
    dispatch_time_ms: 7.581
    learner:
      cur_lr: 0.0010739529971033335
      grad_gnorm: 0.09887581318616867
      policy_entropy: 0.334689199924469
      policy_loss: 1.8915738110081293e-05
      var_gnorm: 22.90727996826172
      vf_explained_var: 0.0
      vf_loss: 7.567705324618146e-06
    num_steps_sampled: 4300000
    num_steps_trained: 4300000
    wait_time_ms: 69.22
  iterations_since_restore: 860
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7495.675010442734
  time_this_iter_s: 7.9505393505096436
  time_total_s: 7495.675010442734
  timestamp: 1594856016
  timesteps_since_restore: 4300000
  timesteps_this_iter: 5000
  timesteps_total: 4300000
  training_iteration: 860
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7495 s, 860 iter, 4300000 ts, 329 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-33-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 323.3965841540572
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 860
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.639
    dispatch_time_ms: 7.243
    learner:
      cur_lr: 0.0010736200492829084
      grad_gnorm: 0.019065534695982933
      policy_entropy: 0.3375866711139679
      policy_loss: 3.909276529157069e-06
      var_gnorm: 22.90736961364746
      vf_explained_var: 0.0
      vf_loss: 2.7751838160838815e-07
    num_steps_sampled: 4305000
    num_steps_trained: 4305000
    wait_time_ms: 69.534
  iterations_since_restore: 861
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7503.328289747238
  time_this_iter_s: 7.6532793045043945
  time_total_s: 7503.328289747238
  timestamp: 1594856024
  timesteps_since_restore: 4305000
  timesteps_this_iter: 5000
  timesteps_total: 4305000
  training_iteration: 861
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7503 s, 861 iter, 4305000 ts, 323 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-33-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 321.50658415410203
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 861
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.071
    dispatch_time_ms: 6.615
    learner:
      cur_lr: 0.0010732869850471616
      grad_gnorm: 2.2328805923461914
      policy_entropy: 0.46581363677978516
      policy_loss: -0.0005752812139689922
      var_gnorm: 22.90666389465332
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.003763338550925255
    num_steps_sampled: 4310000
    num_steps_trained: 4310000
    wait_time_ms: 71.358
  iterations_since_restore: 862
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7511.383649349213
  time_this_iter_s: 8.055359601974487
  time_total_s: 7511.383649349213
  timestamp: 1594856032
  timesteps_since_restore: 4310000
  timesteps_this_iter: 5000
  timesteps_total: 4310000
  training_iteration: 862
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7511 s, 862 iter, 4310000 ts, 322 rew

agent-1: 1.5999790024147647
agent-2: 1.5999790024147647
agent-3: 1.5999790024147647
agent-4: 1.5999790024147647
agent-5: 2.5999790024147638
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-34-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 321.5965831042228
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 862
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.164
    dispatch_time_ms: 7.556
    learner:
      cur_lr: 0.0010729540372267365
      grad_gnorm: 5.152088642120361
      policy_entropy: 0.7059247493743896
      policy_loss: -0.002136217663064599
      var_gnorm: 22.90576934814453
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.02055657096207142
    num_steps_sampled: 4315000
    num_steps_trained: 4315000
    wait_time_ms: 70.65
  iterations_since_restore: 863
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7519.476736307144
  time_this_iter_s: 8.093086957931519
  time_total_s: 7519.476736307144
  timestamp: 1594856040
  timesteps_since_restore: 4315000
  timesteps_this_iter: 5000
  timesteps_total: 4315000
  training_iteration: 863
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7519 s, 863 iter, 4315000 ts, 322 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-34-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 321.50658310485306
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 863
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.867
    dispatch_time_ms: 6.158
    learner:
      cur_lr: 0.0010726209729909897
      grad_gnorm: 3.7831618785858154
      policy_entropy: 2.0704474449157715
      policy_loss: -0.007812265306711197
      var_gnorm: 22.903614044189453
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.011075614020228386
    num_steps_sampled: 4320000
    num_steps_trained: 4320000
    wait_time_ms: 71.991
  iterations_since_restore: 864
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7527.580996751785
  time_this_iter_s: 8.104260444641113
  time_total_s: 7527.580996751785
  timestamp: 1594856048
  timesteps_since_restore: 4320000
  timesteps_this_iter: 5000
  timesteps_total: 4320000
  training_iteration: 864
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7527 s, 864 iter, 4320000 ts, 322 rew

agent-1: 30.842672415612927
agent-2: 22.842672415612938
agent-3: 22.842672415612938
agent-4: 29.842672415612927
agent-5: 29.842672415612935
Extrinsic Rewards:
8
0
0
7
7
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.41818181818181815
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-34-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 320.07871699293776
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 864
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.045
    dispatch_time_ms: 8.627
    learner:
      cur_lr: 0.0010722880251705647
      grad_gnorm: 40.0
      policy_entropy: 33.3941764831543
      policy_loss: 38.53070068359375
      var_gnorm: 22.922359466552734
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 36.33028793334961
    num_steps_sampled: 4325000
    num_steps_trained: 4325000
    wait_time_ms: 74.345
  iterations_since_restore: 865
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7535.840415239334
  time_this_iter_s: 8.259418487548828
  time_total_s: 7535.840415239334
  timestamp: 1594856057
  timesteps_since_restore: 4325000
  timesteps_this_iter: 5000
  timesteps_total: 4325000
  training_iteration: 865
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7535 s, 865 iter, 4325000 ts, 320 rew

agent-1: 95.23252200132157
agent-2: 100.23252200132154
agent-3: 94.23252200132157
agent-4: 93.23252200132157
agent-5: 102.23252200132154
Extrinsic Rewards:
9
14
8
7
16
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 7
Max Reward: 16
Gini Coefficient: 0.17777777777777778
20:20 Ratio: 2.2857142857142856
Max-min Ratio: 2.2857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-34-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 319.71034310461596
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 865
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.332
    dispatch_time_ms: 7.615
    learner:
      cur_lr: 0.0010719549609348178
      grad_gnorm: 40.0
      policy_entropy: 4.989767551422119
      policy_loss: -0.33648353815078735
      var_gnorm: 22.90389633178711
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.829122304916382
    num_steps_sampled: 4330000
    num_steps_trained: 4330000
    wait_time_ms: 78.805
  iterations_since_restore: 866
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7544.465882062912
  time_this_iter_s: 8.62546682357788
  time_total_s: 7544.465882062912
  timestamp: 1594856065
  timesteps_since_restore: 4330000
  timesteps_this_iter: 5000
  timesteps_total: 4330000
  training_iteration: 866
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7544 s, 866 iter, 4330000 ts, 320 rew

agent-1: 47.79999999079426
agent-2: 56.79999999079428
agent-3: 45.79999999079428
agent-4: 51.799999990794255
agent-5: 49.799999990794255
Extrinsic Rewards:
3
12
1
7
5
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.37142857142857144
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-34-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 319.37580041759844
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 866
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 7.267
    learner:
      cur_lr: 0.0010716220131143928
      grad_gnorm: 39.999996185302734
      policy_entropy: 8.79843521118164
      policy_loss: 2.5809080600738525
      var_gnorm: 22.89383888244629
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 44.77584457397461
    num_steps_sampled: 4335000
    num_steps_trained: 4335000
    wait_time_ms: 76.015
  iterations_since_restore: 867
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7553.125753879547
  time_this_iter_s: 8.659871816635132
  time_total_s: 7553.125753879547
  timestamp: 1594856074
  timesteps_since_restore: 4335000
  timesteps_this_iter: 5000
  timesteps_total: 4335000
  training_iteration: 867
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7553 s, 867 iter, 4335000 ts, 319 rew

agent-1: 50.59999999734525
agent-2: 43.59999999734528
agent-3: 50.599999997345265
agent-4: 43.59999999734525
agent-5: 45.59999999734525
Extrinsic Rewards:
9
2
9
2
4
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.3230769230769231
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-34-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 315.9835292109101
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 867
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.064
    dispatch_time_ms: 11.709
    learner:
      cur_lr: 0.001071288948878646
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.361509323120117
      policy_loss: -7.786405563354492
      var_gnorm: 22.912796020507812
      vf_explained_var: 0.0
      vf_loss: 2.920980215072632
    num_steps_sampled: 4340000
    num_steps_trained: 4340000
    wait_time_ms: 74.544
  iterations_since_restore: 868
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7561.719524383545
  time_this_iter_s: 8.593770503997803
  time_total_s: 7561.719524383545
  timestamp: 1594856083
  timesteps_since_restore: 4340000
  timesteps_this_iter: 5000
  timesteps_total: 4340000
  training_iteration: 868
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7561 s, 868 iter, 4340000 ts, 316 rew

agent-1: 152.79980915083578
agent-2: 140.7998091508358
agent-3: 144.7998091508358
agent-4: 157.7998091508358
agent-5: 150.79980915083573
Extrinsic Rewards:
20
8
12
25
18
Sum Reward: 83
Avg Reward: 16.6
Min Reward: 8
Max Reward: 25
Gini Coefficient: 0.20240963855421687
20:20 Ratio: 3.125
Max-min Ratio: 3.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-34-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 318.95351970524416
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 868
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.681
    dispatch_time_ms: 8.613
    learner:
      cur_lr: 0.0010709560010582209
      grad_gnorm: 40.0
      policy_entropy: 13.622186660766602
      policy_loss: 6.410717964172363
      var_gnorm: 22.895362854003906
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 13.090291023254395
    num_steps_sampled: 4345000
    num_steps_trained: 4345000
    wait_time_ms: 75.495
  iterations_since_restore: 869
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7570.32670044899
  time_this_iter_s: 8.607176065444946
  time_total_s: 7570.32670044899
  timestamp: 1594856091
  timesteps_since_restore: 4345000
  timesteps_this_iter: 5000
  timesteps_total: 4345000
  training_iteration: 869
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7570 s, 869 iter, 4345000 ts, 319 rew

agent-1: 63.59999994681624
agent-2: 68.59999994681633
agent-3: 59.59999994681624
agent-4: 71.5999999468163
agent-5: 60.59999994681624
Extrinsic Rewards:
6
11
2
14
3
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.35555555555555557
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-35-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 319.853519702778
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 869
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 5.643
    learner:
      cur_lr: 0.0010706230532377958
      grad_gnorm: 40.0
      policy_entropy: 28.284229278564453
      policy_loss: -8.162019729614258
      var_gnorm: 22.897218704223633
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.5527726411819458
    num_steps_sampled: 4350000
    num_steps_trained: 4350000
    wait_time_ms: 77.936
  iterations_since_restore: 870
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7578.9582624435425
  time_this_iter_s: 8.631561994552612
  time_total_s: 7578.9582624435425
  timestamp: 1594856100
  timesteps_since_restore: 4350000
  timesteps_this_iter: 5000
  timesteps_total: 4350000
  training_iteration: 870
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7578 s, 870 iter, 4350000 ts, 320 rew

agent-1: 99.5999983729457
agent-2: 102.59999837294573
agent-3: 96.59999837294573
agent-4: 97.59999837294573
agent-5: 107.59999837294576
Extrinsic Rewards:
10
13
7
8
18
Sum Reward: 56
Avg Reward: 11.2
Min Reward: 7
Max Reward: 18
Gini Coefficient: 0.19285714285714287
20:20 Ratio: 2.5714285714285716
Max-min Ratio: 2.5714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-35-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 319.58352646932525
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 870
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.024
    dispatch_time_ms: 8.554
    learner:
      cur_lr: 0.001070289989002049
      grad_gnorm: 10.944735527038574
      policy_entropy: 26.22356414794922
      policy_loss: -1.4531338214874268
      var_gnorm: 22.894500732421875
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0897960364818573
    num_steps_sampled: 4355000
    num_steps_trained: 4355000
    wait_time_ms: 74.87
  iterations_since_restore: 871
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7587.690029621124
  time_this_iter_s: 8.731767177581787
  time_total_s: 7587.690029621124
  timestamp: 1594856109
  timesteps_since_restore: 4355000
  timesteps_this_iter: 5000
  timesteps_total: 4355000
  training_iteration: 871
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7587 s, 871 iter, 4355000 ts, 320 rew

agent-1: 54.39999999335398
agent-2: 48.39999999335398
agent-3: 60.399999993353966
agent-4: 49.39999999335398
agent-5: 48.39999999335398
Extrinsic Rewards:
8
2
14
3
2
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.41379310344827586
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-35-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 316.43353120247997
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 871
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.736
    dispatch_time_ms: 7.097
    learner:
      cur_lr: 0.001069957041181624
      grad_gnorm: 11.416743278503418
      policy_entropy: 34.21598815917969
      policy_loss: -2.071281909942627
      var_gnorm: 22.894363403320312
      vf_explained_var: 0.0
      vf_loss: 0.09622594714164734
    num_steps_sampled: 4360000
    num_steps_trained: 4360000
    wait_time_ms: 73.815
  iterations_since_restore: 872
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7596.303910970688
  time_this_iter_s: 8.613881349563599
  time_total_s: 7596.303910970688
  timestamp: 1594856117
  timesteps_since_restore: 4360000
  timesteps_this_iter: 5000
  timesteps_total: 4360000
  training_iteration: 872
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7596 s, 872 iter, 4360000 ts, 316 rew

agent-1: 33.5999999996312
agent-2: 28.59999999963108
agent-3: 28.59999999963108
agent-4: 26.599999999631084
agent-5: 26.599999999631084
Extrinsic Rewards:
8
3
3
1
1
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.4
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-35-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 314.9035312026573
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 872
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.858
    dispatch_time_ms: 6.159
    learner:
      cur_lr: 0.001069623976945877
      grad_gnorm: 30.66830825805664
      policy_entropy: 30.42487907409668
      policy_loss: 4.494147777557373
      var_gnorm: 22.895177841186523
      vf_explained_var: 0.0
      vf_loss: 0.7356797456741333
    num_steps_sampled: 4365000
    num_steps_trained: 4365000
    wait_time_ms: 81.166
  iterations_since_restore: 873
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7604.9686052799225
  time_this_iter_s: 8.66469430923462
  time_total_s: 7604.9686052799225
  timestamp: 1594856126
  timesteps_since_restore: 4365000
  timesteps_this_iter: 5000
  timesteps_total: 4365000
  training_iteration: 873
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7604 s, 873 iter, 4365000 ts, 315 rew

agent-1: 33.999999998912244
agent-2: 36.99999999891223
agent-3: 36.99999999891222
agent-4: 36.99999999891223
agent-5: 34.99999999891224
Extrinsic Rewards:
2
5
5
5
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.16
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-35-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.3107250076664
  episode_reward_mean: 307.52353716468787
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 873
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 7.8
    learner:
      cur_lr: 0.001069291029125452
      grad_gnorm: 16.18827247619629
      policy_entropy: 27.668550491333008
      policy_loss: -2.5779500007629395
      var_gnorm: 22.894590377807617
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.19716894626617432
    num_steps_sampled: 4370000
    num_steps_trained: 4370000
    wait_time_ms: 74.923
  iterations_since_restore: 874
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7613.563563346863
  time_this_iter_s: 8.594958066940308
  time_total_s: 7613.563563346863
  timestamp: 1594856135
  timesteps_since_restore: 4370000
  timesteps_this_iter: 5000
  timesteps_total: 4370000
  training_iteration: 874
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7613 s, 874 iter, 4370000 ts, 308 rew

agent-1: 37.3999999991778
agent-2: 34.39999999917781
agent-3: 31.399999999177776
agent-4: 32.399999999177815
agent-5: 35.399999999177815
Extrinsic Rewards:
7
4
1
2
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.3157894736842105
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-35-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 298.80042991457
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 874
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 9.947
    learner:
      cur_lr: 0.0010689579648897052
      grad_gnorm: 40.000003814697266
      policy_entropy: 33.372642517089844
      policy_loss: 16.030452728271484
      var_gnorm: 22.895156860351562
      vf_explained_var: 0.0
      vf_loss: 8.511765480041504
    num_steps_sampled: 4375000
    num_steps_trained: 4375000
    wait_time_ms: 74.256
  iterations_since_restore: 875
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7622.122430562973
  time_this_iter_s: 8.55886721611023
  time_total_s: 7622.122430562973
  timestamp: 1594856143
  timesteps_since_restore: 4375000
  timesteps_this_iter: 5000
  timesteps_total: 4375000
  training_iteration: 875
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7622 s, 875 iter, 4375000 ts, 299 rew

agent-1: 55.59999999535175
agent-2: 55.59999999535175
agent-3: 54.599999995351766
agent-4: 54.59999999535175
agent-5: 58.59999999535175
Extrinsic Rewards:
6
6
5
5
9
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 5
Max Reward: 9
Gini Coefficient: 0.11612903225806452
20:20 Ratio: 1.8
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-35-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 297.9004299180227
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 875
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.246
    dispatch_time_ms: 8.695
    learner:
      cur_lr: 0.0010686250170692801
      grad_gnorm: 26.416994094848633
      policy_entropy: 19.307687759399414
      policy_loss: -2.2126643657684326
      var_gnorm: 22.8945369720459
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.5375947952270508
    num_steps_sampled: 4380000
    num_steps_trained: 4380000
    wait_time_ms: 75.87
  iterations_since_restore: 876
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7630.766516685486
  time_this_iter_s: 8.644086122512817
  time_total_s: 7630.766516685486
  timestamp: 1594856152
  timesteps_since_restore: 4380000
  timesteps_this_iter: 5000
  timesteps_total: 4380000
  training_iteration: 876
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7630 s, 876 iter, 4380000 ts, 298 rew

agent-1: 37.799999997748394
agent-2: 47.799999997748415
agent-3: 38.799999997748394
agent-4: 41.7999999977484
agent-5: 40.799999997748394
Extrinsic Rewards:
1
11
2
5
4
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.4
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-36-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 296.910429918193
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 876
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 9.836
    learner:
      cur_lr: 0.0010682919528335333
      grad_gnorm: 12.52064323425293
      policy_entropy: 28.877605438232422
      policy_loss: -1.2646868228912354
      var_gnorm: 22.89402198791504
      vf_explained_var: 0.0
      vf_loss: 0.10526856034994125
    num_steps_sampled: 4385000
    num_steps_trained: 4385000
    wait_time_ms: 74.375
  iterations_since_restore: 877
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7639.358682870865
  time_this_iter_s: 8.592166185379028
  time_total_s: 7639.358682870865
  timestamp: 1594856161
  timesteps_since_restore: 4385000
  timesteps_this_iter: 5000
  timesteps_total: 4385000
  training_iteration: 877
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7639 s, 877 iter, 4385000 ts, 297 rew

agent-1: 57.39999997902509
agent-2: 49.399999979025104
agent-3: 54.39999997902509
agent-4: 48.39999997902512
agent-5: 51.399999979025104
Extrinsic Rewards:
11
3
8
2
5
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.31724137931034485
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-36-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 298.0804299171658
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 877
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.064
    dispatch_time_ms: 6.293
    learner:
      cur_lr: 0.0010679590050131083
      grad_gnorm: 29.739206314086914
      policy_entropy: 31.524457931518555
      policy_loss: -4.318925380706787
      var_gnorm: 22.89348030090332
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.6701211929321289
    num_steps_sampled: 4390000
    num_steps_trained: 4390000
    wait_time_ms: 80.67
  iterations_since_restore: 878
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7647.993522405624
  time_this_iter_s: 8.634839534759521
  time_total_s: 7647.993522405624
  timestamp: 1594856169
  timesteps_since_restore: 4390000
  timesteps_this_iter: 5000
  timesteps_total: 4390000
  training_iteration: 878
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7647 s, 878 iter, 4390000 ts, 298 rew

agent-1: 45.79999999855185
agent-2: 38.79999999855183
agent-3: 36.79999999855183
agent-4: 40.79999999855182
agent-5: 44.79999999855185
Extrinsic Rewards:
9
2
0
4
8
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.41739130434782606
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-36-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 297.90042991716496
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 878
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.526
    dispatch_time_ms: 8.83
    learner:
      cur_lr: 0.0010676260571926832
      grad_gnorm: 40.000003814697266
      policy_entropy: 32.447265625
      policy_loss: 15.272806167602539
      var_gnorm: 22.894296646118164
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.202064514160156
    num_steps_sampled: 4395000
    num_steps_trained: 4395000
    wait_time_ms: 75.048
  iterations_since_restore: 879
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7656.594369888306
  time_this_iter_s: 8.600847482681274
  time_total_s: 7656.594369888306
  timestamp: 1594856178
  timesteps_since_restore: 4395000
  timesteps_this_iter: 5000
  timesteps_total: 4395000
  training_iteration: 879
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7656 s, 879 iter, 4395000 ts, 298 rew

agent-1: 66.79999994015772
agent-2: 70.79999994015768
agent-3: 70.79999994015768
agent-4: 65.79999994015772
agent-5: 67.79999994015765
Extrinsic Rewards:
6
10
10
5
7
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 5
Max Reward: 10
Gini Coefficient: 0.14736842105263157
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-36-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 298.71042991426066
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 879
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.552
    dispatch_time_ms: 6.127
    learner:
      cur_lr: 0.0010672929929569364
      grad_gnorm: 12.008868217468262
      policy_entropy: 33.3626708984375
      policy_loss: -2.02008318901062
      var_gnorm: 22.89379119873047
      vf_explained_var: 0.0
      vf_loss: 0.11089232563972473
    num_steps_sampled: 4400000
    num_steps_trained: 4400000
    wait_time_ms: 82.016
  iterations_since_restore: 880
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7665.219416379929
  time_this_iter_s: 8.625046491622925
  time_total_s: 7665.219416379929
  timestamp: 1594856187
  timesteps_since_restore: 4400000
  timesteps_this_iter: 5000
  timesteps_total: 4400000
  training_iteration: 880
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7665 s, 880 iter, 4400000 ts, 299 rew

agent-1: 32.999999998499895
agent-2: 33.9999999984999
agent-3: 34.99999999849991
agent-4: 38.99999999849993
agent-5: 38.99999999849993
Extrinsic Rewards:
1
2
3
7
7
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.34
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-36-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 296.55042992920187
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 880
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 6.793
    learner:
      cur_lr: 0.0010669600451365113
      grad_gnorm: 40.0
      policy_entropy: 20.49182891845703
      policy_loss: 21.997905731201172
      var_gnorm: 22.89491844177246
      vf_explained_var: 0.0
      vf_loss: 24.212913513183594
    num_steps_sampled: 4405000
    num_steps_trained: 4405000
    wait_time_ms: 79.893
  iterations_since_restore: 881
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7673.910706043243
  time_this_iter_s: 8.69128966331482
  time_total_s: 7673.910706043243
  timestamp: 1594856195
  timesteps_since_restore: 4405000
  timesteps_this_iter: 5000
  timesteps_total: 4405000
  training_iteration: 881
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7673 s, 881 iter, 4405000 ts, 297 rew

agent-1: 38.799999998718846
agent-2: 38.79999999871886
agent-3: 46.799999998718846
agent-4: 39.79999999871886
agent-5: 42.79999999871886
Extrinsic Rewards:
2
2
10
3
6
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.34782608695652173
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-36-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 294.3904299926415
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 881
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 9.177
    learner:
      cur_lr: 0.0010666269809007645
      grad_gnorm: 35.011592864990234
      policy_entropy: 19.2940616607666
      policy_loss: 3.4731497764587402
      var_gnorm: 22.888065338134766
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.9930327534675598
    num_steps_sampled: 4410000
    num_steps_trained: 4410000
    wait_time_ms: 75.216
  iterations_since_restore: 882
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7682.551047801971
  time_this_iter_s: 8.640341758728027
  time_total_s: 7682.551047801971
  timestamp: 1594856204
  timesteps_since_restore: 4410000
  timesteps_this_iter: 5000
  timesteps_total: 4410000
  training_iteration: 882
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7682 s, 882 iter, 4410000 ts, 294 rew

agent-1: 47.19999999718562
agent-2: 50.19999999718564
agent-3: 47.19999999718562
agent-4: 44.19999999718563
agent-5: 54.19999999718564
Extrinsic Rewards:
4
7
4
1
11
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.34074074074074073
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-36-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 291.78043020700596
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 882
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.367
    dispatch_time_ms: 7.045
    learner:
      cur_lr: 0.0010662940330803394
      grad_gnorm: 40.0
      policy_entropy: 33.53144836425781
      policy_loss: 72.05550384521484
      var_gnorm: 22.888641357421875
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 150.0634002685547
    num_steps_sampled: 4415000
    num_steps_trained: 4415000
    wait_time_ms: 74.196
  iterations_since_restore: 883
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7691.215688943863
  time_this_iter_s: 8.66464114189148
  time_total_s: 7691.215688943863
  timestamp: 1594856213
  timesteps_since_restore: 4415000
  timesteps_this_iter: 5000
  timesteps_total: 4415000
  training_iteration: 883
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7691 s, 883 iter, 4415000 ts, 292 rew

agent-1: 97.39999979270743
agent-2: 98.39999979270745
agent-3: 102.3999997927074
agent-4: 92.39999979270743
agent-5: 95.39999979270745
Extrinsic Rewards:
11
12
16
6
9
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 6
Max Reward: 16
Gini Coefficient: 0.17037037037037037
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-37-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 293.13043019783316
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 883
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.981
    dispatch_time_ms: 8.659
    learner:
      cur_lr: 0.0010659609688445926
      grad_gnorm: 20.779983520507812
      policy_entropy: 34.57469177246094
      policy_loss: -3.9702413082122803
      var_gnorm: 22.886287689208984
      vf_explained_var: 0.0
      vf_loss: 0.3274437189102173
    num_steps_sampled: 4420000
    num_steps_trained: 4420000
    wait_time_ms: 74.854
  iterations_since_restore: 884
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7699.792136192322
  time_this_iter_s: 8.576447248458862
  time_total_s: 7699.792136192322
  timestamp: 1594856221
  timesteps_since_restore: 4420000
  timesteps_this_iter: 5000
  timesteps_total: 4420000
  training_iteration: 884
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7699 s, 884 iter, 4420000 ts, 293 rew

agent-1: 69.99999997184601
agent-2: 56.99999997184598
agent-3: 64.99999997184604
agent-4: 61.99999997184598
agent-5: 60.999999971845966
Extrinsic Rewards:
14
1
9
6
5
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.34285714285714286
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-37-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 290.07043040266007
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 884
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.809
    dispatch_time_ms: 10.011
    learner:
      cur_lr: 0.0010656280210241675
      grad_gnorm: 10.26538372039795
      policy_entropy: 28.808860778808594
      policy_loss: -1.6097325086593628
      var_gnorm: 22.888710021972656
      vf_explained_var: 0.0
      vf_loss: 0.07919120043516159
    num_steps_sampled: 4425000
    num_steps_trained: 4425000
    wait_time_ms: 72.108
  iterations_since_restore: 885
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7708.296324491501
  time_this_iter_s: 8.504188299179077
  time_total_s: 7708.296324491501
  timestamp: 1594856230
  timesteps_since_restore: 4425000
  timesteps_this_iter: 5000
  timesteps_total: 4425000
  training_iteration: 885
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7708 s, 885 iter, 4425000 ts, 290 rew

agent-1: 60.399999997242205
agent-2: 50.399999997242205
agent-3: 49.399999997242205
agent-4: 50.399999997242205
agent-5: 50.399999997242205
Extrinsic Rewards:
14
4
3
4
4
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.30344827586206896
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-37-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 289.9804304026051
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 885
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.738
    dispatch_time_ms: 9.105
    learner:
      cur_lr: 0.0010652949567884207
      grad_gnorm: 30.110166549682617
      policy_entropy: 10.89062213897705
      policy_loss: -0.5485779047012329
      var_gnorm: 22.891254425048828
      vf_explained_var: 0.0
      vf_loss: 0.668061375617981
    num_steps_sampled: 4430000
    num_steps_trained: 4430000
    wait_time_ms: 78.659
  iterations_since_restore: 886
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7728.553055524826
  time_this_iter_s: 20.256731033325195
  time_total_s: 7728.553055524826
  timestamp: 1594856250
  timesteps_since_restore: 4430000
  timesteps_this_iter: 5000
  timesteps_total: 4430000
  training_iteration: 886
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7728 s, 886 iter, 4430000 ts, 290 rew

agent-1: 82.59999789336418
agent-2: 90.59999789336415
agent-3: 105.59999789336412
agent-4: 87.59999789336418
agent-5: 92.59999789336415
Extrinsic Rewards:
1
9
24
6
11
Sum Reward: 51
Avg Reward: 10.2
Min Reward: 1
Max Reward: 24
Gini Coefficient: 0.4
20:20 Ratio: 24.0
Max-min Ratio: 24.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-37-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 292.6804302973237
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 886
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 7.691
    learner:
      cur_lr: 0.0010649620089679956
      grad_gnorm: 40.0
      policy_entropy: 23.13378143310547
      policy_loss: 13.727654457092285
      var_gnorm: 22.88144874572754
      vf_explained_var: 0.0
      vf_loss: 9.74146842956543
    num_steps_sampled: 4435000
    num_steps_trained: 4435000
    wait_time_ms: 77.498
  iterations_since_restore: 887
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7737.282993555069
  time_this_iter_s: 8.72993803024292
  time_total_s: 7737.282993555069
  timestamp: 1594856259
  timesteps_since_restore: 4435000
  timesteps_this_iter: 5000
  timesteps_total: 4435000
  training_iteration: 887
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7737 s, 887 iter, 4435000 ts, 293 rew

agent-1: 68.39999992367618
agent-2: 66.39999992367615
agent-3: 69.39999992367615
agent-4: 78.39999992367615
agent-5: 68.39999992367618
Extrinsic Rewards:
6
4
7
16
6
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 4
Max Reward: 16
Gini Coefficient: 0.2564102564102564
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-37-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 292.0504302950239
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 887
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.275
    dispatch_time_ms: 7.394
    learner:
      cur_lr: 0.0010646289447322488
      grad_gnorm: 15.706742286682129
      policy_entropy: 34.1999397277832
      policy_loss: -2.9392426013946533
      var_gnorm: 22.881114959716797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.16765077412128448
    num_steps_sampled: 4440000
    num_steps_trained: 4440000
    wait_time_ms: 75.754
  iterations_since_restore: 888
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7745.994861602783
  time_this_iter_s: 8.711868047714233
  time_total_s: 7745.994861602783
  timestamp: 1594856268
  timesteps_since_restore: 4440000
  timesteps_this_iter: 5000
  timesteps_total: 4440000
  training_iteration: 888
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7745 s, 888 iter, 4440000 ts, 292 rew

agent-1: 41.19999999761512
agent-2: 40.199999997615116
agent-3: 35.19999999761511
agent-4: 42.199999997615144
agent-5: 39.199999997615116
Extrinsic Rewards:
6
5
0
7
4
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.2909090909090909
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-37-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 292.05043029499177
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 888
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 8.613
    learner:
      cur_lr: 0.0010642959969118237
      grad_gnorm: 40.0
      policy_entropy: 34.658348083496094
      policy_loss: 44.353511810302734
      var_gnorm: 22.882104873657227
      vf_explained_var: 0.0
      vf_loss: 52.78688049316406
    num_steps_sampled: 4445000
    num_steps_trained: 4445000
    wait_time_ms: 72.801
  iterations_since_restore: 889
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7754.556011199951
  time_this_iter_s: 8.561149597167969
  time_total_s: 7754.556011199951
  timestamp: 1594856276
  timesteps_since_restore: 4445000
  timesteps_this_iter: 5000
  timesteps_total: 4445000
  training_iteration: 889
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7754 s, 889 iter, 4445000 ts, 292 rew

agent-1: 49.19999999783624
agent-2: 46.19999999783625
agent-3: 51.199999997836244
agent-4: 46.19999999783625
agent-5: 50.19999999783624
Extrinsic Rewards:
6
3
8
3
7
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 8
Gini Coefficient: 0.2074074074074074
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-38-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 291.78043029507006
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 889
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.707
    dispatch_time_ms: 8.597
    learner:
      cur_lr: 0.0010639630490913987
      grad_gnorm: 40.0
      policy_entropy: 34.43706130981445
      policy_loss: -8.165284156799316
      var_gnorm: 22.883670806884766
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.395487904548645
    num_steps_sampled: 4450000
    num_steps_trained: 4450000
    wait_time_ms: 74.528
  iterations_since_restore: 890
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7763.0982410907745
  time_this_iter_s: 8.542229890823364
  time_total_s: 7763.0982410907745
  timestamp: 1594856285
  timesteps_since_restore: 4450000
  timesteps_this_iter: 5000
  timesteps_total: 4450000
  training_iteration: 890
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7763 s, 890 iter, 4450000 ts, 292 rew

agent-1: 122.19999279529397
agent-2: 109.19999279529394
agent-3: 111.19999279529397
agent-4: 107.19999279529397
agent-5: 108.19999279529397
Extrinsic Rewards:
23
10
12
8
9
Sum Reward: 62
Avg Reward: 12.4
Min Reward: 8
Max Reward: 23
Gini Coefficient: 0.2129032258064516
20:20 Ratio: 2.875
Max-min Ratio: 2.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-38-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 295.92042993485916
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 890
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.66
    dispatch_time_ms: 9.044
    learner:
      cur_lr: 0.0010636299848556519
      grad_gnorm: 12.171399116516113
      policy_entropy: 14.53336238861084
      policy_loss: -1.2410242557525635
      var_gnorm: 22.882579803466797
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.11031918972730637
    num_steps_sampled: 4455000
    num_steps_trained: 4455000
    wait_time_ms: 74.541
  iterations_since_restore: 891
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7771.734541416168
  time_this_iter_s: 8.636300325393677
  time_total_s: 7771.734541416168
  timestamp: 1594856294
  timesteps_since_restore: 4455000
  timesteps_this_iter: 5000
  timesteps_total: 4455000
  training_iteration: 891
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7771 s, 891 iter, 4455000 ts, 296 rew

agent-1: 33.59999999844733
agent-2: 37.599999998447366
agent-3: 41.599999998447366
agent-4: 38.599999998447366
agent-5: 37.59999999844735
Extrinsic Rewards:
0
4
8
5
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.3238095238095238
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-38-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 845.9996324488301
  episode_reward_mean: 296.01042993481246
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 891
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.629
    dispatch_time_ms: 7.915
    learner:
      cur_lr: 0.0010632970370352268
      grad_gnorm: 40.0
      policy_entropy: 20.69423484802246
      policy_loss: 28.346450805664062
      var_gnorm: 22.902875900268555
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 80.64830780029297
    num_steps_sampled: 4460000
    num_steps_trained: 4460000
    wait_time_ms: 75.325
  iterations_since_restore: 892
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7780.2967936992645
  time_this_iter_s: 8.562252283096313
  time_total_s: 7780.2967936992645
  timestamp: 1594856302
  timesteps_since_restore: 4460000
  timesteps_this_iter: 5000
  timesteps_total: 4460000
  training_iteration: 892
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7780 s, 892 iter, 4460000 ts, 296 rew

agent-1: 241.7641621862066
agent-2: 239.7641621862067
agent-3: 250.7641621862066
agent-4: 249.7641621862066
agent-5: 231.76416218620665
Extrinsic Rewards:
26
24
35
34
16
Sum Reward: 135
Avg Reward: 27.0
Min Reward: 16
Max Reward: 35
Gini Coefficient: 0.14222222222222222
20:20 Ratio: 2.1875
Max-min Ratio: 2.1875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-38-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 305.08863804626236
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 892
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 12.956
    learner:
      cur_lr: 0.00106296397279948
      grad_gnorm: 40.0
      policy_entropy: 21.890079498291016
      policy_loss: -13.576770782470703
      var_gnorm: 22.909690856933594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 8.887203216552734
    num_steps_sampled: 4465000
    num_steps_trained: 4465000
    wait_time_ms: 73.543
  iterations_since_restore: 893
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7788.938497066498
  time_this_iter_s: 8.641703367233276
  time_total_s: 7788.938497066498
  timestamp: 1594856311
  timesteps_since_restore: 4465000
  timesteps_this_iter: 5000
  timesteps_total: 4465000
  training_iteration: 893
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7788 s, 893 iter, 4465000 ts, 305 rew

agent-1: 137.9999953086673
agent-2: 144.9999953086674
agent-3: 146.99999530866737
agent-4: 142.99999530866737
agent-5: 146.9999953086673
Extrinsic Rewards:
10
17
19
15
19
Sum Reward: 80
Avg Reward: 16.0
Min Reward: 10
Max Reward: 19
Gini Coefficient: 0.11
20:20 Ratio: 1.9
Max-min Ratio: 1.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-38-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 309.04863781240874
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 893
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.403
    dispatch_time_ms: 8.617
    learner:
      cur_lr: 0.001062631024979055
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.633745193481445
      policy_loss: 7.35059928894043
      var_gnorm: 22.894084930419922
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.602245569229126
    num_steps_sampled: 4470000
    num_steps_trained: 4470000
    wait_time_ms: 75.774
  iterations_since_restore: 894
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7797.582041025162
  time_this_iter_s: 8.64354395866394
  time_total_s: 7797.582041025162
  timestamp: 1594856320
  timesteps_since_restore: 4470000
  timesteps_this_iter: 5000
  timesteps_total: 4470000
  training_iteration: 894
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7797 s, 894 iter, 4470000 ts, 309 rew

agent-1: 53.39999999647983
agent-2: 54.39999999647983
agent-3: 49.39999999647982
agent-4: 48.39999999647982
agent-5: 55.39999999647983
Extrinsic Rewards:
7
8
3
2
9
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2620689655172414
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-38-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 309.4086378122895
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 894
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.461
    dispatch_time_ms: 6.335
    learner:
      cur_lr: 0.001062297960743308
      grad_gnorm: 40.0
      policy_entropy: 11.026060104370117
      policy_loss: 7.415952682495117
      var_gnorm: 22.88479995727539
      vf_explained_var: 0.0
      vf_loss: 35.46195602416992
    num_steps_sampled: 4475000
    num_steps_trained: 4475000
    wait_time_ms: 77.033
  iterations_since_restore: 895
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7806.295085906982
  time_this_iter_s: 8.713044881820679
  time_total_s: 7806.295085906982
  timestamp: 1594856328
  timesteps_since_restore: 4475000
  timesteps_this_iter: 5000
  timesteps_total: 4475000
  training_iteration: 895
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7806 s, 895 iter, 4475000 ts, 309 rew

agent-1: 87.99999975621914
agent-2: 93.99999975621914
agent-3: 88.99999975621914
agent-4: 91.99999975621914
agent-5: 86.99999975621914
Extrinsic Rewards:
8
14
9
12
7
Sum Reward: 50
Avg Reward: 10.0
Min Reward: 7
Max Reward: 14
Gini Coefficient: 0.144
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-38-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 312.28863780012665
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 895
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.508
    dispatch_time_ms: 11.076
    learner:
      cur_lr: 0.001061965012922883
      grad_gnorm: 40.0
      policy_entropy: 21.541772842407227
      policy_loss: 38.41503143310547
      var_gnorm: 22.898733139038086
      vf_explained_var: 0.0
      vf_loss: 54.10602951049805
    num_steps_sampled: 4480000
    num_steps_trained: 4480000
    wait_time_ms: 71.875
  iterations_since_restore: 896
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7814.778584480286
  time_this_iter_s: 8.483498573303223
  time_total_s: 7814.778584480286
  timestamp: 1594856337
  timesteps_since_restore: 4480000
  timesteps_this_iter: 5000
  timesteps_total: 4480000
  training_iteration: 896
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7814 s, 896 iter, 4480000 ts, 312 rew

agent-1: 216.7201748399941
agent-2: 225.72017483999414
agent-3: 221.72017483999414
agent-4: 221.72017483999414
agent-5: 220.72017483999412
Extrinsic Rewards:
20
29
25
25
24
Sum Reward: 123
Avg Reward: 24.6
Min Reward: 20
Max Reward: 29
Gini Coefficient: 0.061788617886178863
20:20 Ratio: 1.45
Max-min Ratio: 1.45
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-39-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 321.55464654217195
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 896
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 8.586
    learner:
      cur_lr: 0.0010616319486871362
      grad_gnorm: 37.853477478027344
      policy_entropy: 25.766923904418945
      policy_loss: 3.5042829513549805
      var_gnorm: 22.895248413085938
      vf_explained_var: 0.0
      vf_loss: 1.1126130819320679
    num_steps_sampled: 4485000
    num_steps_trained: 4485000
    wait_time_ms: 75.531
  iterations_since_restore: 897
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7823.427937269211
  time_this_iter_s: 8.649352788925171
  time_total_s: 7823.427937269211
  timestamp: 1594856345
  timesteps_since_restore: 4485000
  timesteps_this_iter: 5000
  timesteps_total: 4485000
  training_iteration: 897
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7823 s, 897 iter, 4485000 ts, 322 rew

agent-1: 97.79999949624116
agent-2: 107.79999949624117
agent-3: 109.79999949624116
agent-4: 105.79999949624117
agent-5: 100.79999949624118
Extrinsic Rewards:
5
15
17
13
8
Sum Reward: 58
Avg Reward: 11.6
Min Reward: 5
Max Reward: 17
Gini Coefficient: 0.21379310344827587
20:20 Ratio: 3.4
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-39-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 324.4346465175219
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 897
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.024
    dispatch_time_ms: 8.212
    learner:
      cur_lr: 0.0010612990008667111
      grad_gnorm: 21.43140983581543
      policy_entropy: 19.68626594543457
      policy_loss: -1.6351443529129028
      var_gnorm: 22.88617515563965
      vf_explained_var: 0.0
      vf_loss: 0.34236040711402893
    num_steps_sampled: 4490000
    num_steps_trained: 4490000
    wait_time_ms: 75.513
  iterations_since_restore: 898
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7832.100514173508
  time_this_iter_s: 8.672576904296875
  time_total_s: 7832.100514173508
  timestamp: 1594856354
  timesteps_since_restore: 4490000
  timesteps_this_iter: 5000
  timesteps_total: 4490000
  training_iteration: 898
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7832 s, 898 iter, 4490000 ts, 324 rew

agent-1: 58.79999999717952
agent-2: 62.799999997179526
agent-3: 59.799999997179526
agent-4: 52.799999997179526
agent-5: 62.799999997179526
Extrinsic Rewards:
6
10
7
0
10
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.2909090909090909
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-39-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 323.3546465225332
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 898
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.188
    dispatch_time_ms: 8.204
    learner:
      cur_lr: 0.001060966053046286
      grad_gnorm: 10.7555570602417
      policy_entropy: 34.179134368896484
      policy_loss: -1.567437767982483
      var_gnorm: 22.886747360229492
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.08951529860496521
    num_steps_sampled: 4495000
    num_steps_trained: 4495000
    wait_time_ms: 79.104
  iterations_since_restore: 899
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7840.763095855713
  time_this_iter_s: 8.6625816822052
  time_total_s: 7840.763095855713
  timestamp: 1594856363
  timesteps_since_restore: 4495000
  timesteps_this_iter: 5000
  timesteps_total: 4495000
  training_iteration: 899
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7840 s, 899 iter, 4495000 ts, 323 rew

agent-1: 30.599999999594083
agent-2: 30.599999999594083
agent-3: 25.599999999594075
agent-4: 29.599999999594083
agent-5: 27.599999999594075
Extrinsic Rewards:
5
5
0
4
2
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 5
Gini Coefficient: 0.325
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-39-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 323.44464652253686
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 899
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.631
    dispatch_time_ms: 7.857
    learner:
      cur_lr: 0.0010606329888105392
      grad_gnorm: 12.446035385131836
      policy_entropy: 16.799720764160156
      policy_loss: -1.4680923223495483
      var_gnorm: 22.88618278503418
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.11758279800415039
    num_steps_sampled: 4500000
    num_steps_trained: 4500000
    wait_time_ms: 76.566
  iterations_since_restore: 900
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7849.362676620483
  time_this_iter_s: 8.599580764770508
  time_total_s: 7849.362676620483
  timestamp: 1594856371
  timesteps_since_restore: 4500000
  timesteps_this_iter: 5000
  timesteps_total: 4500000
  training_iteration: 900
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7849 s, 900 iter, 4500000 ts, 323 rew

agent-1: 31.399999998797934
agent-2: 32.399999998798016
agent-3: 32.39999999879801
agent-4: 41.39999999879802
agent-5: 33.39999999879801
Extrinsic Rewards:
1
2
2
11
3
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.4421052631578947
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-39-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 321.7346465257858
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 900
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.516
    dispatch_time_ms: 8.774
    learner:
      cur_lr: 0.0010603000409901142
      grad_gnorm: 40.0
      policy_entropy: 21.219717025756836
      policy_loss: 17.95601463317871
      var_gnorm: 22.886180877685547
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 47.617977142333984
    num_steps_sampled: 4505000
    num_steps_trained: 4505000
    wait_time_ms: 76.232
  iterations_since_restore: 901
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7858.158386230469
  time_this_iter_s: 8.795709609985352
  time_total_s: 7858.158386230469
  timestamp: 1594856380
  timesteps_since_restore: 4505000
  timesteps_this_iter: 5000
  timesteps_total: 4505000
  training_iteration: 901
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7858 s, 901 iter, 4505000 ts, 322 rew

agent-1: 35.9999999991301
agent-2: 35.9999999991301
agent-3: 36.99999999913009
agent-4: 32.99999999913009
agent-5: 37.99999999913008
Extrinsic Rewards:
4
4
5
1
6
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.22
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-39-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 320.2046465266876
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 901
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.818
    dispatch_time_ms: 7.855
    learner:
      cur_lr: 0.0010599669767543674
      grad_gnorm: 31.608306884765625
      policy_entropy: 22.086788177490234
      policy_loss: -2.288052558898926
      var_gnorm: 22.88445281982422
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.6979398131370544
    num_steps_sampled: 4510000
    num_steps_trained: 4510000
    wait_time_ms: 75.912
  iterations_since_restore: 902
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7866.722799539566
  time_this_iter_s: 8.56441330909729
  time_total_s: 7866.722799539566
  timestamp: 1594856389
  timesteps_since_restore: 4510000
  timesteps_this_iter: 5000
  timesteps_total: 4510000
  training_iteration: 902
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7866 s, 902 iter, 4510000 ts, 320 rew

agent-1: 67.79999981417104
agent-2: 63.79999981417116
agent-3: 73.7999998141711
agent-4: 64.79999981417109
agent-5: 71.79999981417106
Extrinsic Rewards:
7
3
13
4
11
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.28421052631578947
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-39-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 321.64464651746096
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 902
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.57
    dispatch_time_ms: 6.031
    learner:
      cur_lr: 0.0010596340289339423
      grad_gnorm: 40.0
      policy_entropy: 5.337992191314697
      policy_loss: 9.61563777923584
      var_gnorm: 22.887001037597656
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 29.229564666748047
    num_steps_sampled: 4515000
    num_steps_trained: 4515000
    wait_time_ms: 80.06
  iterations_since_restore: 903
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7875.481977701187
  time_this_iter_s: 8.759178161621094
  time_total_s: 7875.481977701187
  timestamp: 1594856398
  timesteps_since_restore: 4515000
  timesteps_this_iter: 5000
  timesteps_total: 4515000
  training_iteration: 903
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7875 s, 903 iter, 4515000 ts, 322 rew

agent-1: 53.19999999418891
agent-2: 62.19999999418891
agent-3: 51.19999999418891
agent-4: 57.19999999418891
agent-5: 64.19999999418884
Extrinsic Rewards:
2
11
0
6
13
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.4375
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-40-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 322.3646465172364
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 903
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 9.414
    learner:
      cur_lr: 0.0010593009646981955
      grad_gnorm: 40.0
      policy_entropy: 25.57638168334961
      policy_loss: 5.896235466003418
      var_gnorm: 22.896329879760742
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.225780725479126
    num_steps_sampled: 4520000
    num_steps_trained: 4520000
    wait_time_ms: 74.912
  iterations_since_restore: 904
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7883.963102817535
  time_this_iter_s: 8.481125116348267
  time_total_s: 7883.963102817535
  timestamp: 1594856406
  timesteps_since_restore: 4520000
  timesteps_this_iter: 5000
  timesteps_total: 4520000
  training_iteration: 904
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7883 s, 904 iter, 4520000 ts, 322 rew

agent-1: 148.79883488605077
agent-2: 148.79883488605074
agent-3: 144.7988348860507
agent-4: 154.79883488605074
agent-5: 149.79883488605077
Extrinsic Rewards:
16
16
12
22
17
Sum Reward: 83
Avg Reward: 16.6
Min Reward: 12
Max Reward: 22
Gini Coefficient: 0.10120481927710843
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-40-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 328.2145882615772
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 904
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.929
    dispatch_time_ms: 8.516
    learner:
      cur_lr: 0.0010589680168777704
      grad_gnorm: 40.0
      policy_entropy: 18.25037956237793
      policy_loss: 17.401569366455078
      var_gnorm: 22.88546371459961
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 25.30933380126953
    num_steps_sampled: 4525000
    num_steps_trained: 4525000
    wait_time_ms: 76.825
  iterations_since_restore: 905
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7892.698894023895
  time_this_iter_s: 8.735791206359863
  time_total_s: 7892.698894023895
  timestamp: 1594856415
  timesteps_since_restore: 4525000
  timesteps_this_iter: 5000
  timesteps_total: 4525000
  training_iteration: 905
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7892 s, 905 iter, 4525000 ts, 328 rew

agent-1: 92.7999918613378
agent-2: 93.79999186133783
agent-3: 96.79999186133783
agent-4: 97.79999186133783
agent-5: 95.7999918613378
Extrinsic Rewards:
8
9
12
13
11
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 8
Max Reward: 13
Gini Coefficient: 0.09811320754716982
20:20 Ratio: 1.625
Max-min Ratio: 1.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-40-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 330.8245878547017
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 905
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.011
    dispatch_time_ms: 28.508
    learner:
      cur_lr: 0.0010586349526420236
      grad_gnorm: 40.00000762939453
      policy_entropy: 27.6461124420166
      policy_loss: 27.92523193359375
      var_gnorm: 22.886507034301758
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 59.02006912231445
    num_steps_sampled: 4530000
    num_steps_trained: 4530000
    wait_time_ms: 63.04
  iterations_since_restore: 906
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7901.683001279831
  time_this_iter_s: 8.984107255935669
  time_total_s: 7901.683001279831
  timestamp: 1594856424
  timesteps_since_restore: 4530000
  timesteps_this_iter: 5000
  timesteps_total: 4530000
  training_iteration: 906
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7901 s, 906 iter, 4530000 ts, 331 rew

agent-1: 107.39999879715324
agent-2: 101.39999879715323
agent-3: 103.39999879715324
agent-4: 110.39999879715326
agent-5: 108.39999879715326
Extrinsic Rewards:
13
7
9
16
14
Sum Reward: 59
Avg Reward: 11.8
Min Reward: 7
Max Reward: 16
Gini Coefficient: 0.15593220338983052
20:20 Ratio: 2.2857142857142856
Max-min Ratio: 2.2857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-40-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 333.8845877947208
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 906
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 28.946
    learner:
      cur_lr: 0.0010583020048215985
      grad_gnorm: 10.150686264038086
      policy_entropy: 0.902175784111023
      policy_loss: -0.010149194858968258
      var_gnorm: 22.89225196838379
      vf_explained_var: 0.0
      vf_loss: 0.07978588342666626
    num_steps_sampled: 4535000
    num_steps_trained: 4535000
    wait_time_ms: 55.741
  iterations_since_restore: 907
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7910.760959863663
  time_this_iter_s: 9.077958583831787
  time_total_s: 7910.760959863663
  timestamp: 1594856433
  timesteps_since_restore: 4535000
  timesteps_this_iter: 5000
  timesteps_total: 4535000
  training_iteration: 907
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7910 s, 907 iter, 4535000 ts, 334 rew

agent-1: 87.19999952384022
agent-2: 93.19999952384022
agent-3: 76.19999952384022
agent-4: 83.19999952384023
agent-5: 83.19999952384022
Extrinsic Rewards:
12
18
1
8
8
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 1
Max Reward: 18
Gini Coefficient: 0.32340425531914896
20:20 Ratio: 18.0
Max-min Ratio: 18.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-40-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 336.40458777098235
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 907
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 22.639
    learner:
      cur_lr: 0.0010579690570011735
      grad_gnorm: 16.724143981933594
      policy_entropy: 0.9826597571372986
      policy_loss: 0.014241358265280724
      var_gnorm: 22.892728805541992
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.2220793217420578
    num_steps_sampled: 4540000
    num_steps_trained: 4540000
    wait_time_ms: 56.331
  iterations_since_restore: 908
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7919.26834654808
  time_this_iter_s: 8.507386684417725
  time_total_s: 7919.26834654808
  timestamp: 1594856442
  timesteps_since_restore: 4540000
  timesteps_this_iter: 5000
  timesteps_total: 4540000
  training_iteration: 908
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7919 s, 908 iter, 4540000 ts, 336 rew

agent-1: 3.193236324075642
agent-2: 3.193236324075642
agent-3: 4.193236324075642
agent-4: 4.193236324075641
agent-5: 3.193236324075642
Extrinsic Rewards:
0
0
1
1
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.6
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-40-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 333.97424958725816
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 908
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.016
    dispatch_time_ms: 36.486
    learner:
      cur_lr: 0.0010576359927654266
      grad_gnorm: 4.170536994934082
      policy_entropy: 1.9087448120117188
      policy_loss: 0.0053408946841955185
      var_gnorm: 22.891502380371094
      vf_explained_var: 0.0
      vf_loss: 0.01346864178776741
    num_steps_sampled: 4545000
    num_steps_trained: 4545000
    wait_time_ms: 51.393
  iterations_since_restore: 909
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7927.810259342194
  time_this_iter_s: 8.54191279411316
  time_total_s: 7927.810259342194
  timestamp: 1594856450
  timesteps_since_restore: 4545000
  timesteps_this_iter: 5000
  timesteps_total: 4545000
  training_iteration: 909
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7927 s, 909 iter, 4545000 ts, 334 rew

agent-1: 3.1947048987318376
agent-2: 3.1947048987318376
agent-3: 3.1947048987318376
agent-4: 5.19470489873184
agent-5: 3.1947048987318376
Extrinsic Rewards:
0
0
0
2
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-40-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 330.91398483378435
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 909
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.573
    dispatch_time_ms: 51.921
    learner:
      cur_lr: 0.0010573030449450016
      grad_gnorm: 0.44535690546035767
      policy_entropy: 2.281881809234619
      policy_loss: -0.007818765938282013
      var_gnorm: 22.891986846923828
      vf_explained_var: 0.0
      vf_loss: 0.000319766259053722
    num_steps_sampled: 4550000
    num_steps_trained: 4550000
    wait_time_ms: 41.329
  iterations_since_restore: 910
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7936.436800479889
  time_this_iter_s: 8.626541137695312
  time_total_s: 7936.436800479889
  timestamp: 1594856459
  timesteps_since_restore: 4550000
  timesteps_this_iter: 5000
  timesteps_total: 4550000
  training_iteration: 910
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7936 s, 910 iter, 4550000 ts, 331 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-41-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 326.9539849753918
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 910
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 51.353
    learner:
      cur_lr: 0.0010569699807092547
      grad_gnorm: 31.97286605834961
      policy_entropy: 8.64892578125
      policy_loss: 0.545074999332428
      var_gnorm: 22.888580322265625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.9819875955581665
    num_steps_sampled: 4555000
    num_steps_trained: 4555000
    wait_time_ms: 42.503
  iterations_since_restore: 911
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7944.740022420883
  time_this_iter_s: 8.303221940994263
  time_total_s: 7944.740022420883
  timestamp: 1594856467
  timesteps_since_restore: 4555000
  timesteps_this_iter: 5000
  timesteps_total: 4555000
  training_iteration: 911
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7944 s, 911 iter, 4555000 ts, 327 rew

agent-1: 29.10189538560655
agent-2: 19.10189538560655
agent-3: 22.10189538560655
agent-4: 21.101895385606554
agent-5: 19.10189538560655
Extrinsic Rewards:
10
0
3
2
0
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.6133333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-41-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 324.2790797591269
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 911
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.716
    dispatch_time_ms: 30.771
    learner:
      cur_lr: 0.0010566370328888297
      grad_gnorm: 40.0
      policy_entropy: 31.60919952392578
      policy_loss: 6.514858245849609
      var_gnorm: 22.885547637939453
      vf_explained_var: 0.0
      vf_loss: 2.205310583114624
    num_steps_sampled: 4560000
    num_steps_trained: 4560000
    wait_time_ms: 57.022
  iterations_since_restore: 912
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7953.205327987671
  time_this_iter_s: 8.46530556678772
  time_total_s: 7953.205327987671
  timestamp: 1594856476
  timesteps_since_restore: 4560000
  timesteps_this_iter: 5000
  timesteps_total: 4560000
  training_iteration: 912
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7953 s, 912 iter, 4560000 ts, 324 rew

agent-1: 104.90865830178544
agent-2: 117.90865830178545
agent-3: 109.90865830178544
agent-4: 115.90865830178544
agent-5: 127.90865830178545
Extrinsic Rewards:
3
16
8
14
26
Sum Reward: 67
Avg Reward: 13.4
Min Reward: 3
Max Reward: 26
Gini Coefficient: 0.32238805970149254
20:20 Ratio: 8.666666666666666
Max-min Ratio: 8.666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-41-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 328.424512674247
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 912
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.768
    dispatch_time_ms: 28.626
    learner:
      cur_lr: 0.0010563039686530828
      grad_gnorm: 40.0
      policy_entropy: 18.41570472717285
      policy_loss: 10.457635879516602
      var_gnorm: 22.87110710144043
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 18.059072494506836
    num_steps_sampled: 4565000
    num_steps_trained: 4565000
    wait_time_ms: 63.179
  iterations_since_restore: 913
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7962.20210146904
  time_this_iter_s: 8.996773481369019
  time_total_s: 7962.20210146904
  timestamp: 1594856485
  timesteps_since_restore: 4565000
  timesteps_this_iter: 5000
  timesteps_total: 4565000
  training_iteration: 913
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7962 s, 913 iter, 4565000 ts, 328 rew

agent-1: 85.59999926529592
agent-2: 99.59999926529593
agent-3: 90.59999926529593
agent-4: 89.59999926529593
agent-5: 93.59999926529595
Extrinsic Rewards:
4
18
9
8
12
Sum Reward: 51
Avg Reward: 10.2
Min Reward: 4
Max Reward: 18
Gini Coefficient: 0.25098039215686274
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-41-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 329.594512638491
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 913
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.087
    dispatch_time_ms: 33.025
    learner:
      cur_lr: 0.0010559710208326578
      grad_gnorm: 40.0
      policy_entropy: 19.174470901489258
      policy_loss: 22.05052947998047
      var_gnorm: 22.882566452026367
      vf_explained_var: 0.0
      vf_loss: 54.49924087524414
    num_steps_sampled: 4570000
    num_steps_trained: 4570000
    wait_time_ms: 33.232
  iterations_since_restore: 914
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7972.310764074326
  time_this_iter_s: 10.108662605285645
  time_total_s: 7972.310764074326
  timestamp: 1594856495
  timesteps_since_restore: 4570000
  timesteps_this_iter: 5000
  timesteps_total: 4570000
  training_iteration: 914
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7972 s, 914 iter, 4570000 ts, 330 rew

agent-1: 222.62642479097232
agent-2: 206.62642479097232
agent-3: 219.6264247909724
agent-4: 235.62642479097238
agent-5: 221.62642479097232
Extrinsic Rewards:
26
10
23
39
25
Sum Reward: 123
Avg Reward: 24.6
Min Reward: 10
Max Reward: 39
Gini Coefficient: 0.1983739837398374
20:20 Ratio: 3.9
Max-min Ratio: 3.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-41-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 338.31583387814163
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 914
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.875
    dispatch_time_ms: 8.389
    learner:
      cur_lr: 0.001055637956596911
      grad_gnorm: 39.999996185302734
      policy_entropy: 26.918363571166992
      policy_loss: -8.441482543945312
      var_gnorm: 22.86568260192871
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.550257444381714
    num_steps_sampled: 4575000
    num_steps_trained: 4575000
    wait_time_ms: 74.56
  iterations_since_restore: 915
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7980.9947991371155
  time_this_iter_s: 8.684035062789917
  time_total_s: 7980.9947991371155
  timestamp: 1594856504
  timesteps_since_restore: 4575000
  timesteps_this_iter: 5000
  timesteps_total: 4575000
  training_iteration: 915
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7980 s, 915 iter, 4575000 ts, 338 rew

agent-1: 54.79999999059639
agent-2: 68.7999999905964
agent-3: 60.79999999059639
agent-4: 55.79999999059639
agent-5: 56.79999999059639
Extrinsic Rewards:
2
16
8
3
4
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.4
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-41-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 339.03583387777996
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 915
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.601
    dispatch_time_ms: 9.263
    learner:
      cur_lr: 0.001055305008776486
      grad_gnorm: 1.0181665420532227
      policy_entropy: 34.5359992980957
      policy_loss: 0.17085182666778564
      var_gnorm: 22.8552303314209
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0019382578320801258
    num_steps_sampled: 4580000
    num_steps_trained: 4580000
    wait_time_ms: 71.653
  iterations_since_restore: 916
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7989.590430259705
  time_this_iter_s: 8.595631122589111
  time_total_s: 7989.590430259705
  timestamp: 1594856512
  timesteps_since_restore: 4580000
  timesteps_this_iter: 5000
  timesteps_total: 4580000
  training_iteration: 916
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7989 s, 916 iter, 4580000 ts, 339 rew

agent-1: 41.39999998960025
agent-2: 44.399999989600246
agent-3: 42.399999989600246
agent-4: 43.39999998960024
agent-5: 44.39999998960024
Extrinsic Rewards:
3
6
4
5
6
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 3
Max Reward: 6
Gini Coefficient: 0.13333333333333333
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-42-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 335.25583420888603
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 916
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.034
    dispatch_time_ms: 9.276
    learner:
      cur_lr: 0.001054971944540739
      grad_gnorm: 40.0
      policy_entropy: 28.416776657104492
      policy_loss: 45.1937255859375
      var_gnorm: 22.854555130004883
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 106.58643341064453
    num_steps_sampled: 4585000
    num_steps_trained: 4585000
    wait_time_ms: 75.052
  iterations_since_restore: 917
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 7998.324294090271
  time_this_iter_s: 8.733863830566406
  time_total_s: 7998.324294090271
  timestamp: 1594856521
  timesteps_since_restore: 4585000
  timesteps_this_iter: 5000
  timesteps_total: 4585000
  training_iteration: 917
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 7998 s, 917 iter, 4585000 ts, 335 rew

agent-1: 47.79999998320983
agent-2: 52.799999983209844
agent-3: 50.79999998320982
agent-4: 51.79999998320982
agent-5: 48.79999998320982
Extrinsic Rewards:
3
8
6
7
4
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 3
Max Reward: 8
Gini Coefficient: 0.18571428571428572
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-42-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 333.5458342181547
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 917
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.363
    dispatch_time_ms: 8.749
    learner:
      cur_lr: 0.001054638996720314
      grad_gnorm: 21.726768493652344
      policy_entropy: 29.90530014038086
      policy_loss: -3.240114688873291
      var_gnorm: 22.854663848876953
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.36289241909980774
    num_steps_sampled: 4590000
    num_steps_trained: 4590000
    wait_time_ms: 75.414
  iterations_since_restore: 918
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8006.986043453217
  time_this_iter_s: 8.661749362945557
  time_total_s: 8006.986043453217
  timestamp: 1594856530
  timesteps_since_restore: 4590000
  timesteps_this_iter: 5000
  timesteps_total: 4590000
  training_iteration: 918
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8006 s, 918 iter, 4590000 ts, 334 rew

agent-1: 88.39999995313536
agent-2: 80.39999995313536
agent-3: 78.39999995313534
agent-4: 97.39999995313534
agent-5: 96.39999995313534
Extrinsic Rewards:
10
2
0
19
18
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 0
Max Reward: 19
Gini Coefficient: 0.44081632653061226
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-42-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 331.9258342642362
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 918
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.306
    dispatch_time_ms: 8.345
    learner:
      cur_lr: 0.001054306048899889
      grad_gnorm: 40.0
      policy_entropy: 22.09601593017578
      policy_loss: 5.469997882843018
      var_gnorm: 22.855119705200195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.607067584991455
    num_steps_sampled: 4595000
    num_steps_trained: 4595000
    wait_time_ms: 76.743
  iterations_since_restore: 919
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8015.665899038315
  time_this_iter_s: 8.679855585098267
  time_total_s: 8015.665899038315
  timestamp: 1594856538
  timesteps_since_restore: 4595000
  timesteps_this_iter: 5000
  timesteps_total: 4595000
  training_iteration: 919
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8015 s, 919 iter, 4595000 ts, 332 rew

agent-1: 39.399999997793294
agent-2: 46.399999997793266
agent-3: 40.39999999779329
agent-4: 43.39999999779327
agent-5: 46.39999999779327
Extrinsic Rewards:
1
8
2
5
8
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.3333333333333333
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-42-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 331.475834264733
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 919
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.725
    dispatch_time_ms: 6.849
    learner:
      cur_lr: 0.0010539729846641421
      grad_gnorm: 21.66615867614746
      policy_entropy: 25.813617706298828
      policy_loss: -2.993746519088745
      var_gnorm: 22.85521125793457
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.3606123924255371
    num_steps_sampled: 4600000
    num_steps_trained: 4600000
    wait_time_ms: 80.84
  iterations_since_restore: 920
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8024.391318559647
  time_this_iter_s: 8.725419521331787
  time_total_s: 8024.391318559647
  timestamp: 1594856547
  timesteps_since_restore: 4600000
  timesteps_this_iter: 5000
  timesteps_total: 4600000
  training_iteration: 920
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8024 s, 920 iter, 4600000 ts, 331 rew

agent-1: 58.799999994635805
agent-2: 61.799999994635805
agent-3: 54.79999999463582
agent-4: 65.79999999463583
agent-5: 55.79999999463582
Extrinsic Rewards:
6
9
2
13
3
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.3393939393939394
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-42-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 332.82583426458507
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 920
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.49
    dispatch_time_ms: 10.894
    learner:
      cur_lr: 0.001053640036843717
      grad_gnorm: 40.000003814697266
      policy_entropy: 34.25326919555664
      policy_loss: 32.776912689208984
      var_gnorm: 22.854814529418945
      vf_explained_var: 0.0
      vf_loss: 29.464441299438477
    num_steps_sampled: 4605000
    num_steps_trained: 4605000
    wait_time_ms: 72.912
  iterations_since_restore: 921
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8033.015372276306
  time_this_iter_s: 8.624053716659546
  time_total_s: 8033.015372276306
  timestamp: 1594856556
  timesteps_since_restore: 4605000
  timesteps_this_iter: 5000
  timesteps_total: 4605000
  training_iteration: 921
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8033 s, 921 iter, 4605000 ts, 333 rew

agent-1: 64.99999999301626
agent-2: 64.99999999301626
agent-3: 62.99999999301639
agent-4: 57.999999993016374
agent-5: 63.999999993016374
Extrinsic Rewards:
9
9
7
2
8
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.18285714285714286
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-42-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 331.6558342762692
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 921
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.931
    dispatch_time_ms: 10.588
    learner:
      cur_lr: 0.0010533069726079702
      grad_gnorm: 23.69101905822754
      policy_entropy: 33.5557975769043
      policy_loss: -4.154910564422607
      var_gnorm: 22.854766845703125
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.3839564621448517
    num_steps_sampled: 4610000
    num_steps_trained: 4610000
    wait_time_ms: 73.52
  iterations_since_restore: 922
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8041.596794366837
  time_this_iter_s: 8.581422090530396
  time_total_s: 8041.596794366837
  timestamp: 1594856565
  timesteps_since_restore: 4610000
  timesteps_this_iter: 5000
  timesteps_total: 4610000
  training_iteration: 922
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8041 s, 922 iter, 4610000 ts, 332 rew

agent-1: 74.99999990647869
agent-2: 65.99999990647875
agent-3: 69.99999990647873
agent-4: 79.99999990647865
agent-5: 68.99999990647875
Extrinsic Rewards:
11
2
6
16
5
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.34
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-42-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 330.1258346580767
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 922
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.095
    dispatch_time_ms: 8.331
    learner:
      cur_lr: 0.0010529740247875452
      grad_gnorm: 14.032752990722656
      policy_entropy: 31.82027816772461
      policy_loss: -1.9852982759475708
      var_gnorm: 22.855466842651367
      vf_explained_var: 0.0
      vf_loss: 0.15202926099300385
    num_steps_sampled: 4615000
    num_steps_trained: 4615000
    wait_time_ms: 74.272
  iterations_since_restore: 923
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8050.150616407394
  time_this_iter_s: 8.553822040557861
  time_total_s: 8050.150616407394
  timestamp: 1594856573
  timesteps_since_restore: 4615000
  timesteps_this_iter: 5000
  timesteps_total: 4615000
  training_iteration: 923
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8050 s, 923 iter, 4615000 ts, 330 rew

agent-1: 52.39999999818208
agent-2: 50.39999999818208
agent-3: 49.39999999818208
agent-4: 53.39999999818208
agent-5: 55.39999999818208
Extrinsic Rewards:
6
4
3
7
9
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.20689655172413793
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-43-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 328.32583465992997
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 923
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.052
    dispatch_time_ms: 8.225
    learner:
      cur_lr: 0.0010526409605517983
      grad_gnorm: 20.048137664794922
      policy_entropy: 31.156124114990234
      policy_loss: -3.0514943599700928
      var_gnorm: 22.855382919311523
      vf_explained_var: 0.0
      vf_loss: 0.3107852637767792
    num_steps_sampled: 4620000
    num_steps_trained: 4620000
    wait_time_ms: 74.23
  iterations_since_restore: 924
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8058.741764307022
  time_this_iter_s: 8.591147899627686
  time_total_s: 8058.741764307022
  timestamp: 1594856582
  timesteps_since_restore: 4620000
  timesteps_this_iter: 5000
  timesteps_total: 4620000
  training_iteration: 924
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8058 s, 924 iter, 4620000 ts, 328 rew

agent-1: 36.79999999870662
agent-2: 41.79999999870662
agent-3: 42.79999999870663
agent-4: 43.79999999870662
agent-5: 41.79999999870663
Extrinsic Rewards:
0
5
6
7
5
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.2608695652173913
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-43-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 324.3658355764364
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 924
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.458
    dispatch_time_ms: 10.331
    learner:
      cur_lr: 0.0010523080127313733
      grad_gnorm: 40.0
      policy_entropy: 30.394153594970703
      policy_loss: 26.21761131286621
      var_gnorm: 22.85563850402832
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 22.738149642944336
    num_steps_sampled: 4625000
    num_steps_trained: 4625000
    wait_time_ms: 72.732
  iterations_since_restore: 925
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8067.274703502655
  time_this_iter_s: 8.532939195632935
  time_total_s: 8067.274703502655
  timestamp: 1594856590
  timesteps_since_restore: 4625000
  timesteps_this_iter: 5000
  timesteps_total: 4625000
  training_iteration: 925
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8067 s, 925 iter, 4625000 ts, 324 rew

agent-1: 67.19999999414195
agent-2: 64.199999994142
agent-3: 69.19999999414195
agent-4: 60.199999994141855
agent-5: 72.19999999414196
Extrinsic Rewards:
8
5
10
1
13
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.31351351351351353
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-43-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 323.1958355810803
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 925
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.754
    dispatch_time_ms: 8.963
    learner:
      cur_lr: 0.0010519749484956264
      grad_gnorm: 28.502033233642578
      policy_entropy: 33.02992630004883
      policy_loss: -4.395046710968018
      var_gnorm: 22.855756759643555
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.6147477030754089
    num_steps_sampled: 4630000
    num_steps_trained: 4630000
    wait_time_ms: 74.816
  iterations_since_restore: 926
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8075.814955949783
  time_this_iter_s: 8.540252447128296
  time_total_s: 8075.814955949783
  timestamp: 1594856599
  timesteps_since_restore: 4630000
  timesteps_this_iter: 5000
  timesteps_total: 4630000
  training_iteration: 926
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8075 s, 926 iter, 4630000 ts, 323 rew

agent-1: 54.599999930784925
agent-2: 60.5999999307849
agent-3: 51.59999993078493
agent-4: 53.59999993078492
agent-5: 58.599999930784925
Extrinsic Rewards:
5
11
2
4
9
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.2967741935483871
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-43-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 322.385835578804
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 926
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 6.55
    learner:
      cur_lr: 0.0010516420006752014
      grad_gnorm: 17.22551727294922
      policy_entropy: 28.437013626098633
      policy_loss: -2.368377923965454
      var_gnorm: 22.855655670166016
      vf_explained_var: 0.0
      vf_loss: 0.22803734242916107
    num_steps_sampled: 4635000
    num_steps_trained: 4635000
    wait_time_ms: 79.573
  iterations_since_restore: 927
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8084.415572881699
  time_this_iter_s: 8.600616931915283
  time_total_s: 8084.415572881699
  timestamp: 1594856608
  timesteps_since_restore: 4635000
  timesteps_this_iter: 5000
  timesteps_total: 4635000
  training_iteration: 927
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8084 s, 927 iter, 4635000 ts, 322 rew

agent-1: 58.59999995402355
agent-2: 64.59999995402372
agent-3: 69.59999995402369
agent-4: 65.59999995402372
agent-5: 65.59999995402367
Extrinsic Rewards:
1
7
12
8
8
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.25555555555555554
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-43-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 322.92583557662783
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 927
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.218
    dispatch_time_ms: 6.944
    learner:
      cur_lr: 0.0010513090528547764
      grad_gnorm: 30.5185604095459
      policy_entropy: 32.47053909301758
      policy_loss: -5.046154975891113
      var_gnorm: 22.855865478515625
      vf_explained_var: 0.0
      vf_loss: 0.6814596652984619
    num_steps_sampled: 4640000
    num_steps_trained: 4640000
    wait_time_ms: 80.668
  iterations_since_restore: 928
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8093.017101764679
  time_this_iter_s: 8.601528882980347
  time_total_s: 8093.017101764679
  timestamp: 1594856616
  timesteps_since_restore: 4640000
  timesteps_this_iter: 5000
  timesteps_total: 4640000
  training_iteration: 928
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8093 s, 928 iter, 4640000 ts, 323 rew

agent-1: 77.39999989687823
agent-2: 78.39999989687823
agent-3: 83.39999989687823
agent-4: 78.39999989687823
agent-5: 78.39999989687823
Extrinsic Rewards:
7
8
13
8
8
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 7
Max Reward: 13
Gini Coefficient: 0.10909090909090909
20:20 Ratio: 1.8571428571428572
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-43-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 323.0158356765311
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 928
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 9.225
    learner:
      cur_lr: 0.0010509759886190295
      grad_gnorm: 33.335296630859375
      policy_entropy: 34.40238952636719
      policy_loss: 5.9081711769104
      var_gnorm: 22.855504989624023
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.8886445760726929
    num_steps_sampled: 4645000
    num_steps_trained: 4645000
    wait_time_ms: 74.069
  iterations_since_restore: 929
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8101.534735441208
  time_this_iter_s: 8.51763367652893
  time_total_s: 8101.534735441208
  timestamp: 1594856625
  timesteps_since_restore: 4645000
  timesteps_this_iter: 5000
  timesteps_total: 4645000
  training_iteration: 929
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8101 s, 929 iter, 4645000 ts, 323 rew

agent-1: 64.59999995961144
agent-2: 69.59999995961141
agent-3: 62.59999995961129
agent-4: 67.59999995961138
agent-5: 59.599999959611274
Extrinsic Rewards:
7
12
5
10
2
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.2777777777777778
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-43-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 324.4558356745516
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 929
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 8.662
    learner:
      cur_lr: 0.0010506430407986045
      grad_gnorm: 20.959115982055664
      policy_entropy: 27.66933822631836
      policy_loss: -3.21903920173645
      var_gnorm: 22.85564422607422
      vf_explained_var: 0.0
      vf_loss: 0.33166372776031494
    num_steps_sampled: 4650000
    num_steps_trained: 4650000
    wait_time_ms: 75.224
  iterations_since_restore: 930
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8110.102182626724
  time_this_iter_s: 8.567447185516357
  time_total_s: 8110.102182626724
  timestamp: 1594856633
  timesteps_since_restore: 4650000
  timesteps_this_iter: 5000
  timesteps_total: 4650000
  training_iteration: 930
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8110 s, 930 iter, 4650000 ts, 324 rew

agent-1: 48.59999999654013
agent-2: 45.59999999654012
agent-3: 44.59999999654013
agent-4: 53.59999999654012
agent-5: 41.59999999654013
Extrinsic Rewards:
7
4
3
12
0
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.4307692307692308
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-44-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 318.33583934989036
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 930
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.67
    dispatch_time_ms: 7.633
    learner:
      cur_lr: 0.0010503099765628576
      grad_gnorm: 15.392722129821777
      policy_entropy: 26.01690101623535
      policy_loss: -1.771077275276184
      var_gnorm: 22.85594367980957
      vf_explained_var: 0.0
      vf_loss: 0.18088196218013763
    num_steps_sampled: 4655000
    num_steps_trained: 4655000
    wait_time_ms: 72.723
  iterations_since_restore: 931
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8118.774396657944
  time_this_iter_s: 8.672214031219482
  time_total_s: 8118.774396657944
  timestamp: 1594856642
  timesteps_since_restore: 4655000
  timesteps_this_iter: 5000
  timesteps_total: 4655000
  training_iteration: 931
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8118 s, 931 iter, 4655000 ts, 318 rew

agent-1: 55.999999994965066
agent-2: 56.99999999496508
agent-3: 47.999999994965066
agent-4: 56.999999994965066
agent-5: 51.99999999496508
Extrinsic Rewards:
8
9
0
9
4
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.30666666666666664
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-44-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 317.88583935013975
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 931
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.629
    dispatch_time_ms: 7.839
    learner:
      cur_lr: 0.0010499770287424326
      grad_gnorm: 16.40863037109375
      policy_entropy: 23.376848220825195
      policy_loss: -2.047555446624756
      var_gnorm: 22.856237411499023
      vf_explained_var: 0.0
      vf_loss: 0.20731444656848907
    num_steps_sampled: 4660000
    num_steps_trained: 4660000
    wait_time_ms: 76.594
  iterations_since_restore: 932
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8127.4804582595825
  time_this_iter_s: 8.706061601638794
  time_total_s: 8127.4804582595825
  timestamp: 1594856651
  timesteps_since_restore: 4660000
  timesteps_this_iter: 5000
  timesteps_total: 4660000
  training_iteration: 932
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8127 s, 932 iter, 4660000 ts, 318 rew

agent-1: 49.99999999886432
agent-2: 45.999999998864325
agent-3: 39.99999999886432
agent-4: 48.99999999886432
agent-5: 39.99999999886432
Extrinsic Rewards:
10
6
0
9
0
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.464
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-44-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 315.995839528401
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 932
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 7.3
    learner:
      cur_lr: 0.0010496439645066857
      grad_gnorm: 7.951105117797852
      policy_entropy: 31.677997589111328
      policy_loss: -1.1702550649642944
      var_gnorm: 22.855979919433594
      vf_explained_var: 0.0
      vf_loss: 0.04687177762389183
    num_steps_sampled: 4665000
    num_steps_trained: 4665000
    wait_time_ms: 79.066
  iterations_since_restore: 933
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8136.090738773346
  time_this_iter_s: 8.610280513763428
  time_total_s: 8136.090738773346
  timestamp: 1594856659
  timesteps_since_restore: 4665000
  timesteps_this_iter: 5000
  timesteps_total: 4665000
  training_iteration: 933
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8136 s, 933 iter, 4665000 ts, 316 rew

agent-1: 34.99999998362867
agent-2: 32.999999983628705
agent-3: 43.999999983628705
agent-4: 34.99999998362867
agent-5: 32.999999983628705
Extrinsic Rewards:
3
1
12
3
1
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.48
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-44-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 315.1858395279143
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 933
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 6.221
    learner:
      cur_lr: 0.0010493110166862607
      grad_gnorm: 22.711162567138672
      policy_entropy: 20.648374557495117
      policy_loss: -1.5956120491027832
      var_gnorm: 22.856733322143555
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.38876667618751526
    num_steps_sampled: 4670000
    num_steps_trained: 4670000
    wait_time_ms: 82.767
  iterations_since_restore: 934
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8144.755905866623
  time_this_iter_s: 8.665167093276978
  time_total_s: 8144.755905866623
  timestamp: 1594856668
  timesteps_since_restore: 4670000
  timesteps_this_iter: 5000
  timesteps_total: 4670000
  training_iteration: 934
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8144 s, 934 iter, 4670000 ts, 315 rew

agent-1: 27.199999999424374
agent-2: 34.19999999942444
agent-3: 30.199999999424374
agent-4: 32.199999999424406
agent-5: 29.199999999424374
Extrinsic Rewards:
0
7
3
5
2
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-44-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 310.77584134581844
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 934
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.438
    dispatch_time_ms: 8.685
    learner:
      cur_lr: 0.0010489779524505138
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.576501846313477
      policy_loss: 36.350128173828125
      var_gnorm: 22.8574275970459
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 154.0416259765625
    num_steps_sampled: 4675000
    num_steps_trained: 4675000
    wait_time_ms: 75.853
  iterations_since_restore: 935
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8153.357478380203
  time_this_iter_s: 8.601572513580322
  time_total_s: 8153.357478380203
  timestamp: 1594856677
  timesteps_since_restore: 4675000
  timesteps_this_iter: 5000
  timesteps_total: 4675000
  training_iteration: 935
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8153 s, 935 iter, 4675000 ts, 311 rew

agent-1: 80.59999977547199
agent-2: 81.59999977547199
agent-3: 84.599999775472
agent-4: 85.59999977547197
agent-5: 81.599999775472
Extrinsic Rewards:
7
8
11
12
8
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 7
Max Reward: 12
Gini Coefficient: 0.11304347826086956
20:20 Ratio: 1.7142857142857142
Max-min Ratio: 1.7142857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-44-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 312.5758413349178
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 935
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.013
    dispatch_time_ms: 9.72
    learner:
      cur_lr: 0.0010486450046300888
      grad_gnorm: 39.999996185302734
      policy_entropy: 29.460315704345703
      policy_loss: -7.088929653167725
      var_gnorm: 22.86235237121582
      vf_explained_var: 0.0
      vf_loss: 2.53957462310791
    num_steps_sampled: 4680000
    num_steps_trained: 4680000
    wait_time_ms: 73.415
  iterations_since_restore: 936
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8162.0465478897095
  time_this_iter_s: 8.689069509506226
  time_total_s: 8162.0465478897095
  timestamp: 1594856686
  timesteps_since_restore: 4680000
  timesteps_this_iter: 5000
  timesteps_total: 4680000
  training_iteration: 936
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8162 s, 936 iter, 4680000 ts, 313 rew

agent-1: 153.9999050657413
agent-2: 157.99990506574136
agent-3: 166.9999050657413
agent-4: 166.9999050657413
agent-5: 163.9999050657413
Extrinsic Rewards:
10
14
23
23
20
Sum Reward: 90
Avg Reward: 18.0
Min Reward: 10
Max Reward: 23
Gini Coefficient: 0.15555555555555556
20:20 Ratio: 2.3
Max-min Ratio: 2.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-44-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 313.0258462540197
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 936
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.041
    dispatch_time_ms: 8.351
    learner:
      cur_lr: 0.0010483120568096638
      grad_gnorm: 28.649059295654297
      policy_entropy: 6.717901229858398
      policy_loss: 0.940230131149292
      var_gnorm: 22.859790802001953
      vf_explained_var: 0.0
      vf_loss: 0.6514827609062195
    num_steps_sampled: 4685000
    num_steps_trained: 4685000
    wait_time_ms: 69.947
  iterations_since_restore: 937
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8170.356813430786
  time_this_iter_s: 8.31026554107666
  time_total_s: 8170.356813430786
  timestamp: 1594856694
  timesteps_since_restore: 4685000
  timesteps_this_iter: 5000
  timesteps_total: 4685000
  training_iteration: 937
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8170 s, 937 iter, 4685000 ts, 313 rew

agent-1: 43.39999999732132
agent-2: 39.39999999732132
agent-3: 45.39999999732131
agent-4: 43.39999999732132
agent-5: 44.39999999732132
Extrinsic Rewards:
5
1
7
5
6
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.21666666666666667
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-45-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 311.13584626058747
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 937
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.895
    dispatch_time_ms: 8.766
    learner:
      cur_lr: 0.001047978992573917
      grad_gnorm: 40.00000762939453
      policy_entropy: 34.332763671875
      policy_loss: 34.627525329589844
      var_gnorm: 22.861108779907227
      vf_explained_var: 0.0
      vf_loss: 31.455459594726562
    num_steps_sampled: 4690000
    num_steps_trained: 4690000
    wait_time_ms: 75.619
  iterations_since_restore: 938
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8178.650408267975
  time_this_iter_s: 8.29359483718872
  time_total_s: 8178.650408267975
  timestamp: 1594856702
  timesteps_since_restore: 4690000
  timesteps_this_iter: 5000
  timesteps_total: 4690000
  training_iteration: 938
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8178 s, 938 iter, 4690000 ts, 311 rew

agent-1: 93.81664711953528
agent-2: 98.8166471195353
agent-3: 106.8166471195353
agent-4: 96.81664711953529
agent-5: 97.81664711953528
Extrinsic Rewards:
6
11
19
9
10
Sum Reward: 55
Avg Reward: 11.0
Min Reward: 6
Max Reward: 19
Gini Coefficient: 0.20363636363636364
20:20 Ratio: 3.1666666666666665
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-45-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 313.466678617219
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 938
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.029
    dispatch_time_ms: 7.868
    learner:
      cur_lr: 0.0010476460447534919
      grad_gnorm: 40.0
      policy_entropy: 32.34989929199219
      policy_loss: -7.7285943031311035
      var_gnorm: 22.858535766601562
      vf_explained_var: 0.0
      vf_loss: 1.505575180053711
    num_steps_sampled: 4695000
    num_steps_trained: 4695000
    wait_time_ms: 75.879
  iterations_since_restore: 939
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8187.204160690308
  time_this_iter_s: 8.553752422332764
  time_total_s: 8187.204160690308
  timestamp: 1594856711
  timesteps_since_restore: 4695000
  timesteps_this_iter: 5000
  timesteps_total: 4695000
  training_iteration: 939
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8187 s, 939 iter, 4695000 ts, 313 rew

agent-1: 37.99999999096378
agent-2: 32.99999999096383
agent-3: 33.99999999096381
agent-4: 37.99999999096379
agent-5: 36.99999999096379
Extrinsic Rewards:
6
1
2
6
5
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.28
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-45-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 312.83667861710785
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 939
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.851
    dispatch_time_ms: 6.901
    learner:
      cur_lr: 0.001047312980517745
      grad_gnorm: 24.56328010559082
      policy_entropy: 26.615585327148438
      policy_loss: -2.2529215812683105
      var_gnorm: 22.85822868347168
      vf_explained_var: 0.0
      vf_loss: 0.4355805218219757
    num_steps_sampled: 4700000
    num_steps_trained: 4700000
    wait_time_ms: 75.366
  iterations_since_restore: 940
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8195.709527730942
  time_this_iter_s: 8.505367040634155
  time_total_s: 8195.709527730942
  timestamp: 1594856719
  timesteps_since_restore: 4700000
  timesteps_this_iter: 5000
  timesteps_total: 4700000
  training_iteration: 940
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8195 s, 940 iter, 4700000 ts, 313 rew

agent-1: 62.199999965454815
agent-2: 57.19999996545484
agent-3: 55.19999996545483
agent-4: 54.19999996545484
agent-5: 59.19999996545484
Extrinsic Rewards:
11
6
4
3
8
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.25
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-45-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 310.766678631378
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 940
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.95
    dispatch_time_ms: 7.194
    learner:
      cur_lr: 0.00104698003269732
      grad_gnorm: 14.236526489257812
      policy_entropy: 20.413854598999023
      policy_loss: -1.8321480751037598
      var_gnorm: 22.859500885009766
      vf_explained_var: 0.0
      vf_loss: 0.1546933799982071
    num_steps_sampled: 4705000
    num_steps_trained: 4705000
    wait_time_ms: 76.612
  iterations_since_restore: 941
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8204.581379890442
  time_this_iter_s: 8.871852159500122
  time_total_s: 8204.581379890442
  timestamp: 1594856728
  timesteps_since_restore: 4705000
  timesteps_this_iter: 5000
  timesteps_total: 4705000
  training_iteration: 941
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8204 s, 941 iter, 4705000 ts, 311 rew

agent-1: 81.99999982652567
agent-2: 72.99999982652564
agent-3: 75.99999982652567
agent-4: 84.99999982652567
agent-5: 88.99999982652564
Extrinsic Rewards:
10
1
4
13
17
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 1
Max Reward: 17
Gini Coefficient: 0.36444444444444446
20:20 Ratio: 17.0
Max-min Ratio: 17.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-46-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 311.3066786285285
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 941
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.171
    dispatch_time_ms: 18.168
    learner:
      cur_lr: 0.0010466469684615731
      grad_gnorm: 10.186470031738281
      policy_entropy: 26.630922317504883
      policy_loss: 0.8755871653556824
      var_gnorm: 22.858875274658203
      vf_explained_var: 0.0
      vf_loss: 0.07008534669876099
    num_steps_sampled: 4710000
    num_steps_trained: 4710000
    wait_time_ms: 18.083
  iterations_since_restore: 942
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8242.622374296188
  time_this_iter_s: 38.04099440574646
  time_total_s: 8242.622374296188
  timestamp: 1594856766
  timesteps_since_restore: 4710000
  timesteps_this_iter: 5000
  timesteps_total: 4710000
  training_iteration: 942
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8242 s, 942 iter, 4710000 ts, 311 rew

agent-1: 32.19999999960014
agent-2: 31.199999999600134
agent-3: 28.199999999600138
agent-4: 29.199999999600138
agent-5: 32.19999999960014
Extrinsic Rewards:
5
4
1
2
5
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 5
Gini Coefficient: 0.25882352941176473
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-46-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 310.49667862905
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 942
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.608
    dispatch_time_ms: 9.46
    learner:
      cur_lr: 0.001046314020641148
      grad_gnorm: 6.270570278167725
      policy_entropy: 32.762474060058594
      policy_loss: -0.9641239047050476
      var_gnorm: 22.85724449157715
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.029309842735528946
    num_steps_sampled: 4715000
    num_steps_trained: 4715000
    wait_time_ms: 73.345
  iterations_since_restore: 943
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8251.094286441803
  time_this_iter_s: 8.471912145614624
  time_total_s: 8251.094286441803
  timestamp: 1594856775
  timesteps_since_restore: 4715000
  timesteps_this_iter: 5000
  timesteps_total: 4715000
  training_iteration: 943
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8251 s, 943 iter, 4715000 ts, 310 rew

agent-1: 48.399999998667596
agent-2: 39.399999998667624
agent-3: 48.39999999866761
agent-4: 41.399999998667624
agent-5: 38.39999999866761
Extrinsic Rewards:
10
1
10
3
0
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.48333333333333334
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-46-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 308.6066786295716
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 943
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.416
    dispatch_time_ms: 6.086
    learner:
      cur_lr: 0.0010459809564054012
      grad_gnorm: 20.018869400024414
      policy_entropy: 33.96392059326172
      policy_loss: -2.43412446975708
      var_gnorm: 22.856983184814453
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2607557773590088
    num_steps_sampled: 4720000
    num_steps_trained: 4720000
    wait_time_ms: 75.004
  iterations_since_restore: 944
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8259.679150104523
  time_this_iter_s: 8.584863662719727
  time_total_s: 8259.679150104523
  timestamp: 1594856783
  timesteps_since_restore: 4720000
  timesteps_this_iter: 5000
  timesteps_total: 4720000
  training_iteration: 944
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8259 s, 944 iter, 4720000 ts, 309 rew

agent-1: 53.399999997232946
agent-2: 41.399999997232946
agent-3: 39.399999997232946
agent-4: 41.399999997232946
agent-5: 40.399999997232946
Extrinsic Rewards:
15
3
1
3
2
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 15
Gini Coefficient: 0.48333333333333334
20:20 Ratio: 15.0
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-46-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 307.4366786295825
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 944
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.478
    dispatch_time_ms: 5.555
    learner:
      cur_lr: 0.0010456480085849762
      grad_gnorm: 10.76081657409668
      policy_entropy: 31.912967681884766
      policy_loss: -1.7497106790542603
      var_gnorm: 22.857650756835938
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.08872242271900177
    num_steps_sampled: 4725000
    num_steps_trained: 4725000
    wait_time_ms: 79.18
  iterations_since_restore: 945
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8268.375729560852
  time_this_iter_s: 8.696579456329346
  time_total_s: 8268.375729560852
  timestamp: 1594856792
  timesteps_since_restore: 4725000
  timesteps_this_iter: 5000
  timesteps_total: 4725000
  training_iteration: 945
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8268 s, 945 iter, 4725000 ts, 307 rew

agent-1: 53.799999995031165
agent-2: 45.799999995031165
agent-3: 54.79999999503116
agent-4: 49.79999999503117
agent-5: 47.79999999503115
Extrinsic Rewards:
9
1
10
5
3
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.34285714285714286
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-46-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 307.1666786294734
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 945
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.633
    dispatch_time_ms: 6.392
    learner:
      cur_lr: 0.0010453149443492293
      grad_gnorm: 40.0
      policy_entropy: 23.399587631225586
      policy_loss: 11.33475399017334
      var_gnorm: 22.85707664489746
      vf_explained_var: 0.0
      vf_loss: 8.108783721923828
    num_steps_sampled: 4730000
    num_steps_trained: 4730000
    wait_time_ms: 81.359
  iterations_since_restore: 946
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8277.001203775406
  time_this_iter_s: 8.625474214553833
  time_total_s: 8277.001203775406
  timestamp: 1594856801
  timesteps_since_restore: 4730000
  timesteps_this_iter: 5000
  timesteps_total: 4730000
  training_iteration: 946
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8277 s, 946 iter, 4730000 ts, 307 rew

agent-1: 27.199999999570096
agent-2: 32.19999999957007
agent-3: 33.19999999957005
agent-4: 30.199999999570096
agent-5: 30.199999999570093
Extrinsic Rewards:
0
5
6
3
3
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.32941176470588235
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-46-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 306.6266786294932
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 946
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.02
    dispatch_time_ms: 5.817
    learner:
      cur_lr: 0.0010449819965288043
      grad_gnorm: 31.877151489257812
      policy_entropy: 16.633386611938477
      policy_loss: -2.5195775032043457
      var_gnorm: 22.857118606567383
      vf_explained_var: 0.0
      vf_loss: 0.7868247628211975
    num_steps_sampled: 4735000
    num_steps_trained: 4735000
    wait_time_ms: 81.05
  iterations_since_restore: 947
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8285.672133207321
  time_this_iter_s: 8.670929431915283
  time_total_s: 8285.672133207321
  timestamp: 1594856810
  timesteps_since_restore: 4735000
  timesteps_this_iter: 5000
  timesteps_total: 4735000
  training_iteration: 947
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8285 s, 947 iter, 4735000 ts, 307 rew

agent-1: 112.79999826218047
agent-2: 102.79999826218047
agent-3: 96.79999826218047
agent-4: 107.79999826218044
agent-5: 101.79999826218052
Extrinsic Rewards:
20
10
4
15
9
Sum Reward: 58
Avg Reward: 11.6
Min Reward: 4
Max Reward: 20
Gini Coefficient: 0.2620689655172414
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-46-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 310.04667854270986
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 947
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 9.88
    learner:
      cur_lr: 0.0010446490487083793
      grad_gnorm: 27.31287956237793
      policy_entropy: 34.65813064575195
      policy_loss: -4.279664039611816
      var_gnorm: 22.855581283569336
      vf_explained_var: 0.0
      vf_loss: 0.5372108221054077
    num_steps_sampled: 4740000
    num_steps_trained: 4740000
    wait_time_ms: 74.034
  iterations_since_restore: 948
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8294.259774923325
  time_this_iter_s: 8.587641716003418
  time_total_s: 8294.259774923325
  timestamp: 1594856818
  timesteps_since_restore: 4740000
  timesteps_this_iter: 5000
  timesteps_total: 4740000
  training_iteration: 948
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8294 s, 948 iter, 4740000 ts, 310 rew

agent-1: 60.39999973248587
agent-2: 64.39999973248577
agent-3: 55.39999973248585
agent-4: 64.39999973248575
agent-5: 61.39999973248586
Extrinsic Rewards:
6
10
1
10
7
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.25882352941176473
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-47-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 309.32667853053323
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 948
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 5.748
    learner:
      cur_lr: 0.0010443159844726324
      grad_gnorm: 40.000003814697266
      policy_entropy: 34.65134811401367
      policy_loss: 54.11362838745117
      var_gnorm: 22.856143951416016
      vf_explained_var: 0.0
      vf_loss: 85.59785461425781
    num_steps_sampled: 4745000
    num_steps_trained: 4745000
    wait_time_ms: 74.929
  iterations_since_restore: 949
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8302.846313238144
  time_this_iter_s: 8.586538314819336
  time_total_s: 8302.846313238144
  timestamp: 1594856827
  timesteps_since_restore: 4745000
  timesteps_this_iter: 5000
  timesteps_total: 4745000
  training_iteration: 949
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8302 s, 949 iter, 4745000 ts, 309 rew

agent-1: 56.599999994706266
agent-2: 54.599999994706266
agent-3: 52.59999999470628
agent-4: 59.599999994706266
agent-5: 55.599999994706266
Extrinsic Rewards:
7
5
3
10
6
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.2064516129032258
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-47-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 310.1366785303887
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 949
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 6.938
    learner:
      cur_lr: 0.0010439830366522074
      grad_gnorm: 32.55281066894531
      policy_entropy: 18.026199340820312
      policy_loss: -2.94168758392334
      var_gnorm: 22.855484008789062
      vf_explained_var: 0.0
      vf_loss: 0.8205937147140503
    num_steps_sampled: 4750000
    num_steps_trained: 4750000
    wait_time_ms: 80.801
  iterations_since_restore: 950
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8311.496848344803
  time_this_iter_s: 8.650535106658936
  time_total_s: 8311.496848344803
  timestamp: 1594856836
  timesteps_since_restore: 4750000
  timesteps_this_iter: 5000
  timesteps_total: 4750000
  training_iteration: 950
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8311 s, 950 iter, 4750000 ts, 310 rew

agent-1: 90.3999990092193
agent-2: 72.3999990092192
agent-3: 73.3999990092192
agent-4: 82.39999900921926
agent-5: 77.39999900921924
Extrinsic Rewards:
20
2
3
12
7
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 2
Max Reward: 20
Gini Coefficient: 0.4090909090909091
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-47-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 310.5866784829204
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 950
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.501
    dispatch_time_ms: 5.474
    learner:
      cur_lr: 0.0010436499724164605
      grad_gnorm: 4.493842124938965
      policy_entropy: 13.440073013305664
      policy_loss: -0.15766720473766327
      var_gnorm: 22.855684280395508
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.014499874785542488
    num_steps_sampled: 4755000
    num_steps_trained: 4755000
    wait_time_ms: 78.716
  iterations_since_restore: 951
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8320.154422521591
  time_this_iter_s: 8.65757417678833
  time_total_s: 8320.154422521591
  timestamp: 1594856844
  timesteps_since_restore: 4755000
  timesteps_this_iter: 5000
  timesteps_total: 4755000
  training_iteration: 951
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8320 s, 951 iter, 4755000 ts, 311 rew

agent-1: 58.199999994202614
agent-2: 57.1999999942026
agent-3: 60.199999994202614
agent-4: 55.1999999942026
agent-5: 57.199999994202614
Extrinsic Rewards:
7
6
9
4
6
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.1375
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-47-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 307.1666815047467
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 951
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.609
    dispatch_time_ms: 8.882
    learner:
      cur_lr: 0.0010433170245960355
      grad_gnorm: 19.1960391998291
      policy_entropy: 17.451404571533203
      policy_loss: -2.8260982036590576
      var_gnorm: 22.855337142944336
      vf_explained_var: 0.0
      vf_loss: 0.2480364590883255
    num_steps_sampled: 4760000
    num_steps_trained: 4760000
    wait_time_ms: 74.071
  iterations_since_restore: 952
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8328.876935720444
  time_this_iter_s: 8.722513198852539
  time_total_s: 8328.876935720444
  timestamp: 1594856853
  timesteps_since_restore: 4760000
  timesteps_this_iter: 5000
  timesteps_total: 4760000
  training_iteration: 952
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8328 s, 952 iter, 4760000 ts, 307 rew

agent-1: 42.599999998082886
agent-2: 33.59999999808292
agent-3: 39.5999999980829
agent-4: 35.599999998082914
agent-5: 37.599999998082914
Extrinsic Rewards:
9
0
6
2
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.41904761904761906
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-47-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 302.2166861345254
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 952
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.927
    dispatch_time_ms: 8.379
    learner:
      cur_lr: 0.0010429839603602886
      grad_gnorm: 5.946096420288086
      policy_entropy: 33.12678527832031
      policy_loss: 1.118670105934143
      var_gnorm: 22.854028701782227
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.027921082451939583
    num_steps_sampled: 4765000
    num_steps_trained: 4765000
    wait_time_ms: 75.868
  iterations_since_restore: 953
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8337.521117687225
  time_this_iter_s: 8.644181966781616
  time_total_s: 8337.521117687225
  timestamp: 1594856862
  timesteps_since_restore: 4765000
  timesteps_this_iter: 5000
  timesteps_total: 4765000
  training_iteration: 953
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8337 s, 953 iter, 4765000 ts, 302 rew

agent-1: 49.799999997852105
agent-2: 53.79999999785209
agent-3: 45.79999999785209
agent-4: 53.79999999785209
agent-5: 48.799999997852105
Extrinsic Rewards:
5
9
1
9
4
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-47-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 302.12668613451837
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 953
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.862
    dispatch_time_ms: 17.274
    learner:
      cur_lr: 0.0010426510125398636
      grad_gnorm: 21.550045013427734
      policy_entropy: 25.48127555847168
      policy_loss: -2.928270101547241
      var_gnorm: 22.852998733520508
      vf_explained_var: 0.0
      vf_loss: 0.3084585964679718
    num_steps_sampled: 4770000
    num_steps_trained: 4770000
    wait_time_ms: 66.265
  iterations_since_restore: 954
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8346.195256710052
  time_this_iter_s: 8.674139022827148
  time_total_s: 8346.195256710052
  timestamp: 1594856870
  timesteps_since_restore: 4770000
  timesteps_this_iter: 5000
  timesteps_total: 4770000
  training_iteration: 954
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8346 s, 954 iter, 4770000 ts, 302 rew

agent-1: 54.599999996542174
agent-2: 58.599999996542174
agent-3: 52.59999999654218
agent-4: 55.599999996542174
agent-5: 57.599999996542174
Extrinsic Rewards:
5
9
3
6
8
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.1935483870967742
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-47-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 304.9166861343455
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 954
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.73
    dispatch_time_ms: 15.135
    learner:
      cur_lr: 0.0010423179483041167
      grad_gnorm: 14.59568977355957
      policy_entropy: 11.999334335327148
      policy_loss: -0.5244450569152832
      var_gnorm: 22.855348587036133
      vf_explained_var: 0.0
      vf_loss: 0.16322799026966095
    num_steps_sampled: 4775000
    num_steps_trained: 4775000
    wait_time_ms: 70.411
  iterations_since_restore: 955
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8354.899854183197
  time_this_iter_s: 8.704597473144531
  time_total_s: 8354.899854183197
  timestamp: 1594856879
  timesteps_since_restore: 4775000
  timesteps_this_iter: 5000
  timesteps_total: 4775000
  training_iteration: 955
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8354 s, 955 iter, 4775000 ts, 305 rew

agent-1: 54.999999995602614
agent-2: 51.999999995602614
agent-3: 60.999999995602614
agent-4: 49.999999995602614
agent-5: 51.999999995602614
Extrinsic Rewards:
7
4
13
2
4
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.3333333333333333
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-48-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 307.61668613412564
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 955
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.998
    dispatch_time_ms: 21.212
    learner:
      cur_lr: 0.0010419850004836917
      grad_gnorm: 40.0
      policy_entropy: 19.283266067504883
      policy_loss: 26.549928665161133
      var_gnorm: 22.857975006103516
      vf_explained_var: 0.0
      vf_loss: 53.050296783447266
    num_steps_sampled: 4780000
    num_steps_trained: 4780000
    wait_time_ms: 66.122
  iterations_since_restore: 956
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8363.580243349075
  time_this_iter_s: 8.680389165878296
  time_total_s: 8363.580243349075
  timestamp: 1594856888
  timesteps_since_restore: 4780000
  timesteps_this_iter: 5000
  timesteps_total: 4780000
  training_iteration: 956
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8363 s, 956 iter, 4780000 ts, 308 rew

agent-1: 107.38971345448672
agent-2: 113.38971345448672
agent-3: 116.38971345448672
agent-4: 129.3897134544866
agent-5: 109.38971345448672
Extrinsic Rewards:
5
11
14
27
7
Sum Reward: 64
Avg Reward: 12.8
Min Reward: 5
Max Reward: 27
Gini Coefficient: 0.31875
20:20 Ratio: 5.4
Max-min Ratio: 5.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-48-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 313.37617180685004
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 956
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.987
    dispatch_time_ms: 21.201
    learner:
      cur_lr: 0.0010416520526632667
      grad_gnorm: 40.0
      policy_entropy: 33.66327667236328
      policy_loss: -8.894301414489746
      var_gnorm: 22.850658416748047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.335985779762268
    num_steps_sampled: 4785000
    num_steps_trained: 4785000
    wait_time_ms: 63.272
  iterations_since_restore: 957
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8372.451868772507
  time_this_iter_s: 8.871625423431396
  time_total_s: 8372.451868772507
  timestamp: 1594856897
  timesteps_since_restore: 4785000
  timesteps_this_iter: 5000
  timesteps_total: 4785000
  training_iteration: 957
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8372 s, 957 iter, 4785000 ts, 313 rew

agent-1: 80.79999957542998
agent-2: 62.799999575430114
agent-3: 71.79999957542998
agent-4: 62.799999575430114
agent-5: 63.79999957543013
Extrinsic Rewards:
20
2
11
2
3
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 2
Max Reward: 20
Gini Coefficient: 0.47368421052631576
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-48-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 316.7961717856215
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 957
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.123
    dispatch_time_ms: 15.51
    learner:
      cur_lr: 0.0010413189884275198
      grad_gnorm: 0.05811154097318649
      policy_entropy: 0.9241026639938354
      policy_loss: -0.018795998767018318
      var_gnorm: 22.857254028320312
      vf_explained_var: 0.0
      vf_loss: 2.0492886960710166e-06
    num_steps_sampled: 4790000
    num_steps_trained: 4790000
    wait_time_ms: 67.493
  iterations_since_restore: 958
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8380.965104341507
  time_this_iter_s: 8.513235569000244
  time_total_s: 8380.965104341507
  timestamp: 1594856905
  timesteps_since_restore: 4790000
  timesteps_this_iter: 5000
  timesteps_total: 4790000
  training_iteration: 958
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8380 s, 958 iter, 4790000 ts, 317 rew

agent-1: 35.199999999083026
agent-2: 44.19999999908303
agent-3: 38.19999999908303
agent-4: 41.19999999908303
agent-5: 39.199999999083026
Extrinsic Rewards:
0
9
3
6
4
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.38181818181818183
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-48-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 318.7761717855756
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 958
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.154
    dispatch_time_ms: 20.917
    learner:
      cur_lr: 0.0010409860406070948
      grad_gnorm: 3.006804943084717
      policy_entropy: 1.6018269062042236
      policy_loss: -0.005072043742984533
      var_gnorm: 22.856203079223633
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.006989486049860716
    num_steps_sampled: 4795000
    num_steps_trained: 4795000
    wait_time_ms: 60.796
  iterations_since_restore: 959
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8389.275582313538
  time_this_iter_s: 8.31047797203064
  time_total_s: 8389.275582313538
  timestamp: 1594856914
  timesteps_since_restore: 4795000
  timesteps_this_iter: 5000
  timesteps_total: 4795000
  training_iteration: 959
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8389 s, 959 iter, 4795000 ts, 319 rew

agent-1: 4.794476958355735
agent-2: 4.794476958355735
agent-3: 5.794476958355737
agent-4: 4.794476958355735
agent-5: 6.794476958355743
Extrinsic Rewards:
0
0
1
0
2
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-48-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 318.95918923888576
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 959
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 14.975
    learner:
      cur_lr: 0.001040652976371348
      grad_gnorm: 0.15285156667232513
      policy_entropy: 2.3854877948760986
      policy_loss: 0.0037442161701619625
      var_gnorm: 22.855995178222656
      vf_explained_var: 0.0
      vf_loss: 1.7771339116734453e-05
    num_steps_sampled: 4800000
    num_steps_trained: 4800000
    wait_time_ms: 66.862
  iterations_since_restore: 960
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8397.410217523575
  time_this_iter_s: 8.134635210037231
  time_total_s: 8397.410217523575
  timestamp: 1594856922
  timesteps_since_restore: 4800000
  timesteps_this_iter: 5000
  timesteps_total: 4800000
  training_iteration: 960
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8397 s, 960 iter, 4800000 ts, 319 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-48-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 318.9591892388857
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 960
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.535
    dispatch_time_ms: 19.665
    learner:
      cur_lr: 0.0010403200285509229
      grad_gnorm: 18.265766143798828
      policy_entropy: 5.306162357330322
      policy_loss: 0.42569199204444885
      var_gnorm: 22.85462760925293
      vf_explained_var: 0.0
      vf_loss: 0.2669107913970947
    num_steps_sampled: 4805000
    num_steps_trained: 4805000
    wait_time_ms: 60.557
  iterations_since_restore: 961
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8405.57981300354
  time_this_iter_s: 8.16959547996521
  time_total_s: 8405.57981300354
  timestamp: 1594856930
  timesteps_since_restore: 4805000
  timesteps_this_iter: 5000
  timesteps_total: 4805000
  training_iteration: 961
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8405 s, 961 iter, 4805000 ts, 319 rew

agent-1: 17.98457205352024
agent-2: 16.98457205352024
agent-3: 28.98457205352021
agent-4: 17.98457205352024
agent-5: 16.98457205352024
Extrinsic Rewards:
1
0
12
1
0
Sum Reward: 14
Avg Reward: 2.8
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.7142857142857143
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-48-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 319.9484178415617
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 961
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 8.178
    learner:
      cur_lr: 0.001039986964315176
      grad_gnorm: 40.0
      policy_entropy: 26.84785270690918
      policy_loss: -5.18652868270874
      var_gnorm: 22.864110946655273
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.7393107414245605
    num_steps_sampled: 4810000
    num_steps_trained: 4810000
    wait_time_ms: 72.017
  iterations_since_restore: 962
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8414.053433895111
  time_this_iter_s: 8.473620891571045
  time_total_s: 8414.053433895111
  timestamp: 1594856939
  timesteps_since_restore: 4810000
  timesteps_this_iter: 5000
  timesteps_total: 4810000
  training_iteration: 962
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8414 s, 962 iter, 4810000 ts, 320 rew

agent-1: 158.26709064818976
agent-2: 166.2670906481897
agent-3: 160.26709064818974
agent-4: 144.26709064818974
agent-5: 149.26709064818976
Extrinsic Rewards:
21
29
23
7
12
Sum Reward: 92
Avg Reward: 18.4
Min Reward: 7
Max Reward: 29
Gini Coefficient: 0.2391304347826087
20:20 Ratio: 4.142857142857143
Max-min Ratio: 4.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-49-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 327.64177342385045
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 962
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.625
    dispatch_time_ms: 7.314
    learner:
      cur_lr: 0.001039654016494751
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.861818313598633
      policy_loss: -12.927969932556152
      var_gnorm: 22.859567642211914
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.493196964263916
    num_steps_sampled: 4815000
    num_steps_trained: 4815000
    wait_time_ms: 78.881
  iterations_since_restore: 963
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8422.577506303787
  time_this_iter_s: 8.524072408676147
  time_total_s: 8422.577506303787
  timestamp: 1594856947
  timesteps_since_restore: 4815000
  timesteps_this_iter: 5000
  timesteps_total: 4815000
  training_iteration: 963
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8422 s, 963 iter, 4815000 ts, 328 rew

agent-1: 59.59999998888177
agent-2: 59.59999998888177
agent-3: 63.59999998888177
agent-4: 70.59999998888182
agent-5: 70.5999999888818
Extrinsic Rewards:
2
2
6
13
13
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.36666666666666664
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-49-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 330.88177342329465
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 963
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.779
    dispatch_time_ms: 10.165
    learner:
      cur_lr: 0.0010393209522590041
      grad_gnorm: 26.458345413208008
      policy_entropy: 30.967796325683594
      policy_loss: -3.6357834339141846
      var_gnorm: 22.847394943237305
      vf_explained_var: 0.0
      vf_loss: 0.5320448279380798
    num_steps_sampled: 4820000
    num_steps_trained: 4820000
    wait_time_ms: 71.352
  iterations_since_restore: 964
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8430.94110584259
  time_this_iter_s: 8.3635995388031
  time_total_s: 8430.94110584259
  timestamp: 1594856955
  timesteps_since_restore: 4820000
  timesteps_this_iter: 5000
  timesteps_total: 4820000
  training_iteration: 964
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8430 s, 964 iter, 4820000 ts, 331 rew

agent-1: 34.59999999892641
agent-2: 39.59999999892641
agent-3: 36.5999999989264
agent-4: 37.59999999892641
agent-5: 40.599999998926414
Extrinsic Rewards:
1
6
3
4
7
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.2857142857142857
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-49-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 331.4096398024603
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 964
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.604
    dispatch_time_ms: 6.701
    learner:
      cur_lr: 0.001038988004438579
      grad_gnorm: 23.558929443359375
      policy_entropy: 34.65797805786133
      policy_loss: -4.139345169067383
      var_gnorm: 22.847646713256836
      vf_explained_var: 0.0
      vf_loss: 0.4270951449871063
    num_steps_sampled: 4825000
    num_steps_trained: 4825000
    wait_time_ms: 77.49
  iterations_since_restore: 965
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8439.589526176453
  time_this_iter_s: 8.648420333862305
  time_total_s: 8439.589526176453
  timestamp: 1594856964
  timesteps_since_restore: 4825000
  timesteps_this_iter: 5000
  timesteps_total: 4825000
  training_iteration: 965
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8439 s, 965 iter, 4825000 ts, 331 rew

agent-1: 72.79999960388243
agent-2: 67.79999960388234
agent-3: 61.79999960388242
agent-4: 70.7999996038824
agent-5: 68.79999960388237
Extrinsic Rewards:
12
7
1
10
8
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.2631578947368421
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-49-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 329.97801368258837
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 965
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 9.303
    learner:
      cur_lr: 0.001038655056618154
      grad_gnorm: 20.276575088500977
      policy_entropy: 34.538570404052734
      policy_loss: -3.44039249420166
      var_gnorm: 22.84843635559082
      vf_explained_var: 0.0
      vf_loss: 0.3033720552921295
    num_steps_sampled: 4830000
    num_steps_trained: 4830000
    wait_time_ms: 75.154
  iterations_since_restore: 966
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8448.124920845032
  time_this_iter_s: 8.535394668579102
  time_total_s: 8448.124920845032
  timestamp: 1594856973
  timesteps_since_restore: 4830000
  timesteps_this_iter: 5000
  timesteps_total: 4830000
  training_iteration: 966
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8448 s, 966 iter, 4830000 ts, 330 rew

agent-1: 41.399999998511944
agent-2: 41.399999998511944
agent-3: 45.399999998511944
agent-4: 49.399999998511944
agent-5: 38.39999999851193
Extrinsic Rewards:
3
3
7
11
0
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.43333333333333335
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-49-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 329.61801368297427
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 966
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 8.44
    learner:
      cur_lr: 0.0010383219923824072
      grad_gnorm: 5.656274795532227
      policy_entropy: 31.449058532714844
      policy_loss: -0.7896918654441833
      var_gnorm: 22.848224639892578
      vf_explained_var: 0.0
      vf_loss: 0.02236533910036087
    num_steps_sampled: 4835000
    num_steps_trained: 4835000
    wait_time_ms: 74.289
  iterations_since_restore: 967
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8456.77908873558
  time_this_iter_s: 8.654167890548706
  time_total_s: 8456.77908873558
  timestamp: 1594856981
  timesteps_since_restore: 4835000
  timesteps_this_iter: 5000
  timesteps_total: 4835000
  training_iteration: 967
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8456 s, 967 iter, 4835000 ts, 330 rew

agent-1: 68.9999998629151
agent-2: 68.9999998629151
agent-3: 81.99999986291516
agent-4: 69.99999986291512
agent-5: 69.99999986291512
Extrinsic Rewards:
5
5
18
6
6
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 5
Max Reward: 18
Gini Coefficient: 0.27
20:20 Ratio: 3.6
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-49-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 330.87801367625275
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 967
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.82
    dispatch_time_ms: 8.802
    learner:
      cur_lr: 0.0010379890445619822
      grad_gnorm: 40.0
      policy_entropy: 17.131330490112305
      policy_loss: 30.136484146118164
      var_gnorm: 22.849788665771484
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 129.573486328125
    num_steps_sampled: 4840000
    num_steps_trained: 4840000
    wait_time_ms: 74.443
  iterations_since_restore: 968
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8465.35284948349
  time_this_iter_s: 8.573760747909546
  time_total_s: 8465.35284948349
  timestamp: 1594856990
  timesteps_since_restore: 4840000
  timesteps_this_iter: 5000
  timesteps_total: 4840000
  training_iteration: 968
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8465 s, 968 iter, 4840000 ts, 331 rew

agent-1: 45.39999999767642
agent-2: 38.39999999767643
agent-3: 41.39999999767641
agent-4: 42.3999999976764
agent-5: 48.39999999767644
Extrinsic Rewards:
7
0
3
4
10
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-49-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 325.5680232185948
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 968
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.433
    dispatch_time_ms: 9.916
    learner:
      cur_lr: 0.0010376559803262353
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.847166061401367
      policy_loss: -5.627328872680664
      var_gnorm: 22.84943962097168
      vf_explained_var: 0.0
      vf_loss: 1.468590497970581
    num_steps_sampled: 4845000
    num_steps_trained: 4845000
    wait_time_ms: 73.048
  iterations_since_restore: 969
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8474.047837257385
  time_this_iter_s: 8.694987773895264
  time_total_s: 8474.047837257385
  timestamp: 1594856999
  timesteps_since_restore: 4845000
  timesteps_this_iter: 5000
  timesteps_total: 4845000
  training_iteration: 969
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8474 s, 969 iter, 4845000 ts, 326 rew

agent-1: 143.59998318483656
agent-2: 135.59998318483656
agent-3: 142.59998318483653
agent-4: 162.5999831848365
agent-5: 144.59998318483653
Extrinsic Rewards:
14
6
13
33
15
Sum Reward: 81
Avg Reward: 16.2
Min Reward: 6
Max Reward: 33
Gini Coefficient: 0.2765432098765432
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-50-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 329.61802238049574
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 969
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.644
    dispatch_time_ms: 8.415
    learner:
      cur_lr: 0.0010373230325058103
      grad_gnorm: 21.816654205322266
      policy_entropy: 34.64988327026367
      policy_loss: -3.6487250328063965
      var_gnorm: 22.849090576171875
      vf_explained_var: 0.0
      vf_loss: 0.3555210828781128
    num_steps_sampled: 4850000
    num_steps_trained: 4850000
    wait_time_ms: 75.322
  iterations_since_restore: 970
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8482.62736082077
  time_this_iter_s: 8.57952356338501
  time_total_s: 8482.62736082077
  timestamp: 1594857007
  timesteps_since_restore: 4850000
  timesteps_this_iter: 5000
  timesteps_total: 4850000
  training_iteration: 970
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8482 s, 970 iter, 4850000 ts, 330 rew

agent-1: 83.5999999771493
agent-2: 84.59999997714931
agent-3: 81.59999997714928
agent-4: 84.5999999771493
agent-5: 79.59999997714928
Extrinsic Rewards:
10
11
8
11
6
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 6
Max Reward: 11
Gini Coefficient: 0.11304347826086956
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-50-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 328.7180224607058
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 970
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.884
    dispatch_time_ms: 8.363
    learner:
      cur_lr: 0.0010369899682700634
      grad_gnorm: 1.5879026651382446
      policy_entropy: 34.658504486083984
      policy_loss: -0.21458369493484497
      var_gnorm: 22.852041244506836
      vf_explained_var: 0.0
      vf_loss: 0.001663699047639966
    num_steps_sampled: 4855000
    num_steps_trained: 4855000
    wait_time_ms: 75.542
  iterations_since_restore: 971
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8491.678687095642
  time_this_iter_s: 9.051326274871826
  time_total_s: 8491.678687095642
  timestamp: 1594857016
  timesteps_since_restore: 4855000
  timesteps_this_iter: 5000
  timesteps_total: 4855000
  training_iteration: 971
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8491 s, 971 iter, 4855000 ts, 329 rew

agent-1: 54.5999999965452
agent-2: 57.5999999965452
agent-3: 63.5999999965452
agent-4: 53.59999999654521
agent-5: 49.5999999965452
Extrinsic Rewards:
5
8
14
4
0
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.4129032258064516
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-50-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 328.8980224608655
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 971
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.45
    dispatch_time_ms: 9.162
    learner:
      cur_lr: 0.0010366570204496384
      grad_gnorm: 11.475552558898926
      policy_entropy: 33.43391418457031
      policy_loss: -2.0323009490966797
      var_gnorm: 22.85344886779785
      vf_explained_var: 0.0
      vf_loss: 0.09882015734910965
    num_steps_sampled: 4860000
    num_steps_trained: 4860000
    wait_time_ms: 74.19
  iterations_since_restore: 972
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8500.287899255753
  time_this_iter_s: 8.609212160110474
  time_total_s: 8500.287899255753
  timestamp: 1594857025
  timesteps_since_restore: 4860000
  timesteps_this_iter: 5000
  timesteps_total: 4860000
  training_iteration: 972
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.4/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8500 s, 972 iter, 4860000 ts, 329 rew

agent-1: 54.19999999644338
agent-2: 50.19999999644338
agent-3: 44.199999996443395
agent-4: 46.19999999644338
agent-5: 48.19999999644338
Extrinsic Rewards:
11
7
1
3
5
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.35555555555555557
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-50-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 329.8880224607061
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 972
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.653
    dispatch_time_ms: 5.987
    learner:
      cur_lr: 0.0010363239562138915
      grad_gnorm: 16.197368621826172
      policy_entropy: 33.260047912597656
      policy_loss: -2.634124994277954
      var_gnorm: 22.853504180908203
      vf_explained_var: 0.0
      vf_loss: 0.20317670702934265
    num_steps_sampled: 4865000
    num_steps_trained: 4865000
    wait_time_ms: 77.336
  iterations_since_restore: 973
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8508.818300962448
  time_this_iter_s: 8.530401706695557
  time_total_s: 8508.818300962448
  timestamp: 1594857034
  timesteps_since_restore: 4865000
  timesteps_this_iter: 5000
  timesteps_total: 4865000
  training_iteration: 973
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8508 s, 973 iter, 4865000 ts, 330 rew

agent-1: 42.19999999912338
agent-2: 44.19999999912338
agent-3: 36.19999999912336
agent-4: 37.199999999123364
agent-5: 38.19999999912337
Extrinsic Rewards:
7
9
1
2
3
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.38181818181818183
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-50-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 330.0680224607167
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 973
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 6.608
    learner:
      cur_lr: 0.0010359910083934665
      grad_gnorm: 19.597185134887695
      policy_entropy: 26.420333862304688
      policy_loss: -1.829906702041626
      var_gnorm: 22.852561950683594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.28803181648254395
    num_steps_sampled: 4870000
    num_steps_trained: 4870000
    wait_time_ms: 76.12
  iterations_since_restore: 974
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8517.480029821396
  time_this_iter_s: 8.661728858947754
  time_total_s: 8517.480029821396
  timestamp: 1594857042
  timesteps_since_restore: 4870000
  timesteps_this_iter: 5000
  timesteps_total: 4870000
  training_iteration: 974
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8517 s, 974 iter, 4870000 ts, 330 rew

agent-1: 39.1999999981369
agent-2: 36.19999999813692
agent-3: 44.19999999813689
agent-4: 40.19999999813689
agent-5: 38.19999999813692
Extrinsic Rewards:
4
1
9
5
3
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.32727272727272727
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-50-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 330.3380224606646
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 974
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.942
    dispatch_time_ms: 8.788
    learner:
      cur_lr: 0.0010356579441577196
      grad_gnorm: 39.22235107421875
      policy_entropy: 20.78134536743164
      policy_loss: 3.9371588230133057
      var_gnorm: 22.853059768676758
      vf_explained_var: 0.0
      vf_loss: 1.2326743602752686
    num_steps_sampled: 4875000
    num_steps_trained: 4875000
    wait_time_ms: 70.545
  iterations_since_restore: 975
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8525.347654104233
  time_this_iter_s: 7.867624282836914
  time_total_s: 8525.347654104233
  timestamp: 1594857051
  timesteps_since_restore: 4875000
  timesteps_this_iter: 5000
  timesteps_total: 4875000
  training_iteration: 975
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8525 s, 975 iter, 4875000 ts, 330 rew

agent-1: 40.99999999332838
agent-2: 39.99999999332839
agent-3: 54.99999999332838
agent-4: 40.99999999332838
agent-5: 47.999999993328366
Extrinsic Rewards:
1
0
15
1
8
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 15
Gini Coefficient: 0.592
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-51-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 329.7980224605635
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 975
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.728
    dispatch_time_ms: 7.227
    learner:
      cur_lr: 0.0010353249963372946
      grad_gnorm: 40.0
      policy_entropy: 31.99748992919922
      policy_loss: -9.856176376342773
      var_gnorm: 22.849624633789062
      vf_explained_var: 0.0
      vf_loss: 2.077594518661499
    num_steps_sampled: 4880000
    num_steps_trained: 4880000
    wait_time_ms: 75.31
  iterations_since_restore: 976
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8533.958069086075
  time_this_iter_s: 8.610414981842041
  time_total_s: 8533.958069086075
  timestamp: 1594857060
  timesteps_since_restore: 4880000
  timesteps_this_iter: 5000
  timesteps_total: 4880000
  training_iteration: 976
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8533 s, 976 iter, 4880000 ts, 330 rew

agent-1: 106.59981795022996
agent-2: 114.59981795022998
agent-3: 107.59981795022995
agent-4: 107.59981795022992
agent-5: 112.59981795022992
Extrinsic Rewards:
9
17
10
10
15
Sum Reward: 61
Avg Reward: 12.2
Min Reward: 9
Max Reward: 17
Gini Coefficient: 0.1377049180327869
20:20 Ratio: 1.8888888888888888
Max-min Ratio: 1.8888888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-51-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 333.21801335818753
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 976
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.57
    dispatch_time_ms: 6.879
    learner:
      cur_lr: 0.0010349920485168695
      grad_gnorm: 20.99564552307129
      policy_entropy: 16.312562942504883
      policy_loss: -1.4985558986663818
      var_gnorm: 22.850610733032227
      vf_explained_var: 0.0
      vf_loss: 0.34046077728271484
    num_steps_sampled: 4885000
    num_steps_trained: 4885000
    wait_time_ms: 76.368
  iterations_since_restore: 977
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8542.64269065857
  time_this_iter_s: 8.684621572494507
  time_total_s: 8542.64269065857
  timestamp: 1594857069
  timesteps_since_restore: 4885000
  timesteps_this_iter: 5000
  timesteps_total: 4885000
  training_iteration: 977
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8542 s, 977 iter, 4885000 ts, 333 rew

agent-1: 58.799999998334656
agent-2: 51.79999999833465
agent-3: 48.79999999833464
agent-4: 47.79999999833464
agent-5: 44.79999999833464
Extrinsic Rewards:
14
7
4
3
0
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.45714285714285713
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-51-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 333.12801335915304
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 977
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.42
    dispatch_time_ms: 8.141
    learner:
      cur_lr: 0.0010346589842811227
      grad_gnorm: 28.068058013916016
      policy_entropy: 23.41972541809082
      policy_loss: -3.322075366973877
      var_gnorm: 22.849605560302734
      vf_explained_var: 0.0
      vf_loss: 0.606872022151947
    num_steps_sampled: 4890000
    num_steps_trained: 4890000
    wait_time_ms: 73.995
  iterations_since_restore: 978
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8551.28596329689
  time_this_iter_s: 8.643272638320923
  time_total_s: 8551.28596329689
  timestamp: 1594857077
  timesteps_since_restore: 4890000
  timesteps_this_iter: 5000
  timesteps_total: 4890000
  training_iteration: 978
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8551 s, 978 iter, 4890000 ts, 333 rew

agent-1: 89.79999845545545
agent-2: 86.79999845545544
agent-3: 88.79999845545544
agent-4: 81.79999845545547
agent-5: 84.79999845545544
Extrinsic Rewards:
13
10
12
5
8
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 5
Max Reward: 13
Gini Coefficient: 0.16666666666666666
20:20 Ratio: 2.6
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-51-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 335.3780132819982
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 978
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.714
    dispatch_time_ms: 6.522
    learner:
      cur_lr: 0.0010343260364606977
      grad_gnorm: 23.565568923950195
      policy_entropy: 25.323104858398438
      policy_loss: 3.3827240467071533
      var_gnorm: 22.850662231445312
      vf_explained_var: 0.0
      vf_loss: 0.43577882647514343
    num_steps_sampled: 4895000
    num_steps_trained: 4895000
    wait_time_ms: 77.088
  iterations_since_restore: 979
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8559.87735581398
  time_this_iter_s: 8.591392517089844
  time_total_s: 8559.87735581398
  timestamp: 1594857086
  timesteps_since_restore: 4895000
  timesteps_this_iter: 5000
  timesteps_total: 4895000
  training_iteration: 979
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8559 s, 979 iter, 4895000 ts, 335 rew

agent-1: 41.79999999862192
agent-2: 40.79999999862192
agent-3: 39.799999998621914
agent-4: 44.79999999862192
agent-5: 39.799999998621914
Extrinsic Rewards:
5
4
3
8
3
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 3
Max Reward: 8
Gini Coefficient: 0.20869565217391303
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-51-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 334.0280132849213
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 979
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.069
    dispatch_time_ms: 9.883
    learner:
      cur_lr: 0.0010339929722249508
      grad_gnorm: 19.02784538269043
      policy_entropy: 32.9383430480957
      policy_loss: -2.4306583404541016
      var_gnorm: 22.850147247314453
      vf_explained_var: 0.0
      vf_loss: 0.28039976954460144
    num_steps_sampled: 4900000
    num_steps_trained: 4900000
    wait_time_ms: 74.646
  iterations_since_restore: 980
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8568.517065763474
  time_this_iter_s: 8.639709949493408
  time_total_s: 8568.517065763474
  timestamp: 1594857095
  timesteps_since_restore: 4900000
  timesteps_this_iter: 5000
  timesteps_total: 4900000
  training_iteration: 980
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8568 s, 980 iter, 4900000 ts, 334 rew

agent-1: 69.39999998956282
agent-2: 66.39999998956277
agent-3: 71.3999999895628
agent-4: 68.3999999895628
agent-5: 75.39999998956274
Extrinsic Rewards:
7
4
9
6
13
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 4
Max Reward: 13
Gini Coefficient: 0.2153846153846154
20:20 Ratio: 3.25
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-51-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 335.73801328447445
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 980
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.1
    dispatch_time_ms: 7.109
    learner:
      cur_lr: 0.0010336600244045258
      grad_gnorm: 21.578115463256836
      policy_entropy: 34.61260986328125
      policy_loss: -3.2291712760925293
      var_gnorm: 22.84946632385254
      vf_explained_var: 0.0
      vf_loss: 0.3129499852657318
    num_steps_sampled: 4905000
    num_steps_trained: 4905000
    wait_time_ms: 77.139
  iterations_since_restore: 981
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8577.094188928604
  time_this_iter_s: 8.577123165130615
  time_total_s: 8577.094188928604
  timestamp: 1594857103
  timesteps_since_restore: 4905000
  timesteps_this_iter: 5000
  timesteps_total: 4905000
  training_iteration: 981
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8577 s, 981 iter, 4905000 ts, 336 rew

agent-1: 51.3999999905025
agent-2: 50.3999999905025
agent-3: 54.3999999905025
agent-4: 51.399999990502515
agent-5: 53.3999999905025
Extrinsic Rewards:
5
4
8
5
7
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 4
Max Reward: 8
Gini Coefficient: 0.13793103448275862
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-51-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 336.27801328406366
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 981
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.589
    dispatch_time_ms: 9.969
    learner:
      cur_lr: 0.001033326960168779
      grad_gnorm: 8.434136390686035
      policy_entropy: 25.702251434326172
      policy_loss: -1.078801155090332
      var_gnorm: 22.851917266845703
      vf_explained_var: 0.0
      vf_loss: 0.054019659757614136
    num_steps_sampled: 4910000
    num_steps_trained: 4910000
    wait_time_ms: 78.664
  iterations_since_restore: 982
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8585.727752685547
  time_this_iter_s: 8.633563756942749
  time_total_s: 8585.727752685547
  timestamp: 1594857112
  timesteps_since_restore: 4910000
  timesteps_this_iter: 5000
  timesteps_total: 4910000
  training_iteration: 982
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8585 s, 982 iter, 4910000 ts, 336 rew

agent-1: 42.99999999570139
agent-2: 49.99999999570137
agent-3: 46.99999999570137
agent-4: 41.99999999570139
agent-5: 42.99999999570139
Extrinsic Rewards:
3
10
7
2
3
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.32
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-52-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 336.0980132839894
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 982
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.719
    dispatch_time_ms: 6.112
    learner:
      cur_lr: 0.0010329940123483539
      grad_gnorm: 20.666954040527344
      policy_entropy: 20.097597122192383
      policy_loss: -1.266945242881775
      var_gnorm: 22.851377487182617
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.31870296597480774
    num_steps_sampled: 4915000
    num_steps_trained: 4915000
    wait_time_ms: 79.547
  iterations_since_restore: 983
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8594.35123872757
  time_this_iter_s: 8.623486042022705
  time_total_s: 8594.35123872757
  timestamp: 1594857120
  timesteps_since_restore: 4915000
  timesteps_this_iter: 5000
  timesteps_total: 4915000
  training_iteration: 983
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8594 s, 983 iter, 4915000 ts, 336 rew

agent-1: 38.999999998888306
agent-2: 31.999999998888324
agent-3: 38.999999998888306
agent-4: 35.99999999888831
agent-5: 33.99999999888832
Extrinsic Rewards:
7
0
7
4
2
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.38
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-52-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 333.0380132942984
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 983
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 8.818
    learner:
      cur_lr: 0.001032660948112607
      grad_gnorm: 31.007471084594727
      policy_entropy: 34.459930419921875
      policy_loss: -4.682880878448486
      var_gnorm: 22.84991455078125
      vf_explained_var: 0.0
      vf_loss: 0.5117316842079163
    num_steps_sampled: 4920000
    num_steps_trained: 4920000
    wait_time_ms: 73.485
  iterations_since_restore: 984
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8602.949443340302
  time_this_iter_s: 8.598204612731934
  time_total_s: 8602.949443340302
  timestamp: 1594857129
  timesteps_since_restore: 4920000
  timesteps_this_iter: 5000
  timesteps_total: 4920000
  training_iteration: 984
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8602 s, 984 iter, 4920000 ts, 333 rew

agent-1: 123.5999982280839
agent-2: 123.59999822808392
agent-3: 119.59999822808392
agent-4: 112.59999822808392
agent-5: 114.5999982280839
Extrinsic Rewards:
18
18
14
7
9
Sum Reward: 66
Avg Reward: 13.2
Min Reward: 7
Max Reward: 18
Gini Coefficient: 0.18787878787878787
20:20 Ratio: 2.5714285714285716
Max-min Ratio: 2.5714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-52-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 335.82801320711036
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 984
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 9.238
    learner:
      cur_lr: 0.001032328000292182
      grad_gnorm: 20.335750579833984
      policy_entropy: 24.486831665039062
      policy_loss: -1.9666138887405396
      var_gnorm: 22.85131072998047
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.3094593286514282
    num_steps_sampled: 4925000
    num_steps_trained: 4925000
    wait_time_ms: 74.614
  iterations_since_restore: 985
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8611.558373451233
  time_this_iter_s: 8.608930110931396
  time_total_s: 8611.558373451233
  timestamp: 1594857138
  timesteps_since_restore: 4925000
  timesteps_this_iter: 5000
  timesteps_total: 4925000
  training_iteration: 985
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8611 s, 985 iter, 4925000 ts, 336 rew

agent-1: 31.999999999084523
agent-2: 36.999999999084686
agent-3: 34.99999999908467
agent-4: 39.999999999084686
agent-5: 35.999999999084686
Extrinsic Rewards:
0
5
3
8
4
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.36
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-52-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 335.01801320720256
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 985
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.759
    dispatch_time_ms: 7.108
    learner:
      cur_lr: 0.001031995052471757
      grad_gnorm: 17.18821144104004
      policy_entropy: 34.03622055053711
      policy_loss: -2.715005874633789
      var_gnorm: 22.85039520263672
      vf_explained_var: 0.0
      vf_loss: 0.22559411823749542
    num_steps_sampled: 4930000
    num_steps_trained: 4930000
    wait_time_ms: 80.208
  iterations_since_restore: 986
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8620.099129199982
  time_this_iter_s: 8.54075574874878
  time_total_s: 8620.099129199982
  timestamp: 1594857146
  timesteps_since_restore: 4930000
  timesteps_this_iter: 5000
  timesteps_total: 4930000
  training_iteration: 986
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8620 s, 986 iter, 4930000 ts, 335 rew

agent-1: 71.59999998704407
agent-2: 76.59999998704407
agent-3: 75.59999998704409
agent-4: 71.59999998704407
agent-5: 73.59999998704409
Extrinsic Rewards:
6
11
10
6
8
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 6
Max Reward: 11
Gini Coefficient: 0.13658536585365855
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-52-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 334.11801331188656
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 986
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 7.787
    learner:
      cur_lr: 0.00103166198823601
      grad_gnorm: 11.442056655883789
      policy_entropy: 32.93044662475586
      policy_loss: -1.7939908504486084
      var_gnorm: 22.851011276245117
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.09294141083955765
    num_steps_sampled: 4935000
    num_steps_trained: 4935000
    wait_time_ms: 76.942
  iterations_since_restore: 987
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8628.717725515366
  time_this_iter_s: 8.618596315383911
  time_total_s: 8628.717725515366
  timestamp: 1594857155
  timesteps_since_restore: 4935000
  timesteps_this_iter: 5000
  timesteps_total: 4935000
  training_iteration: 987
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8628 s, 987 iter, 4935000 ts, 334 rew

agent-1: 43.99999999517037
agent-2: 50.999999995170356
agent-3: 42.99999999517036
agent-4: 45.999999995170356
agent-5: 40.999999995170356
Extrinsic Rewards:
4
11
3
6
1
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.368
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-52-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 332.85801331546116
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 987
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.054
    dispatch_time_ms: 7.472
    learner:
      cur_lr: 0.001031329040415585
      grad_gnorm: 18.852746963500977
      policy_entropy: 23.347196578979492
      policy_loss: -2.0209953784942627
      var_gnorm: 22.849702835083008
      vf_explained_var: 0.0
      vf_loss: 0.2745945453643799
    num_steps_sampled: 4940000
    num_steps_trained: 4940000
    wait_time_ms: 76.206
  iterations_since_restore: 988
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8637.358039855957
  time_this_iter_s: 8.64031434059143
  time_total_s: 8637.358039855957
  timestamp: 1594857164
  timesteps_since_restore: 4940000
  timesteps_this_iter: 5000
  timesteps_total: 4940000
  training_iteration: 988
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8637 s, 988 iter, 4940000 ts, 333 rew

agent-1: 31.199999999021877
agent-2: 29.199999999021877
agent-3: 29.199999999021877
agent-4: 31.199999999021877
agent-5: 32.199999999021834
Extrinsic Rewards:
4
2
2
4
5
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.18823529411764706
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-52-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 332.4080133155315
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 988
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.818
    dispatch_time_ms: 9.14
    learner:
      cur_lr: 0.0010309959761798382
      grad_gnorm: 7.78836727142334
      policy_entropy: 31.688199996948242
      policy_loss: 1.3018715381622314
      var_gnorm: 22.847291946411133
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.04819601774215698
    num_steps_sampled: 4945000
    num_steps_trained: 4945000
    wait_time_ms: 72.585
  iterations_since_restore: 989
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8645.926604509354
  time_this_iter_s: 8.568564653396606
  time_total_s: 8645.926604509354
  timestamp: 1594857172
  timesteps_since_restore: 4945000
  timesteps_this_iter: 5000
  timesteps_total: 4945000
  training_iteration: 989
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8645 s, 989 iter, 4945000 ts, 332 rew

agent-1: 55.39999999579937
agent-2: 50.39999999579936
agent-3: 52.39999999579937
agent-4: 49.39999999579936
agent-5: 53.39999999579937
Extrinsic Rewards:
9
4
6
3
7
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.20689655172413793
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-53-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 332.58801331542963
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 989
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 9.985
    learner:
      cur_lr: 0.0010306630283594131
      grad_gnorm: 40.0
      policy_entropy: 32.45158767700195
      policy_loss: 50.438812255859375
      var_gnorm: 22.847007751464844
      vf_explained_var: 0.0
      vf_loss: 82.20845794677734
    num_steps_sampled: 4950000
    num_steps_trained: 4950000
    wait_time_ms: 72.34
  iterations_since_restore: 990
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8654.482610464096
  time_this_iter_s: 8.556005954742432
  time_total_s: 8654.482610464096
  timestamp: 1594857181
  timesteps_since_restore: 4950000
  timesteps_this_iter: 5000
  timesteps_total: 4950000
  training_iteration: 990
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8654 s, 990 iter, 4950000 ts, 333 rew

agent-1: 56.99999999304358
agent-2: 57.999999993043566
agent-3: 50.999999993043595
agent-4: 50.999999993043595
agent-5: 52.99999999304358
Extrinsic Rewards:
9
10
3
3
5
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-53-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 329.70801367531703
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 990
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.532
    dispatch_time_ms: 8.164
    learner:
      cur_lr: 0.0010303299641236663
      grad_gnorm: 21.095170974731445
      policy_entropy: 21.972808837890625
      policy_loss: -2.0050809383392334
      var_gnorm: 22.846506118774414
      vf_explained_var: 0.0
      vf_loss: 0.33703264594078064
    num_steps_sampled: 4955000
    num_steps_trained: 4955000
    wait_time_ms: 79.708
  iterations_since_restore: 991
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8663.148394823074
  time_this_iter_s: 8.665784358978271
  time_total_s: 8663.148394823074
  timestamp: 1594857190
  timesteps_since_restore: 4955000
  timesteps_this_iter: 5000
  timesteps_total: 4955000
  training_iteration: 991
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8663 s, 991 iter, 4955000 ts, 330 rew

agent-1: 76.79999974535883
agent-2: 81.79999974535885
agent-3: 75.79999974535883
agent-4: 69.79999974535885
agent-5: 82.79999974535887
Extrinsic Rewards:
8
13
7
1
14
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.29767441860465116
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-53-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1213.8208109310463
  episode_reward_mean: 331.6880136626626
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 991
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 7.759
    learner:
      cur_lr: 0.0010299970163032413
      grad_gnorm: 16.21503448486328
      policy_entropy: 29.6525821685791
      policy_loss: -2.32781982421875
      var_gnorm: 22.845909118652344
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 0.2035953551530838
    num_steps_sampled: 4960000
    num_steps_trained: 4960000
    wait_time_ms: 73.167
  iterations_since_restore: 992
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8671.818257808685
  time_this_iter_s: 8.669862985610962
  time_total_s: 8671.818257808685
  timestamp: 1594857198
  timesteps_since_restore: 4960000
  timesteps_this_iter: 5000
  timesteps_total: 4960000
  training_iteration: 992
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8671 s, 992 iter, 4960000 ts, 332 rew

agent-1: 40.799999999108174
agent-2: 43.7999999991082
agent-3: 40.79999999910819
agent-4: 36.79999999910819
agent-5: 44.7999999991082
Extrinsic Rewards:
4
7
4
0
8
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.33043478260869563
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-53-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.6008741999706
  episode_reward_mean: 321.6198055533076
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 992
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.575
    dispatch_time_ms: 5.574
    learner:
      cur_lr: 0.0010296639520674944
      grad_gnorm: 20.921831130981445
      policy_entropy: 34.5716438293457
      policy_loss: -3.143357038497925
      var_gnorm: 22.8442440032959
      vf_explained_var: 0.0
      vf_loss: 0.33104240894317627
    num_steps_sampled: 4965000
    num_steps_trained: 4965000
    wait_time_ms: 78.573
  iterations_since_restore: 993
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8680.355793952942
  time_this_iter_s: 8.537536144256592
  time_total_s: 8680.355793952942
  timestamp: 1594857207
  timesteps_since_restore: 4965000
  timesteps_this_iter: 5000
  timesteps_total: 4965000
  training_iteration: 993
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8680 s, 993 iter, 4965000 ts, 322 rew

agent-1: 50.19999999868826
agent-2: 46.19999999868826
agent-3: 50.19999999868826
agent-4: 47.19999999868826
agent-5: 49.19999999868826
Extrinsic Rewards:
7
3
7
4
6
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.16296296296296298
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-53-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.6008741999706
  episode_reward_mean: 316.8498057878087
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 993
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.199
    dispatch_time_ms: 7.823
    learner:
      cur_lr: 0.0010293310042470694
      grad_gnorm: 11.69396686553955
      policy_entropy: 31.900020599365234
      policy_loss: -1.6007429361343384
      var_gnorm: 22.84488868713379
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.09369271248579025
    num_steps_sampled: 4970000
    num_steps_trained: 4970000
    wait_time_ms: 77.226
  iterations_since_restore: 994
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8688.989369869232
  time_this_iter_s: 8.633575916290283
  time_total_s: 8688.989369869232
  timestamp: 1594857216
  timesteps_since_restore: 4970000
  timesteps_this_iter: 5000
  timesteps_total: 4970000
  training_iteration: 994
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8688 s, 994 iter, 4970000 ts, 317 rew

agent-1: 59.99999996138674
agent-2: 48.99999996138674
agent-3: 53.999999961386735
agent-4: 55.999999961386735
agent-5: 50.99999996138674
Extrinsic Rewards:
12
1
6
8
3
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.36
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-53-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.6008741999706
  episode_reward_mean: 316.9398057860541
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 994
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.531
    dispatch_time_ms: 8.75
    learner:
      cur_lr: 0.0010289980564266443
      grad_gnorm: 21.52446746826172
      policy_entropy: 22.503889083862305
      policy_loss: -2.7577927112579346
      var_gnorm: 22.844167709350586
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.3536941111087799
    num_steps_sampled: 4975000
    num_steps_trained: 4975000
    wait_time_ms: 75.234
  iterations_since_restore: 995
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8697.729558706284
  time_this_iter_s: 8.740188837051392
  time_total_s: 8697.729558706284
  timestamp: 1594857224
  timesteps_since_restore: 4975000
  timesteps_this_iter: 5000
  timesteps_total: 4975000
  training_iteration: 995
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8697 s, 995 iter, 4975000 ts, 317 rew

agent-1: 35.19999999913111
agent-2: 45.199999999131066
agent-3: 37.199999999131116
agent-4: 42.19999999913107
agent-5: 38.199999999131094
Extrinsic Rewards:
0
10
2
7
3
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.45454545454545453
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-53-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.6008741999706
  episode_reward_mean: 314.41980579819966
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 995
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.863
    dispatch_time_ms: 8.862
    learner:
      cur_lr: 0.0010286649921908975
      grad_gnorm: 25.92171287536621
      policy_entropy: 22.95366668701172
      policy_loss: -2.1497960090637207
      var_gnorm: 22.84266471862793
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.5063138604164124
    num_steps_sampled: 4980000
    num_steps_trained: 4980000
    wait_time_ms: 74.042
  iterations_since_restore: 996
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8706.358551740646
  time_this_iter_s: 8.628993034362793
  time_total_s: 8706.358551740646
  timestamp: 1594857233
  timesteps_since_restore: 4980000
  timesteps_this_iter: 5000
  timesteps_total: 4980000
  training_iteration: 996
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8706 s, 996 iter, 4980000 ts, 314 rew

agent-1: 107.19999945108086
agent-2: 116.19999945108083
agent-3: 109.19999945108086
agent-4: 118.19999945108086
agent-5: 107.19999945108086
Extrinsic Rewards:
8
17
10
19
8
Sum Reward: 62
Avg Reward: 12.4
Min Reward: 8
Max Reward: 19
Gini Coefficient: 0.2
20:20 Ratio: 2.375
Max-min Ratio: 2.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-54-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 308.933797028754
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 996
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 6.117
    learner:
      cur_lr: 0.0010283320443704724
      grad_gnorm: 40.000003814697266
      policy_entropy: 23.256092071533203
      policy_loss: -6.7168169021606445
      var_gnorm: 22.84136390686035
      vf_explained_var: 0.0
      vf_loss: 2.1818153858184814
    num_steps_sampled: 4985000
    num_steps_trained: 4985000
    wait_time_ms: 81.201
  iterations_since_restore: 997
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8714.991498231888
  time_this_iter_s: 8.632946491241455
  time_total_s: 8714.991498231888
  timestamp: 1594857242
  timesteps_since_restore: 4985000
  timesteps_this_iter: 5000
  timesteps_total: 4985000
  training_iteration: 997
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8714 s, 997 iter, 4985000 ts, 309 rew

agent-1: 137.59998326862024
agent-2: 131.59998326862026
agent-3: 137.59998326862026
agent-4: 136.59998326862024
agent-5: 140.5999832686202
Extrinsic Rewards:
16
10
16
15
19
Sum Reward: 76
Avg Reward: 15.2
Min Reward: 10
Max Reward: 19
Gini Coefficient: 0.1
20:20 Ratio: 1.9
Max-min Ratio: 1.9
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-54-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 310.55379621737313
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 997
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.614
    dispatch_time_ms: 8.292
    learner:
      cur_lr: 0.0010279989801347256
      grad_gnorm: 10.542611122131348
      policy_entropy: 34.534759521484375
      policy_loss: -1.7730571031570435
      var_gnorm: 22.841951370239258
      vf_explained_var: 0.0
      vf_loss: 0.0813707709312439
    num_steps_sampled: 4990000
    num_steps_trained: 4990000
    wait_time_ms: 76.226
  iterations_since_restore: 998
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8723.65813779831
  time_this_iter_s: 8.666639566421509
  time_total_s: 8723.65813779831
  timestamp: 1594857250
  timesteps_since_restore: 4990000
  timesteps_this_iter: 5000
  timesteps_total: 4990000
  training_iteration: 998
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8723 s, 998 iter, 4990000 ts, 311 rew

agent-1: 64.19999998541097
agent-2: 66.19999998541087
agent-3: 68.19999998541088
agent-4: 70.1999999854109
agent-5: 64.19999998541097
Extrinsic Rewards:
5
7
9
11
5
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 5
Max Reward: 11
Gini Coefficient: 0.17297297297297298
20:20 Ratio: 2.2
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-54-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 310.91379621678465
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 998
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 5.306
    learner:
      cur_lr: 0.0010276660323143005
      grad_gnorm: 20.443744659423828
      policy_entropy: 30.792560577392578
      policy_loss: -3.069385528564453
      var_gnorm: 22.840660095214844
      vf_explained_var: 0.0
      vf_loss: 0.3232695758342743
    num_steps_sampled: 4995000
    num_steps_trained: 4995000
    wait_time_ms: 79.764
  iterations_since_restore: 999
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8732.547835588455
  time_this_iter_s: 8.889697790145874
  time_total_s: 8732.547835588455
  timestamp: 1594857259
  timesteps_since_restore: 4995000
  timesteps_this_iter: 5000
  timesteps_total: 4995000
  training_iteration: 999
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8732 s, 999 iter, 4995000 ts, 311 rew

agent-1: 39.59999999892696
agent-2: 35.599999998926975
agent-3: 38.59999999892697
agent-4: 40.59999999892698
agent-5: 34.59999999892698
Extrinsic Rewards:
6
2
5
7
1
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.3047619047619048
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-54-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 311.3637962167512
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 999
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.182
    dispatch_time_ms: 8.538
    learner:
      cur_lr: 0.0010273329680785537
      grad_gnorm: 40.0
      policy_entropy: 14.643643379211426
      policy_loss: 17.6282901763916
      var_gnorm: 22.839948654174805
      vf_explained_var: 0.0
      vf_loss: 34.39408493041992
    num_steps_sampled: 5000000
    num_steps_trained: 5000000
    wait_time_ms: 73.206
  iterations_since_restore: 1000
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8741.206818819046
  time_this_iter_s: 8.65898323059082
  time_total_s: 8741.206818819046
  timestamp: 1594857268
  timesteps_since_restore: 5000000
  timesteps_this_iter: 5000
  timesteps_total: 5000000
  training_iteration: 1000
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8741 s, 1000 iter, 5000000 ts, 311 rew

agent-1: 73.79999986100994
agent-2: 85.79999986100997
agent-3: 78.79999986100997
agent-4: 76.79999986101
agent-5: 71.79999986100997
Extrinsic Rewards:
5
17
10
8
3
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 3
Max Reward: 17
Gini Coefficient: 0.30697674418604654
20:20 Ratio: 5.666666666666667
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-54-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 313.52379620986176
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1000
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.062
    dispatch_time_ms: 8.069
    learner:
      cur_lr: 0.0010270000202581286
      grad_gnorm: 39.999996185302734
      policy_entropy: 28.42747688293457
      policy_loss: -8.42000675201416
      var_gnorm: 22.84113883972168
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.1649107933044434
    num_steps_sampled: 5005000
    num_steps_trained: 5005000
    wait_time_ms: 77.067
  iterations_since_restore: 1001
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8749.823840379715
  time_this_iter_s: 8.617021560668945
  time_total_s: 8749.823840379715
  timestamp: 1594857277
  timesteps_since_restore: 5005000
  timesteps_this_iter: 5000
  timesteps_total: 5005000
  training_iteration: 1001
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8749 s, 1001 iter, 5005000 ts, 314 rew

agent-1: 192.59656410611768
agent-2: 198.59656410611774
agent-3: 189.59656410611768
agent-4: 185.59656410611763
agent-5: 187.59656410611768
Extrinsic Rewards:
23
29
20
16
18
Sum Reward: 106
Avg Reward: 21.2
Min Reward: 16
Max Reward: 29
Gini Coefficient: 0.1169811320754717
20:20 Ratio: 1.8125
Max-min Ratio: 1.8125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-54-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 321.2636244152111
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1001
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.664
    dispatch_time_ms: 7.869
    learner:
      cur_lr: 0.0010266669560223818
      grad_gnorm: 40.0
      policy_entropy: 31.46470832824707
      policy_loss: 23.188533782958984
      var_gnorm: 22.839792251586914
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 21.912601470947266
    num_steps_sampled: 5010000
    num_steps_trained: 5010000
    wait_time_ms: 74.979
  iterations_since_restore: 1002
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8758.384452581406
  time_this_iter_s: 8.560612201690674
  time_total_s: 8758.384452581406
  timestamp: 1594857285
  timesteps_since_restore: 5010000
  timesteps_this_iter: 5000
  timesteps_total: 5010000
  training_iteration: 1002
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8758 s, 1002 iter, 5010000 ts, 321 rew

agent-1: 34.599999998899655
agent-2: 38.59999999889965
agent-3: 35.59999999889965
agent-4: 42.599999998899655
agent-5: 37.59999999889965
Extrinsic Rewards:
1
5
2
9
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3619047619047619
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-54-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 319.73362442444756
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1002
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.857
    dispatch_time_ms: 9.344
    learner:
      cur_lr: 0.0010263340082019567
      grad_gnorm: 27.78982162475586
      policy_entropy: 31.4678955078125
      policy_loss: -4.697233200073242
      var_gnorm: 22.83872413635254
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.5840663313865662
    num_steps_sampled: 5015000
    num_steps_trained: 5015000
    wait_time_ms: 73.758
  iterations_since_restore: 1003
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8766.901157617569
  time_this_iter_s: 8.51670503616333
  time_total_s: 8766.901157617569
  timestamp: 1594857294
  timesteps_since_restore: 5015000
  timesteps_this_iter: 5000
  timesteps_total: 5015000
  training_iteration: 1003
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8766 s, 1003 iter, 5015000 ts, 320 rew

agent-1: 91.39999968277219
agent-2: 101.39999968277219
agent-3: 96.39999968277222
agent-4: 104.39999968277219
agent-5: 92.39999968277213
Extrinsic Rewards:
5
15
10
18
6
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 5
Max Reward: 18
Gini Coefficient: 0.25925925925925924
20:20 Ratio: 3.6
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-55-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 321.71362440887674
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1003
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.698
    dispatch_time_ms: 7.911
    learner:
      cur_lr: 0.0010260009439662099
      grad_gnorm: 16.455806732177734
      policy_entropy: 34.524410247802734
      policy_loss: -2.7303154468536377
      var_gnorm: 22.841915130615234
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.20960287749767303
    num_steps_sampled: 5020000
    num_steps_trained: 5020000
    wait_time_ms: 75.842
  iterations_since_restore: 1004
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8775.439808368683
  time_this_iter_s: 8.538650751113892
  time_total_s: 8775.439808368683
  timestamp: 1594857302
  timesteps_since_restore: 5020000
  timesteps_this_iter: 5000
  timesteps_total: 5020000
  training_iteration: 1004
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8775 s, 1004 iter, 5020000 ts, 322 rew

agent-1: 39.99999999659286
agent-2: 39.99999999659286
agent-3: 41.99999999659285
agent-4: 49.99999999659285
agent-5: 52.99999999659285
Extrinsic Rewards:
0
0
2
10
13
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.576
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-55-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 316.49368266440393
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1004
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 8.591
    learner:
      cur_lr: 0.0010256679961457849
      grad_gnorm: 23.2961483001709
      policy_entropy: 33.962493896484375
      policy_loss: 4.08445930480957
      var_gnorm: 22.837717056274414
      vf_explained_var: 0.0
      vf_loss: 0.43366971611976624
    num_steps_sampled: 5025000
    num_steps_trained: 5025000
    wait_time_ms: 74.427
  iterations_since_restore: 1005
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8784.007636547089
  time_this_iter_s: 8.567828178405762
  time_total_s: 8784.007636547089
  timestamp: 1594857311
  timesteps_since_restore: 5025000
  timesteps_this_iter: 5000
  timesteps_total: 5025000
  training_iteration: 1005
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8784 s, 1005 iter, 5025000 ts, 316 rew

agent-1: 54.59999998130626
agent-2: 50.59999998130627
agent-3: 53.59999998130627
agent-4: 60.59999998130626
agent-5: 59.59999998130626
Extrinsic Rewards:
5
1
4
11
10
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.33548387096774196
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-55-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 314.5136830704024
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1005
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 7.163
    learner:
      cur_lr: 0.0010253350483253598
      grad_gnorm: 40.0
      policy_entropy: 32.82239532470703
      policy_loss: 9.821184158325195
      var_gnorm: 22.83816909790039
      vf_explained_var: 0.0
      vf_loss: 3.7690324783325195
    num_steps_sampled: 5030000
    num_steps_trained: 5030000
    wait_time_ms: 75.23
  iterations_since_restore: 1006
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8792.579436063766
  time_this_iter_s: 8.571799516677856
  time_total_s: 8792.579436063766
  timestamp: 1594857320
  timesteps_since_restore: 5030000
  timesteps_this_iter: 5000
  timesteps_total: 5030000
  training_iteration: 1006
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8792 s, 1006 iter, 5030000 ts, 315 rew

agent-1: 53.79999998569537
agent-2: 57.799999985695386
agent-3: 66.79999998569548
agent-4: 57.799999985695386
agent-5: 60.799999985695386
Extrinsic Rewards:
1
5
14
5
8
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.3515151515151515
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-55-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 312.17368312982956
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1006
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.338
    dispatch_time_ms: 7.203
    learner:
      cur_lr: 0.001025001984089613
      grad_gnorm: 40.000003814697266
      policy_entropy: 31.981395721435547
      policy_loss: 42.003387451171875
      var_gnorm: 22.8348331451416
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 48.23444366455078
    num_steps_sampled: 5035000
    num_steps_trained: 5035000
    wait_time_ms: 71.951
  iterations_since_restore: 1007
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8801.131865501404
  time_this_iter_s: 8.552429437637329
  time_total_s: 8801.131865501404
  timestamp: 1594857328
  timesteps_since_restore: 5035000
  timesteps_this_iter: 5000
  timesteps_total: 5035000
  training_iteration: 1007
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8801 s, 1007 iter, 5035000 ts, 312 rew

agent-1: 61.19999947928407
agent-2: 60.19999947928407
agent-3: 53.19999947928405
agent-4: 56.19999947928407
agent-5: 57.19999947928405
Extrinsic Rewards:
10
9
2
5
6
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.25
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-55-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 310.8236831276018
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1007
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.39
    dispatch_time_ms: 11.477
    learner:
      cur_lr: 0.001024669036269188
      grad_gnorm: 8.98122787475586
      policy_entropy: 34.07337188720703
      policy_loss: 1.3924614191055298
      var_gnorm: 22.836536407470703
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.06283960491418839
    num_steps_sampled: 5040000
    num_steps_trained: 5040000
    wait_time_ms: 70.529
  iterations_since_restore: 1008
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8809.678519487381
  time_this_iter_s: 8.546653985977173
  time_total_s: 8809.678519487381
  timestamp: 1594857337
  timesteps_since_restore: 5040000
  timesteps_this_iter: 5000
  timesteps_total: 5040000
  training_iteration: 1008
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8809 s, 1008 iter, 5040000 ts, 311 rew

agent-1: 98.59999989277956
agent-2: 84.59999989277954
agent-3: 87.59999989277954
agent-4: 91.59999989277954
agent-5: 96.59999989277956
Extrinsic Rewards:
17
3
6
10
15
Sum Reward: 51
Avg Reward: 10.2
Min Reward: 3
Max Reward: 17
Gini Coefficient: 0.2901960784313726
20:20 Ratio: 5.666666666666667
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-55-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 315.234021306037
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1008
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.481
    dispatch_time_ms: 6.182
    learner:
      cur_lr: 0.001024335972033441
      grad_gnorm: 40.0
      policy_entropy: 34.37287139892578
      policy_loss: 24.720645904541016
      var_gnorm: 22.837284088134766
      vf_explained_var: 0.0
      vf_loss: 17.220449447631836
    num_steps_sampled: 5045000
    num_steps_trained: 5045000
    wait_time_ms: 78.573
  iterations_since_restore: 1009
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8818.232685089111
  time_this_iter_s: 8.554165601730347
  time_total_s: 8818.232685089111
  timestamp: 1594857345
  timesteps_since_restore: 5045000
  timesteps_this_iter: 5000
  timesteps_total: 5045000
  training_iteration: 1009
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8818 s, 1009 iter, 5045000 ts, 315 rew

agent-1: 53.39999999661684
agent-2: 52.39999999661685
agent-3: 51.39999999661685
agent-4: 55.39999999661684
agent-5: 48.399999996616856
Extrinsic Rewards:
7
6
5
9
2
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2206896551724138
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-55-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 317.6642860609312
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1009
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.983
    dispatch_time_ms: 8.041
    learner:
      cur_lr: 0.001024003024213016
      grad_gnorm: 22.18576431274414
      policy_entropy: 22.729610443115234
      policy_loss: -2.2824020385742188
      var_gnorm: 22.83585548400879
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.37923121452331543
    num_steps_sampled: 5050000
    num_steps_trained: 5050000
    wait_time_ms: 78.363
  iterations_since_restore: 1010
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8826.835229635239
  time_this_iter_s: 8.60254454612732
  time_total_s: 8826.835229635239
  timestamp: 1594857354
  timesteps_since_restore: 5050000
  timesteps_this_iter: 5000
  timesteps_total: 5050000
  training_iteration: 1010
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8826 s, 1010 iter, 5050000 ts, 318 rew

agent-1: 91.59999909139435
agent-2: 95.59999909139434
agent-3: 91.59999909139434
agent-4: 92.59999909139432
agent-5: 87.59999909139437
Extrinsic Rewards:
10
14
10
11
6
Sum Reward: 51
Avg Reward: 10.2
Min Reward: 6
Max Reward: 14
Gini Coefficient: 0.13333333333333333
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-56-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 322.254286015501
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1010
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.871
    dispatch_time_ms: 9.914
    learner:
      cur_lr: 0.0010236699599772692
      grad_gnorm: 14.937527656555176
      policy_entropy: 12.896734237670898
      policy_loss: 0.8456624746322632
      var_gnorm: 22.837604522705078
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.18159432709217072
    num_steps_sampled: 5055000
    num_steps_trained: 5055000
    wait_time_ms: 73.726
  iterations_since_restore: 1011
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8835.259948253632
  time_this_iter_s: 8.424718618392944
  time_total_s: 8835.259948253632
  timestamp: 1594857362
  timesteps_since_restore: 5055000
  timesteps_this_iter: 5000
  timesteps_total: 5055000
  training_iteration: 1011
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8835 s, 1011 iter, 5055000 ts, 322 rew

agent-1: 40.799999999295586
agent-2: 42.799999999295586
agent-3: 42.799999999295586
agent-4: 40.799999999295586
agent-5: 39.799999999295586
Extrinsic Rewards:
4
6
6
4
3
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 3
Max Reward: 6
Gini Coefficient: 0.1391304347826087
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-56-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 323.21919124618546
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1011
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.596
    dispatch_time_ms: 9.336
    learner:
      cur_lr: 0.0010233370121568441
      grad_gnorm: 40.00000762939453
      policy_entropy: 28.82530403137207
      policy_loss: 13.516496658325195
      var_gnorm: 22.835735321044922
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 11.494391441345215
    num_steps_sampled: 5060000
    num_steps_trained: 5060000
    wait_time_ms: 70.983
  iterations_since_restore: 1012
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8843.797922849655
  time_this_iter_s: 8.53797459602356
  time_total_s: 8843.797922849655
  timestamp: 1594857371
  timesteps_since_restore: 5060000
  timesteps_this_iter: 5000
  timesteps_total: 5060000
  training_iteration: 1012
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8843 s, 1012 iter, 5060000 ts, 323 rew

agent-1: 53.99999998948009
agent-2: 54.99999998948009
agent-3: 49.999999989480095
agent-4: 49.999999989480095
agent-5: 60.999999989480095
Extrinsic Rewards:
6
7
2
2
13
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.36
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-56-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 320.1537583305702
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1012
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.073
    dispatch_time_ms: 8.526
    learner:
      cur_lr: 0.0010230039479210973
      grad_gnorm: 3.941058397293091
      policy_entropy: 33.24435806274414
      policy_loss: -0.5809073448181152
      var_gnorm: 22.833824157714844
      vf_explained_var: 0.0
      vf_loss: 0.010854726657271385
    num_steps_sampled: 5065000
    num_steps_trained: 5065000
    wait_time_ms: 76.46
  iterations_since_restore: 1013
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8852.255675792694
  time_this_iter_s: 8.45775294303894
  time_total_s: 8852.255675792694
  timestamp: 1594857380
  timesteps_since_restore: 5065000
  timesteps_this_iter: 5000
  timesteps_total: 5065000
  training_iteration: 1013
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8852 s, 1013 iter, 5065000 ts, 320 rew

agent-1: 70.39999997960159
agent-2: 68.3999999796016
agent-3: 68.3999999796016
agent-4: 73.39999997960159
agent-5: 70.39999997960159
Extrinsic Rewards:
8
6
6
11
8
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 6
Max Reward: 11
Gini Coefficient: 0.12307692307692308
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-56-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1106.1321239548752
  episode_reward_mean: 319.07375836628546
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1013
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.199
    dispatch_time_ms: 7.8
    learner:
      cur_lr: 0.0010226710001006722
      grad_gnorm: 39.999996185302734
      policy_entropy: 34.572105407714844
      policy_loss: 14.02525806427002
      var_gnorm: 22.83555030822754
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.187004566192627
    num_steps_sampled: 5070000
    num_steps_trained: 5070000
    wait_time_ms: 75.087
  iterations_since_restore: 1014
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8860.682755231857
  time_this_iter_s: 8.427079439163208
  time_total_s: 8860.682755231857
  timestamp: 1594857388
  timesteps_since_restore: 5070000
  timesteps_this_iter: 5000
  timesteps_total: 5070000
  training_iteration: 1014
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8860 s, 1014 iter, 5070000 ts, 319 rew

agent-1: 55.9999999958169
agent-2: 50.99999999581689
agent-3: 53.9999999958169
agent-4: 56.9999999958169
agent-5: 51.99999999581689
Extrinsic Rewards:
8
3
6
9
4
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.21333333333333335
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-56-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 953.9828205305903
  episode_reward_mean: 310.7124371265276
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1014
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 8.086
    learner:
      cur_lr: 0.0010223380522802472
      grad_gnorm: 6.747447490692139
      policy_entropy: 25.093303680419922
      policy_loss: -0.592461884021759
      var_gnorm: 22.83336067199707
      vf_explained_var: 0.0
      vf_loss: 0.031936995685100555
    num_steps_sampled: 5075000
    num_steps_trained: 5075000
    wait_time_ms: 76.294
  iterations_since_restore: 1015
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8869.155967712402
  time_this_iter_s: 8.473212480545044
  time_total_s: 8869.155967712402
  timestamp: 1594857396
  timesteps_since_restore: 5075000
  timesteps_this_iter: 5000
  timesteps_total: 5075000
  training_iteration: 1015
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8869 s, 1015 iter, 5075000 ts, 311 rew

agent-1: 43.5999999816657
agent-2: 48.59999998166568
agent-3: 50.59999998166568
agent-4: 47.59999998166568
agent-5: 43.5999999816657
Extrinsic Rewards:
2
7
9
6
2
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2923076923076923
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-56-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 953.9828205305903
  episode_reward_mean: 310.0824371260811
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1015
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.463
    dispatch_time_ms: 9.602
    learner:
      cur_lr: 0.0010220049880445004
      grad_gnorm: 15.61127758026123
      policy_entropy: 17.220439910888672
      policy_loss: -1.0445326566696167
      var_gnorm: 22.834945678710938
      vf_explained_var: 0.0
      vf_loss: 0.18640375137329102
    num_steps_sampled: 5080000
    num_steps_trained: 5080000
    wait_time_ms: 70.835
  iterations_since_restore: 1016
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8877.667824029922
  time_this_iter_s: 8.511856317520142
  time_total_s: 8877.667824029922
  timestamp: 1594857405
  timesteps_since_restore: 5080000
  timesteps_this_iter: 5000
  timesteps_total: 5080000
  training_iteration: 1016
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8877 s, 1016 iter, 5080000 ts, 310 rew

agent-1: 45.39999999666119
agent-2: 39.39999999666119
agent-3: 42.399999996661194
agent-4: 42.399999996661194
agent-5: 46.399999996661194
Extrinsic Rewards:
7
1
4
4
8
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.2833333333333333
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-56-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 953.9828205305903
  episode_reward_mean: 310.0824371264342
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1016
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.701
    dispatch_time_ms: 6.889
    learner:
      cur_lr: 0.0010216720402240753
      grad_gnorm: 40.000003814697266
      policy_entropy: 12.737736701965332
      policy_loss: 25.25581169128418
      var_gnorm: 22.834707260131836
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 141.90719604492188
    num_steps_sampled: 5085000
    num_steps_trained: 5085000
    wait_time_ms: 75.786
  iterations_since_restore: 1017
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8886.271985530853
  time_this_iter_s: 8.604161500930786
  time_total_s: 8886.271985530853
  timestamp: 1594857414
  timesteps_since_restore: 5085000
  timesteps_this_iter: 5000
  timesteps_total: 5085000
  training_iteration: 1017
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8886 s, 1017 iter, 5085000 ts, 310 rew

agent-1: 42.799999999030746
agent-2: 43.79999999903075
agent-3: 38.79999999903076
agent-4: 36.79999999903076
agent-5: 44.79999999903074
Extrinsic Rewards:
6
7
2
0
8
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.3652173913043478
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-57-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 953.9828205305903
  episode_reward_mean: 309.6324371272252
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1017
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 7.578
    learner:
      cur_lr: 0.0010213389759883285
      grad_gnorm: 18.155475616455078
      policy_entropy: 15.977575302124023
      policy_loss: -1.3266518115997314
      var_gnorm: 22.839170455932617
      vf_explained_var: 0.0
      vf_loss: 0.23665332794189453
    num_steps_sampled: 5090000
    num_steps_trained: 5090000
    wait_time_ms: 77.042
  iterations_since_restore: 1018
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8894.776238918304
  time_this_iter_s: 8.504253387451172
  time_total_s: 8894.776238918304
  timestamp: 1594857422
  timesteps_since_restore: 5090000
  timesteps_this_iter: 5000
  timesteps_total: 5090000
  training_iteration: 1018
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8894 s, 1018 iter, 5090000 ts, 310 rew

agent-1: 204.19548376738038
agent-2: 199.19548376738035
agent-3: 207.19548376738038
agent-4: 195.1954837673804
agent-5: 202.19548376738035
Extrinsic Rewards:
25
20
28
16
23
Sum Reward: 112
Avg Reward: 22.4
Min Reward: 16
Max Reward: 28
Gini Coefficient: 0.10357142857142858
20:20 Ratio: 1.75
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-57-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 315.30221131793746
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1018
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.576
    dispatch_time_ms: 10.265
    learner:
      cur_lr: 0.0010210060281679034
      grad_gnorm: 23.176895141601562
      policy_entropy: 24.01721954345703
      policy_loss: -2.9035656452178955
      var_gnorm: 22.83102798461914
      vf_explained_var: 0.0
      vf_loss: 0.40550777316093445
    num_steps_sampled: 5095000
    num_steps_trained: 5095000
    wait_time_ms: 74.431
  iterations_since_restore: 1019
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8903.405302286148
  time_this_iter_s: 8.629063367843628
  time_total_s: 8903.405302286148
  timestamp: 1594857431
  timesteps_since_restore: 5095000
  timesteps_this_iter: 5000
  timesteps_total: 5095000
  training_iteration: 1019
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8903 s, 1019 iter, 5095000 ts, 315 rew

agent-1: 89.39999982642198
agent-2: 101.39999982642198
agent-3: 102.39999982642199
agent-4: 94.39999982642198
agent-5: 98.39999982642199
Extrinsic Rewards:
3
15
16
8
12
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 3
Max Reward: 16
Gini Coefficient: 0.24444444444444444
20:20 Ratio: 5.333333333333333
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-57-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 318.00221130936893
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1019
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.823
    dispatch_time_ms: 8.47
    learner:
      cur_lr: 0.0010206729639321566
      grad_gnorm: 19.95515251159668
      policy_entropy: 13.30620288848877
      policy_loss: -1.110483169555664
      var_gnorm: 22.833574295043945
      vf_explained_var: 0.0
      vf_loss: 0.3076331615447998
    num_steps_sampled: 5100000
    num_steps_trained: 5100000
    wait_time_ms: 74.956
  iterations_since_restore: 1020
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8912.115639209747
  time_this_iter_s: 8.710336923599243
  time_total_s: 8912.115639209747
  timestamp: 1594857440
  timesteps_since_restore: 5100000
  timesteps_this_iter: 5000
  timesteps_total: 5100000
  training_iteration: 1020
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8912 s, 1020 iter, 5100000 ts, 318 rew

agent-1: 54.39999999413637
agent-2: 49.39999999413636
agent-3: 50.399999994136365
agent-4: 48.39999999413636
agent-5: 58.39999999413637
Extrinsic Rewards:
8
3
4
2
12
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.3448275862068966
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-57-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 317.64221130934396
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1020
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.219
    dispatch_time_ms: 7.756
    learner:
      cur_lr: 0.0010203400161117315
      grad_gnorm: 31.62797737121582
      policy_entropy: 33.6049919128418
      policy_loss: -5.269796848297119
      var_gnorm: 22.830778121948242
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.7449684739112854
    num_steps_sampled: 5105000
    num_steps_trained: 5105000
    wait_time_ms: 76.726
  iterations_since_restore: 1021
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8920.672206401825
  time_this_iter_s: 8.556567192077637
  time_total_s: 8920.672206401825
  timestamp: 1594857448
  timesteps_since_restore: 5105000
  timesteps_this_iter: 5000
  timesteps_total: 5105000
  training_iteration: 1021
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8920 s, 1021 iter, 5105000 ts, 318 rew

agent-1: 85.79999824958398
agent-2: 92.79999824958401
agent-3: 87.799998249584
agent-4: 78.79999824958395
agent-5: 86.79999824958396
Extrinsic Rewards:
9
16
11
2
10
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.25
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-57-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 318.8122112221724
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1021
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.621
    dispatch_time_ms: 9.562
    learner:
      cur_lr: 0.0010200069518759847
      grad_gnorm: 18.222135543823242
      policy_entropy: 27.505470275878906
      policy_loss: -2.211275339126587
      var_gnorm: 22.83490753173828
      vf_explained_var: 0.0
      vf_loss: 0.2563838064670563
    num_steps_sampled: 5110000
    num_steps_trained: 5110000
    wait_time_ms: 74.823
  iterations_since_restore: 1022
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8929.155045747757
  time_this_iter_s: 8.482839345932007
  time_total_s: 8929.155045747757
  timestamp: 1594857457
  timesteps_since_restore: 5110000
  timesteps_this_iter: 5000
  timesteps_total: 5110000
  training_iteration: 1022
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8929 s, 1022 iter, 5110000 ts, 319 rew

agent-1: 57.599999997410556
agent-2: 54.599999997410556
agent-3: 55.599999997410556
agent-4: 52.599999997410556
agent-5: 58.599999997410556
Extrinsic Rewards:
8
5
6
3
9
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.1935483870967742
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-57-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 318.00221122671894
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1022
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.075
    dispatch_time_ms: 6.909
    learner:
      cur_lr: 0.0010196740040555596
      grad_gnorm: 19.470842361450195
      policy_entropy: 33.445926666259766
      policy_loss: -3.5335097312927246
      var_gnorm: 22.83376693725586
      vf_explained_var: 0.0
      vf_loss: 0.2865960896015167
    num_steps_sampled: 5115000
    num_steps_trained: 5115000
    wait_time_ms: 77.113
  iterations_since_restore: 1023
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8937.716672182083
  time_this_iter_s: 8.561626434326172
  time_total_s: 8937.716672182083
  timestamp: 1594857465
  timesteps_since_restore: 5115000
  timesteps_this_iter: 5000
  timesteps_total: 5115000
  training_iteration: 1023
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8937 s, 1023 iter, 5115000 ts, 318 rew

agent-1: 78.39999959495648
agent-2: 76.39999959495648
agent-3: 91.3999995949565
agent-4: 73.39999959495647
agent-5: 76.39999959495647
Extrinsic Rewards:
8
6
21
3
6
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 3
Max Reward: 21
Gini Coefficient: 0.34545454545454546
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-57-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 319.3522112065577
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1023
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.405
    dispatch_time_ms: 8.984
    learner:
      cur_lr: 0.0010193410562351346
      grad_gnorm: 40.0
      policy_entropy: 33.87760543823242
      policy_loss: 10.664362907409668
      var_gnorm: 22.83038330078125
      vf_explained_var: 0.0
      vf_loss: 3.0546953678131104
    num_steps_sampled: 5120000
    num_steps_trained: 5120000
    wait_time_ms: 74.358
  iterations_since_restore: 1024
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8946.40153169632
  time_this_iter_s: 8.68485951423645
  time_total_s: 8946.40153169632
  timestamp: 1594857474
  timesteps_since_restore: 5120000
  timesteps_this_iter: 5000
  timesteps_total: 5120000
  training_iteration: 1024
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8946 s, 1024 iter, 5120000 ts, 319 rew

agent-1: 27.599999999477976
agent-2: 25.599999999477976
agent-3: 34.5999999994782
agent-4: 26.599999999477976
agent-5: 29.599999999477976
Extrinsic Rewards:
2
0
9
1
4
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.525
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-58-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 318.7222112065962
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1024
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.282
    dispatch_time_ms: 8.122
    learner:
      cur_lr: 0.0010190079919993877
      grad_gnorm: 18.821258544921875
      policy_entropy: 25.219507217407227
      policy_loss: -2.1840200424194336
      var_gnorm: 22.829347610473633
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.27276191115379333
    num_steps_sampled: 5125000
    num_steps_trained: 5125000
    wait_time_ms: 72.772
  iterations_since_restore: 1025
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8954.953274011612
  time_this_iter_s: 8.551742315292358
  time_total_s: 8954.953274011612
  timestamp: 1594857483
  timesteps_since_restore: 5125000
  timesteps_this_iter: 5000
  timesteps_total: 5125000
  training_iteration: 1025
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8954 s, 1025 iter, 5125000 ts, 319 rew

agent-1: 60.59999998488428
agent-2: 53.599999984884285
agent-3: 53.599999984884285
agent-4: 52.599999984884285
agent-5: 58.59999998488428
Extrinsic Rewards:
11
4
4
3
9
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.2709677419354839
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-58-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 318.1822112061334
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1025
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.199
    dispatch_time_ms: 9.174
    learner:
      cur_lr: 0.0010186750441789627
      grad_gnorm: 40.0
      policy_entropy: 29.64276885986328
      policy_loss: 39.511940002441406
      var_gnorm: 22.828113555908203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 79.37399291992188
    num_steps_sampled: 5130000
    num_steps_trained: 5130000
    wait_time_ms: 71.789
  iterations_since_restore: 1026
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8963.62577867508
  time_this_iter_s: 8.672504663467407
  time_total_s: 8963.62577867508
  timestamp: 1594857491
  timesteps_since_restore: 5130000
  timesteps_this_iter: 5000
  timesteps_total: 5130000
  training_iteration: 1026
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8963 s, 1026 iter, 5130000 ts, 318 rew

agent-1: 61.19999999800016
agent-2: 56.19999999800016
agent-3: 57.19999999800016
agent-4: 58.19999999800016
agent-5: 55.19999999800016
Extrinsic Rewards:
10
5
6
7
4
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 4
Max Reward: 10
Gini Coefficient: 0.175
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-58-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 318.27221120949406
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1026
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.591
    dispatch_time_ms: 7.285
    learner:
      cur_lr: 0.0010183419799432158
      grad_gnorm: 14.236884117126465
      policy_entropy: 30.95514488220215
      policy_loss: -2.4948177337646484
      var_gnorm: 22.825088500976562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.15263597667217255
    num_steps_sampled: 5135000
    num_steps_trained: 5135000
    wait_time_ms: 78.186
  iterations_since_restore: 1027
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8982.633213996887
  time_this_iter_s: 19.00743532180786
  time_total_s: 8982.633213996887
  timestamp: 1594857510
  timesteps_since_restore: 5135000
  timesteps_this_iter: 5000
  timesteps_total: 5135000
  training_iteration: 1027
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8982 s, 1027 iter, 5135000 ts, 318 rew

agent-1: 111.99999956084031
agent-2: 102.99999956084034
agent-3: 88.99999956084031
agent-4: 96.99999956084034
agent-5: 93.99999956084032
Extrinsic Rewards:
24
15
1
9
6
Sum Reward: 55
Avg Reward: 11.0
Min Reward: 1
Max Reward: 24
Gini Coefficient: 0.4
20:20 Ratio: 24.0
Max-min Ratio: 24.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-58-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 319.98221118983497
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1027
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.854
    dispatch_time_ms: 8.033
    learner:
      cur_lr: 0.0010180090321227908
      grad_gnorm: 40.0
      policy_entropy: 32.532958984375
      policy_loss: 37.75864791870117
      var_gnorm: 22.825027465820312
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 32.07085037231445
    num_steps_sampled: 5140000
    num_steps_trained: 5140000
    wait_time_ms: 73.656
  iterations_since_restore: 1028
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8991.225129365921
  time_this_iter_s: 8.591915369033813
  time_total_s: 8991.225129365921
  timestamp: 1594857519
  timesteps_since_restore: 5140000
  timesteps_this_iter: 5000
  timesteps_total: 5140000
  training_iteration: 1028
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8991 s, 1028 iter, 5140000 ts, 320 rew

agent-1: 41.59999999804303
agent-2: 45.59999999804302
agent-3: 52.59999999804302
agent-4: 50.59999999804303
agent-5: 43.59999999804302
Extrinsic Rewards:
0
4
11
9
2
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.4461538461538462
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-58-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 318.36221119489323
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1028
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.656
    dispatch_time_ms: 6.564
    learner:
      cur_lr: 0.001017675967887044
      grad_gnorm: 19.182283401489258
      policy_entropy: 26.398395538330078
      policy_loss: -2.23490047454834
      var_gnorm: 22.825496673583984
      vf_explained_var: 0.0
      vf_loss: 0.2805496156215668
    num_steps_sampled: 5145000
    num_steps_trained: 5145000
    wait_time_ms: 79.334
  iterations_since_restore: 1029
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 8999.76764535904
  time_this_iter_s: 8.542515993118286
  time_total_s: 8999.76764535904
  timestamp: 1594857528
  timesteps_since_restore: 5145000
  timesteps_this_iter: 5000
  timesteps_total: 5145000
  training_iteration: 1029
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 8999 s, 1029 iter, 5145000 ts, 318 rew

agent-1: 92.39999995255373
agent-2: 87.39999995255373
agent-3: 84.39999995255373
agent-4: 93.3999999525537
agent-5: 83.39999995255373
Extrinsic Rewards:
14
9
6
15
5
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 5
Max Reward: 15
Gini Coefficient: 0.22857142857142856
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-58-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 319.53221119454037
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1029
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.014
    dispatch_time_ms: 8.392
    learner:
      cur_lr: 0.001017343020066619
      grad_gnorm: 40.000003814697266
      policy_entropy: 29.81801986694336
      policy_loss: 39.116676330566406
      var_gnorm: 22.825664520263672
      vf_explained_var: 0.0
      vf_loss: 52.066287994384766
    num_steps_sampled: 5150000
    num_steps_trained: 5150000
    wait_time_ms: 77.253
  iterations_since_restore: 1030
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9008.273761034012
  time_this_iter_s: 8.506115674972534
  time_total_s: 9008.273761034012
  timestamp: 1594857536
  timesteps_since_restore: 5150000
  timesteps_this_iter: 5000
  timesteps_total: 5150000
  training_iteration: 1030
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9008 s, 1030 iter, 5150000 ts, 320 rew

agent-1: 30.19999999826696
agent-2: 27.199999998266957
agent-3: 31.199999998266957
agent-4: 32.19999999826691
agent-5: 32.199999998266904
Extrinsic Rewards:
3
0
4
5
5
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 5
Gini Coefficient: 0.2823529411764706
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-59-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 318.7222111946267
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1030
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 20.559
    learner:
      cur_lr: 0.001017009955830872
      grad_gnorm: 40.0
      policy_entropy: 21.674957275390625
      policy_loss: 24.02977752685547
      var_gnorm: 22.82353973388672
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 49.340877532958984
    num_steps_sampled: 5155000
    num_steps_trained: 5155000
    wait_time_ms: 31.247
  iterations_since_restore: 1031
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9017.138643980026
  time_this_iter_s: 8.864882946014404
  time_total_s: 9017.138643980026
  timestamp: 1594857545
  timesteps_since_restore: 5155000
  timesteps_this_iter: 5000
  timesteps_total: 5155000
  training_iteration: 1031
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9017 s, 1031 iter, 5155000 ts, 319 rew

agent-1: 77.7999998774271
agent-2: 75.7999998774271
agent-3: 82.79999987742704
agent-4: 70.79999987742711
agent-5: 79.79999987742711
Extrinsic Rewards:
9
7
14
2
11
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.26046511627906976
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-59-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 319.89221118874974
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1031
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.852
    dispatch_time_ms: 21.674
    learner:
      cur_lr: 0.001016677008010447
      grad_gnorm: 33.77020263671875
      policy_entropy: 33.55564880371094
      policy_loss: 6.842799663543701
      var_gnorm: 22.822681427001953
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.8997456431388855
    num_steps_sampled: 5160000
    num_steps_trained: 5160000
    wait_time_ms: 70.335
  iterations_since_restore: 1032
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9026.137726545334
  time_this_iter_s: 8.999082565307617
  time_total_s: 9026.137726545334
  timestamp: 1594857554
  timesteps_since_restore: 5160000
  timesteps_this_iter: 5000
  timesteps_total: 5160000
  training_iteration: 1032
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9026 s, 1032 iter, 5160000 ts, 320 rew

agent-1: 122.19945481337295
agent-2: 113.19945481337295
agent-3: 115.19945481337295
agent-4: 125.19945481337298
agent-5: 127.19945481337298
Extrinsic Rewards:
15
6
8
18
20
Sum Reward: 67
Avg Reward: 13.4
Min Reward: 6
Max Reward: 20
Gini Coefficient: 0.22686567164179106
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-59-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 323.67218392947524
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1032
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.668
    dispatch_time_ms: 16.268
    learner:
      cur_lr: 0.0010163439437747002
      grad_gnorm: 8.40239429473877
      policy_entropy: 0.9938579201698303
      policy_loss: -0.007390955928713083
      var_gnorm: 22.821998596191406
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.054629020392894745
    num_steps_sampled: 5165000
    num_steps_trained: 5165000
    wait_time_ms: 67.809
  iterations_since_restore: 1033
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9035.017583370209
  time_this_iter_s: 8.879856824874878
  time_total_s: 9035.017583370209
  timestamp: 1594857563
  timesteps_since_restore: 5165000
  timesteps_this_iter: 5000
  timesteps_total: 5165000
  training_iteration: 1033
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9035 s, 1033 iter, 5165000 ts, 324 rew

agent-1: 59.59999998350729
agent-2: 58.5999999835073
agent-3: 55.59999998350729
agent-4: 53.59999998350729
agent-5: 51.59999998350729
Extrinsic Rewards:
10
9
6
4
2
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.2709677419354839
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-59-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 324.6621839294692
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1033
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.683
    dispatch_time_ms: 27.875
    learner:
      cur_lr: 0.0010160109959542751
      grad_gnorm: 24.883922576904297
      policy_entropy: 1.6858744621276855
      policy_loss: 0.03314334899187088
      var_gnorm: 22.82105827331543
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.4924471080303192
    num_steps_sampled: 5170000
    num_steps_trained: 5170000
    wait_time_ms: 53.552
  iterations_since_restore: 1034
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9043.611132860184
  time_this_iter_s: 8.593549489974976
  time_total_s: 9043.611132860184
  timestamp: 1594857572
  timesteps_since_restore: 5170000
  timesteps_this_iter: 5000
  timesteps_total: 5170000
  training_iteration: 1034
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9043 s, 1034 iter, 5170000 ts, 325 rew

agent-1: 10.30598717299231
agent-2: 12.305987172992317
agent-3: 14.305987172992316
agent-4: 10.30598717299231
agent-5: 11.30598717299231
Extrinsic Rewards:
0
2
4
0
1
Sum Reward: 7
Avg Reward: 1.4
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.5714285714285714
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-59-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 323.71748328814755
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1034
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.819
    dispatch_time_ms: 29.82
    learner:
      cur_lr: 0.00101567804813385
      grad_gnorm: 40.0
      policy_entropy: 14.454473495483398
      policy_loss: 5.07492733001709
      var_gnorm: 22.81797218322754
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.206399917602539
    num_steps_sampled: 5175000
    num_steps_trained: 5175000
    wait_time_ms: 50.003
  iterations_since_restore: 1035
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9052.140133142471
  time_this_iter_s: 8.529000282287598
  time_total_s: 9052.140133142471
  timestamp: 1594857580
  timesteps_since_restore: 5175000
  timesteps_this_iter: 5000
  timesteps_total: 5175000
  training_iteration: 1035
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9052 s, 1035 iter, 5175000 ts, 324 rew

agent-1: 53.06718999782932
agent-2: 63.06718999782932
agent-3: 54.06718999782934
agent-4: 54.06718999782933
agent-5: 50.067189997829324
Extrinsic Rewards:
5
15
6
6
2
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.3176470588235294
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-59-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 322.3208427992654
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1035
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.008
    dispatch_time_ms: 51.266
    learner:
      cur_lr: 0.0010153449838981032
      grad_gnorm: 23.412979125976562
      policy_entropy: 24.038724899291992
      policy_loss: -6.690505027770996
      var_gnorm: 22.829620361328125
      vf_explained_var: 0.0
      vf_loss: 0.5065416693687439
    num_steps_sampled: 5180000
    num_steps_trained: 5180000
    wait_time_ms: 38.179
  iterations_since_restore: 1036
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9061.016003370285
  time_this_iter_s: 8.87587022781372
  time_total_s: 9061.016003370285
  timestamp: 1594857589
  timesteps_since_restore: 5180000
  timesteps_this_iter: 5000
  timesteps_total: 5180000
  training_iteration: 1036
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9061 s, 1036 iter, 5180000 ts, 322 rew

agent-1: 75.99980773185939
agent-2: 79.99980773185936
agent-3: 63.999807731859505
agent-4: 72.99980773185939
agent-5: 66.99980773185932
Extrinsic Rewards:
12
16
0
9
3
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 0
Max Reward: 16
Gini Coefficient: 0.41
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_19-59-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 317.82083793257135
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1036
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.825
    dispatch_time_ms: 22.959
    learner:
      cur_lr: 0.0010150120360776782
      grad_gnorm: 39.7347526550293
      policy_entropy: 33.79315948486328
      policy_loss: -6.259746074676514
      var_gnorm: 22.82338523864746
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.1404335498809814
    num_steps_sampled: 5185000
    num_steps_trained: 5185000
    wait_time_ms: 66.922
  iterations_since_restore: 1037
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9069.806218862534
  time_this_iter_s: 8.790215492248535
  time_total_s: 9069.806218862534
  timestamp: 1594857598
  timesteps_since_restore: 5185000
  timesteps_this_iter: 5000
  timesteps_total: 5185000
  training_iteration: 1037
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9069 s, 1037 iter, 5185000 ts, 318 rew

agent-1: 63.999270987876194
agent-2: 67.99927098787617
agent-3: 57.99927098787621
agent-4: 64.99927098787617
agent-5: 59.99927098787621
Extrinsic Rewards:
8
12
2
9
4
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.2857142857142857
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-00-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 318.8108014820991
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1037
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.049
    dispatch_time_ms: 24.725
    learner:
      cur_lr: 0.0010146789718419313
      grad_gnorm: 29.432905197143555
      policy_entropy: 33.12699508666992
      policy_loss: -4.83548641204834
      var_gnorm: 22.820011138916016
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.6578627228736877
    num_steps_sampled: 5190000
    num_steps_trained: 5190000
    wait_time_ms: 63.379
  iterations_since_restore: 1038
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9078.88998055458
  time_this_iter_s: 9.08376169204712
  time_total_s: 9078.88998055458
  timestamp: 1594857607
  timesteps_since_restore: 5190000
  timesteps_this_iter: 5000
  timesteps_total: 5190000
  training_iteration: 1038
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9078 s, 1038 iter, 5190000 ts, 319 rew

agent-1: 49.79999995881126
agent-2: 49.799999958811256
agent-3: 50.799999958811256
agent-4: 50.79999995881126
agent-5: 50.799999958811256
Extrinsic Rewards:
5
5
6
6
6
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 5
Max Reward: 6
Gini Coefficient: 0.04285714285714286
20:20 Ratio: 1.2
Max-min Ratio: 1.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-00-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 316.389969124063
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1038
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.898
    dispatch_time_ms: 9.26
    learner:
      cur_lr: 0.0010143460240215063
      grad_gnorm: 40.0
      policy_entropy: 33.96206283569336
      policy_loss: 7.737354755401611
      var_gnorm: 22.82061004638672
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 1.560328483581543
    num_steps_sampled: 5195000
    num_steps_trained: 5195000
    wait_time_ms: 73.364
  iterations_since_restore: 1039
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9087.44905948639
  time_this_iter_s: 8.559078931808472
  time_total_s: 9087.44905948639
  timestamp: 1594857616
  timesteps_since_restore: 5195000
  timesteps_this_iter: 5000
  timesteps_total: 5195000
  training_iteration: 1039
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9087 s, 1039 iter, 5195000 ts, 316 rew

agent-1: 84.59999995166379
agent-2: 79.5999999516638
agent-3: 94.59999995166376
agent-4: 78.59999995166378
agent-5: 76.59999995166378
Extrinsic Rewards:
11
6
21
5
3
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 3
Max Reward: 21
Gini Coefficient: 0.3652173913043478
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-00-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 318.729969122098
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1039
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.63
    dispatch_time_ms: 31.849
    learner:
      cur_lr: 0.0010140129597857594
      grad_gnorm: 3.9800612926483154
      policy_entropy: 34.56604766845703
      policy_loss: 1.6477330923080444
      var_gnorm: 22.823760986328125
      vf_explained_var: 0.0
      vf_loss: 0.02865186147391796
    num_steps_sampled: 5200000
    num_steps_trained: 5200000
    wait_time_ms: 67.738
  iterations_since_restore: 1040
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9096.629625082016
  time_this_iter_s: 9.180565595626831
  time_total_s: 9096.629625082016
  timestamp: 1594857625
  timesteps_since_restore: 5200000
  timesteps_this_iter: 5000
  timesteps_total: 5200000
  training_iteration: 1040
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9096 s, 1040 iter, 5200000 ts, 319 rew

agent-1: 67.99999996283094
agent-2: 75.99999996283096
agent-3: 71.99999996283093
agent-4: 66.99999996283096
agent-5: 76.99999996283096
Extrinsic Rewards:
4
12
8
3
13
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.28
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-00-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 319.4499691219668
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1040
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.104
    dispatch_time_ms: 24.351
    learner:
      cur_lr: 0.0010136800119653344
      grad_gnorm: 23.485685348510742
      policy_entropy: 31.96323013305664
      policy_loss: -3.049354076385498
      var_gnorm: 22.821382522583008
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.402058869600296
    num_steps_sampled: 5205000
    num_steps_trained: 5205000
    wait_time_ms: 65.612
  iterations_since_restore: 1041
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9105.492382764816
  time_this_iter_s: 8.862757682800293
  time_total_s: 9105.492382764816
  timestamp: 1594857634
  timesteps_since_restore: 5205000
  timesteps_this_iter: 5000
  timesteps_total: 5205000
  training_iteration: 1041
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9105 s, 1041 iter, 5205000 ts, 319 rew

agent-1: 57.599999997469546
agent-2: 52.59999999746957
agent-3: 53.59999999746955
agent-4: 61.599999997469546
agent-5: 53.59999999746955
Extrinsic Rewards:
8
3
4
12
4
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.2838709677419355
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-00-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 318.18996913051393
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1041
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.465
    dispatch_time_ms: 32.48
    learner:
      cur_lr: 0.0010133469477295876
      grad_gnorm: 24.765626907348633
      policy_entropy: 25.928852081298828
      policy_loss: -5.813375473022461
      var_gnorm: 22.81817626953125
      vf_explained_var: 0.0
      vf_loss: 0.48402300477027893
    num_steps_sampled: 5210000
    num_steps_trained: 5210000
    wait_time_ms: 71.17
  iterations_since_restore: 1042
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9114.82157254219
  time_this_iter_s: 9.329189777374268
  time_total_s: 9114.82157254219
  timestamp: 1594857643
  timesteps_since_restore: 5210000
  timesteps_this_iter: 5000
  timesteps_total: 5210000
  training_iteration: 1042
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9114 s, 1042 iter, 5210000 ts, 318 rew

agent-1: 127.19997006081996
agent-2: 109.19997006082
agent-3: 120.19997006082002
agent-4: 124.19997006081988
agent-5: 122.19997006082002
Extrinsic Rewards:
20
2
13
17
15
Sum Reward: 67
Avg Reward: 13.4
Min Reward: 2
Max Reward: 20
Gini Coefficient: 0.23880597014925373
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-00-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 322.68996763357495
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1042
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.37
    dispatch_time_ms: 29.328
    learner:
      cur_lr: 0.0010130139999091625
      grad_gnorm: 34.15107727050781
      policy_entropy: 13.698959350585938
      policy_loss: -0.867997407913208
      var_gnorm: 22.82145118713379
      vf_explained_var: 0.0
      vf_loss: 0.8171520233154297
    num_steps_sampled: 5215000
    num_steps_trained: 5215000
    wait_time_ms: 69.337
  iterations_since_restore: 1043
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9123.81860756874
  time_this_iter_s: 8.997035026550293
  time_total_s: 9123.81860756874
  timestamp: 1594857652
  timesteps_since_restore: 5215000
  timesteps_this_iter: 5000
  timesteps_total: 5215000
  training_iteration: 1043
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9123 s, 1043 iter, 5215000 ts, 323 rew

agent-1: 37.39999999888307
agent-2: 35.39999999888307
agent-3: 35.39999999888307
agent-4: 31.399999998883104
agent-5: 31.399999998883104
Extrinsic Rewards:
7
5
5
1
1
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.3368421052631579
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-01-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 322.2399676335857
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1043
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.826
    dispatch_time_ms: 22.873
    learner:
      cur_lr: 0.0010126810520887375
      grad_gnorm: 18.89389991760254
      policy_entropy: 19.06774139404297
      policy_loss: -1.6444848775863647
      var_gnorm: 22.8219051361084
      vf_explained_var: 0.0
      vf_loss: 0.2760452926158905
    num_steps_sampled: 5220000
    num_steps_trained: 5220000
    wait_time_ms: 73.274
  iterations_since_restore: 1044
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9132.896925210953
  time_this_iter_s: 9.078317642211914
  time_total_s: 9132.896925210953
  timestamp: 1594857661
  timesteps_since_restore: 5220000
  timesteps_this_iter: 5000
  timesteps_total: 5220000
  training_iteration: 1044
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9132 s, 1044 iter, 5220000 ts, 322 rew

agent-1: 78.99999993459973
agent-2: 85.99999993459969
agent-3: 85.9999999345997
agent-4: 75.99999993459971
agent-5: 77.99999993459973
Extrinsic Rewards:
7
14
14
4
6
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 4
Max Reward: 14
Gini Coefficient: 0.24888888888888888
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-01-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 324.1299676304541
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1044
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.674
    dispatch_time_ms: 23.934
    learner:
      cur_lr: 0.0010123479878529906
      grad_gnorm: 24.22376251220703
      policy_entropy: 18.57117462158203
      policy_loss: -2.284379482269287
      var_gnorm: 22.82023811340332
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.45352792739868164
    num_steps_sampled: 5225000
    num_steps_trained: 5225000
    wait_time_ms: 59.619
  iterations_since_restore: 1045
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9141.972513914108
  time_this_iter_s: 9.075588703155518
  time_total_s: 9141.972513914108
  timestamp: 1594857670
  timesteps_since_restore: 5225000
  timesteps_this_iter: 5000
  timesteps_total: 5225000
  training_iteration: 1045
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9141 s, 1045 iter, 5225000 ts, 324 rew

agent-1: 78.39999997070039
agent-2: 78.39999997070039
agent-3: 81.39999997070042
agent-4: 81.39999997070039
agent-5: 76.3999999707004
Extrinsic Rewards:
8
8
11
11
6
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 6
Max Reward: 11
Gini Coefficient: 0.11818181818181818
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-01-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 325.5699676292375
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1045
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.822
    dispatch_time_ms: 28.406
    learner:
      cur_lr: 0.0010120150400325656
      grad_gnorm: 12.608685493469238
      policy_entropy: 34.6473274230957
      policy_loss: -1.726319670677185
      var_gnorm: 22.822099685668945
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.12265612185001373
    num_steps_sampled: 5230000
    num_steps_trained: 5230000
    wait_time_ms: 58.604
  iterations_since_restore: 1046
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9151.034857749939
  time_this_iter_s: 9.062343835830688
  time_total_s: 9151.034857749939
  timestamp: 1594857680
  timesteps_since_restore: 5230000
  timesteps_this_iter: 5000
  timesteps_total: 5230000
  training_iteration: 1046
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9151 s, 1046 iter, 5230000 ts, 326 rew

agent-1: 68.39999999578797
agent-2: 60.399999995787795
agent-3: 62.399999995787795
agent-4: 58.399999995787795
agent-5: 56.399999995787795
Extrinsic Rewards:
14
6
8
4
2
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.32941176470588235
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-01-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 327.0999676290484
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1046
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.457
    dispatch_time_ms: 7.559
    learner:
      cur_lr: 0.0010116819757968187
      grad_gnorm: 15.296833038330078
      policy_entropy: 32.31943130493164
      policy_loss: -2.7984392642974854
      var_gnorm: 22.819292068481445
      vf_explained_var: 0.0
      vf_loss: 0.1522209197282791
    num_steps_sampled: 5235000
    num_steps_trained: 5235000
    wait_time_ms: 75.654
  iterations_since_restore: 1047
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9159.967255353928
  time_this_iter_s: 8.932397603988647
  time_total_s: 9159.967255353928
  timestamp: 1594857689
  timesteps_since_restore: 5235000
  timesteps_this_iter: 5000
  timesteps_total: 5235000
  training_iteration: 1047
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9159 s, 1047 iter, 5235000 ts, 327 rew

agent-1: 35.39999999900272
agent-2: 34.39999999900272
agent-3: 32.39999999900272
agent-4: 34.39999999900273
agent-5: 34.39999999900272
Extrinsic Rewards:
5
4
2
4
4
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.12631578947368421
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-01-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 323.58996771588943
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1047
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.839
    dispatch_time_ms: 7.983
    learner:
      cur_lr: 0.0010113490279763937
      grad_gnorm: 13.235917091369629
      policy_entropy: 33.82750701904297
      policy_loss: -1.9785115718841553
      var_gnorm: 22.820035934448242
      vf_explained_var: 0.0
      vf_loss: 0.12759162485599518
    num_steps_sampled: 5240000
    num_steps_trained: 5240000
    wait_time_ms: 76.382
  iterations_since_restore: 1048
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9168.46802163124
  time_this_iter_s: 8.500766277313232
  time_total_s: 9168.46802163124
  timestamp: 1594857697
  timesteps_since_restore: 5240000
  timesteps_this_iter: 5000
  timesteps_total: 5240000
  training_iteration: 1048
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9168 s, 1048 iter, 5240000 ts, 324 rew

agent-1: 37.19999999840431
agent-2: 42.1999999984043
agent-3: 36.1999999984043
agent-4: 43.19999999840431
agent-5: 39.19999999840431
Extrinsic Rewards:
2
7
1
8
4
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.34545454545454546
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-01-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 322.5099677291854
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1048
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 8.273
    learner:
      cur_lr: 0.0010110159637406468
      grad_gnorm: 15.248992919921875
      policy_entropy: 23.78091812133789
      policy_loss: -2.119077205657959
      var_gnorm: 22.818286895751953
      vf_explained_var: 0.0
      vf_loss: 0.17647568881511688
    num_steps_sampled: 5245000
    num_steps_trained: 5245000
    wait_time_ms: 74.611
  iterations_since_restore: 1049
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9177.095011234283
  time_this_iter_s: 8.626989603042603
  time_total_s: 9177.095011234283
  timestamp: 1594857706
  timesteps_since_restore: 5245000
  timesteps_this_iter: 5000
  timesteps_total: 5245000
  training_iteration: 1049
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9177 s, 1049 iter, 5245000 ts, 323 rew

agent-1: 38.199999998842436
agent-2: 36.19999999884245
agent-3: 40.199999998842436
agent-4: 44.199999998842436
agent-5: 39.19999999884243
Extrinsic Rewards:
3
1
5
9
4
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.32727272727272727
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-01-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 321.6999677293922
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1049
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.516
    dispatch_time_ms: 6.43
    learner:
      cur_lr: 0.0010106830159202218
      grad_gnorm: 12.578706741333008
      policy_entropy: 28.468271255493164
      policy_loss: -1.2029317617416382
      var_gnorm: 22.820905685424805
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.12186402827501297
    num_steps_sampled: 5250000
    num_steps_trained: 5250000
    wait_time_ms: 75.917
  iterations_since_restore: 1050
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9185.709912538528
  time_this_iter_s: 8.614901304244995
  time_total_s: 9185.709912538528
  timestamp: 1594857714
  timesteps_since_restore: 5250000
  timesteps_this_iter: 5000
  timesteps_total: 5250000
  training_iteration: 1050
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9185 s, 1050 iter, 5250000 ts, 322 rew

agent-1: 45.59999999703837
agent-2: 44.59999999703837
agent-3: 52.59999999703835
agent-4: 46.59999999703835
agent-5: 44.59999999703835
Extrinsic Rewards:
4
3
11
5
3
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.27692307692307694
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-02-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 320.07996777878316
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1050
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.909
    dispatch_time_ms: 8.944
    learner:
      cur_lr: 0.001010349951684475
      grad_gnorm: 19.417951583862305
      policy_entropy: 22.132583618164062
      policy_loss: -1.4258594512939453
      var_gnorm: 22.8181095123291
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2702679932117462
    num_steps_sampled: 5255000
    num_steps_trained: 5255000
    wait_time_ms: 74.284
  iterations_since_restore: 1051
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9194.362023830414
  time_this_iter_s: 8.652111291885376
  time_total_s: 9194.362023830414
  timestamp: 1594857723
  timesteps_since_restore: 5255000
  timesteps_this_iter: 5000
  timesteps_total: 5255000
  training_iteration: 1051
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9194 s, 1051 iter, 5255000 ts, 320 rew

agent-1: 66.39999996291357
agent-2: 80.39999996291358
agent-3: 68.39999996291354
agent-4: 65.39999996291358
agent-5: 70.39999996291357
Extrinsic Rewards:
4
18
6
3
8
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 3
Max Reward: 18
Gini Coefficient: 0.3487179487179487
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-02-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 320.7099677772188
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1051
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.998
    dispatch_time_ms: 8.701
    learner:
      cur_lr: 0.00101001700386405
      grad_gnorm: 40.0
      policy_entropy: 17.20744514465332
      policy_loss: 4.027868747711182
      var_gnorm: 22.822402954101562
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.9720596075057983
    num_steps_sampled: 5260000
    num_steps_trained: 5260000
    wait_time_ms: 74.093
  iterations_since_restore: 1052
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9203.016946077347
  time_this_iter_s: 8.654922246932983
  time_total_s: 9203.016946077347
  timestamp: 1594857732
  timesteps_since_restore: 5260000
  timesteps_this_iter: 5000
  timesteps_total: 5260000
  training_iteration: 1052
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9203 s, 1052 iter, 5260000 ts, 321 rew

agent-1: 60.99999999809872
agent-2: 52.99999999809872
agent-3: 52.99999999809873
agent-4: 52.99999999809873
agent-5: 49.99999999809872
Extrinsic Rewards:
13
5
5
5
2
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.29333333333333333
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-02-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 321.5199677772197
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1052
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.498
    dispatch_time_ms: 5.995
    learner:
      cur_lr: 0.0010096840560436249
      grad_gnorm: 12.790181159973145
      policy_entropy: 24.276365280151367
      policy_loss: -1.999455451965332
      var_gnorm: 22.81751823425293
      vf_explained_var: 0.0
      vf_loss: 0.11815275251865387
    num_steps_sampled: 5265000
    num_steps_trained: 5265000
    wait_time_ms: 77.268
  iterations_since_restore: 1053
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9211.586681604385
  time_this_iter_s: 8.569735527038574
  time_total_s: 9211.586681604385
  timestamp: 1594857740
  timesteps_since_restore: 5265000
  timesteps_this_iter: 5000
  timesteps_total: 5265000
  training_iteration: 1053
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9211 s, 1053 iter, 5265000 ts, 322 rew

agent-1: 39.199999998006575
agent-2: 40.19999999800657
agent-3: 40.19999999800656
agent-4: 38.19999999800657
agent-5: 40.199999998006575
Extrinsic Rewards:
4
5
5
3
5
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 3
Max Reward: 5
Gini Coefficient: 0.09090909090909091
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-02-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 320.9799677772274
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1053
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.127
    dispatch_time_ms: 7.756
    learner:
      cur_lr: 0.001009350991807878
      grad_gnorm: 12.70848274230957
      policy_entropy: 10.407137870788574
      policy_loss: -0.28643807768821716
      var_gnorm: 22.821680068969727
      vf_explained_var: 0.0
      vf_loss: 0.12413369119167328
    num_steps_sampled: 5270000
    num_steps_trained: 5270000
    wait_time_ms: 74.332
  iterations_since_restore: 1054
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9220.253326892853
  time_this_iter_s: 8.666645288467407
  time_total_s: 9220.253326892853
  timestamp: 1594857749
  timesteps_since_restore: 5270000
  timesteps_this_iter: 5000
  timesteps_total: 5270000
  training_iteration: 1054
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9220 s, 1054 iter, 5270000 ts, 321 rew

agent-1: 72.5999999819656
agent-2: 68.5999999819656
agent-3: 74.59999998196558
agent-4: 72.59999998196561
agent-5: 80.5999999819656
Extrinsic Rewards:
7
3
9
7
15
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 3
Max Reward: 15
Gini Coefficient: 0.25365853658536586
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-02-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 321.8799677764985
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1054
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.978
    dispatch_time_ms: 8.784
    learner:
      cur_lr: 0.001009018043987453
      grad_gnorm: 32.6263427734375
      policy_entropy: 8.729924201965332
      policy_loss: -1.3981108665466309
      var_gnorm: 22.818370819091797
      vf_explained_var: 0.0
      vf_loss: 0.8210616111755371
    num_steps_sampled: 5275000
    num_steps_trained: 5275000
    wait_time_ms: 76.393
  iterations_since_restore: 1055
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9228.902879714966
  time_this_iter_s: 8.649552822113037
  time_total_s: 9228.902879714966
  timestamp: 1594857758
  timesteps_since_restore: 5275000
  timesteps_this_iter: 5000
  timesteps_total: 5275000
  training_iteration: 1055
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9228 s, 1055 iter, 5275000 ts, 322 rew

agent-1: 84.79999443706006
agent-2: 94.79999443706006
agent-3: 103.79999443706009
agent-4: 99.79999443706009
agent-5: 93.79999443706006
Extrinsic Rewards:
0
10
19
15
9
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 0
Max Reward: 19
Gini Coefficient: 0.3320754716981132
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-02-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 323.94996749857137
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1055
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.178
    dispatch_time_ms: 12.722
    learner:
      cur_lr: 0.0010086849797517061
      grad_gnorm: 18.46690559387207
      policy_entropy: 3.4741904735565186
      policy_loss: 0.07457509636878967
      var_gnorm: 22.82296371459961
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.27148810029029846
    num_steps_sampled: 5280000
    num_steps_trained: 5280000
    wait_time_ms: 69.56
  iterations_since_restore: 1056
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9248.452661514282
  time_this_iter_s: 19.549781799316406
  time_total_s: 9248.452661514282
  timestamp: 1594857777
  timesteps_since_restore: 5280000
  timesteps_this_iter: 5000
  timesteps_total: 5280000
  training_iteration: 1056
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9248 s, 1056 iter, 5280000 ts, 324 rew

agent-1: 30.19999999924042
agent-2: 29.199999999240415
agent-3: 27.199999999240408
agent-4: 33.19999999924037
agent-5: 33.19999999924037
Extrinsic Rewards:
3
2
0
6
6
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.3764705882352941
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-03-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 319.7204818258091
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1056
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.654
    dispatch_time_ms: 33.584
    learner:
      cur_lr: 0.001008352031931281
      grad_gnorm: 40.0
      policy_entropy: 16.339561462402344
      policy_loss: 7.145561218261719
      var_gnorm: 22.8245792388916
      vf_explained_var: 0.0
      vf_loss: 5.586411476135254
    num_steps_sampled: 5285000
    num_steps_trained: 5285000
    wait_time_ms: 52.982
  iterations_since_restore: 1057
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9257.213493585587
  time_this_iter_s: 8.760832071304321
  time_total_s: 9257.213493585587
  timestamp: 1594857786
  timesteps_since_restore: 5285000
  timesteps_this_iter: 5000
  timesteps_total: 5285000
  training_iteration: 1057
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9257 s, 1057 iter, 5285000 ts, 320 rew

agent-1: 131.736875728124
agent-2: 144.736875728124
agent-3: 130.736875728124
agent-4: 122.73687572812385
agent-5: 126.73687572812388
Extrinsic Rewards:
15
28
14
6
10
Sum Reward: 73
Avg Reward: 14.6
Min Reward: 6
Max Reward: 28
Gini Coefficient: 0.2684931506849315
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-03-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 322.86732563344367
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1057
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.471
    dispatch_time_ms: 23.031
    learner:
      cur_lr: 0.0010080189676955342
      grad_gnorm: 39.999996185302734
      policy_entropy: 9.130770683288574
      policy_loss: 12.572062492370605
      var_gnorm: 22.822551727294922
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 27.847578048706055
    num_steps_sampled: 5290000
    num_steps_trained: 5290000
    wait_time_ms: 57.09
  iterations_since_restore: 1058
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9266.382070302963
  time_this_iter_s: 9.168576717376709
  time_total_s: 9266.382070302963
  timestamp: 1594857795
  timesteps_since_restore: 5290000
  timesteps_this_iter: 5000
  timesteps_total: 5290000
  training_iteration: 1058
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9266 s, 1058 iter, 5290000 ts, 323 rew

agent-1: 72.3999998671135
agent-2: 69.39999986711345
agent-3: 68.39999986711341
agent-4: 69.39999986711345
agent-5: 71.39999986711346
Extrinsic Rewards:
10
7
6
7
9
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 6
Max Reward: 10
Gini Coefficient: 0.10256410256410256
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-03-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 324.39732562684526
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1058
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.304
    dispatch_time_ms: 8.095
    learner:
      cur_lr: 0.0010076860198751092
      grad_gnorm: 40.000003814697266
      policy_entropy: 24.920562744140625
      policy_loss: -7.94404411315918
      var_gnorm: 22.83625602722168
      vf_explained_var: 0.0
      vf_loss: 2.603825330734253
    num_steps_sampled: 5295000
    num_steps_trained: 5295000
    wait_time_ms: 74.063
  iterations_since_restore: 1059
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9275.115550041199
  time_this_iter_s: 8.733479738235474
  time_total_s: 9275.115550041199
  timestamp: 1594857804
  timesteps_since_restore: 5295000
  timesteps_this_iter: 5000
  timesteps_total: 5295000
  training_iteration: 1059
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9275 s, 1059 iter, 5295000 ts, 324 rew

agent-1: 158.9992651311749
agent-2: 161.99926513117495
agent-3: 161.99926513117492
agent-4: 163.9992651311749
agent-5: 162.99926513117492
Extrinsic Rewards:
15
18
18
20
19
Sum Reward: 90
Avg Reward: 18.0
Min Reward: 15
Max Reward: 20
Gini Coefficient: 0.04888888888888889
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-03-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 332.2275650354862
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1059
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.663
    dispatch_time_ms: 8.559
    learner:
      cur_lr: 0.0010073529556393623
      grad_gnorm: 26.42752456665039
      policy_entropy: 28.114688873291016
      policy_loss: 3.202863931655884
      var_gnorm: 22.827116012573242
      vf_explained_var: 0.0
      vf_loss: 0.5556108355522156
    num_steps_sampled: 5300000
    num_steps_trained: 5300000
    wait_time_ms: 74.596
  iterations_since_restore: 1060
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9283.693561315536
  time_this_iter_s: 8.578011274337769
  time_total_s: 9283.693561315536
  timestamp: 1594857813
  timesteps_since_restore: 5300000
  timesteps_this_iter: 5000
  timesteps_total: 5300000
  training_iteration: 1060
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9283 s, 1060 iter, 5300000 ts, 332 rew

agent-1: 80.59999997560828
agent-2: 68.59999997560828
agent-3: 70.5999999756083
agent-4: 72.5999999756083
agent-5: 76.59999997560826
Extrinsic Rewards:
15
3
5
7
11
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 3
Max Reward: 15
Gini Coefficient: 0.2926829268292683
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-03-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 335.9175650342666
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1060
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.274
    dispatch_time_ms: 8.262
    learner:
      cur_lr: 0.0010070200078189373
      grad_gnorm: 26.099946975708008
      policy_entropy: 25.01043128967285
      policy_loss: -2.637038469314575
      var_gnorm: 22.846097946166992
      vf_explained_var: 0.0
      vf_loss: 0.5152137279510498
    num_steps_sampled: 5305000
    num_steps_trained: 5305000
    wait_time_ms: 71.677
  iterations_since_restore: 1061
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9292.077731132507
  time_this_iter_s: 8.384169816970825
  time_total_s: 9292.077731132507
  timestamp: 1594857821
  timesteps_since_restore: 5305000
  timesteps_this_iter: 5000
  timesteps_total: 5305000
  training_iteration: 1061
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9292 s, 1061 iter, 5305000 ts, 336 rew

agent-1: 53.999999996546784
agent-2: 47.99999999654679
agent-3: 50.99999999654679
agent-4: 57.99999999654678
agent-5: 58.99999999654678
Extrinsic Rewards:
6
0
3
10
11
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.38666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-03-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 337.6283364314179
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1061
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 5.958
    learner:
      cur_lr: 0.0010066869435831904
      grad_gnorm: 20.544692993164062
      policy_entropy: 20.78782081604004
      policy_loss: -1.1214208602905273
      var_gnorm: 22.847328186035156
      vf_explained_var: 0.0
      vf_loss: 0.30414584279060364
    num_steps_sampled: 5310000
    num_steps_trained: 5310000
    wait_time_ms: 72.795
  iterations_since_restore: 1062
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9300.577345609665
  time_this_iter_s: 8.499614477157593
  time_total_s: 9300.577345609665
  timestamp: 1594857830
  timesteps_since_restore: 5310000
  timesteps_this_iter: 5000
  timesteps_total: 5310000
  training_iteration: 1062
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9300 s, 1062 iter, 5310000 ts, 338 rew

agent-1: 125.59999947034021
agent-2: 117.5999994703402
agent-3: 119.59999947034018
agent-4: 113.59999947034021
agent-5: 117.5999994703402
Extrinsic Rewards:
20
12
14
8
12
Sum Reward: 66
Avg Reward: 13.2
Min Reward: 8
Max Reward: 20
Gini Coefficient: 0.15757575757575756
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-03-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 335.7849818725254
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1062
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.113
    dispatch_time_ms: 5.754
    learner:
      cur_lr: 0.0010063539957627654
      grad_gnorm: 23.653892517089844
      policy_entropy: 17.81786346435547
      policy_loss: -2.913663387298584
      var_gnorm: 22.844562530517578
      vf_explained_var: 0.0
      vf_loss: 0.41543376445770264
    num_steps_sampled: 5315000
    num_steps_trained: 5315000
    wait_time_ms: 76.375
  iterations_since_restore: 1063
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9309.052969932556
  time_this_iter_s: 8.475624322891235
  time_total_s: 9309.052969932556
  timestamp: 1594857838
  timesteps_since_restore: 5315000
  timesteps_this_iter: 5000
  timesteps_total: 5315000
  training_iteration: 1063
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9309 s, 1063 iter, 5315000 ts, 336 rew

agent-1: 46.59999999589692
agent-2: 45.59999999589692
agent-3: 47.59999999589694
agent-4: 43.59999999589694
agent-5: 50.59999999589694
Extrinsic Rewards:
5
4
6
2
9
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.24615384615384617
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-04-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 334.8849818728762
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1063
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.524
    dispatch_time_ms: 8.31
    learner:
      cur_lr: 0.0010060210479423404
      grad_gnorm: 15.065335273742676
      policy_entropy: 14.77623176574707
      policy_loss: -0.5901475548744202
      var_gnorm: 22.84783363342285
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.17097507417201996
    num_steps_sampled: 5320000
    num_steps_trained: 5320000
    wait_time_ms: 73.578
  iterations_since_restore: 1064
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9317.51258444786
  time_this_iter_s: 8.459614515304565
  time_total_s: 9317.51258444786
  timestamp: 1594857847
  timesteps_since_restore: 5320000
  timesteps_this_iter: 5000
  timesteps_total: 5320000
  training_iteration: 1064
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9317 s, 1064 iter, 5320000 ts, 335 rew

agent-1: 61.399999988153176
agent-2: 56.399999988153176
agent-3: 66.39999998815317
agent-4: 57.399999988153176
agent-5: 64.39999998815321
Extrinsic Rewards:
7
2
12
3
10
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.3176470588235294
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-04-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 336.0549818723376
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1064
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 9.375
    learner:
      cur_lr: 0.0010056879837065935
      grad_gnorm: 30.814449310302734
      policy_entropy: 30.335763931274414
      policy_loss: -5.1566081047058105
      var_gnorm: 22.83778190612793
      vf_explained_var: 0.0
      vf_loss: 0.647818922996521
    num_steps_sampled: 5325000
    num_steps_trained: 5325000
    wait_time_ms: 74.195
  iterations_since_restore: 1065
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9325.992692232132
  time_this_iter_s: 8.48010778427124
  time_total_s: 9325.992692232132
  timestamp: 1594857855
  timesteps_since_restore: 5325000
  timesteps_this_iter: 5000
  timesteps_total: 5325000
  training_iteration: 1065
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9325 s, 1065 iter, 5325000 ts, 336 rew

agent-1: 114.59999734701347
agent-2: 123.59999734701347
agent-3: 109.5999973470135
agent-4: 127.59999734701344
agent-5: 118.59999734701347
Extrinsic Rewards:
9
18
4
22
13
Sum Reward: 66
Avg Reward: 13.2
Min Reward: 4
Max Reward: 22
Gini Coefficient: 0.2727272727272727
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-04-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 338.5749817594941
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1065
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 7.684
    learner:
      cur_lr: 0.0010053550358861685
      grad_gnorm: 40.00000762939453
      policy_entropy: 16.612546920776367
      policy_loss: 17.193559646606445
      var_gnorm: 22.84281349182129
      vf_explained_var: 0.0
      vf_loss: 20.996904373168945
    num_steps_sampled: 5330000
    num_steps_trained: 5330000
    wait_time_ms: 73.58
  iterations_since_restore: 1066
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9334.589300632477
  time_this_iter_s: 8.596608400344849
  time_total_s: 9334.589300632477
  timestamp: 1594857864
  timesteps_since_restore: 5330000
  timesteps_this_iter: 5000
  timesteps_total: 5330000
  training_iteration: 1066
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9334 s, 1066 iter, 5330000 ts, 339 rew

agent-1: 68.79999999505509
agent-2: 74.79999999505513
agent-3: 64.79999999505507
agent-4: 60.799999995055224
agent-5: 72.79999999505513
Extrinsic Rewards:
8
14
4
0
12
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.37894736842105264
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-04-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 339.8349817593212
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1066
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.039
    dispatch_time_ms: 9.081
    learner:
      cur_lr: 0.0010050219716504216
      grad_gnorm: 18.771251678466797
      policy_entropy: 32.98721694946289
      policy_loss: -3.0071516036987305
      var_gnorm: 22.83805274963379
      vf_explained_var: 0.0
      vf_loss: 0.2530949115753174
    num_steps_sampled: 5335000
    num_steps_trained: 5335000
    wait_time_ms: 72.711
  iterations_since_restore: 1067
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9342.918466091156
  time_this_iter_s: 8.3291654586792
  time_total_s: 9342.918466091156
  timestamp: 1594857872
  timesteps_since_restore: 5335000
  timesteps_this_iter: 5000
  timesteps_total: 5335000
  training_iteration: 1067
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9342 s, 1067 iter, 5335000 ts, 340 rew

agent-1: 98.79999963389275
agent-2: 101.79999963389272
agent-3: 110.79999963389267
agent-4: 102.79999963389275
agent-5: 107.7999996338927
Extrinsic Rewards:
6
9
18
10
15
Sum Reward: 58
Avg Reward: 11.6
Min Reward: 6
Max Reward: 18
Gini Coefficient: 0.20689655172413793
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-04-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 341.45498174787014
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1067
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.898
    dispatch_time_ms: 6.304
    learner:
      cur_lr: 0.0010046890238299966
      grad_gnorm: 16.07594108581543
      policy_entropy: 33.68186569213867
      policy_loss: -2.202242374420166
      var_gnorm: 22.842121124267578
      vf_explained_var: 0.0
      vf_loss: 0.1848061978816986
    num_steps_sampled: 5340000
    num_steps_trained: 5340000
    wait_time_ms: 77.762
  iterations_since_restore: 1068
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9351.318207979202
  time_this_iter_s: 8.399741888046265
  time_total_s: 9351.318207979202
  timestamp: 1594857881
  timesteps_since_restore: 5340000
  timesteps_this_iter: 5000
  timesteps_total: 5340000
  training_iteration: 1068
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9351 s, 1068 iter, 5340000 ts, 341 rew

agent-1: 55.19999999332653
agent-2: 60.19999999332652
agent-3: 52.19999999332653
agent-4: 66.19999999332673
agent-5: 54.19999999332653
Extrinsic Rewards:
4
9
1
15
3
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 1
Max Reward: 15
Gini Coefficient: 0.425
20:20 Ratio: 15.0
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-04-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 342.17498174765257
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1068
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.54
    dispatch_time_ms: 10.26
    learner:
      cur_lr: 0.0010043559595942497
      grad_gnorm: 17.42778778076172
      policy_entropy: 19.17643928527832
      policy_loss: -0.7126379609107971
      var_gnorm: 22.840314865112305
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2138766050338745
    num_steps_sampled: 5345000
    num_steps_trained: 5345000
    wait_time_ms: 76.725
  iterations_since_restore: 1069
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9359.845014095306
  time_this_iter_s: 8.526806116104126
  time_total_s: 9359.845014095306
  timestamp: 1594857889
  timesteps_since_restore: 5345000
  timesteps_this_iter: 5000
  timesteps_total: 5345000
  training_iteration: 1069
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9359 s, 1069 iter, 5345000 ts, 342 rew

agent-1: 50.99999995248871
agent-2: 48.999999952488714
agent-3: 53.9999999524887
agent-4: 64.99999995248868
agent-5: 50.99999995248871
Extrinsic Rewards:
3
1
6
17
3
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 1
Max Reward: 17
Gini Coefficient: 0.4666666666666667
20:20 Ratio: 17.0
Max-min Ratio: 17.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-04-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 337.58498258603527
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1069
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.961
    dispatch_time_ms: 7.755
    learner:
      cur_lr: 0.0010040230117738247
      grad_gnorm: 14.565431594848633
      policy_entropy: 17.624269485473633
      policy_loss: -1.571548581123352
      var_gnorm: 22.840824127197266
      vf_explained_var: 0.0
      vf_loss: 0.16151492297649384
    num_steps_sampled: 5350000
    num_steps_trained: 5350000
    wait_time_ms: 80.333
  iterations_since_restore: 1070
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9368.542064905167
  time_this_iter_s: 8.69705080986023
  time_total_s: 9368.542064905167
  timestamp: 1594857898
  timesteps_since_restore: 5350000
  timesteps_this_iter: 5000
  timesteps_total: 5350000
  training_iteration: 1070
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9368 s, 1070 iter, 5350000 ts, 338 rew

agent-1: 32.39999999920982
agent-2: 35.39999999920982
agent-3: 33.399999999209825
agent-4: 37.39999999920981
agent-5: 32.39999999920982
Extrinsic Rewards:
2
5
3
7
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.2736842105263158
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-05-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 335.1549825871383
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1070
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 6.239
    learner:
      cur_lr: 0.0010036899475380778
      grad_gnorm: 12.697602272033691
      policy_entropy: 10.245329856872559
      policy_loss: -0.6111176013946533
      var_gnorm: 22.83951759338379
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.12349630892276764
    num_steps_sampled: 5355000
    num_steps_trained: 5355000
    wait_time_ms: 79.097
  iterations_since_restore: 1071
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9377.178010463715
  time_this_iter_s: 8.635945558547974
  time_total_s: 9377.178010463715
  timestamp: 1594857907
  timesteps_since_restore: 5355000
  timesteps_this_iter: 5000
  timesteps_total: 5355000
  training_iteration: 1071
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9377 s, 1071 iter, 5355000 ts, 335 rew

agent-1: 58.19999999709243
agent-2: 61.199999997092426
agent-3: 57.19999999709244
agent-4: 56.19999999709244
agent-5: 55.199999997092426
Extrinsic Rewards:
7
10
6
5
4
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 4
Max Reward: 10
Gini Coefficient: 0.175
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-05-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 335.2449825871656
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1071
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 8.394
    learner:
      cur_lr: 0.0010033569997176528
      grad_gnorm: 40.0
      policy_entropy: 13.407320976257324
      policy_loss: 15.13011646270752
      var_gnorm: 22.83942222595215
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 103.02400970458984
    num_steps_sampled: 5360000
    num_steps_trained: 5360000
    wait_time_ms: 75.238
  iterations_since_restore: 1072
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9385.878357887268
  time_this_iter_s: 8.700347423553467
  time_total_s: 9385.878357887268
  timestamp: 1594857915
  timesteps_since_restore: 5360000
  timesteps_this_iter: 5000
  timesteps_total: 5360000
  training_iteration: 1072
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9385 s, 1072 iter, 5360000 ts, 335 rew

agent-1: 38.59999999673382
agent-2: 34.599999996733835
agent-3: 44.59999999673385
agent-4: 35.599999996733835
agent-5: 35.599999996733835
Extrinsic Rewards:
5
1
11
2
2
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.4380952380952381
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-05-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 334.70498258718004
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1072
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.458
    dispatch_time_ms: 9.587
    learner:
      cur_lr: 0.0010030240518972278
      grad_gnorm: 38.21815872192383
      policy_entropy: 34.503353118896484
      policy_loss: -6.771186828613281
      var_gnorm: 22.854902267456055
      vf_explained_var: 0.0
      vf_loss: 1.126792073249817
    num_steps_sampled: 5365000
    num_steps_trained: 5365000
    wait_time_ms: 74.208
  iterations_since_restore: 1073
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9394.43058013916
  time_this_iter_s: 8.55222225189209
  time_total_s: 9394.43058013916
  timestamp: 1594857924
  timesteps_since_restore: 5365000
  timesteps_this_iter: 5000
  timesteps_total: 5365000
  training_iteration: 1073
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9394 s, 1073 iter, 5365000 ts, 335 rew

agent-1: 147.19998874981928
agent-2: 148.19998874981934
agent-3: 155.19998874981928
agent-4: 142.1999887498193
agent-5: 145.19998874981937
Extrinsic Rewards:
16
17
24
11
14
Sum Reward: 82
Avg Reward: 16.4
Min Reward: 11
Max Reward: 24
Gini Coefficient: 0.14146341463414633
20:20 Ratio: 2.1818181818181817
Max-min Ratio: 2.1818181818181817
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-05-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 340.104982024715
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1073
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 7.567
    learner:
      cur_lr: 0.001002690987661481
      grad_gnorm: 14.285317420959473
      policy_entropy: 34.442501068115234
      policy_loss: -2.323698043823242
      var_gnorm: 22.856019973754883
      vf_explained_var: 0.0
      vf_loss: 0.1543700248003006
    num_steps_sampled: 5370000
    num_steps_trained: 5370000
    wait_time_ms: 74.569
  iterations_since_restore: 1074
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9402.997918128967
  time_this_iter_s: 8.567337989807129
  time_total_s: 9402.997918128967
  timestamp: 1594857933
  timesteps_since_restore: 5370000
  timesteps_this_iter: 5000
  timesteps_total: 5370000
  training_iteration: 1074
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9402 s, 1074 iter, 5370000 ts, 340 rew

agent-1: 44.59999999878146
agent-2: 37.599999998781456
agent-3: 34.59999999878146
agent-4: 34.59999999878146
agent-5: 37.599999998781456
Extrinsic Rewards:
11
4
1
1
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.4380952380952381
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-05-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 340.01498202474716
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1074
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.594
    dispatch_time_ms: 7.531
    learner:
      cur_lr: 0.0010023580398410559
      grad_gnorm: 10.887526512145996
      policy_entropy: 26.109195709228516
      policy_loss: -1.2342581748962402
      var_gnorm: 22.855436325073242
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.08824978023767471
    num_steps_sampled: 5375000
    num_steps_trained: 5375000
    wait_time_ms: 74.623
  iterations_since_restore: 1075
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9411.550839424133
  time_this_iter_s: 8.552921295166016
  time_total_s: 9411.550839424133
  timestamp: 1594857941
  timesteps_since_restore: 5375000
  timesteps_this_iter: 5000
  timesteps_total: 5375000
  training_iteration: 1075
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9411 s, 1075 iter, 5375000 ts, 340 rew

agent-1: 30.79999999927658
agent-2: 31.799999999276572
agent-3: 32.79999999927651
agent-4: 33.7999999992765
agent-5: 32.79999999927651
Extrinsic Rewards:
2
3
4
5
4
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.15555555555555556
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-05-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 339.3849820250447
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1075
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.061
    dispatch_time_ms: 27.663
    learner:
      cur_lr: 0.001002024975605309
      grad_gnorm: 28.983753204345703
      policy_entropy: 34.45752716064453
      policy_loss: 7.010193347930908
      var_gnorm: 22.856613159179688
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.6265645623207092
    num_steps_sampled: 5380000
    num_steps_trained: 5380000
    wait_time_ms: 62.232
  iterations_since_restore: 1076
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9420.578568458557
  time_this_iter_s: 9.027729034423828
  time_total_s: 9420.578568458557
  timestamp: 1594857950
  timesteps_since_restore: 5380000
  timesteps_this_iter: 5000
  timesteps_total: 5380000
  training_iteration: 1076
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9420 s, 1076 iter, 5380000 ts, 339 rew

agent-1: 49.59999999368597
agent-2: 45.59999999368597
agent-3: 44.59999999368597
agent-4: 42.59999999368596
agent-5: 51.599999993685955
Extrinsic Rewards:
8
4
3
1
10
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.35384615384615387
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-05-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 336.2349911272174
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1076
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.647
    dispatch_time_ms: 28.082
    learner:
      cur_lr: 0.001001692027784884
      grad_gnorm: 13.65119743347168
      policy_entropy: 21.253585815429688
      policy_loss: 0.8879533410072327
      var_gnorm: 22.859582901000977
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.14170366525650024
    num_steps_sampled: 5385000
    num_steps_trained: 5385000
    wait_time_ms: 59.986
  iterations_since_restore: 1077
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9429.69724702835
  time_this_iter_s: 9.118678569793701
  time_total_s: 9429.69724702835
  timestamp: 1594857959
  timesteps_since_restore: 5385000
  timesteps_this_iter: 5000
  timesteps_total: 5385000
  training_iteration: 1077
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9429 s, 1077 iter, 5385000 ts, 336 rew

agent-1: 52.199999996959264
agent-2: 49.199999996959264
agent-3: 46.199999996959264
agent-4: 48.199999996959264
agent-5: 47.19999999695926
Extrinsic Rewards:
9
6
3
5
4
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.2074074074074074
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-06-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 336.14499112714867
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1077
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.744
    dispatch_time_ms: 31.903
    learner:
      cur_lr: 0.0010013589635491371
      grad_gnorm: 40.0
      policy_entropy: 28.81117820739746
      policy_loss: 46.107933044433594
      var_gnorm: 22.857927322387695
      vf_explained_var: 0.0
      vf_loss: 66.54161071777344
    num_steps_sampled: 5390000
    num_steps_trained: 5390000
    wait_time_ms: 57.992
  iterations_since_restore: 1078
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9438.474834918976
  time_this_iter_s: 8.777587890625
  time_total_s: 9438.474834918976
  timestamp: 1594857968
  timesteps_since_restore: 5390000
  timesteps_this_iter: 5000
  timesteps_total: 5390000
  training_iteration: 1078
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9438 s, 1078 iter, 5390000 ts, 336 rew

agent-1: 148.4267806622677
agent-2: 171.42678066226787
agent-3: 160.42678066226773
agent-4: 153.42678066226773
agent-5: 166.42678066226782
Extrinsic Rewards:
8
31
20
13
26
Sum Reward: 98
Avg Reward: 19.6
Min Reward: 8
Max Reward: 31
Gini Coefficient: 0.24081632653061225
20:20 Ratio: 3.875
Max-min Ratio: 3.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-06-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 339.8263302374893
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1078
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.969
    dispatch_time_ms: 35.536
    learner:
      cur_lr: 0.001001026015728712
      grad_gnorm: 40.0
      policy_entropy: 8.08757209777832
      policy_loss: -6.757612705230713
      var_gnorm: 22.867643356323242
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.705374240875244
    num_steps_sampled: 5395000
    num_steps_trained: 5395000
    wait_time_ms: 45.535
  iterations_since_restore: 1079
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9447.566815137863
  time_this_iter_s: 9.091980218887329
  time_total_s: 9447.566815137863
  timestamp: 1594857977
  timesteps_since_restore: 5395000
  timesteps_this_iter: 5000
  timesteps_total: 5395000
  training_iteration: 1079
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9447 s, 1079 iter, 5395000 ts, 340 rew

agent-1: 66.19999955017916
agent-2: 66.19999955017916
agent-3: 63.199999550179136
agent-4: 73.19999955017916
agent-5: 64.19999955017913
Extrinsic Rewards:
7
7
4
14
5
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 4
Max Reward: 14
Gini Coefficient: 0.23783783783783785
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-06-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 341.0863302150672
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1079
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 23.541
    learner:
      cur_lr: 0.0010006929514929652
      grad_gnorm: 19.948833465576172
      policy_entropy: 4.296705722808838
      policy_loss: -0.07013614475727081
      var_gnorm: 22.849456787109375
      vf_explained_var: 0.0
      vf_loss: 0.3076789975166321
    num_steps_sampled: 5400000
    num_steps_trained: 5400000
    wait_time_ms: 62.906
  iterations_since_restore: 1080
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9456.68044757843
  time_this_iter_s: 9.113632440567017
  time_total_s: 9456.68044757843
  timestamp: 1594857987
  timesteps_since_restore: 5400000
  timesteps_this_iter: 5000
  timesteps_total: 5400000
  training_iteration: 1080
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9456 s, 1080 iter, 5400000 ts, 341 rew

agent-1: 53.99999999455646
agent-2: 52.99999999455647
agent-3: 52.99999999455646
agent-4: 55.999999994556454
agent-5: 53.99999999455646
Extrinsic Rewards:
6
5
5
8
6
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 5
Max Reward: 8
Gini Coefficient: 0.09333333333333334
20:20 Ratio: 1.6
Max-min Ratio: 1.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-06-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1007.9774188369039
  episode_reward_mean: 340.276330215317
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1080
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.58
    dispatch_time_ms: 25.765
    learner:
      cur_lr: 0.0010003600036725402
      grad_gnorm: 40.0
      policy_entropy: 9.787765502929688
      policy_loss: 5.763126373291016
      var_gnorm: 22.86317253112793
      vf_explained_var: 0.0
      vf_loss: 57.21855163574219
    num_steps_sampled: 5405000
    num_steps_trained: 5405000
    wait_time_ms: 63.378
  iterations_since_restore: 1081
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9465.68664431572
  time_this_iter_s: 9.006196737289429
  time_total_s: 9465.68664431572
  timestamp: 1594857996
  timesteps_since_restore: 5405000
  timesteps_this_iter: 5000
  timesteps_total: 5405000
  training_iteration: 1081
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9465 s, 1081 iter, 5405000 ts, 340 rew

agent-1: 207.55260867024893
agent-2: 214.552608670249
agent-3: 211.55260867024904
agent-4: 227.552608670249
agent-5: 206.552608670249
Extrinsic Rewards:
18
25
22
38
17
Sum Reward: 120
Avg Reward: 24.0
Min Reward: 17
Max Reward: 38
Gini Coefficient: 0.16333333333333333
20:20 Ratio: 2.235294117647059
Max-min Ratio: 2.235294117647059
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-06-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 348.34396064930434
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1081
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.872
    dispatch_time_ms: 33.052
    learner:
      cur_lr: 0.0010000270558521152
      grad_gnorm: 39.999996185302734
      policy_entropy: 34.371315002441406
      policy_loss: -23.51824951171875
      var_gnorm: 22.908109664916992
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 14.033038139343262
    num_steps_sampled: 5410000
    num_steps_trained: 5410000
    wait_time_ms: 57.025
  iterations_since_restore: 1082
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9474.70458483696
  time_this_iter_s: 9.017940521240234
  time_total_s: 9474.70458483696
  timestamp: 1594858005
  timesteps_since_restore: 5410000
  timesteps_this_iter: 5000
  timesteps_total: 5410000
  training_iteration: 1082
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9474 s, 1082 iter, 5410000 ts, 348 rew

agent-1: 172.39721758356137
agent-2: 190.39721758356143
agent-3: 191.3972175835614
agent-4: 188.3972175835614
agent-5: 193.3972175835614
Extrinsic Rewards:
6
24
25
22
27
Sum Reward: 104
Avg Reward: 20.8
Min Reward: 6
Max Reward: 27
Gini Coefficient: 0.17307692307692307
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-06-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 355.4538215286973
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1082
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 33.112
    learner:
      cur_lr: 0.0009996939916163683
      grad_gnorm: 40.00000762939453
      policy_entropy: 26.061513900756836
      policy_loss: 20.951690673828125
      var_gnorm: 22.87928009033203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 24.65606117248535
    num_steps_sampled: 5415000
    num_steps_trained: 5415000
    wait_time_ms: 51.961
  iterations_since_restore: 1083
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9483.762651920319
  time_this_iter_s: 9.058067083358765
  time_total_s: 9483.762651920319
  timestamp: 1594858014
  timesteps_since_restore: 5415000
  timesteps_this_iter: 5000
  timesteps_total: 5415000
  training_iteration: 1083
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9483 s, 1083 iter, 5415000 ts, 355 rew

agent-1: 54.999999949634905
agent-2: 49.99999994963489
agent-3: 61.999999949634905
agent-4: 50.999999949634905
agent-5: 51.9999999496349
Extrinsic Rewards:
7
2
14
3
4
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.37333333333333335
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-07-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 356.3538215262345
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1083
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.807
    dispatch_time_ms: 10.499
    learner:
      cur_lr: 0.0009993610437959433
      grad_gnorm: 40.0
      policy_entropy: 0.11266512423753738
      policy_loss: -0.0035547635052353144
      var_gnorm: 22.86614418029785
      vf_explained_var: 0.0
      vf_loss: 2.4254775047302246
    num_steps_sampled: 5420000
    num_steps_trained: 5420000
    wait_time_ms: 69.47
  iterations_since_restore: 1084
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9500.270335674286
  time_this_iter_s: 16.507683753967285
  time_total_s: 9500.270335674286
  timestamp: 1594858030
  timesteps_since_restore: 5420000
  timesteps_this_iter: 5000
  timesteps_total: 5420000
  training_iteration: 1084
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9500 s, 1084 iter, 5420000 ts, 356 rew

agent-1: 92.19999949700362
agent-2: 101.19999949700359
agent-3: 95.19999949700362
agent-4: 92.19999949700362
agent-5: 87.19999949700359
Extrinsic Rewards:
9
18
12
9
4
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 4
Max Reward: 18
Gini Coefficient: 0.23846153846153847
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-07-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 355.09382158968043
  episode_reward_min: 58.529935864961594
  episodes_this_iter: 1
  episodes_total: 1084
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.932
    dispatch_time_ms: 6.98
    learner:
      cur_lr: 0.0009990279795601964
      grad_gnorm: 2.259488344192505
      policy_entropy: 0.11346399784088135
      policy_loss: -0.00015697124763391912
      var_gnorm: 22.856769561767578
      vf_explained_var: 0.0
      vf_loss: 0.003953850362449884
    num_steps_sampled: 5425000
    num_steps_trained: 5425000
    wait_time_ms: 73.746
  iterations_since_restore: 1085
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9508.4079144001
  time_this_iter_s: 8.13757872581482
  time_total_s: 9508.4079144001
  timestamp: 1594858039
  timesteps_since_restore: 5425000
  timesteps_this_iter: 5000
  timesteps_total: 5425000
  training_iteration: 1085
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9508 s, 1085 iter, 5425000 ts, 355 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-07-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 353.29382158972624
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1085
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.154
    dispatch_time_ms: 8.192
    learner:
      cur_lr: 0.0009986950317397714
      grad_gnorm: 0.04099210724234581
      policy_entropy: 0.11379481106996536
      policy_loss: 2.5892211397149367e-06
      var_gnorm: 22.856760025024414
      vf_explained_var: 0.0
      vf_loss: 1.3012280533075682e-06
    num_steps_sampled: 5430000
    num_steps_trained: 5430000
    wait_time_ms: 67.653
  iterations_since_restore: 1086
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9516.397958517075
  time_this_iter_s: 7.990044116973877
  time_total_s: 9516.397958517075
  timestamp: 1594858047
  timesteps_since_restore: 5430000
  timesteps_this_iter: 5000
  timesteps_total: 5430000
  training_iteration: 1086
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9516 s, 1086 iter, 5430000 ts, 353 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-07-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 349.60382159037397
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1086
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.443
    dispatch_time_ms: 8.01
    learner:
      cur_lr: 0.0009983619675040245
      grad_gnorm: 3.4307923316955566
      policy_entropy: 0.13717806339263916
      policy_loss: -0.00025410455418750644
      var_gnorm: 22.856250762939453
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.009115675464272499
    num_steps_sampled: 5435000
    num_steps_trained: 5435000
    wait_time_ms: 69.394
  iterations_since_restore: 1087
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9524.479125022888
  time_this_iter_s: 8.081166505813599
  time_total_s: 9524.479125022888
  timestamp: 1594858055
  timesteps_since_restore: 5435000
  timesteps_this_iter: 5000
  timesteps_total: 5435000
  training_iteration: 1087
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9524 s, 1087 iter, 5435000 ts, 350 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-07-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 347.3538215906154
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1087
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.585
    dispatch_time_ms: 9.13
    learner:
      cur_lr: 0.0009980290196835995
      grad_gnorm: 0.091084785759449
      policy_entropy: 0.1391351968050003
      policy_loss: 7.441920843120897e-06
      var_gnorm: 22.856189727783203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.422884325729683e-06
    num_steps_sampled: 5440000
    num_steps_trained: 5440000
    wait_time_ms: 64.978
  iterations_since_restore: 1088
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9532.536395311356
  time_this_iter_s: 8.057270288467407
  time_total_s: 9532.536395311356
  timestamp: 1594858063
  timesteps_since_restore: 5440000
  timesteps_this_iter: 5000
  timesteps_total: 5440000
  training_iteration: 1088
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9532 s, 1088 iter, 5440000 ts, 347 rew

agent-1: 1.5999999995971412
agent-2: 1.5999999995971412
agent-3: 1.5999999995971412
agent-4: 1.5999999995971412
agent-5: 2.599999999597141
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-07-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 345.91382159064415
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1088
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.936
    dispatch_time_ms: 8.124
    learner:
      cur_lr: 0.0009976959554478526
      grad_gnorm: 0.01383206993341446
      policy_entropy: 0.13944877684116364
      policy_loss: 1.3010336488150642e-06
      var_gnorm: 22.856212615966797
      vf_explained_var: 0.0
      vf_loss: 1.472514981060158e-07
    num_steps_sampled: 5445000
    num_steps_trained: 5445000
    wait_time_ms: 69.056
  iterations_since_restore: 1089
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9540.594118833542
  time_this_iter_s: 8.05772352218628
  time_total_s: 9540.594118833542
  timestamp: 1594858071
  timesteps_since_restore: 5445000
  timesteps_this_iter: 5000
  timesteps_total: 5445000
  training_iteration: 1089
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9540 s, 1089 iter, 5445000 ts, 346 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-07-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 343.3038215908543
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1089
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 9.084
    learner:
      cur_lr: 0.0009973630076274276
      grad_gnorm: 0.024275505915284157
      policy_entropy: 0.139787957072258
      policy_loss: 2.85304076896864e-06
      var_gnorm: 22.856239318847656
      vf_explained_var: 0.0
      vf_loss: 4.553270969154255e-07
    num_steps_sampled: 5450000
    num_steps_trained: 5450000
    wait_time_ms: 66.592
  iterations_since_restore: 1090
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9548.615895748138
  time_this_iter_s: 8.021776914596558
  time_total_s: 9548.615895748138
  timestamp: 1594858079
  timesteps_since_restore: 5450000
  timesteps_this_iter: 5000
  timesteps_total: 5450000
  training_iteration: 1090
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9548 s, 1090 iter, 5450000 ts, 343 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-08-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 340.60382159120206
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1090
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.568
    dispatch_time_ms: 7.703
    learner:
      cur_lr: 0.0009970299433916807
      grad_gnorm: 0.013320703990757465
      policy_entropy: 0.14015844464302063
      policy_loss: 1.0148324918191065e-06
      var_gnorm: 22.856266021728516
      vf_explained_var: 0.0
      vf_loss: 1.3680212873623532e-07
    num_steps_sampled: 5455000
    num_steps_trained: 5455000
    wait_time_ms: 70.959
  iterations_since_restore: 1091
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9556.75625538826
  time_this_iter_s: 8.14035964012146
  time_total_s: 9556.75625538826
  timestamp: 1594858087
  timesteps_since_restore: 5455000
  timesteps_this_iter: 5000
  timesteps_total: 5455000
  training_iteration: 1091
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9556 s, 1091 iter, 5455000 ts, 341 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-08-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 336.73382160393413
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1091
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.304
    dispatch_time_ms: 9.235
    learner:
      cur_lr: 0.0009966969955712557
      grad_gnorm: 0.025113416835665703
      policy_entropy: 0.1405474841594696
      policy_loss: 2.219076804976794e-06
      var_gnorm: 22.856294631958008
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.881223958363989e-07
    num_steps_sampled: 5460000
    num_steps_trained: 5460000
    wait_time_ms: 71.307
  iterations_since_restore: 1092
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9564.785656929016
  time_this_iter_s: 8.029401540756226
  time_total_s: 9564.785656929016
  timestamp: 1594858095
  timesteps_since_restore: 5460000
  timesteps_this_iter: 5000
  timesteps_total: 5460000
  training_iteration: 1092
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9564 s, 1092 iter, 5460000 ts, 337 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-08-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 334.6638216039787
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1092
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.014
    dispatch_time_ms: 5.685
    learner:
      cur_lr: 0.0009963640477508307
      grad_gnorm: 0.010451718233525753
      policy_entropy: 0.1409626454114914
      policy_loss: 9.97026859295147e-07
      var_gnorm: 22.856321334838867
      vf_explained_var: 0.0
      vf_loss: 8.3830137498353e-08
    num_steps_sampled: 5465000
    num_steps_trained: 5465000
    wait_time_ms: 71.208
  iterations_since_restore: 1093
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9572.807235479355
  time_this_iter_s: 8.021578550338745
  time_total_s: 9572.807235479355
  timestamp: 1594858103
  timesteps_since_restore: 5465000
  timesteps_this_iter: 5000
  timesteps_total: 5465000
  training_iteration: 1093
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9572 s, 1093 iter, 5465000 ts, 335 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-08-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 332.23382160404435
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1093
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.002
    dispatch_time_ms: 9.685
    learner:
      cur_lr: 0.0009960309835150838
      grad_gnorm: 0.027394142001867294
      policy_entropy: 0.1413910835981369
      policy_loss: 2.467952981533017e-06
      var_gnorm: 22.856351852416992
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.805811724712839e-07
    num_steps_sampled: 5470000
    num_steps_trained: 5470000
    wait_time_ms: 69.208
  iterations_since_restore: 1094
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9580.856545448303
  time_this_iter_s: 8.049309968948364
  time_total_s: 9580.856545448303
  timestamp: 1594858111
  timesteps_since_restore: 5470000
  timesteps_this_iter: 5000
  timesteps_total: 5470000
  training_iteration: 1094
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9580 s, 1094 iter, 5470000 ts, 332 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-08-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 329.53382160597494
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1094
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.014
    dispatch_time_ms: 7.339
    learner:
      cur_lr: 0.0009956980356946588
      grad_gnorm: 0.008717343211174011
      policy_entropy: 0.1418401002883911
      policy_loss: 7.730557740615041e-07
      var_gnorm: 22.85638427734375
      vf_explained_var: 0.0
      vf_loss: 5.790925072801656e-08
    num_steps_sampled: 5475000
    num_steps_trained: 5475000
    wait_time_ms: 70.005
  iterations_since_restore: 1095
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9588.97828578949
  time_this_iter_s: 8.121740341186523
  time_total_s: 9588.97828578949
  timestamp: 1594858119
  timesteps_since_restore: 5475000
  timesteps_this_iter: 5000
  timesteps_total: 5475000
  training_iteration: 1095
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9588 s, 1095 iter, 5475000 ts, 330 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-08-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 327.5538216060184
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1095
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 33.643
    learner:
      cur_lr: 0.000995364971458912
      grad_gnorm: 0.010040510445833206
      policy_entropy: 0.14233636856079102
      policy_loss: 2.5218055270670447e-06
      var_gnorm: 22.856414794921875
      vf_explained_var: 0.0
      vf_loss: 1.6052378271069756e-07
    num_steps_sampled: 5480000
    num_steps_trained: 5480000
    wait_time_ms: 51.966
  iterations_since_restore: 1096
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9597.501515388489
  time_this_iter_s: 8.523229598999023
  time_total_s: 9597.501515388489
  timestamp: 1594858128
  timesteps_since_restore: 5480000
  timesteps_this_iter: 5000
  timesteps_total: 5480000
  training_iteration: 1096
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9597 s, 1096 iter, 5480000 ts, 328 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-08-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 321.9738216334644
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1096
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.784
    dispatch_time_ms: 37.406
    learner:
      cur_lr: 0.0009950320236384869
      grad_gnorm: 0.02570560947060585
      policy_entropy: 0.14282989501953125
      policy_loss: 4.6176937757991254e-06
      var_gnorm: 22.856449127197266
      vf_explained_var: 0.0
      vf_loss: 6.482049457190442e-07
    num_steps_sampled: 5485000
    num_steps_trained: 5485000
    wait_time_ms: 34.452
  iterations_since_restore: 1097
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9606.307093381882
  time_this_iter_s: 8.805577993392944
  time_total_s: 9606.307093381882
  timestamp: 1594858137
  timesteps_since_restore: 5485000
  timesteps_this_iter: 5000
  timesteps_total: 5485000
  training_iteration: 1097
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9606 s, 1097 iter, 5485000 ts, 322 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-09-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 315.13382247003335
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1097
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.899
    dispatch_time_ms: 30.82
    learner:
      cur_lr: 0.00099469895940274
      grad_gnorm: 0.01620994322001934
      policy_entropy: 0.14334747195243835
      policy_loss: 1.9877138583979104e-06
      var_gnorm: 22.856483459472656
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.0263573219381215e-07
    num_steps_sampled: 5490000
    num_steps_trained: 5490000
    wait_time_ms: 52.587
  iterations_since_restore: 1098
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9614.787403345108
  time_this_iter_s: 8.480309963226318
  time_total_s: 9614.787403345108
  timestamp: 1594858146
  timesteps_since_restore: 5490000
  timesteps_this_iter: 5000
  timesteps_total: 5490000
  training_iteration: 1098
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9614 s, 1098 iter, 5490000 ts, 315 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-09-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 311.8038224707627
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1098
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.527
    dispatch_time_ms: 33.309
    learner:
      cur_lr: 0.000994366011582315
      grad_gnorm: 0.00762689346447587
      policy_entropy: 0.1439008116722107
      policy_loss: 2.1809275949635776e-06
      var_gnorm: 22.85651969909668
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.2834142637530022e-07
    num_steps_sampled: 5495000
    num_steps_trained: 5495000
    wait_time_ms: 51.219
  iterations_since_restore: 1099
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9623.36124587059
  time_this_iter_s: 8.573842525482178
  time_total_s: 9623.36124587059
  timestamp: 1594858154
  timesteps_since_restore: 5495000
  timesteps_this_iter: 5000
  timesteps_total: 5495000
  training_iteration: 1099
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9623 s, 1099 iter, 5495000 ts, 312 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-09-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 309.91382247081646
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1099
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.902
    dispatch_time_ms: 21.7
    learner:
      cur_lr: 0.000994032947346568
      grad_gnorm: 0.020972546190023422
      policy_entropy: 0.14450520277023315
      policy_loss: 2.35997003983357e-06
      var_gnorm: 22.856557846069336
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.394961538560892e-07
    num_steps_sampled: 5500000
    num_steps_trained: 5500000
    wait_time_ms: 55.441
  iterations_since_restore: 1100
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9631.820313215256
  time_this_iter_s: 8.459067344665527
  time_total_s: 9631.820313215256
  timestamp: 1594858163
  timesteps_since_restore: 5500000
  timesteps_this_iter: 5000
  timesteps_total: 5500000
  training_iteration: 1100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9631 s, 1100 iter, 5500000 ts, 310 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-09-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 306.04382247776596
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1100
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.75
    dispatch_time_ms: 23.324
    learner:
      cur_lr: 0.000993699999526143
      grad_gnorm: 0.00799051858484745
      policy_entropy: 0.14513200521469116
      policy_loss: 1.0424984111523372e-06
      var_gnorm: 22.856597900390625
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.8828699306113776e-08
    num_steps_sampled: 5505000
    num_steps_trained: 5505000
    wait_time_ms: 59.088
  iterations_since_restore: 1101
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9640.388365745544
  time_this_iter_s: 8.568052530288696
  time_total_s: 9640.388365745544
  timestamp: 1594858171
  timesteps_since_restore: 5505000
  timesteps_this_iter: 5000
  timesteps_total: 5505000
  training_iteration: 1101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9640 s, 1101 iter, 5505000 ts, 306 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-09-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 296.50399427246003
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1101
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.009
    dispatch_time_ms: 35.177
    learner:
      cur_lr: 0.000993367051705718
      grad_gnorm: 0.023841453716158867
      policy_entropy: 0.14581294357776642
      policy_loss: 2.6071136289829155e-06
      var_gnorm: 22.856637954711914
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 4.095010694982193e-07
    num_steps_sampled: 5510000
    num_steps_trained: 5510000
    wait_time_ms: 52.867
  iterations_since_restore: 1102
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9648.861342191696
  time_this_iter_s: 8.472976446151733
  time_total_s: 9648.861342191696
  timestamp: 1594858180
  timesteps_since_restore: 5510000
  timesteps_this_iter: 5000
  timesteps_total: 5510000
  training_iteration: 1102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9648 s, 1102 iter, 5510000 ts, 297 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-09-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 294.6139942725151
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1102
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 33.84
    learner:
      cur_lr: 0.0009930339874699712
      grad_gnorm: 0.007932697422802448
      policy_entropy: 0.14652712643146515
      policy_loss: 5.2494857527563e-07
      var_gnorm: 22.856679916381836
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.787680651929804e-08
    num_steps_sampled: 5515000
    num_steps_trained: 5515000
    wait_time_ms: 44.6
  iterations_since_restore: 1103
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9657.526284694672
  time_this_iter_s: 8.664942502975464
  time_total_s: 9657.526284694672
  timestamp: 1594858188
  timesteps_since_restore: 5515000
  timesteps_this_iter: 5000
  timesteps_total: 5515000
  training_iteration: 1103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9657 s, 1103 iter, 5515000 ts, 295 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-09-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 289.7539942883765
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1103
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 7.75
    learner:
      cur_lr: 0.0009927010396495461
      grad_gnorm: 12.341358184814453
      policy_entropy: 0.19216987490653992
      policy_loss: 0.0013449069811031222
      var_gnorm: 22.855945587158203
      vf_explained_var: 0.0
      vf_loss: 0.12119022756814957
    num_steps_sampled: 5520000
    num_steps_trained: 5520000
    wait_time_ms: 68.096
  iterations_since_restore: 1104
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9665.546482801437
  time_this_iter_s: 8.020198106765747
  time_total_s: 9665.546482801437
  timestamp: 1594858197
  timesteps_since_restore: 5520000
  timesteps_this_iter: 5000
  timesteps_total: 5520000
  training_iteration: 1104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9665 s, 1104 iter, 5520000 ts, 290 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-10-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 287.50399428854683
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1104
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 8.997
    learner:
      cur_lr: 0.0009923679754137993
      grad_gnorm: 0.08374325186014175
      policy_entropy: 0.22354714572429657
      policy_loss: 1.587367933097994e-06
      var_gnorm: 22.855567932128906
      vf_explained_var: 0.0
      vf_loss: 5.429356406239094e-06
    num_steps_sampled: 5525000
    num_steps_trained: 5525000
    wait_time_ms: 66.008
  iterations_since_restore: 1105
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9673.605577468872
  time_this_iter_s: 8.059094667434692
  time_total_s: 9673.605577468872
  timestamp: 1594858205
  timesteps_since_restore: 5525000
  timesteps_this_iter: 5000
  timesteps_total: 5525000
  training_iteration: 1105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9673 s, 1105 iter, 5525000 ts, 288 rew

agent-1: 3.191086130951375
agent-2: 3.191086130951375
agent-3: 3.191086130951375
agent-4: 5.191086130951369
agent-5: 3.191086130951375
Extrinsic Rewards:
0
0
0
2
0
Sum Reward: 2
Avg Reward: 0.4
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-10-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 284.893548596029
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1105
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.55
    dispatch_time_ms: 8.051
    learner:
      cur_lr: 0.0009920350275933743
      grad_gnorm: 0.6364462375640869
      policy_entropy: 0.37523919343948364
      policy_loss: 0.00023677616263739765
      var_gnorm: 22.854232788085938
      vf_explained_var: 0.0
      vf_loss: 0.0003136858867947012
    num_steps_sampled: 5530000
    num_steps_trained: 5530000
    wait_time_ms: 70.097
  iterations_since_restore: 1106
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9681.652394533157
  time_this_iter_s: 8.046817064285278
  time_total_s: 9681.652394533157
  timestamp: 1594858213
  timesteps_since_restore: 5530000
  timesteps_this_iter: 5000
  timesteps_total: 5530000
  training_iteration: 1106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9681 s, 1106 iter, 5530000 ts, 285 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-10-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 281.9235485967443
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1106
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 8.678
    learner:
      cur_lr: 0.0009917019633576274
      grad_gnorm: 0.0135220130905509
      policy_entropy: 0.380270391702652
      policy_loss: -2.1681926227756776e-06
      var_gnorm: 22.85430908203125
      vf_explained_var: 0.0
      vf_loss: 1.3651435892825248e-07
    num_steps_sampled: 5535000
    num_steps_trained: 5535000
    wait_time_ms: 68.965
  iterations_since_restore: 1107
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9689.687403440475
  time_this_iter_s: 8.035008907318115
  time_total_s: 9689.687403440475
  timestamp: 1594858221
  timesteps_since_restore: 5535000
  timesteps_this_iter: 5000
  timesteps_total: 5535000
  training_iteration: 1107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9689 s, 1107 iter, 5535000 ts, 282 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-10-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 279.04354862278
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1107
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.381
    dispatch_time_ms: 6.125
    learner:
      cur_lr: 0.0009913690155372024
      grad_gnorm: 0.0072600217536091805
      policy_entropy: 0.38605332374572754
      policy_loss: 2.634277279867092e-06
      var_gnorm: 22.854389190673828
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.548430527189339e-08
    num_steps_sampled: 5540000
    num_steps_trained: 5540000
    wait_time_ms: 70.756
  iterations_since_restore: 1108
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9697.670902252197
  time_this_iter_s: 7.983498811721802
  time_total_s: 9697.670902252197
  timestamp: 1594858229
  timesteps_since_restore: 5540000
  timesteps_this_iter: 5000
  timesteps_total: 5540000
  training_iteration: 1108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9697 s, 1108 iter, 5540000 ts, 279 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-10-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 274.45354862814105
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1108
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.7
    dispatch_time_ms: 8.625
    learner:
      cur_lr: 0.0009910359513014555
      grad_gnorm: 6.2063093185424805
      policy_entropy: 0.6945857405662537
      policy_loss: -0.0027890836354345083
      var_gnorm: 22.853116989135742
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.029829682782292366
    num_steps_sampled: 5545000
    num_steps_trained: 5545000
    wait_time_ms: 71.041
  iterations_since_restore: 1109
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9705.716434001923
  time_this_iter_s: 8.045531749725342
  time_total_s: 9705.716434001923
  timestamp: 1594858237
  timesteps_since_restore: 5545000
  timesteps_this_iter: 5000
  timesteps_total: 5545000
  training_iteration: 1109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9705 s, 1109 iter, 5545000 ts, 274 rew

agent-1: 1.5844416099355396
agent-2: 1.5844416099355396
agent-3: 1.5844416099355396
agent-4: 1.5844416099355396
agent-5: 2.58444160993554
Extrinsic Rewards:
0
0
0
0
1
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-10-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 271.932770708807
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1109
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.863
    dispatch_time_ms: 8.981
    learner:
      cur_lr: 0.0009907030034810305
      grad_gnorm: 40.0
      policy_entropy: 31.076061248779297
      policy_loss: 60.967647552490234
      var_gnorm: 22.863601684570312
      vf_explained_var: 0.0
      vf_loss: 101.74627685546875
    num_steps_sampled: 5550000
    num_steps_trained: 5550000
    wait_time_ms: 71.593
  iterations_since_restore: 1110
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9713.922600984573
  time_this_iter_s: 8.206166982650757
  time_total_s: 9713.922600984573
  timestamp: 1594858245
  timesteps_since_restore: 5550000
  timesteps_this_iter: 5000
  timesteps_total: 5550000
  training_iteration: 1110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9713 s, 1110 iter, 5550000 ts, 272 rew

agent-1: 96.76772596101846
agent-2: 101.76772596101846
agent-3: 86.76772596101848
agent-4: 86.76772596101846
agent-5: 98.76772596101846
Extrinsic Rewards:
14
19
4
4
16
Sum Reward: 57
Avg Reward: 11.4
Min Reward: 4
Max Reward: 19
Gini Coefficient: 0.29473684210526313
20:20 Ratio: 4.75
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-10-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 272.0511570522882
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1110
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.802
    dispatch_time_ms: 6.805
    learner:
      cur_lr: 0.0009903700556606054
      grad_gnorm: 40.0
      policy_entropy: 14.720513343811035
      policy_loss: 22.07065773010254
      var_gnorm: 22.90631866455078
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 52.08484649658203
    num_steps_sampled: 5555000
    num_steps_trained: 5555000
    wait_time_ms: 76.015
  iterations_since_restore: 1111
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9722.355279445648
  time_this_iter_s: 8.432678461074829
  time_total_s: 9722.355279445648
  timestamp: 1594858254
  timesteps_since_restore: 5555000
  timesteps_this_iter: 5000
  timesteps_total: 5555000
  training_iteration: 1111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9722 s, 1111 iter, 5555000 ts, 272 rew

agent-1: 100.5999899353762
agent-2: 95.59998993537619
agent-3: 95.5999899353762
agent-4: 109.59998993537616
agent-5: 102.59998993537613
Extrinsic Rewards:
11
6
6
20
13
Sum Reward: 56
Avg Reward: 11.2
Min Reward: 6
Max Reward: 20
Gini Coefficient: 0.25
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 275.0211565490922
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1111
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 7.054
    learner:
      cur_lr: 0.0009900369914248586
      grad_gnorm: 40.0
      policy_entropy: 34.60888671875
      policy_loss: -11.655607223510742
      var_gnorm: 22.857479095458984
      vf_explained_var: 0.0
      vf_loss: 3.3329989910125732
    num_steps_sampled: 5560000
    num_steps_trained: 5560000
    wait_time_ms: 74.805
  iterations_since_restore: 1112
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9734.130896806717
  time_this_iter_s: 11.775617361068726
  time_total_s: 9734.130896806717
  timestamp: 1594858266
  timesteps_since_restore: 5560000
  timesteps_this_iter: 5000
  timesteps_total: 5560000
  training_iteration: 1112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9734 s, 1112 iter, 5560000 ts, 275 rew

agent-1: 120.19999859680725
agent-2: 112.1999985968073
agent-3: 105.19999859680728
agent-4: 107.1999985968073
agent-5: 113.19999859680728
Extrinsic Rewards:
21
13
6
8
14
Sum Reward: 62
Avg Reward: 12.4
Min Reward: 6
Max Reward: 21
Gini Coefficient: 0.23225806451612904
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 277.9011564794587
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1112
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.956
    dispatch_time_ms: 8.316
    learner:
      cur_lr: 0.0009897040436044335
      grad_gnorm: 40.0
      policy_entropy: 25.39153480529785
      policy_loss: 25.54439353942871
      var_gnorm: 22.850807189941406
      vf_explained_var: 0.0
      vf_loss: 21.062110900878906
    num_steps_sampled: 5565000
    num_steps_trained: 5565000
    wait_time_ms: 71.482
  iterations_since_restore: 1113
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9742.616858005524
  time_this_iter_s: 8.485961198806763
  time_total_s: 9742.616858005524
  timestamp: 1594858274
  timesteps_since_restore: 5565000
  timesteps_this_iter: 5000
  timesteps_total: 5565000
  training_iteration: 1113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9742 s, 1113 iter, 5565000 ts, 278 rew

agent-1: 39.59999999935221
agent-2: 39.59999999935221
agent-3: 33.59999999935219
agent-4: 38.59999999935221
agent-5: 37.5999999993522
Extrinsic Rewards:
6
6
0
5
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.26666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 276.2811564804462
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1113
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.17
    dispatch_time_ms: 7.269
    learner:
      cur_lr: 0.0009893709793686867
      grad_gnorm: 39.999996185302734
      policy_entropy: 34.29075622558594
      policy_loss: 87.2498550415039
      var_gnorm: 22.855571746826172
      vf_explained_var: 0.0
      vf_loss: 208.9151611328125
    num_steps_sampled: 5570000
    num_steps_trained: 5570000
    wait_time_ms: 73.481
  iterations_since_restore: 1114
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9751.091032505035
  time_this_iter_s: 8.474174499511719
  time_total_s: 9751.091032505035
  timestamp: 1594858283
  timesteps_since_restore: 5570000
  timesteps_this_iter: 5000
  timesteps_total: 5570000
  training_iteration: 1114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9751 s, 1114 iter, 5570000 ts, 276 rew

agent-1: 154.69626714550267
agent-2: 158.69626714550282
agent-3: 144.69626714550262
agent-4: 170.69626714550267
agent-5: 162.69626714550273
Extrinsic Rewards:
14
18
4
30
22
Sum Reward: 88
Avg Reward: 17.6
Min Reward: 4
Max Reward: 30
Gini Coefficient: 0.2727272727272727
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 281.4959698379304
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1114
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.33
    dispatch_time_ms: 8.695
    learner:
      cur_lr: 0.0009890380315482616
      grad_gnorm: 40.0
      policy_entropy: 28.60678482055664
      policy_loss: -8.89348316192627
      var_gnorm: 22.851303100585938
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.6262989044189453
    num_steps_sampled: 5575000
    num_steps_trained: 5575000
    wait_time_ms: 66.807
  iterations_since_restore: 1115
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9759.636842250824
  time_this_iter_s: 8.545809745788574
  time_total_s: 9759.636842250824
  timestamp: 1594858291
  timesteps_since_restore: 5575000
  timesteps_this_iter: 5000
  timesteps_total: 5575000
  training_iteration: 1115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9759 s, 1115 iter, 5575000 ts, 281 rew

agent-1: 74.99999995990835
agent-2: 63.99999995990831
agent-3: 76.99999995990835
agent-4: 74.99999995990834
agent-5: 68.99999995990842
Extrinsic Rewards:
11
0
13
11
5
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.32
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 282.75596983684255
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1115
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.854
    dispatch_time_ms: 7.265
    learner:
      cur_lr: 0.0009887049673125148
      grad_gnorm: 40.0
      policy_entropy: 11.14018726348877
      policy_loss: 2.9371769428253174
      var_gnorm: 22.850242614746094
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.815892219543457
    num_steps_sampled: 5580000
    num_steps_trained: 5580000
    wait_time_ms: 75.548
  iterations_since_restore: 1116
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9768.228870868683
  time_this_iter_s: 8.592028617858887
  time_total_s: 9768.228870868683
  timestamp: 1594858300
  timesteps_since_restore: 5580000
  timesteps_this_iter: 5000
  timesteps_total: 5580000
  training_iteration: 1116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9768 s, 1116 iter, 5580000 ts, 283 rew

agent-1: 49.59999999470767
agent-2: 50.59999999470766
agent-3: 47.59999999470766
agent-4: 41.59999999470769
agent-5: 44.59999999470767
Extrinsic Rewards:
8
9
6
0
3
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.35384615384615387
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 282.93596983674485
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1116
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.392
    dispatch_time_ms: 8.932
    learner:
      cur_lr: 0.0009883720194920897
      grad_gnorm: 3.9206998348236084
      policy_entropy: 32.6134147644043
      policy_loss: -0.5479968786239624
      var_gnorm: 22.848115921020508
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.009586242027580738
    num_steps_sampled: 5585000
    num_steps_trained: 5585000
    wait_time_ms: 73.375
  iterations_since_restore: 1117
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9776.699449062347
  time_this_iter_s: 8.47057819366455
  time_total_s: 9776.699449062347
  timestamp: 1594858308
  timesteps_since_restore: 5585000
  timesteps_this_iter: 5000
  timesteps_total: 5585000
  training_iteration: 1117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9776 s, 1117 iter, 5585000 ts, 283 rew

agent-1: 64.19999987314482
agent-2: 64.1999998731448
agent-3: 66.19999987314476
agent-4: 69.19999987314475
agent-5: 69.19999987314476
Extrinsic Rewards:
5
5
7
10
10
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 5
Max Reward: 10
Gini Coefficient: 0.16216216216216217
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-11-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 284.1959698304506
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1117
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 6.267
    learner:
      cur_lr: 0.0009880389552563429
      grad_gnorm: 5.708724021911621
      policy_entropy: 33.578895568847656
      policy_loss: -0.8891680836677551
      var_gnorm: 22.851186752319336
      vf_explained_var: 0.0
      vf_loss: 0.024016236886382103
    num_steps_sampled: 5590000
    num_steps_trained: 5590000
    wait_time_ms: 74.595
  iterations_since_restore: 1118
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9785.176834106445
  time_this_iter_s: 8.4773850440979
  time_total_s: 9785.176834106445
  timestamp: 1594858317
  timesteps_since_restore: 5590000
  timesteps_this_iter: 5000
  timesteps_total: 5590000
  training_iteration: 1118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9785 s, 1118 iter, 5590000 ts, 284 rew

agent-1: 74.59999998149223
agent-2: 75.59999998149222
agent-3: 71.59999998149226
agent-4: 73.59999998149227
agent-5: 73.59999998149225
Extrinsic Rewards:
9
10
6
8
8
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 6
Max Reward: 10
Gini Coefficient: 0.08780487804878048
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 277.80619564115614
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1118
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.223
    dispatch_time_ms: 9.886
    learner:
      cur_lr: 0.0009877060074359179
      grad_gnorm: 12.59817886352539
      policy_entropy: 27.287263870239258
      policy_loss: -1.9416193962097168
      var_gnorm: 22.85051918029785
      vf_explained_var: 0.0
      vf_loss: 0.1212218776345253
    num_steps_sampled: 5595000
    num_steps_trained: 5595000
    wait_time_ms: 71.442
  iterations_since_restore: 1119
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9793.613300085068
  time_this_iter_s: 8.436465978622437
  time_total_s: 9793.613300085068
  timestamp: 1594858325
  timesteps_since_restore: 5595000
  timesteps_this_iter: 5000
  timesteps_total: 5595000
  training_iteration: 1119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9793 s, 1119 iter, 5595000 ts, 278 rew

agent-1: 36.399999999428445
agent-2: 33.39999999942843
agent-3: 30.399999999428463
agent-4: 35.39999999942843
agent-5: 35.39999999942844
Extrinsic Rewards:
6
3
0
5
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.29473684210526313
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 274.6561956498065
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1119
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.002
    dispatch_time_ms: 7.264
    learner:
      cur_lr: 0.000987372943200171
      grad_gnorm: 15.785497665405273
      policy_entropy: 29.648231506347656
      policy_loss: -1.6107063293457031
      var_gnorm: 22.844484329223633
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.19271351397037506
    num_steps_sampled: 5600000
    num_steps_trained: 5600000
    wait_time_ms: 75.047
  iterations_since_restore: 1120
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9802.102138757706
  time_this_iter_s: 8.48883867263794
  time_total_s: 9802.102138757706
  timestamp: 1594858334
  timesteps_since_restore: 5600000
  timesteps_this_iter: 5000
  timesteps_total: 5600000
  training_iteration: 1120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9802 s, 1120 iter, 5600000 ts, 275 rew

agent-1: 50.59999999828076
agent-2: 43.59999999828076
agent-3: 47.59999999828076
agent-4: 48.599999998280744
agent-5: 43.59999999828076
Extrinsic Rewards:
9
2
6
7
2
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2923076923076923
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 274.38619565001363
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1120
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.09
    dispatch_time_ms: 10.205
    learner:
      cur_lr: 0.000987039995379746
      grad_gnorm: 21.106679916381836
      policy_entropy: 33.88459396362305
      policy_loss: -3.3595619201660156
      var_gnorm: 22.84439468383789
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.3298628330230713
    num_steps_sampled: 5605000
    num_steps_trained: 5605000
    wait_time_ms: 72.911
  iterations_since_restore: 1121
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9810.644716739655
  time_this_iter_s: 8.542577981948853
  time_total_s: 9810.644716739655
  timestamp: 1594858342
  timesteps_since_restore: 5605000
  timesteps_this_iter: 5000
  timesteps_total: 5605000
  training_iteration: 1121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9810 s, 1121 iter, 5605000 ts, 274 rew

agent-1: 59.999999995304094
agent-2: 61.99999999530409
agent-3: 62.99999999530409
agent-4: 71.9999999953041
agent-5: 57.999999995304094
Extrinsic Rewards:
4
6
7
16
2
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.35428571428571426
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 273.2161957372996
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1121
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 7.96
    learner:
      cur_lr: 0.000986707047559321
      grad_gnorm: 13.860392570495605
      policy_entropy: 33.30498123168945
      policy_loss: -2.2347867488861084
      var_gnorm: 22.845829010009766
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.14854884147644043
    num_steps_sampled: 5610000
    num_steps_trained: 5610000
    wait_time_ms: 73.602
  iterations_since_restore: 1122
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9819.00108242035
  time_this_iter_s: 8.35636568069458
  time_total_s: 9819.00108242035
  timestamp: 1594858351
  timesteps_since_restore: 5610000
  timesteps_this_iter: 5000
  timesteps_total: 5610000
  training_iteration: 1122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9819 s, 1122 iter, 5610000 ts, 273 rew

agent-1: 56.59999999484636
agent-2: 65.59999999484631
agent-3: 52.59999999484636
agent-4: 49.59999999484636
agent-5: 54.59999999484636
Extrinsic Rewards:
7
16
3
0
5
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 0
Max Reward: 16
Gini Coefficient: 0.4645161290322581
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 273.21619573717135
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1122
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.762
    dispatch_time_ms: 8.344
    learner:
      cur_lr: 0.000986373983323574
      grad_gnorm: 16.10004997253418
      policy_entropy: 29.964885711669922
      policy_loss: -2.6685004234313965
      var_gnorm: 22.845911026000977
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.1980995237827301
    num_steps_sampled: 5615000
    num_steps_trained: 5615000
    wait_time_ms: 77.645
  iterations_since_restore: 1123
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9827.470483779907
  time_this_iter_s: 8.469401359558105
  time_total_s: 9827.470483779907
  timestamp: 1594858359
  timesteps_since_restore: 5615000
  timesteps_this_iter: 5000
  timesteps_total: 5615000
  training_iteration: 1123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9827 s, 1123 iter, 5615000 ts, 273 rew

agent-1: 32.399999999361086
agent-2: 32.399999999361086
agent-3: 36.39999999936111
agent-4: 32.399999999361086
agent-5: 37.39999999936111
Extrinsic Rewards:
2
2
6
2
7
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.29473684210526313
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 270.9661957573916
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1123
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.267
    dispatch_time_ms: 31.016
    learner:
      cur_lr: 0.000986041035503149
      grad_gnorm: 14.370461463928223
      policy_entropy: 33.585304260253906
      policy_loss: -1.9958956241607666
      var_gnorm: 22.845308303833008
      vf_explained_var: 0.0
      vf_loss: 0.15855079889297485
    num_steps_sampled: 5620000
    num_steps_trained: 5620000
    wait_time_ms: 59.841
  iterations_since_restore: 1124
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9836.46555185318
  time_this_iter_s: 8.995068073272705
  time_total_s: 9836.46555185318
  timestamp: 1594858368
  timesteps_since_restore: 5620000
  timesteps_this_iter: 5000
  timesteps_total: 5620000
  training_iteration: 1124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9836 s, 1124 iter, 5620000 ts, 271 rew

agent-1: 36.9999999983017
agent-2: 39.9999999983017
agent-3: 34.99999999830171
agent-4: 31.999999998301682
agent-5: 35.99999999830171
Extrinsic Rewards:
5
8
3
0
4
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.36
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-12-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 271.3261957573327
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1124
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.782
    dispatch_time_ms: 41.288
    learner:
      cur_lr: 0.0009857079712674022
      grad_gnorm: 11.79804515838623
      policy_entropy: 29.436996459960938
      policy_loss: -2.628986120223999
      var_gnorm: 22.844463348388672
      vf_explained_var: 0.0
      vf_loss: 0.10680095106363297
    num_steps_sampled: 5625000
    num_steps_trained: 5625000
    wait_time_ms: 50.314
  iterations_since_restore: 1125
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9845.644881010056
  time_this_iter_s: 9.17932915687561
  time_total_s: 9845.644881010056
  timestamp: 1594858378
  timesteps_since_restore: 5625000
  timesteps_this_iter: 5000
  timesteps_total: 5625000
  training_iteration: 1125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9845 s, 1125 iter, 5625000 ts, 271 rew

agent-1: 32.9999999981713
agent-2: 37.99999999817129
agent-3: 33.999999998171305
agent-4: 38.99999999817129
agent-5: 35.9999999981713
Extrinsic Rewards:
1
6
2
7
4
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.32
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 270.336195757997
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1125
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.489
    dispatch_time_ms: 24.971
    learner:
      cur_lr: 0.0009853750234469771
      grad_gnorm: 14.277132987976074
      policy_entropy: 33.65311050415039
      policy_loss: 3.7320244312286377
      var_gnorm: 22.84542465209961
      vf_explained_var: 0.0
      vf_loss: 0.16437223553657532
    num_steps_sampled: 5630000
    num_steps_trained: 5630000
    wait_time_ms: 66.529
  iterations_since_restore: 1126
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9855.742562294006
  time_this_iter_s: 10.097681283950806
  time_total_s: 9855.742562294006
  timestamp: 1594858388
  timesteps_since_restore: 5630000
  timesteps_this_iter: 5000
  timesteps_total: 5630000
  training_iteration: 1126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9855 s, 1126 iter, 5630000 ts, 270 rew

agent-1: 36.599999998738184
agent-2: 37.59999999873817
agent-3: 36.599999998738184
agent-4: 37.59999999873818
agent-5: 40.599999998738184
Extrinsic Rewards:
3
4
3
4
7
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.17142857142857143
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 269.34619575803396
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1126
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.655
    dispatch_time_ms: 25.817
    learner:
      cur_lr: 0.0009850419592112303
      grad_gnorm: 10.771014213562012
      policy_entropy: 26.79433822631836
      policy_loss: -2.1659343242645264
      var_gnorm: 22.84522819519043
      vf_explained_var: 0.0
      vf_loss: 0.08759315311908722
    num_steps_sampled: 5635000
    num_steps_trained: 5635000
    wait_time_ms: 65.411
  iterations_since_restore: 1127
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9864.993369579315
  time_this_iter_s: 9.250807285308838
  time_total_s: 9864.993369579315
  timestamp: 1594858397
  timesteps_since_restore: 5635000
  timesteps_this_iter: 5000
  timesteps_total: 5635000
  training_iteration: 1127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9864 s, 1127 iter, 5635000 ts, 269 rew

agent-1: 37.7999999980057
agent-2: 39.79999999800569
agent-3: 37.7999999980057
agent-4: 45.79999999800564
agent-5: 45.799999998005646
Extrinsic Rewards:
1
3
1
9
9
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.41739130434782606
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 266.4661957798922
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1127
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 28.581
    learner:
      cur_lr: 0.0009847090113908052
      grad_gnorm: 2.9542996883392334
      policy_entropy: 24.257598876953125
      policy_loss: -0.06923346221446991
      var_gnorm: 22.846195220947266
      vf_explained_var: 0.0
      vf_loss: 0.006220236420631409
    num_steps_sampled: 5640000
    num_steps_trained: 5640000
    wait_time_ms: 56.481
  iterations_since_restore: 1128
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9874.115181446075
  time_this_iter_s: 9.121811866760254
  time_total_s: 9874.115181446075
  timestamp: 1594858406
  timesteps_since_restore: 5640000
  timesteps_this_iter: 5000
  timesteps_total: 5640000
  training_iteration: 1128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9874 s, 1128 iter, 5640000 ts, 266 rew

agent-1: 31.999999999274884
agent-2: 35.99999999927502
agent-3: 33.99999999927501
agent-4: 42.999999999275005
agent-5: 34.99999999927502
Extrinsic Rewards:
0
4
2
11
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.48
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 265.9261957799538
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1128
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.006
    dispatch_time_ms: 27.3
    learner:
      cur_lr: 0.0009843759471550584
      grad_gnorm: 15.594626426696777
      policy_entropy: 22.656583786010742
      policy_loss: -1.9365445375442505
      var_gnorm: 22.844236373901367
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.1875602900981903
    num_steps_sampled: 5645000
    num_steps_trained: 5645000
    wait_time_ms: 58.58
  iterations_since_restore: 1129
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9883.284831523895
  time_this_iter_s: 9.169650077819824
  time_total_s: 9883.284831523895
  timestamp: 1594858415
  timesteps_since_restore: 5645000
  timesteps_this_iter: 5000
  timesteps_total: 5645000
  training_iteration: 1129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9883 s, 1129 iter, 5645000 ts, 266 rew

agent-1: 32.999999999252466
agent-2: 36.99999999925242
agent-3: 33.999999999252466
agent-4: 42.999999999252424
agent-5: 32.999999999252466
Extrinsic Rewards:
1
5
2
11
1
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.48
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 263.31619578228873
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1129
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.65
    dispatch_time_ms: 48.409
    learner:
      cur_lr: 0.0009840429993346334
      grad_gnorm: 15.303783416748047
      policy_entropy: 18.691204071044922
      policy_loss: -1.4097537994384766
      var_gnorm: 22.84566879272461
      vf_explained_var: 0.0
      vf_loss: 0.17983099818229675
    num_steps_sampled: 5650000
    num_steps_trained: 5650000
    wait_time_ms: 38.367
  iterations_since_restore: 1130
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9892.500309467316
  time_this_iter_s: 9.21547794342041
  time_total_s: 9892.500309467316
  timestamp: 1594858425
  timesteps_since_restore: 5650000
  timesteps_this_iter: 5000
  timesteps_total: 5650000
  training_iteration: 1130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9892 s, 1130 iter, 5650000 ts, 263 rew

agent-1: 45.399999998594666
agent-2: 46.399999998594666
agent-3: 41.39999999859465
agent-4: 44.399999998594666
agent-5: 38.399999998594666
Extrinsic Rewards:
7
8
3
6
0
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.3333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-13-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 263.9461957823051
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1130
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.65
    dispatch_time_ms: 39.204
    learner:
      cur_lr: 0.0009837100515142083
      grad_gnorm: 15.228822708129883
      policy_entropy: 28.066062927246094
      policy_loss: 2.8840317726135254
      var_gnorm: 22.84204864501953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.20849072933197021
    num_steps_sampled: 5655000
    num_steps_trained: 5655000
    wait_time_ms: 46.55
  iterations_since_restore: 1131
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9901.573916912079
  time_this_iter_s: 9.073607444763184
  time_total_s: 9901.573916912079
  timestamp: 1594858434
  timesteps_since_restore: 5655000
  timesteps_this_iter: 5000
  timesteps_total: 5655000
  training_iteration: 1131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9901 s, 1131 iter, 5655000 ts, 264 rew

agent-1: 44.599999998184714
agent-2: 45.5999999981847
agent-3: 48.59999999818471
agent-4: 47.59999999818471
agent-5: 47.59999999818471
Extrinsic Rewards:
3
4
7
6
6
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.15384615384615385
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 262.416195788343
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1131
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.496
    dispatch_time_ms: 4.886
    learner:
      cur_lr: 0.0009833769872784615
      grad_gnorm: 18.12236213684082
      policy_entropy: 8.788697242736816
      policy_loss: -1.595479130744934
      var_gnorm: 22.8459415435791
      vf_explained_var: 0.0
      vf_loss: 0.24494296312332153
    num_steps_sampled: 5660000
    num_steps_trained: 5660000
    wait_time_ms: 81.905
  iterations_since_restore: 1132
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9910.545925617218
  time_this_iter_s: 8.97200870513916
  time_total_s: 9910.545925617218
  timestamp: 1594858443
  timesteps_since_restore: 5660000
  timesteps_this_iter: 5000
  timesteps_total: 5660000
  training_iteration: 1132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9910 s, 1132 iter, 5660000 ts, 262 rew

agent-1: 82.99999997895969
agent-2: 83.99999997895969
agent-3: 75.99999997895969
agent-4: 85.99999997895969
agent-5: 75.99999997895969
Extrinsic Rewards:
11
12
4
14
4
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 4
Max Reward: 14
Gini Coefficient: 0.24888888888888888
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 260.4362230466223
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1132
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.358
    dispatch_time_ms: 5.709
    learner:
      cur_lr: 0.0009830440394580364
      grad_gnorm: 40.0
      policy_entropy: 22.0899715423584
      policy_loss: 38.22430419921875
      var_gnorm: 22.859102249145508
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 120.1723403930664
    num_steps_sampled: 5665000
    num_steps_trained: 5665000
    wait_time_ms: 75.51
  iterations_since_restore: 1133
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9919.058574914932
  time_this_iter_s: 8.512649297714233
  time_total_s: 9919.058574914932
  timestamp: 1594858451
  timesteps_since_restore: 5665000
  timesteps_this_iter: 5000
  timesteps_total: 5665000
  training_iteration: 1133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9919 s, 1133 iter, 5665000 ts, 260 rew

agent-1: 204.4702196148691
agent-2: 194.4702196148692
agent-3: 190.47021961486914
agent-4: 187.47021961486914
agent-5: 193.4702196148691
Extrinsic Rewards:
32
22
18
15
21
Sum Reward: 108
Avg Reward: 21.6
Min Reward: 15
Max Reward: 32
Gini Coefficient: 0.14074074074074075
20:20 Ratio: 2.1333333333333333
Max-min Ratio: 2.1333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 267.3497340281903
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1133
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.649
    dispatch_time_ms: 5.879
    learner:
      cur_lr: 0.0009827109752222896
      grad_gnorm: 40.0
      policy_entropy: 10.878215789794922
      policy_loss: 24.373924255371094
      var_gnorm: 22.847253799438477
      vf_explained_var: 0.0
      vf_loss: 68.00875854492188
    num_steps_sampled: 5670000
    num_steps_trained: 5670000
    wait_time_ms: 75.299
  iterations_since_restore: 1134
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9927.733064174652
  time_this_iter_s: 8.674489259719849
  time_total_s: 9927.733064174652
  timestamp: 1594858460
  timesteps_since_restore: 5670000
  timesteps_this_iter: 5000
  timesteps_total: 5670000
  training_iteration: 1134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9927 s, 1134 iter, 5670000 ts, 267 rew

agent-1: 65.39999996309486
agent-2: 56.39999996309477
agent-3: 58.39999996309478
agent-4: 62.399999963094785
agent-5: 63.39999996309478
Extrinsic Rewards:
11
2
4
8
9
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.27058823529411763
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 269.8244346676954
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1134
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.931
    dispatch_time_ms: 7.43
    learner:
      cur_lr: 0.0009823780274018645
      grad_gnorm: 40.0
      policy_entropy: 20.305084228515625
      policy_loss: 54.76576232910156
      var_gnorm: 22.856943130493164
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 94.62274932861328
    num_steps_sampled: 5675000
    num_steps_trained: 5675000
    wait_time_ms: 73.638
  iterations_since_restore: 1135
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9936.315759658813
  time_this_iter_s: 8.582695484161377
  time_total_s: 9936.315759658813
  timestamp: 1594858469
  timesteps_since_restore: 5675000
  timesteps_this_iter: 5000
  timesteps_total: 5675000
  training_iteration: 1135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9936 s, 1135 iter, 5675000 ts, 270 rew

agent-1: 210.12348160722107
agent-2: 193.12348160722107
agent-3: 185.123481607221
agent-4: 193.12348160722107
agent-5: 211.12348160722118
Extrinsic Rewards:
34
17
9
17
35
Sum Reward: 112
Avg Reward: 22.4
Min Reward: 9
Max Reward: 35
Gini Coefficient: 0.24642857142857144
20:20 Ratio: 3.888888888888889
Max-min Ratio: 3.888888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 277.007249248165
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1135
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.646
    dispatch_time_ms: 5.673
    learner:
      cur_lr: 0.0009820449631661177
      grad_gnorm: 40.0
      policy_entropy: 33.249916076660156
      policy_loss: -14.898649215698242
      var_gnorm: 22.85917091369629
      vf_explained_var: 0.0
      vf_loss: 6.887258052825928
    num_steps_sampled: 5680000
    num_steps_trained: 5680000
    wait_time_ms: 80.045
  iterations_since_restore: 1136
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9944.94810795784
  time_this_iter_s: 8.63234829902649
  time_total_s: 9944.94810795784
  timestamp: 1594858477
  timesteps_since_restore: 5680000
  timesteps_this_iter: 5000
  timesteps_total: 5680000
  training_iteration: 1136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9944 s, 1136 iter, 5680000 ts, 277 rew

agent-1: 95.79999840920557
agent-2: 91.79999840920557
agent-3: 97.79999840920554
agent-4: 101.79999840920554
agent-5: 89.7999984092056
Extrinsic Rewards:
11
7
13
17
5
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 5
Max Reward: 17
Gini Coefficient: 0.22641509433962265
20:20 Ratio: 3.4
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 278.1772587820323
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1136
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.79
    dispatch_time_ms: 7.824
    learner:
      cur_lr: 0.0009817120153456926
      grad_gnorm: 17.65471839904785
      policy_entropy: 33.18917465209961
      policy_loss: -3.146223545074463
      var_gnorm: 22.85128402709961
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.23450243473052979
    num_steps_sampled: 5685000
    num_steps_trained: 5685000
    wait_time_ms: 79.021
  iterations_since_restore: 1137
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9953.581872463226
  time_this_iter_s: 8.633764505386353
  time_total_s: 9953.581872463226
  timestamp: 1594858486
  timesteps_since_restore: 5685000
  timesteps_this_iter: 5000
  timesteps_total: 5685000
  training_iteration: 1137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9953 s, 1137 iter, 5685000 ts, 278 rew

agent-1: 36.79999999937302
agent-2: 28.79999999937307
agent-3: 36.79999999937302
agent-4: 29.799999999373078
agent-5: 29.799999999373078
Extrinsic Rewards:
8
0
8
1
1
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.5111111111111111
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-14-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 276.6472952326071
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1137
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 9.718
    learner:
      cur_lr: 0.0009813789511099458
      grad_gnorm: 18.365949630737305
      policy_entropy: 50.31907272338867
      policy_loss: -3.329758405685425
      var_gnorm: 22.984359741210938
      vf_explained_var: 0.0
      vf_loss: 0.23618990182876587
    num_steps_sampled: 5690000
    num_steps_trained: 5690000
    wait_time_ms: 75.689
  iterations_since_restore: 1138
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9962.177555322647
  time_this_iter_s: 8.595682859420776
  time_total_s: 9962.177555322647
  timestamp: 1594858494
  timesteps_since_restore: 5690000
  timesteps_this_iter: 5000
  timesteps_total: 5690000
  training_iteration: 1138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9962 s, 1138 iter, 5690000 ts, 277 rew

agent-1: 61.399999994103446
agent-2: 68.39999999410327
agent-3: 59.39999999410344
agent-4: 55.39999999410343
agent-5: 61.39999999410344
Extrinsic Rewards:
7
14
5
1
7
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.32941176470588235
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 277.1872952343718
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1138
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.717
    dispatch_time_ms: 5.727
    learner:
      cur_lr: 0.0009810460032895207
      grad_gnorm: 23.44647789001465
      policy_entropy: 39.91568374633789
      policy_loss: -3.951666831970215
      var_gnorm: 23.00125503540039
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.40952274203300476
    num_steps_sampled: 5695000
    num_steps_trained: 5695000
    wait_time_ms: 80.451
  iterations_since_restore: 1139
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9970.885350704193
  time_this_iter_s: 8.70779538154602
  time_total_s: 9970.885350704193
  timestamp: 1594858503
  timesteps_since_restore: 5695000
  timesteps_this_iter: 5000
  timesteps_total: 5695000
  training_iteration: 1139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9970 s, 1139 iter, 5695000 ts, 277 rew

agent-1: 58.399999980204925
agent-2: 61.399999980204925
agent-3: 71.39999998020483
agent-4: 59.399999980204925
agent-5: 55.399999980204925
Extrinsic Rewards:
4
7
17
5
1
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 1
Max Reward: 17
Gini Coefficient: 0.4117647058823529
20:20 Ratio: 17.0
Max-min Ratio: 17.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 276.10729523579886
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1139
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 5.214
    dispatch_time_ms: 159.893
    learner:
      cur_lr: 0.0009807130554690957
      grad_gnorm: 14.88486099243164
      policy_entropy: 45.2812385559082
      policy_loss: -4.212028503417969
      var_gnorm: 22.997745513916016
      vf_explained_var: 0.0
      vf_loss: 0.19349658489227295
    num_steps_sampled: 5700000
    num_steps_trained: 5700000
    wait_time_ms: 21.746
  iterations_since_restore: 1140
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9980.59017753601
  time_this_iter_s: 9.704826831817627
  time_total_s: 9980.59017753601
  timestamp: 1594858513
  timesteps_since_restore: 5700000
  timesteps_this_iter: 5000
  timesteps_total: 5700000
  training_iteration: 1140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9980 s, 1140 iter, 5700000 ts, 276 rew

agent-1: 105.79999912523586
agent-2: 106.79999912523586
agent-3: 105.79999912523586
agent-4: 103.79999912523583
agent-5: 99.79999912523586
Extrinsic Rewards:
13
14
13
11
7
Sum Reward: 58
Avg Reward: 11.6
Min Reward: 7
Max Reward: 14
Gini Coefficient: 0.1103448275862069
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 277.7272951939192
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1140
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.473
    dispatch_time_ms: 8.091
    learner:
      cur_lr: 0.0009803799912333488
      grad_gnorm: 12.05239200592041
      policy_entropy: 50.58369064331055
      policy_loss: -3.1919171810150146
      var_gnorm: 22.993282318115234
      vf_explained_var: 0.0
      vf_loss: 0.1097300574183464
    num_steps_sampled: 5705000
    num_steps_trained: 5705000
    wait_time_ms: 77.22
  iterations_since_restore: 1141
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9988.946007966995
  time_this_iter_s: 8.355830430984497
  time_total_s: 9988.946007966995
  timestamp: 1594858521
  timesteps_since_restore: 5705000
  timesteps_this_iter: 5000
  timesteps_total: 5705000
  training_iteration: 1141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9988 s, 1141 iter, 5705000 ts, 278 rew

agent-1: 39.399999999241864
agent-2: 32.3999999992419
agent-3: 32.3999999992419
agent-4: 35.3999999992419
agent-5: 31.399999999241945
Extrinsic Rewards:
9
2
2
5
1
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 276.6472951940079
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1141
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.547
    dispatch_time_ms: 9.973
    learner:
      cur_lr: 0.0009800470434129238
      grad_gnorm: 7.4350666999816895
      policy_entropy: 50.37195587158203
      policy_loss: 2.016669511795044
      var_gnorm: 22.98755645751953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.04588773846626282
    num_steps_sampled: 5710000
    num_steps_trained: 5710000
    wait_time_ms: 74.347
  iterations_since_restore: 1142
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 9997.718137741089
  time_this_iter_s: 8.772129774093628
  time_total_s: 9997.718137741089
  timestamp: 1594858530
  timesteps_since_restore: 5710000
  timesteps_this_iter: 5000
  timesteps_total: 5710000
  training_iteration: 1142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 9997 s, 1142 iter, 5710000 ts, 277 rew

agent-1: 36.999999998978666
agent-2: 35.99999999897865
agent-3: 36.99999999897866
agent-4: 35.99999999897865
agent-5: 33.99999999897865
Extrinsic Rewards:
5
4
5
4
2
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.14
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 272.4172966909157
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1142
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.277
    dispatch_time_ms: 9.044
    learner:
      cur_lr: 0.000979713979177177
      grad_gnorm: 15.695693016052246
      policy_entropy: 51.51885986328125
      policy_loss: -4.2559967041015625
      var_gnorm: 22.99310302734375
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.18908938765525818
    num_steps_sampled: 5715000
    num_steps_trained: 5715000
    wait_time_ms: 78.528
  iterations_since_restore: 1143
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10006.359635353088
  time_this_iter_s: 8.641497611999512
  time_total_s: 10006.359635353088
  timestamp: 1594858539
  timesteps_since_restore: 5715000
  timesteps_this_iter: 5000
  timesteps_total: 5715000
  training_iteration: 1143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10006 s, 1143 iter, 5715000 ts, 272 rew

agent-1: 44.39999999743616
agent-2: 40.39999999743617
agent-3: 43.39999999743616
agent-4: 44.39999999743617
agent-5: 43.399999997436154
Extrinsic Rewards:
6
2
5
6
5
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.15
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 272.8672966908433
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1143
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.365
    dispatch_time_ms: 9.928
    learner:
      cur_lr: 0.000979381031356752
      grad_gnorm: 12.902674674987793
      policy_entropy: 18.032012939453125
      policy_loss: -1.8271846771240234
      var_gnorm: 23.005653381347656
      vf_explained_var: 0.0
      vf_loss: 0.12526102364063263
    num_steps_sampled: 5720000
    num_steps_trained: 5720000
    wait_time_ms: 74.493
  iterations_since_restore: 1144
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10015.052749633789
  time_this_iter_s: 8.693114280700684
  time_total_s: 10015.052749633789
  timestamp: 1594858548
  timesteps_since_restore: 5720000
  timesteps_this_iter: 5000
  timesteps_total: 5720000
  training_iteration: 1144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10015 s, 1144 iter, 5720000 ts, 273 rew

agent-1: 36.19999999835661
agent-2: 38.19999999835661
agent-3: 36.19999999835661
agent-4: 41.1999999983566
agent-5: 46.1999999983566
Extrinsic Rewards:
1
3
1
6
11
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.45454545454545453
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-15-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 270.79729669403116
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1144
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.679
    dispatch_time_ms: 10.078
    learner:
      cur_lr: 0.000979047967121005
      grad_gnorm: 21.567798614501953
      policy_entropy: 31.241426467895508
      policy_loss: -3.575728178024292
      var_gnorm: 23.00189971923828
      vf_explained_var: 0.0
      vf_loss: 0.3567865192890167
    num_steps_sampled: 5725000
    num_steps_trained: 5725000
    wait_time_ms: 75.595
  iterations_since_restore: 1145
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10023.799268960953
  time_this_iter_s: 8.746519327163696
  time_total_s: 10023.799268960953
  timestamp: 1594858556
  timesteps_since_restore: 5725000
  timesteps_this_iter: 5000
  timesteps_total: 5725000
  training_iteration: 1145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10023 s, 1145 iter, 5725000 ts, 271 rew

agent-1: 25.999999999437293
agent-2: 24.99999999943729
agent-3: 24.99999999943729
agent-4: 26.999999999437293
agent-5: 31.9999999994373
Extrinsic Rewards:
2
1
1
3
8
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.4266666666666667
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 268.187296695468
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1145
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.051
    dispatch_time_ms: 7.464
    learner:
      cur_lr: 0.00097871501930058
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.460296630859375
      policy_loss: 31.490833282470703
      var_gnorm: 23.00460433959961
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 37.663761138916016
    num_steps_sampled: 5730000
    num_steps_trained: 5730000
    wait_time_ms: 72.854
  iterations_since_restore: 1146
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10032.424772977829
  time_this_iter_s: 8.62550401687622
  time_total_s: 10032.424772977829
  timestamp: 1594858565
  timesteps_since_restore: 5730000
  timesteps_this_iter: 5000
  timesteps_total: 5730000
  training_iteration: 1146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10032 s, 1146 iter, 5730000 ts, 268 rew

agent-1: 104.79999968485646
agent-2: 105.79999968485645
agent-3: 102.79999968485645
agent-4: 102.79999968485643
agent-5: 105.79999968485643
Extrinsic Rewards:
12
13
10
10
13
Sum Reward: 58
Avg Reward: 11.6
Min Reward: 10
Max Reward: 13
Gini Coefficient: 0.06206896551724138
20:20 Ratio: 1.3
Max-min Ratio: 1.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 270.3472966799213
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1146
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.927
    dispatch_time_ms: 6.649
    learner:
      cur_lr: 0.0009783819550648332
      grad_gnorm: 40.0
      policy_entropy: 33.758399963378906
      policy_loss: -6.412942886352539
      var_gnorm: 23.01093101501465
      vf_explained_var: 0.0
      vf_loss: 1.3853851556777954
    num_steps_sampled: 5735000
    num_steps_trained: 5735000
    wait_time_ms: 77.911
  iterations_since_restore: 1147
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10041.114240169525
  time_this_iter_s: 8.689467191696167
  time_total_s: 10041.114240169525
  timestamp: 1594858574
  timesteps_since_restore: 5735000
  timesteps_this_iter: 5000
  timesteps_total: 5735000
  training_iteration: 1147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10041 s, 1147 iter, 5735000 ts, 270 rew

agent-1: 128.19997477779825
agent-2: 133.19997477779813
agent-3: 146.19997477779816
agent-4: 137.19997477779825
agent-5: 148.19997477779822
Extrinsic Rewards:
5
10
23
14
25
Sum Reward: 77
Avg Reward: 15.4
Min Reward: 5
Max Reward: 25
Gini Coefficient: 0.2753246753246753
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 275.56729541886114
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1147
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.236
    dispatch_time_ms: 10.96
    learner:
      cur_lr: 0.0009780490072444081
      grad_gnorm: 40.0
      policy_entropy: 5.168142795562744
      policy_loss: 2.1303141117095947
      var_gnorm: 23.010963439941406
      vf_explained_var: 0.0
      vf_loss: 3.7438530921936035
    num_steps_sampled: 5740000
    num_steps_trained: 5740000
    wait_time_ms: 70.844
  iterations_since_restore: 1148
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10049.72629070282
  time_this_iter_s: 8.612050533294678
  time_total_s: 10049.72629070282
  timestamp: 1594858582
  timesteps_since_restore: 5740000
  timesteps_this_iter: 5000
  timesteps_total: 5740000
  training_iteration: 1148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10049 s, 1148 iter, 5740000 ts, 276 rew

agent-1: 56.99999999386843
agent-2: 53.999999993868435
agent-3: 51.999999993868435
agent-4: 51.99999999386845
agent-5: 54.99999999386843
Extrinsic Rewards:
9
6
4
4
7
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.17333333333333334
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 276.28729541863436
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1148
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.637
    dispatch_time_ms: 5.499
    learner:
      cur_lr: 0.0009777159430086613
      grad_gnorm: 40.0
      policy_entropy: 25.150278091430664
      policy_loss: -6.486387252807617
      var_gnorm: 23.018836975097656
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.9252759218215942
    num_steps_sampled: 5745000
    num_steps_trained: 5745000
    wait_time_ms: 83.654
  iterations_since_restore: 1149
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10058.373336553574
  time_this_iter_s: 8.647045850753784
  time_total_s: 10058.373336553574
  timestamp: 1594858591
  timesteps_since_restore: 5745000
  timesteps_this_iter: 5000
  timesteps_total: 5745000
  training_iteration: 1149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10058 s, 1149 iter, 5745000 ts, 276 rew

agent-1: 77.79961252562363
agent-2: 82.79961252562363
agent-3: 88.79961252562366
agent-4: 92.79961252562367
agent-5: 89.79961252562364
Extrinsic Rewards:
1
6
12
16
13
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 1
Max Reward: 16
Gini Coefficient: 0.30833333333333335
20:20 Ratio: 16.0
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 278.6272760449734
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1149
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.943
    dispatch_time_ms: 7.186
    learner:
      cur_lr: 0.0009773829951882362
      grad_gnorm: 30.525314331054688
      policy_entropy: 37.492279052734375
      policy_loss: -5.8166399002075195
      var_gnorm: 23.00705909729004
      vf_explained_var: 0.0
      vf_loss: 0.7154895067214966
    num_steps_sampled: 5750000
    num_steps_trained: 5750000
    wait_time_ms: 78.811
  iterations_since_restore: 1150
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10067.091267108917
  time_this_iter_s: 8.717930555343628
  time_total_s: 10067.091267108917
  timestamp: 1594858600
  timesteps_since_restore: 5750000
  timesteps_this_iter: 5000
  timesteps_total: 5750000
  training_iteration: 1150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10067 s, 1150 iter, 5750000 ts, 279 rew

agent-1: 80.99999968636206
agent-2: 76.99999968636206
agent-3: 78.99999968636206
agent-4: 74.99999968636207
agent-5: 92.9999996863621
Extrinsic Rewards:
9
5
7
3
21
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 3
Max Reward: 21
Gini Coefficient: 0.35555555555555557
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 280.33727602943964
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1150
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.698
    dispatch_time_ms: 5.578
    learner:
      cur_lr: 0.0009770500473678112
      grad_gnorm: 24.243249893188477
      policy_entropy: 39.08435821533203
      policy_loss: -4.277767181396484
      var_gnorm: 23.005956649780273
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.4456401765346527
    num_steps_sampled: 5755000
    num_steps_trained: 5755000
    wait_time_ms: 74.997
  iterations_since_restore: 1151
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10075.692335605621
  time_this_iter_s: 8.601068496704102
  time_total_s: 10075.692335605621
  timestamp: 1594858608
  timesteps_since_restore: 5755000
  timesteps_this_iter: 5000
  timesteps_total: 5755000
  training_iteration: 1151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10075 s, 1151 iter, 5755000 ts, 280 rew

agent-1: 58.99999998957426
agent-2: 62.99999998957426
agent-3: 67.99999998957445
agent-4: 61.99999998957426
agent-5: 62.99999998957426
Extrinsic Rewards:
3
7
12
6
7
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.21714285714285714
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-16-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 279.9772760307726
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1151
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 41.759
    learner:
      cur_lr: 0.0009767169831320643
      grad_gnorm: 14.975360870361328
      policy_entropy: 37.14793014526367
      policy_loss: -2.8622682094573975
      var_gnorm: 23.00579833984375
      vf_explained_var: 0.0
      vf_loss: 0.17042581737041473
    num_steps_sampled: 5760000
    num_steps_trained: 5760000
    wait_time_ms: 55.706
  iterations_since_restore: 1152
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10084.799772024155
  time_this_iter_s: 9.107436418533325
  time_total_s: 10084.799772024155
  timestamp: 1594858618
  timesteps_since_restore: 5760000
  timesteps_this_iter: 5000
  timesteps_total: 5760000
  training_iteration: 1152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10084 s, 1152 iter, 5760000 ts, 280 rew

agent-1: 85.59999866906286
agent-2: 85.59999866906286
agent-3: 80.59999866906287
agent-4: 81.59999866906286
agent-5: 80.59999866906287
Extrinsic Rewards:
12
12
7
8
7
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 7
Max Reward: 12
Gini Coefficient: 0.13043478260869565
20:20 Ratio: 1.7142857142857142
Max-min Ratio: 1.7142857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 281.4172759643208
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1152
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.874
    dispatch_time_ms: 5.437
    learner:
      cur_lr: 0.0009763839771039784
      grad_gnorm: 12.40736198425293
      policy_entropy: 19.793798446655273
      policy_loss: -1.6218886375427246
      var_gnorm: 23.007610321044922
      vf_explained_var: 0.0
      vf_loss: 0.11500602960586548
    num_steps_sampled: 5765000
    num_steps_trained: 5765000
    wait_time_ms: 78.421
  iterations_since_restore: 1153
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10093.499794721603
  time_this_iter_s: 8.70002269744873
  time_total_s: 10093.499794721603
  timestamp: 1594858626
  timesteps_since_restore: 5765000
  timesteps_this_iter: 5000
  timesteps_total: 5765000
  training_iteration: 1153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10093 s, 1153 iter, 5765000 ts, 281 rew

agent-1: 49.799999999124225
agent-2: 46.799999999124225
agent-3: 46.799999999124225
agent-4: 55.79999999912424
agent-5: 52.79999999912424
Extrinsic Rewards:
5
2
2
11
8
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.34285714285714286
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 281.95727596437666
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1153
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.008
    dispatch_time_ms: 9.499
    learner:
      cur_lr: 0.0009760509710758924
      grad_gnorm: 40.0
      policy_entropy: 23.039154052734375
      policy_loss: 33.86860275268555
      var_gnorm: 23.007383346557617
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 72.71977996826172
    num_steps_sampled: 5770000
    num_steps_trained: 5770000
    wait_time_ms: 73.887
  iterations_since_restore: 1154
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10102.17273402214
  time_this_iter_s: 8.67293930053711
  time_total_s: 10102.17273402214
  timestamp: 1594858635
  timesteps_since_restore: 5770000
  timesteps_this_iter: 5000
  timesteps_total: 5770000
  training_iteration: 1154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10102 s, 1154 iter, 5770000 ts, 282 rew

agent-1: 50.39999999606538
agent-2: 54.39999999606538
agent-3: 53.39999999606538
agent-4: 54.39999999606538
agent-5: 48.39999999606538
Extrinsic Rewards:
4
8
7
8
2
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2206896551724138
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 280.8772759650817
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1154
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.162
    dispatch_time_ms: 8.687
    learner:
      cur_lr: 0.0009757180232554674
      grad_gnorm: 30.76007080078125
      policy_entropy: 32.99321746826172
      policy_loss: -4.428645610809326
      var_gnorm: 23.008642196655273
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.7290814518928528
    num_steps_sampled: 5775000
    num_steps_trained: 5775000
    wait_time_ms: 74.968
  iterations_since_restore: 1155
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10110.90315413475
  time_this_iter_s: 8.730420112609863
  time_total_s: 10110.90315413475
  timestamp: 1594858644
  timesteps_since_restore: 5775000
  timesteps_this_iter: 5000
  timesteps_total: 5775000
  training_iteration: 1155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10110 s, 1155 iter, 5775000 ts, 281 rew

agent-1: 75.39999986969704
agent-2: 79.39999986969704
agent-3: 78.39999986969704
agent-4: 83.3999998696971
agent-5: 79.39999986969707
Extrinsic Rewards:
5
9
8
13
9
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 5
Max Reward: 13
Gini Coefficient: 0.15454545454545454
20:20 Ratio: 2.6
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 280.0672762367136
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1155
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.857
    dispatch_time_ms: 9.874
    learner:
      cur_lr: 0.0009753850172273815
      grad_gnorm: 5.581419944763184
      policy_entropy: 38.51924514770508
      policy_loss: 1.1044529676437378
      var_gnorm: 23.006664276123047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.026176096871495247
    num_steps_sampled: 5780000
    num_steps_trained: 5780000
    wait_time_ms: 75.012
  iterations_since_restore: 1156
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10119.577092409134
  time_this_iter_s: 8.673938274383545
  time_total_s: 10119.577092409134
  timestamp: 1594858653
  timesteps_since_restore: 5780000
  timesteps_this_iter: 5000
  timesteps_total: 5780000
  training_iteration: 1156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10119 s, 1156 iter, 5780000 ts, 280 rew

agent-1: 80.79999996365534
agent-2: 87.79999996365534
agent-3: 91.79999996365537
agent-4: 88.79999996365534
agent-5: 82.79999996365534
Extrinsic Rewards:
4
11
15
12
6
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 4
Max Reward: 15
Gini Coefficient: 0.23333333333333334
20:20 Ratio: 3.75
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-17-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 282.85727623493426
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1156
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.114
    dispatch_time_ms: 9.146
    learner:
      cur_lr: 0.0009750520111992955
      grad_gnorm: 24.181406021118164
      policy_entropy: 32.072879791259766
      policy_loss: -3.874065637588501
      var_gnorm: 23.006694793701172
      vf_explained_var: 0.0
      vf_loss: 0.4500966966152191
    num_steps_sampled: 5785000
    num_steps_trained: 5785000
    wait_time_ms: 74.278
  iterations_since_restore: 1157
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10138.216719388962
  time_this_iter_s: 18.63962697982788
  time_total_s: 10138.216719388962
  timestamp: 1594858671
  timesteps_since_restore: 5785000
  timesteps_this_iter: 5000
  timesteps_total: 5785000
  training_iteration: 1157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10138 s, 1157 iter, 5785000 ts, 283 rew

agent-1: 38.79999999852541
agent-2: 39.799999998525415
agent-3: 38.799999998525415
agent-4: 48.79999999852541
agent-5: 40.79999999852541
Extrinsic Rewards:
2
3
2
12
4
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.3826086956521739
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 278.3604324484544
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1157
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.281
    dispatch_time_ms: 7.897
    learner:
      cur_lr: 0.0009747190051712096
      grad_gnorm: 18.319543838500977
      policy_entropy: 34.85898971557617
      policy_loss: -3.8411548137664795
      var_gnorm: 23.006044387817383
      vf_explained_var: 0.0
      vf_loss: 0.25596991181373596
    num_steps_sampled: 5790000
    num_steps_trained: 5790000
    wait_time_ms: 76.63
  iterations_since_restore: 1158
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10146.835463762283
  time_this_iter_s: 8.618744373321533
  time_total_s: 10146.835463762283
  timestamp: 1594858680
  timesteps_since_restore: 5790000
  timesteps_this_iter: 5000
  timesteps_total: 5790000
  training_iteration: 1158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10146 s, 1158 iter, 5790000 ts, 278 rew

agent-1: 78.9999997438829
agent-2: 84.9999997438829
agent-3: 88.9999997438829
agent-4: 74.99999974388294
agent-5: 76.99999974388292
Extrinsic Rewards:
7
13
17
3
5
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 3
Max Reward: 17
Gini Coefficient: 0.32
20:20 Ratio: 5.666666666666667
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 278.9004324422929
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1158
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.227
    dispatch_time_ms: 9.178
    learner:
      cur_lr: 0.0009743859991431236
      grad_gnorm: 15.029658317565918
      policy_entropy: 25.808744430541992
      policy_loss: -1.381218433380127
      var_gnorm: 23.006685256958008
      vf_explained_var: 0.0
      vf_loss: 0.16288678348064423
    num_steps_sampled: 5795000
    num_steps_trained: 5795000
    wait_time_ms: 75.448
  iterations_since_restore: 1159
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10155.40988779068
  time_this_iter_s: 8.574424028396606
  time_total_s: 10155.40988779068
  timestamp: 1594858688
  timesteps_since_restore: 5795000
  timesteps_this_iter: 5000
  timesteps_total: 5795000
  training_iteration: 1159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10155 s, 1159 iter, 5795000 ts, 279 rew

agent-1: 79.59999996655992
agent-2: 74.59999996655998
agent-3: 71.59999996655996
agent-4: 67.59999996656
agent-5: 75.59999996655998
Extrinsic Rewards:
14
9
6
2
10
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.2731707317073171
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 274.4904691840622
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1159
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.732
    dispatch_time_ms: 7.093
    learner:
      cur_lr: 0.0009740529931150377
      grad_gnorm: 15.096805572509766
      policy_entropy: 36.98329162597656
      policy_loss: -2.108917713165283
      var_gnorm: 23.006643295288086
      vf_explained_var: 0.0
      vf_loss: 0.1635069102048874
    num_steps_sampled: 5800000
    num_steps_trained: 5800000
    wait_time_ms: 73.74
  iterations_since_restore: 1160
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10164.062848091125
  time_this_iter_s: 8.652960300445557
  time_total_s: 10164.062848091125
  timestamp: 1594858697
  timesteps_since_restore: 5800000
  timesteps_this_iter: 5000
  timesteps_total: 5800000
  training_iteration: 1160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10164 s, 1160 iter, 5800000 ts, 274 rew

agent-1: 49.399999994742295
agent-2: 50.39999999474231
agent-3: 51.39999999474231
agent-4: 59.399999994742295
agent-5: 50.39999999474231
Extrinsic Rewards:
3
4
5
13
4
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.2896551724137931
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 273.4104691850189
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1160
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.331
    dispatch_time_ms: 7.71
    learner:
      cur_lr: 0.0009737199870869517
      grad_gnorm: 16.410078048706055
      policy_entropy: 25.85003662109375
      policy_loss: 2.4405462741851807
      var_gnorm: 23.00507926940918
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.20842419564723969
    num_steps_sampled: 5805000
    num_steps_trained: 5805000
    wait_time_ms: 76.004
  iterations_since_restore: 1161
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10172.659592866898
  time_this_iter_s: 8.596744775772095
  time_total_s: 10172.659592866898
  timestamp: 1594858706
  timesteps_since_restore: 5805000
  timesteps_this_iter: 5000
  timesteps_total: 5805000
  training_iteration: 1161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10172 s, 1161 iter, 5805000 ts, 273 rew

agent-1: 87.79999995756874
agent-2: 86.79999995756872
agent-3: 87.79999995756874
agent-4: 79.79999995756869
agent-5: 89.79999995756872
Extrinsic Rewards:
11
10
11
3
13
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.175
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 275.03046918306995
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1161
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.636
    dispatch_time_ms: 5.525
    learner:
      cur_lr: 0.0009733869810588658
      grad_gnorm: 17.205087661743164
      policy_entropy: 30.192520141601562
      policy_loss: -2.3560776710510254
      var_gnorm: 23.00463104248047
      vf_explained_var: 0.0
      vf_loss: 0.22849996387958527
    num_steps_sampled: 5810000
    num_steps_trained: 5810000
    wait_time_ms: 83.061
  iterations_since_restore: 1162
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10181.406539201736
  time_this_iter_s: 8.746946334838867
  time_total_s: 10181.406539201736
  timestamp: 1594858715
  timesteps_since_restore: 5810000
  timesteps_this_iter: 5000
  timesteps_total: 5810000
  training_iteration: 1162
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10181 s, 1162 iter, 5810000 ts, 275 rew

agent-1: 64.199999983545
agent-2: 61.199999983544885
agent-3: 78.19999998354508
agent-4: 64.199999983545
agent-5: 65.19999998354504
Extrinsic Rewards:
5
2
19
5
6
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 2
Max Reward: 19
Gini Coefficient: 0.3783783783783784
20:20 Ratio: 9.5
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 272.4204692087302
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1162
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.636
    dispatch_time_ms: 7.009
    learner:
      cur_lr: 0.0009730539750307798
      grad_gnorm: 12.853400230407715
      policy_entropy: 22.987476348876953
      policy_loss: -1.5532187223434448
      var_gnorm: 23.005563735961914
      vf_explained_var: 0.0
      vf_loss: 0.12742319703102112
    num_steps_sampled: 5815000
    num_steps_trained: 5815000
    wait_time_ms: 77.124
  iterations_since_restore: 1163
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10190.071557283401
  time_this_iter_s: 8.665018081665039
  time_total_s: 10190.071557283401
  timestamp: 1594858723
  timesteps_since_restore: 5815000
  timesteps_this_iter: 5000
  timesteps_total: 5815000
  training_iteration: 1163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10190 s, 1163 iter, 5815000 ts, 272 rew

agent-1: 81.79999996405886
agent-2: 80.79999996405888
agent-3: 71.79999996405886
agent-4: 73.79999996405888
agent-5: 78.79999996405888
Extrinsic Rewards:
13
12
3
5
10
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.25116279069767444
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-18-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 273.95046920713827
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1163
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.896
    dispatch_time_ms: 6.68
    learner:
      cur_lr: 0.0009727210272103548
      grad_gnorm: 16.681171417236328
      policy_entropy: 21.218786239624023
      policy_loss: -1.6099629402160645
      var_gnorm: 23.005062103271484
      vf_explained_var: 0.0
      vf_loss: 0.215188667178154
    num_steps_sampled: 5820000
    num_steps_trained: 5820000
    wait_time_ms: 79.911
  iterations_since_restore: 1164
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10198.716099500656
  time_this_iter_s: 8.644542217254639
  time_total_s: 10198.716099500656
  timestamp: 1594858732
  timesteps_since_restore: 5820000
  timesteps_this_iter: 5000
  timesteps_total: 5820000
  training_iteration: 1164
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10198 s, 1164 iter, 5820000 ts, 274 rew

agent-1: 26.999999999629786
agent-2: 27.999999999629786
agent-3: 23.99999999962978
agent-4: 27.999999999629786
agent-5: 27.999999999629786
Extrinsic Rewards:
3
4
0
4
4
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 4
Gini Coefficient: 0.24
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1067.7630433512443
  episode_reward_mean: 272.24046920771207
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1164
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.446
    dispatch_time_ms: 8.479
    learner:
      cur_lr: 0.0009723880211822689
      grad_gnorm: 40.000003814697266
      policy_entropy: 17.297985076904297
      policy_loss: -4.334654808044434
      var_gnorm: 23.018444061279297
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.7028495073318481
    num_steps_sampled: 5825000
    num_steps_trained: 5825000
    wait_time_ms: 79.717
  iterations_since_restore: 1165
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10207.327076911926
  time_this_iter_s: 8.610977411270142
  time_total_s: 10207.327076911926
  timestamp: 1594858741
  timesteps_since_restore: 5825000
  timesteps_this_iter: 5000
  timesteps_total: 5825000
  training_iteration: 1165
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10207 s, 1165 iter, 5825000 ts, 272 rew

agent-1: 239.30782063808357
agent-2: 253.30782063808365
agent-3: 263.30782063808374
agent-4: 245.30782063808368
agent-5: 258.3078206380836
Extrinsic Rewards:
16
30
40
22
35
Sum Reward: 143
Avg Reward: 28.6
Min Reward: 16
Max Reward: 40
Gini Coefficient: 0.17062937062937064
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 278.8958603722656
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1165
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 8.351
    learner:
      cur_lr: 0.0009720550151541829
      grad_gnorm: 40.000003814697266
      policy_entropy: 7.927488327026367
      policy_loss: 1.304595947265625
      var_gnorm: 23.01997184753418
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.802966117858887
    num_steps_sampled: 5830000
    num_steps_trained: 5830000
    wait_time_ms: 75.036
  iterations_since_restore: 1166
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10215.966667413712
  time_this_iter_s: 8.639590501785278
  time_total_s: 10215.966667413712
  timestamp: 1594858749
  timesteps_since_restore: 5830000
  timesteps_this_iter: 5000
  timesteps_total: 5830000
  training_iteration: 1166
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10215 s, 1166 iter, 5830000 ts, 279 rew

agent-1: 57.1999999933272
agent-2: 60.1999999933272
agent-3: 56.1999999933272
agent-4: 57.19999999332719
agent-5: 57.1999999933272
Extrinsic Rewards:
6
9
5
6
6
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 5
Max Reward: 9
Gini Coefficient: 0.1
20:20 Ratio: 1.8
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 278.3558603721792
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1166
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.102
    dispatch_time_ms: 8.038
    learner:
      cur_lr: 0.000971722009126097
      grad_gnorm: 40.0
      policy_entropy: 25.038087844848633
      policy_loss: 17.396100997924805
      var_gnorm: 23.02191925048828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 8.951632499694824
    num_steps_sampled: 5835000
    num_steps_trained: 5835000
    wait_time_ms: 75.452
  iterations_since_restore: 1167
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10224.482334136963
  time_this_iter_s: 8.515666723251343
  time_total_s: 10224.482334136963
  timestamp: 1594858758
  timesteps_since_restore: 5835000
  timesteps_this_iter: 5000
  timesteps_total: 5835000
  training_iteration: 1167
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10224 s, 1167 iter, 5835000 ts, 278 rew

agent-1: 169.9155082217688
agent-2: 175.91550822176882
agent-3: 169.91550822176882
agent-4: 167.91550822176882
agent-5: 170.91550822176882
Extrinsic Rewards:
18
24
18
16
19
Sum Reward: 95
Avg Reward: 19.0
Min Reward: 16
Max Reward: 24
Gini Coefficient: 0.07157894736842105
20:20 Ratio: 1.5
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 281.6816358015731
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1167
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.047
    dispatch_time_ms: 8.293
    learner:
      cur_lr: 0.000971389003098011
      grad_gnorm: 39.999996185302734
      policy_entropy: 15.11486530303955
      policy_loss: -3.959925889968872
      var_gnorm: 23.01348304748535
      vf_explained_var: 0.0
      vf_loss: 2.2399699687957764
    num_steps_sampled: 5840000
    num_steps_trained: 5840000
    wait_time_ms: 74.653
  iterations_since_restore: 1168
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10233.099200963974
  time_this_iter_s: 8.616866827011108
  time_total_s: 10233.099200963974
  timestamp: 1594858766
  timesteps_since_restore: 5840000
  timesteps_this_iter: 5000
  timesteps_total: 5840000
  training_iteration: 1168
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10233 s, 1168 iter, 5840000 ts, 282 rew

agent-1: 89.39999977749177
agent-2: 84.39999977749177
agent-3: 87.39999977749179
agent-4: 82.39999977749179
agent-5: 97.39999977749177
Extrinsic Rewards:
11
6
9
4
19
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 4
Max Reward: 19
Gini Coefficient: 0.2857142857142857
20:20 Ratio: 4.75
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 283.2116357907813
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1168
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.405
    dispatch_time_ms: 14.189
    learner:
      cur_lr: 0.0009710559970699251
      grad_gnorm: 29.224830627441406
      policy_entropy: 35.7282829284668
      policy_loss: -5.064097881317139
      var_gnorm: 23.006362915039062
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.6364639401435852
    num_steps_sampled: 5845000
    num_steps_trained: 5845000
    wait_time_ms: 74.751
  iterations_since_restore: 1169
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10242.446687936783
  time_this_iter_s: 9.347486972808838
  time_total_s: 10242.446687936783
  timestamp: 1594858776
  timesteps_since_restore: 5845000
  timesteps_this_iter: 5000
  timesteps_total: 5845000
  training_iteration: 1169
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10242 s, 1169 iter, 5845000 ts, 283 rew

agent-1: 27.5999999995088
agent-2: 33.59999999950888
agent-3: 28.599999999508796
agent-4: 25.5999999995088
agent-5: 28.599999999508796
Extrinsic Rewards:
2
8
3
0
3
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.425
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 281.95163579313225
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1169
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.221
    dispatch_time_ms: 8.431
    learner:
      cur_lr: 0.0009707229910418391
      grad_gnorm: 19.193099975585938
      policy_entropy: 37.087928771972656
      policy_loss: -3.200439214706421
      var_gnorm: 23.00984001159668
      vf_explained_var: 0.0
      vf_loss: 0.27889034152030945
    num_steps_sampled: 5850000
    num_steps_trained: 5850000
    wait_time_ms: 73.369
  iterations_since_restore: 1170
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10251.1540350914
  time_this_iter_s: 8.70734715461731
  time_total_s: 10251.1540350914
  timestamp: 1594858785
  timesteps_since_restore: 5850000
  timesteps_this_iter: 5000
  timesteps_total: 5850000
  training_iteration: 1170
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10251 s, 1170 iter, 5850000 ts, 282 rew

agent-1: 51.3999999940821
agent-2: 47.399999994082094
agent-3: 53.39999999408209
agent-4: 59.39999999408208
agent-5: 49.399999994082094
Extrinsic Rewards:
5
1
7
13
3
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.38620689655172413
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-19-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 282.85163579287587
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1170
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.902
    dispatch_time_ms: 7.787
    learner:
      cur_lr: 0.0009703899850137532
      grad_gnorm: 40.0
      policy_entropy: 27.525142669677734
      policy_loss: 26.131690979003906
      var_gnorm: 23.01133155822754
      vf_explained_var: 0.0
      vf_loss: 29.448862075805664
    num_steps_sampled: 5855000
    num_steps_trained: 5855000
    wait_time_ms: 72.942
  iterations_since_restore: 1171
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10259.507489681244
  time_this_iter_s: 8.35345458984375
  time_total_s: 10259.507489681244
  timestamp: 1594858793
  timesteps_since_restore: 5855000
  timesteps_this_iter: 5000
  timesteps_total: 5855000
  training_iteration: 1171
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10259 s, 1171 iter, 5855000 ts, 283 rew

agent-1: 67.19999972274117
agent-2: 67.19999972274114
agent-3: 72.19999972274111
agent-4: 65.1999997227412
agent-5: 61.199999722741026
Extrinsic Rewards:
8
8
13
6
2
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.2594594594594595
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 283.30163577915835
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1171
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.407
    dispatch_time_ms: 58.241
    learner:
      cur_lr: 0.0009700569789856672
      grad_gnorm: 17.33090591430664
      policy_entropy: 32.449256896972656
      policy_loss: -8.619085311889648
      var_gnorm: 23.00859260559082
      vf_explained_var: 0.0
      vf_loss: 0.26766377687454224
    num_steps_sampled: 5860000
    num_steps_trained: 5860000
    wait_time_ms: 47.219
  iterations_since_restore: 1172
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10268.46288061142
  time_this_iter_s: 8.955390930175781
  time_total_s: 10268.46288061142
  timestamp: 1594858802
  timesteps_since_restore: 5860000
  timesteps_this_iter: 5000
  timesteps_total: 5860000
  training_iteration: 1172
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10268 s, 1172 iter, 5860000 ts, 283 rew

agent-1: 93.59999491145652
agent-2: 84.59999491145653
agent-3: 89.5999949114565
agent-4: 99.59999491145646
agent-5: 91.59999491145652
Extrinsic Rewards:
12
3
8
18
10
Sum Reward: 51
Avg Reward: 10.2
Min Reward: 3
Max Reward: 18
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 286.0016355248945
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1172
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.106
    dispatch_time_ms: 6.813
    learner:
      cur_lr: 0.0009697239729575813
      grad_gnorm: 8.395167350769043
      policy_entropy: 31.359840393066406
      policy_loss: 1.2772084474563599
      var_gnorm: 23.005813598632812
      vf_explained_var: 0.0
      vf_loss: 0.058793485164642334
    num_steps_sampled: 5865000
    num_steps_trained: 5865000
    wait_time_ms: 78.612
  iterations_since_restore: 1173
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10276.966418027878
  time_this_iter_s: 8.50353741645813
  time_total_s: 10276.966418027878
  timestamp: 1594858811
  timesteps_since_restore: 5865000
  timesteps_this_iter: 5000
  timesteps_total: 5865000
  training_iteration: 1173
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10276 s, 1173 iter, 5865000 ts, 286 rew

agent-1: 43.7999999989752
agent-2: 39.799999998975196
agent-3: 39.799999998975196
agent-4: 42.7999999989752
agent-5: 40.79999999897521
Extrinsic Rewards:
7
3
3
6
4
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.19130434782608696
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 280.6916360873523
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1173
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.457
    dispatch_time_ms: 7.096
    learner:
      cur_lr: 0.0009693910251371562
      grad_gnorm: 20.306222915649414
      policy_entropy: 34.54838562011719
      policy_loss: -2.858448028564453
      var_gnorm: 23.005023956298828
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2882204055786133
    num_steps_sampled: 5870000
    num_steps_trained: 5870000
    wait_time_ms: 75.733
  iterations_since_restore: 1174
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10285.423156738281
  time_this_iter_s: 8.456738710403442
  time_total_s: 10285.423156738281
  timestamp: 1594858819
  timesteps_since_restore: 5870000
  timesteps_this_iter: 5000
  timesteps_total: 5870000
  training_iteration: 1174
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10285 s, 1174 iter, 5870000 ts, 281 rew

agent-1: 54.199999994949586
agent-2: 44.1999999949496
agent-3: 51.199999994949586
agent-4: 43.1999999949496
agent-5: 50.199999994949586
Extrinsic Rewards:
11
1
8
0
7
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.42962962962962964
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 281.2316360871608
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1174
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.788
    dispatch_time_ms: 8.7
    learner:
      cur_lr: 0.0009690580191090703
      grad_gnorm: 13.139496803283691
      policy_entropy: 33.3654670715332
      policy_loss: -1.8697614669799805
      var_gnorm: 23.00697898864746
      vf_explained_var: 0.0
      vf_loss: 0.1261536180973053
    num_steps_sampled: 5875000
    num_steps_trained: 5875000
    wait_time_ms: 74.21
  iterations_since_restore: 1175
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10293.920070409775
  time_this_iter_s: 8.49691367149353
  time_total_s: 10293.920070409775
  timestamp: 1594858828
  timesteps_since_restore: 5875000
  timesteps_this_iter: 5000
  timesteps_total: 5875000
  training_iteration: 1175
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10293 s, 1175 iter, 5875000 ts, 281 rew

agent-1: 56.1999999910632
agent-2: 55.1999999910632
agent-3: 55.19999999106319
agent-4: 58.1999999910632
agent-5: 63.1999999910632
Extrinsic Rewards:
5
4
4
7
12
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.2375
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 282.4916360867501
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1175
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.017
    dispatch_time_ms: 6.887
    learner:
      cur_lr: 0.0009687250130809844
      grad_gnorm: 18.401399612426758
      policy_entropy: 33.80665588378906
      policy_loss: -2.7293756008148193
      var_gnorm: 23.003780364990234
      vf_explained_var: 0.0
      vf_loss: 0.2549043893814087
    num_steps_sampled: 5880000
    num_steps_trained: 5880000
    wait_time_ms: 77.259
  iterations_since_restore: 1176
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10302.397039175034
  time_this_iter_s: 8.476968765258789
  time_total_s: 10302.397039175034
  timestamp: 1594858836
  timesteps_since_restore: 5880000
  timesteps_this_iter: 5000
  timesteps_total: 5880000
  training_iteration: 1176
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10302 s, 1176 iter, 5880000 ts, 282 rew

agent-1: 32.599999999456706
agent-2: 25.599999999456692
agent-3: 30.599999999456692
agent-4: 27.599999999456692
agent-5: 27.599999999456692
Extrinsic Rewards:
7
0
5
2
2
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.425
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 281.5916360870386
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1176
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.587
    dispatch_time_ms: 8.058
    learner:
      cur_lr: 0.0009683920070528984
      grad_gnorm: 14.564265251159668
      policy_entropy: 30.903486251831055
      policy_loss: -2.1922638416290283
      var_gnorm: 23.005537033081055
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.1641164869070053
    num_steps_sampled: 5885000
    num_steps_trained: 5885000
    wait_time_ms: 76.71
  iterations_since_restore: 1177
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10310.960146903992
  time_this_iter_s: 8.56310772895813
  time_total_s: 10310.960146903992
  timestamp: 1594858845
  timesteps_since_restore: 5885000
  timesteps_this_iter: 5000
  timesteps_total: 5885000
  training_iteration: 1177
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10310 s, 1177 iter, 5885000 ts, 282 rew

agent-1: 53.59999999251787
agent-2: 54.59999999251787
agent-3: 56.59999999251787
agent-4: 55.59999999251787
agent-5: 58.59999999251787
Extrinsic Rewards:
4
5
7
6
9
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.15483870967741936
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-20-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 281.95163608681645
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1177
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 8.526
    learner:
      cur_lr: 0.0009680590010248125
      grad_gnorm: 17.439722061157227
      policy_entropy: 25.646636962890625
      policy_loss: -1.732558250427246
      var_gnorm: 23.00224494934082
      vf_explained_var: 0.0
      vf_loss: 0.22778089344501495
    num_steps_sampled: 5890000
    num_steps_trained: 5890000
    wait_time_ms: 74.991
  iterations_since_restore: 1178
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10319.600378751755
  time_this_iter_s: 8.640231847763062
  time_total_s: 10319.600378751755
  timestamp: 1594858853
  timesteps_since_restore: 5890000
  timesteps_this_iter: 5000
  timesteps_total: 5890000
  training_iteration: 1178
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10319 s, 1178 iter, 5890000 ts, 282 rew

agent-1: 30.799999999247017
agent-2: 38.79999999924701
agent-3: 32.79999999924699
agent-4: 28.799999999247028
agent-5: 30.799999999247017
Extrinsic Rewards:
2
10
4
0
2
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.4888888888888889
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 275.5702970536654
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1178
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 7.834
    learner:
      cur_lr: 0.0009677259949967265
      grad_gnorm: 17.071983337402344
      policy_entropy: 19.84147071838379
      policy_loss: -1.5674545764923096
      var_gnorm: 23.00140953063965
      vf_explained_var: 0.0
      vf_loss: 0.22569942474365234
    num_steps_sampled: 5895000
    num_steps_trained: 5895000
    wait_time_ms: 77.928
  iterations_since_restore: 1179
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10328.249918699265
  time_this_iter_s: 8.649539947509766
  time_total_s: 10328.249918699265
  timestamp: 1594858862
  timesteps_since_restore: 5895000
  timesteps_this_iter: 5000
  timesteps_total: 5895000
  training_iteration: 1179
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10328 s, 1179 iter, 5895000 ts, 276 rew

agent-1: 36.79999999741454
agent-2: 44.79999999741456
agent-3: 37.799999997414545
agent-4: 44.79999999741456
agent-5: 42.79999999741455
Extrinsic Rewards:
0
8
1
8
6
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 274.3102970760272
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1179
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.001
    dispatch_time_ms: 8.691
    learner:
      cur_lr: 0.0009673929889686406
      grad_gnorm: 31.47072410583496
      policy_entropy: 29.240062713623047
      policy_loss: -5.269677639007568
      var_gnorm: 22.99704933166504
      vf_explained_var: 0.0
      vf_loss: 0.6449341773986816
    num_steps_sampled: 5900000
    num_steps_trained: 5900000
    wait_time_ms: 74.971
  iterations_since_restore: 1180
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10336.864510297775
  time_this_iter_s: 8.614591598510742
  time_total_s: 10336.864510297775
  timestamp: 1594858871
  timesteps_since_restore: 5900000
  timesteps_this_iter: 5000
  timesteps_total: 5900000
  training_iteration: 1180
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10336 s, 1180 iter, 5900000 ts, 274 rew

agent-1: 107.39999735226031
agent-2: 92.39999735226031
agent-3: 95.39999735226031
agent-4: 94.39999735226031
agent-5: 96.39999735226031
Extrinsic Rewards:
21
6
9
8
10
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 6
Max Reward: 21
Gini Coefficient: 0.23703703703703705
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 276.47029694391233
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1180
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.19
    dispatch_time_ms: 6.841
    learner:
      cur_lr: 0.0009670599829405546
      grad_gnorm: 8.796568870544434
      policy_entropy: 24.703516006469727
      policy_loss: -0.6038076281547546
      var_gnorm: 23.002119064331055
      vf_explained_var: 0.0
      vf_loss: 0.05087079480290413
    num_steps_sampled: 5905000
    num_steps_trained: 5905000
    wait_time_ms: 77.91
  iterations_since_restore: 1181
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10345.570266008377
  time_this_iter_s: 8.705755710601807
  time_total_s: 10345.570266008377
  timestamp: 1594858879
  timesteps_since_restore: 5905000
  timesteps_this_iter: 5000
  timesteps_total: 5905000
  training_iteration: 1181
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10345 s, 1181 iter, 5905000 ts, 276 rew

agent-1: 61.999999379916424
agent-2: 69.99999937991637
agent-3: 63.99999937991641
agent-4: 59.999999379916424
agent-5: 58.999999379916424
Extrinsic Rewards:
6
14
8
4
3
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.29714285714285715
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 268.9426664793957
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1181
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.788
    dispatch_time_ms: 7.838
    learner:
      cur_lr: 0.0009667269769124687
      grad_gnorm: 20.61363410949707
      policy_entropy: 29.55162239074707
      policy_loss: -3.2504799365997314
      var_gnorm: 23.002670288085938
      vf_explained_var: 0.0
      vf_loss: 0.3271775543689728
    num_steps_sampled: 5910000
    num_steps_trained: 5910000
    wait_time_ms: 75.047
  iterations_since_restore: 1182
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10354.155858516693
  time_this_iter_s: 8.58559250831604
  time_total_s: 10354.155858516693
  timestamp: 1594858888
  timesteps_since_restore: 5910000
  timesteps_this_iter: 5000
  timesteps_total: 5910000
  training_iteration: 1182
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10354 s, 1182 iter, 5910000 ts, 269 rew

agent-1: 51.79999999829708
agent-2: 48.799999998297075
agent-3: 44.799999998297075
agent-4: 46.79999999829707
agent-5: 59.79999999829708
Extrinsic Rewards:
7
4
0
2
15
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 0
Max Reward: 15
Gini Coefficient: 0.5
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 262.1028056001325
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1182
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.834
    dispatch_time_ms: 8.338
    learner:
      cur_lr: 0.0009663940290920436
      grad_gnorm: 9.195995330810547
      policy_entropy: 32.97500228881836
      policy_loss: -1.6344833374023438
      var_gnorm: 23.00443458557129
      vf_explained_var: 0.0
      vf_loss: 0.05404886230826378
    num_steps_sampled: 5915000
    num_steps_trained: 5915000
    wait_time_ms: 75.832
  iterations_since_restore: 1183
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10362.80407166481
  time_this_iter_s: 8.648213148117065
  time_total_s: 10362.80407166481
  timestamp: 1594858897
  timesteps_since_restore: 5915000
  timesteps_this_iter: 5000
  timesteps_total: 5915000
  training_iteration: 1183
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10362 s, 1183 iter, 5915000 ts, 262 rew

agent-1: 51.199999990391746
agent-2: 65.1999999903919
agent-3: 54.199999990391746
agent-4: 55.199999990391746
agent-5: 62.19999999039176
Extrinsic Rewards:
0
14
3
4
11
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.45
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 262.28280560217047
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1183
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.494
    dispatch_time_ms: 6.136
    learner:
      cur_lr: 0.0009660610230639577
      grad_gnorm: 13.819615364074707
      policy_entropy: 33.702362060546875
      policy_loss: -2.6474416255950928
      var_gnorm: 23.005847930908203
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.14184920489788055
    num_steps_sampled: 5920000
    num_steps_trained: 5920000
    wait_time_ms: 80.333
  iterations_since_restore: 1184
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10371.522074222565
  time_this_iter_s: 8.718002557754517
  time_total_s: 10371.522074222565
  timestamp: 1594858905
  timesteps_since_restore: 5920000
  timesteps_this_iter: 5000
  timesteps_total: 5920000
  training_iteration: 1184
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10371 s, 1184 iter, 5920000 ts, 262 rew

agent-1: 26.999999999644096
agent-2: 25.999999999644093
agent-3: 26.999999999644096
agent-4: 23.999999999644093
agent-5: 30.999999999644096
Extrinsic Rewards:
3
2
3
0
7
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-21-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 258.9528056273025
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1184
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.059
    dispatch_time_ms: 7.612
    learner:
      cur_lr: 0.0009657280170358717
      grad_gnorm: 16.13119125366211
      policy_entropy: 23.285308837890625
      policy_loss: -2.3784971237182617
      var_gnorm: 23.006996154785156
      vf_explained_var: 0.0
      vf_loss: 0.20021694898605347
    num_steps_sampled: 5925000
    num_steps_trained: 5925000
    wait_time_ms: 77.488
  iterations_since_restore: 1185
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10380.194823265076
  time_this_iter_s: 8.672749042510986
  time_total_s: 10380.194823265076
  timestamp: 1594858914
  timesteps_since_restore: 5925000
  timesteps_this_iter: 5000
  timesteps_total: 5925000
  training_iteration: 1185
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10380 s, 1185 iter, 5925000 ts, 259 rew

agent-1: 38.39999999905482
agent-2: 30.39999999905468
agent-3: 32.39999999905481
agent-4: 37.39999999905483
agent-5: 32.39999999905481
Extrinsic Rewards:
8
0
2
7
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4421052631578947
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 260.66280562725524
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1185
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.661
    dispatch_time_ms: 10.634
    learner:
      cur_lr: 0.0009653950110077858
      grad_gnorm: 25.259801864624023
      policy_entropy: 16.09412384033203
      policy_loss: -0.8981805443763733
      var_gnorm: 23.00946044921875
      vf_explained_var: 0.0
      vf_loss: 0.4766163229942322
    num_steps_sampled: 5930000
    num_steps_trained: 5930000
    wait_time_ms: 74.006
  iterations_since_restore: 1186
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10388.848888635635
  time_this_iter_s: 8.654065370559692
  time_total_s: 10388.848888635635
  timestamp: 1594858923
  timesteps_since_restore: 5930000
  timesteps_this_iter: 5000
  timesteps_total: 5930000
  training_iteration: 1186
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10388 s, 1186 iter, 5930000 ts, 261 rew

agent-1: 71.99999998680676
agent-2: 70.99999998680674
agent-3: 66.99999998680678
agent-4: 72.99999998680676
agent-5: 76.99999998680676
Extrinsic Rewards:
8
7
3
9
13
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.22
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 264.2628056265956
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1186
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 7.881
    learner:
      cur_lr: 0.0009650620049796999
      grad_gnorm: 24.82893943786621
      policy_entropy: 23.016246795654297
      policy_loss: -3.064934730529785
      var_gnorm: 23.009235382080078
      vf_explained_var: 0.0
      vf_loss: 0.47049424052238464
    num_steps_sampled: 5935000
    num_steps_trained: 5935000
    wait_time_ms: 74.695
  iterations_since_restore: 1187
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10397.402705430984
  time_this_iter_s: 8.553816795349121
  time_total_s: 10397.402705430984
  timestamp: 1594858931
  timesteps_since_restore: 5935000
  timesteps_this_iter: 5000
  timesteps_total: 5935000
  training_iteration: 1187
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10397 s, 1187 iter, 5935000 ts, 264 rew

agent-1: 167.3999608890203
agent-2: 158.39996088902032
agent-3: 159.39996088902032
agent-4: 153.3999608890203
agent-5: 162.39996088902026
Extrinsic Rewards:
25
16
17
11
20
Sum Reward: 89
Avg Reward: 17.8
Min Reward: 11
Max Reward: 25
Gini Coefficient: 0.14382022471910114
20:20 Ratio: 2.272727272727273
Max-min Ratio: 2.272727272727273
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 272.27280367104663
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1187
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.976
    dispatch_time_ms: 9.297
    learner:
      cur_lr: 0.0009647289989516139
      grad_gnorm: 22.738927841186523
      policy_entropy: 36.91546630859375
      policy_loss: -3.6580748558044434
      var_gnorm: 23.011049270629883
      vf_explained_var: 0.0
      vf_loss: 0.3560919463634491
    num_steps_sampled: 5940000
    num_steps_trained: 5940000
    wait_time_ms: 75.046
  iterations_since_restore: 1188
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10406.030306816101
  time_this_iter_s: 8.627601385116577
  time_total_s: 10406.030306816101
  timestamp: 1594858940
  timesteps_since_restore: 5940000
  timesteps_this_iter: 5000
  timesteps_total: 5940000
  training_iteration: 1188
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10406 s, 1188 iter, 5940000 ts, 272 rew

agent-1: 45.999999998740414
agent-2: 44.99999999874043
agent-3: 44.99999999874043
agent-4: 40.99999999874044
agent-5: 47.999999998740435
Extrinsic Rewards:
6
5
5
1
8
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.24
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 274.4328036710038
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1188
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.49
    dispatch_time_ms: 10.831
    learner:
      cur_lr: 0.000964395992923528
      grad_gnorm: 40.000003814697266
      policy_entropy: 33.58076095581055
      policy_loss: 30.41112518310547
      var_gnorm: 23.0135440826416
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 22.019689559936523
    num_steps_sampled: 5945000
    num_steps_trained: 5945000
    wait_time_ms: 71.954
  iterations_since_restore: 1189
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10414.563599824905
  time_this_iter_s: 8.533293008804321
  time_total_s: 10414.563599824905
  timestamp: 1594858949
  timesteps_since_restore: 5945000
  timesteps_this_iter: 5000
  timesteps_total: 5945000
  training_iteration: 1189
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10414 s, 1189 iter, 5945000 ts, 274 rew

agent-1: 58.19999998233971
agent-2: 59.19999998233971
agent-3: 64.1999999823396
agent-4: 52.19999998233971
agent-5: 54.19999998233971
Extrinsic Rewards:
7
8
13
1
3
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.3625
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 277.3128036701208
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1189
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.847
    dispatch_time_ms: 7.949
    learner:
      cur_lr: 0.000964062986895442
      grad_gnorm: 29.462671279907227
      policy_entropy: 30.87371826171875
      policy_loss: -4.026809215545654
      var_gnorm: 23.00558853149414
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.6652617454528809
    num_steps_sampled: 5950000
    num_steps_trained: 5950000
    wait_time_ms: 76.183
  iterations_since_restore: 1190
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10423.26610159874
  time_this_iter_s: 8.702501773834229
  time_total_s: 10423.26610159874
  timestamp: 1594858957
  timesteps_since_restore: 5950000
  timesteps_this_iter: 5000
  timesteps_total: 5950000
  training_iteration: 1190
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10423 s, 1190 iter, 5950000 ts, 277 rew

agent-1: 90.7999998662788
agent-2: 81.79999986627878
agent-3: 82.79999986627881
agent-4: 91.7999998662788
agent-5: 84.79999986627881
Extrinsic Rewards:
14
5
6
15
8
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 5
Max Reward: 15
Gini Coefficient: 0.23333333333333334
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 281.63280366343474
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1190
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.754
    dispatch_time_ms: 10.34
    learner:
      cur_lr: 0.0009637299808673561
      grad_gnorm: 4.2570695877075195
      policy_entropy: 35.55608367919922
      policy_loss: -0.6256992816925049
      var_gnorm: 23.00126838684082
      vf_explained_var: 0.0
      vf_loss: 0.01313859410583973
    num_steps_sampled: 5955000
    num_steps_trained: 5955000
    wait_time_ms: 71.53
  iterations_since_restore: 1191
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10431.835367679596
  time_this_iter_s: 8.569266080856323
  time_total_s: 10431.835367679596
  timestamp: 1594858966
  timesteps_since_restore: 5955000
  timesteps_this_iter: 5000
  timesteps_total: 5955000
  training_iteration: 1191
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10431 s, 1191 iter, 5955000 ts, 282 rew

agent-1: 82.79999996361589
agent-2: 72.79999996361589
agent-3: 74.79999996361587
agent-4: 79.79999996361587
agent-5: 76.79999996361586
Extrinsic Rewards:
14
4
6
11
8
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 4
Max Reward: 14
Gini Coefficient: 0.23255813953488372
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-22-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 285.50280366161553
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1191
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 8.527
    learner:
      cur_lr: 0.0009633969748392701
      grad_gnorm: 16.25853729248047
      policy_entropy: 18.16511344909668
      policy_loss: -1.7319602966308594
      var_gnorm: 23.00430679321289
      vf_explained_var: 0.0
      vf_loss: 0.20348577201366425
    num_steps_sampled: 5960000
    num_steps_trained: 5960000
    wait_time_ms: 78.815
  iterations_since_restore: 1192
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10440.47435760498
  time_this_iter_s: 8.638989925384521
  time_total_s: 10440.47435760498
  timestamp: 1594858975
  timesteps_since_restore: 5960000
  timesteps_this_iter: 5000
  timesteps_total: 5960000
  training_iteration: 1192
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10440 s, 1192 iter, 5960000 ts, 286 rew

agent-1: 39.99999999891013
agent-2: 47.99999999891012
agent-3: 44.99999999891014
agent-4: 45.999999998910134
agent-5: 45.999999998910134
Extrinsic Rewards:
0
8
5
6
6
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.272
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 287.7528036615611
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1192
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.451
    dispatch_time_ms: 5.903
    learner:
      cur_lr: 0.0009630640270188451
      grad_gnorm: 40.0
      policy_entropy: 18.699859619140625
      policy_loss: 21.70529556274414
      var_gnorm: 23.006011962890625
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 82.03778839111328
    num_steps_sampled: 5965000
    num_steps_trained: 5965000
    wait_time_ms: 76.841
  iterations_since_restore: 1193
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10449.15559387207
  time_this_iter_s: 8.681236267089844
  time_total_s: 10449.15559387207
  timestamp: 1594858983
  timesteps_since_restore: 5965000
  timesteps_this_iter: 5000
  timesteps_total: 5965000
  training_iteration: 1193
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10449 s, 1193 iter, 5965000 ts, 288 rew

agent-1: 46.99999999835327
agent-2: 48.99999999835326
agent-3: 46.99999999835327
agent-4: 39.99999999835326
agent-5: 41.99999999835327
Extrinsic Rewards:
7
9
7
0
2
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.368
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 290.0028036614787
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1193
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.596
    dispatch_time_ms: 8.208
    learner:
      cur_lr: 0.0009627310209907591
      grad_gnorm: 40.0
      policy_entropy: 6.585491180419922
      policy_loss: 1.1842410564422607
      var_gnorm: 23.01226043701172
      vf_explained_var: 0.0
      vf_loss: 24.176050186157227
    num_steps_sampled: 5970000
    num_steps_trained: 5970000
    wait_time_ms: 76.387
  iterations_since_restore: 1194
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10457.740894556046
  time_this_iter_s: 8.58530068397522
  time_total_s: 10457.740894556046
  timestamp: 1594858992
  timesteps_since_restore: 5970000
  timesteps_this_iter: 5000
  timesteps_total: 5970000
  training_iteration: 1194
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10457 s, 1194 iter, 5970000 ts, 290 rew

agent-1: 128.3999966763719
agent-2: 131.3999966763719
agent-3: 136.39999667637173
agent-4: 134.39999667637176
agent-5: 135.39999667637179
Extrinsic Rewards:
10
13
18
16
17
Sum Reward: 74
Avg Reward: 14.8
Min Reward: 10
Max Reward: 18
Gini Coefficient: 0.10810810810810811
20:20 Ratio: 1.8
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 296.6628034952974
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1194
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.424
    dispatch_time_ms: 6.331
    learner:
      cur_lr: 0.0009623980149626732
      grad_gnorm: 40.0
      policy_entropy: 28.966699600219727
      policy_loss: 53.149234771728516
      var_gnorm: 23.02105712890625
      vf_explained_var: 0.0
      vf_loss: 109.63249969482422
    num_steps_sampled: 5975000
    num_steps_trained: 5975000
    wait_time_ms: 78.611
  iterations_since_restore: 1195
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10466.376822710037
  time_this_iter_s: 8.6359281539917
  time_total_s: 10466.376822710037
  timestamp: 1594859001
  timesteps_since_restore: 5975000
  timesteps_this_iter: 5000
  timesteps_total: 5975000
  training_iteration: 1195
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10466 s, 1195 iter, 5975000 ts, 297 rew

agent-1: 158.39073416533512
agent-2: 164.39073416533512
agent-3: 154.39073416533512
agent-4: 159.39073416533515
agent-5: 164.3907341653351
Extrinsic Rewards:
16
22
12
17
22
Sum Reward: 89
Avg Reward: 17.8
Min Reward: 12
Max Reward: 22
Gini Coefficient: 0.11685393258426967
20:20 Ratio: 1.8333333333333333
Max-min Ratio: 1.8333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 304.67234020356415
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1195
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.126
    dispatch_time_ms: 7.674
    learner:
      cur_lr: 0.0009620650089345872
      grad_gnorm: 31.864242553710938
      policy_entropy: 35.95906066894531
      policy_loss: -5.361487865447998
      var_gnorm: 23.012962341308594
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.6810809969902039
    num_steps_sampled: 5980000
    num_steps_trained: 5980000
    wait_time_ms: 77.474
  iterations_since_restore: 1196
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10474.89728140831
  time_this_iter_s: 8.520458698272705
  time_total_s: 10474.89728140831
  timestamp: 1594859009
  timesteps_since_restore: 5980000
  timesteps_this_iter: 5000
  timesteps_total: 5980000
  training_iteration: 1196
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10474 s, 1196 iter, 5980000 ts, 305 rew

agent-1: 93.19999986849965
agent-2: 90.19999986849963
agent-3: 95.19999986849965
agent-4: 95.19999986849965
agent-5: 94.19999986849963
Extrinsic Rewards:
10
7
12
12
11
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 7
Max Reward: 12
Gini Coefficient: 0.09230769230769231
20:20 Ratio: 1.7142857142857142
Max-min Ratio: 1.7142857142857142
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 309.35234019698913
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1196
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.603
    dispatch_time_ms: 15.737
    learner:
      cur_lr: 0.0009617320029065013
      grad_gnorm: 27.50265884399414
      policy_entropy: 37.697017669677734
      policy_loss: -3.383275032043457
      var_gnorm: 23.028425216674805
      vf_explained_var: 0.0
      vf_loss: 0.4870455265045166
    num_steps_sampled: 5985000
    num_steps_trained: 5985000
    wait_time_ms: 70.902
  iterations_since_restore: 1197
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10493.750324726105
  time_this_iter_s: 18.8530433177948
  time_total_s: 10493.750324726105
  timestamp: 1594859028
  timesteps_since_restore: 5985000
  timesteps_this_iter: 5000
  timesteps_total: 5985000
  training_iteration: 1197
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10493 s, 1197 iter, 5985000 ts, 309 rew

agent-1: 59.59999999021115
agent-2: 61.59999999021114
agent-3: 51.599999990211124
agent-4: 53.599999990211124
agent-5: 52.59999999021112
Extrinsic Rewards:
10
12
2
4
3
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.34838709677419355
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-23-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 312.1423401964997
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1197
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 24.653
    learner:
      cur_lr: 0.0009613989968784153
      grad_gnorm: 28.138389587402344
      policy_entropy: 14.888233184814453
      policy_loss: -2.3278050422668457
      var_gnorm: 23.02984046936035
      vf_explained_var: 0.0
      vf_loss: 0.6098793148994446
    num_steps_sampled: 5990000
    num_steps_trained: 5990000
    wait_time_ms: 61.489
  iterations_since_restore: 1198
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10502.571148872375
  time_this_iter_s: 8.820824146270752
  time_total_s: 10502.571148872375
  timestamp: 1594859037
  timesteps_since_restore: 5990000
  timesteps_this_iter: 5000
  timesteps_total: 5990000
  training_iteration: 1198
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10502 s, 1198 iter, 5990000 ts, 312 rew

agent-1: 49.999999939287804
agent-2: 51.99999993928782
agent-3: 56.999999939287804
agent-4: 56.999999939287804
agent-5: 53.999999939287804
Extrinsic Rewards:
2
4
9
9
6
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.25333333333333335
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 314.84234019346405
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1198
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.07
    dispatch_time_ms: 21.448
    learner:
      cur_lr: 0.0009610659908503294
      grad_gnorm: 40.0
      policy_entropy: 22.594602584838867
      policy_loss: 9.717218399047852
      var_gnorm: 23.02597999572754
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.4100775718688965
    num_steps_sampled: 5995000
    num_steps_trained: 5995000
    wait_time_ms: 64.996
  iterations_since_restore: 1199
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10511.41203045845
  time_this_iter_s: 8.840881586074829
  time_total_s: 10511.41203045845
  timestamp: 1594859046
  timesteps_since_restore: 5995000
  timesteps_this_iter: 5000
  timesteps_total: 5995000
  training_iteration: 1199
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10511 s, 1199 iter, 5995000 ts, 315 rew

agent-1: 224.2072217392283
agent-2: 207.20722173922823
agent-3: 222.2072217392283
agent-4: 221.20722173922832
agent-5: 229.2072217392283
Extrinsic Rewards:
28
11
26
25
33
Sum Reward: 123
Avg Reward: 24.6
Min Reward: 11
Max Reward: 33
Gini Coefficient: 0.15284552845528454
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 325.8827012804255
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1199
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 23.56
    learner:
      cur_lr: 0.0009607329848222435
      grad_gnorm: 40.0
      policy_entropy: 21.29427146911621
      policy_loss: 7.105575084686279
      var_gnorm: 23.02353286743164
      vf_explained_var: 0.0
      vf_loss: 3.753241777420044
    num_steps_sampled: 6000000
    num_steps_trained: 6000000
    wait_time_ms: 61.485
  iterations_since_restore: 1200
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10520.561714887619
  time_this_iter_s: 9.149684429168701
  time_total_s: 10520.561714887619
  timestamp: 1594859055
  timesteps_since_restore: 6000000
  timesteps_this_iter: 5000
  timesteps_total: 6000000
  training_iteration: 1200
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10520 s, 1200 iter, 6000000 ts, 326 rew

agent-1: 62.99999999220733
agent-2: 62.99999999220733
agent-3: 64.99999999220748
agent-4: 60.99999999220734
agent-5: 62.99999999220733
Extrinsic Rewards:
7
7
9
5
7
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 5
Max Reward: 9
Gini Coefficient: 0.09142857142857143
20:20 Ratio: 1.8
Max-min Ratio: 1.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 329.03270128003584
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1200
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.651
    dispatch_time_ms: 24.735
    learner:
      cur_lr: 0.0009603999787941575
      grad_gnorm: 25.11515998840332
      policy_entropy: 9.93726921081543
      policy_loss: -1.1306214332580566
      var_gnorm: 23.005876541137695
      vf_explained_var: 0.0
      vf_loss: 0.488455206155777
    num_steps_sampled: 6005000
    num_steps_trained: 6005000
    wait_time_ms: 60.639
  iterations_since_restore: 1201
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10529.653725862503
  time_this_iter_s: 9.092010974884033
  time_total_s: 10529.653725862503
  timestamp: 1594859064
  timesteps_since_restore: 6005000
  timesteps_this_iter: 5000
  timesteps_total: 6005000
  training_iteration: 1201
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10529 s, 1201 iter, 6005000 ts, 329 rew

agent-1: 91.39999984521442
agent-2: 97.39999984521442
agent-3: 100.39999984521442
agent-4: 97.39999984521442
agent-5: 99.39999984521442
Extrinsic Rewards:
5
11
14
11
13
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 5
Max Reward: 14
Gini Coefficient: 0.14814814814814814
20:20 Ratio: 2.8
Max-min Ratio: 2.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 333.8927012722966
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1201
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.247
    dispatch_time_ms: 19.059
    learner:
      cur_lr: 0.0009600669727660716
      grad_gnorm: 36.630245208740234
      policy_entropy: 27.53766632080078
      policy_loss: -5.1934027671813965
      var_gnorm: 23.00439453125
      vf_explained_var: 0.0
      vf_loss: 1.034781813621521
    num_steps_sampled: 6010000
    num_steps_trained: 6010000
    wait_time_ms: 73.644
  iterations_since_restore: 1202
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10538.763493299484
  time_this_iter_s: 9.109767436981201
  time_total_s: 10538.763493299484
  timestamp: 1594859073
  timesteps_since_restore: 6010000
  timesteps_this_iter: 5000
  timesteps_total: 6010000
  training_iteration: 1202
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10538 s, 1202 iter, 6010000 ts, 334 rew

agent-1: 119.19997246604359
agent-2: 122.19997246604359
agent-3: 130.1999724660434
agent-4: 119.19997246604359
agent-5: 112.19997246604362
Extrinsic Rewards:
12
15
23
12
5
Sum Reward: 67
Avg Reward: 13.4
Min Reward: 5
Max Reward: 23
Gini Coefficient: 0.23283582089552238
20:20 Ratio: 4.6
Max-min Ratio: 4.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 339.9226998955988
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1202
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.048
    dispatch_time_ms: 35.995
    learner:
      cur_lr: 0.0009597340249456465
      grad_gnorm: 1.6601027250289917
      policy_entropy: 36.08620834350586
      policy_loss: 0.44924768805503845
      var_gnorm: 23.011510848999023
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0019856481812894344
    num_steps_sampled: 6015000
    num_steps_trained: 6015000
    wait_time_ms: 56.428
  iterations_since_restore: 1203
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10547.914285898209
  time_this_iter_s: 9.150792598724365
  time_total_s: 10547.914285898209
  timestamp: 1594859083
  timesteps_since_restore: 6015000
  timesteps_this_iter: 5000
  timesteps_total: 6015000
  training_iteration: 1203
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10547 s, 1203 iter, 6015000 ts, 340 rew

agent-1: 34.7999999994112
agent-2: 28.799999999411153
agent-3: 28.799999999411153
agent-4: 32.79999999941119
agent-5: 36.799999999411185
Extrinsic Rewards:
6
0
0
4
8
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4888888888888889
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-24-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 341.5426998955694
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1203
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.164
    dispatch_time_ms: 26.876
    learner:
      cur_lr: 0.0009594010189175606
      grad_gnorm: 12.388428688049316
      policy_entropy: 29.081438064575195
      policy_loss: -1.6970269680023193
      var_gnorm: 23.008359909057617
      vf_explained_var: 0.0
      vf_loss: 0.10486738383769989
    num_steps_sampled: 6020000
    num_steps_trained: 6020000
    wait_time_ms: 62.817
  iterations_since_restore: 1204
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10556.99676322937
  time_this_iter_s: 9.082477331161499
  time_total_s: 10556.99676322937
  timestamp: 1594859092
  timesteps_since_restore: 6020000
  timesteps_this_iter: 5000
  timesteps_total: 6020000
  training_iteration: 1204
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10556 s, 1204 iter, 6020000 ts, 342 rew

agent-1: 28.799999998843703
agent-2: 35.79999999884386
agent-3: 32.799999998843816
agent-4: 31.799999998843703
agent-5: 32.799999998843816
Extrinsic Rewards:
0
7
4
3
4
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.3333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 343.16269989551154
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1204
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.572
    dispatch_time_ms: 35.021
    learner:
      cur_lr: 0.0009590680128894746
      grad_gnorm: 12.58637523651123
      policy_entropy: 34.05843734741211
      policy_loss: -1.9972643852233887
      var_gnorm: 23.007429122924805
      vf_explained_var: 0.0
      vf_loss: 0.119151271879673
    num_steps_sampled: 6025000
    num_steps_trained: 6025000
    wait_time_ms: 56.049
  iterations_since_restore: 1205
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10566.120948791504
  time_this_iter_s: 9.124185562133789
  time_total_s: 10566.120948791504
  timestamp: 1594859101
  timesteps_since_restore: 6025000
  timesteps_this_iter: 5000
  timesteps_total: 6025000
  training_iteration: 1205
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10566 s, 1205 iter, 6025000 ts, 343 rew

agent-1: 38.99999999928302
agent-2: 35.999999999283006
agent-3: 34.999999999283
agent-4: 32.999999999282984
agent-5: 36.999999999283006
Extrinsic Rewards:
7
4
3
1
5
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.28
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 344.783145588928
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1205
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 31.812
    learner:
      cur_lr: 0.0009587350068613887
      grad_gnorm: 11.375012397766113
      policy_entropy: 34.19410705566406
      policy_loss: -3.4006919860839844
      var_gnorm: 23.00714683532715
      vf_explained_var: 0.0
      vf_loss: 0.07870902866125107
    num_steps_sampled: 6030000
    num_steps_trained: 6030000
    wait_time_ms: 53.89
  iterations_since_restore: 1206
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10575.321174383163
  time_this_iter_s: 9.200225591659546
  time_total_s: 10575.321174383163
  timestamp: 1594859110
  timesteps_since_restore: 6030000
  timesteps_this_iter: 5000
  timesteps_total: 6030000
  training_iteration: 1206
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10575 s, 1206 iter, 6030000 ts, 345 rew

agent-1: 42.3999999990493
agent-2: 49.3999999990493
agent-3: 39.3999999990493
agent-4: 44.39999999904931
agent-5: 40.3999999990493
Extrinsic Rewards:
4
11
1
6
2
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.4
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 346.94314558888055
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1206
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.146
    dispatch_time_ms: 28.306
    learner:
      cur_lr: 0.0009584020008333027
      grad_gnorm: 14.355047225952148
      policy_entropy: 34.36773681640625
      policy_loss: -0.41342893242836
      var_gnorm: 23.007150650024414
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.15760964155197144
    num_steps_sampled: 6035000
    num_steps_trained: 6035000
    wait_time_ms: 69.455
  iterations_since_restore: 1207
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10584.544187545776
  time_this_iter_s: 9.223013162612915
  time_total_s: 10584.544187545776
  timestamp: 1594859119
  timesteps_since_restore: 6035000
  timesteps_this_iter: 5000
  timesteps_total: 6035000
  training_iteration: 1207
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10584 s, 1207 iter, 6035000 ts, 347 rew

agent-1: 40.99999999938842
agent-2: 31.999999999388326
agent-3: 36.99999999938841
agent-4: 35.999999999388415
agent-5: 33.999999999388415
Extrinsic Rewards:
9
0
5
4
2
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.42
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 348.7431455888499
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1207
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.221
    dispatch_time_ms: 39.68
    learner:
      cur_lr: 0.0009580689948052168
      grad_gnorm: 17.120365142822266
      policy_entropy: 25.868379592895508
      policy_loss: -4.497720718383789
      var_gnorm: 23.01040267944336
      vf_explained_var: 0.0
      vf_loss: 0.207039475440979
    num_steps_sampled: 6040000
    num_steps_trained: 6040000
    wait_time_ms: 52.11
  iterations_since_restore: 1208
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10593.535889863968
  time_this_iter_s: 8.991702318191528
  time_total_s: 10593.535889863968
  timestamp: 1594859128
  timesteps_since_restore: 6040000
  timesteps_this_iter: 5000
  timesteps_total: 6040000
  training_iteration: 1208
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10593 s, 1208 iter, 6040000 ts, 349 rew

agent-1: 56.99999981216229
agent-2: 52.99999981216227
agent-3: 48.99999981216229
agent-4: 52.99999981216229
agent-5: 57.99999981216229
Extrinsic Rewards:
9
5
1
5
10
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.29333333333333333
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 351.4431455794581
  episode_reward_min: 8.922208049677629
  episodes_this_iter: 1
  episodes_total: 1208
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.769
    dispatch_time_ms: 9.626
    learner:
      cur_lr: 0.0009577359887771308
      grad_gnorm: 13.33542537689209
      policy_entropy: 24.329113006591797
      policy_loss: -1.9014651775360107
      var_gnorm: 23.006750106811523
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.13219086825847626
    num_steps_sampled: 6045000
    num_steps_trained: 6045000
    wait_time_ms: 71.111
  iterations_since_restore: 1209
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10602.012746810913
  time_this_iter_s: 8.47685694694519
  time_total_s: 10602.012746810913
  timestamp: 1594859137
  timesteps_since_restore: 6045000
  timesteps_this_iter: 5000
  timesteps_total: 6045000
  training_iteration: 1209
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10602 s, 1209 iter, 6045000 ts, 351 rew

agent-1: 56.39999999220817
agent-2: 52.39999999220819
agent-3: 52.39999999220817
agent-4: 47.39999999220819
agent-5: 52.39999999220819
Extrinsic Rewards:
10
6
6
1
6
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.2482758620689655
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 353.9639234985716
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1209
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 7.964
    learner:
      cur_lr: 0.0009574029827490449
      grad_gnorm: 39.999996185302734
      policy_entropy: 17.564922332763672
      policy_loss: -5.023809432983398
      var_gnorm: 23.01624298095703
      vf_explained_var: 0.0
      vf_loss: 2.491556167602539
    num_steps_sampled: 6050000
    num_steps_trained: 6050000
    wait_time_ms: 80.31
  iterations_since_restore: 1210
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10610.531272649765
  time_this_iter_s: 8.518525838851929
  time_total_s: 10610.531272649765
  timestamp: 1594859145
  timesteps_since_restore: 6050000
  timesteps_this_iter: 5000
  timesteps_total: 6050000
  training_iteration: 1210
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10610 s, 1210 iter, 6050000 ts, 354 rew

agent-1: 131.19950941686363
agent-2: 132.19950941686363
agent-3: 117.19950941686339
agent-4: 125.19950941686339
agent-5: 142.19950941686344
Extrinsic Rewards:
16
17
2
10
27
Sum Reward: 72
Avg Reward: 14.4
Min Reward: 2
Max Reward: 27
Gini Coefficient: 0.31666666666666665
20:20 Ratio: 13.5
Max-min Ratio: 13.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-25-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 355.7355126713639
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1210
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.102
    dispatch_time_ms: 9.77
    learner:
      cur_lr: 0.000957069976720959
      grad_gnorm: 40.0
      policy_entropy: 36.90510559082031
      policy_loss: 14.486320495605469
      var_gnorm: 23.015708923339844
      vf_explained_var: 0.0
      vf_loss: 5.331061840057373
    num_steps_sampled: 6055000
    num_steps_trained: 6055000
    wait_time_ms: 73.738
  iterations_since_restore: 1211
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10619.222889900208
  time_this_iter_s: 8.691617250442505
  time_total_s: 10619.222889900208
  timestamp: 1594859154
  timesteps_since_restore: 6055000
  timesteps_this_iter: 5000
  timesteps_total: 6055000
  training_iteration: 1211
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10619 s, 1211 iter, 6055000 ts, 356 rew

agent-1: 48.79999999568153
agent-2: 49.799999995681546
agent-3: 53.79999999568153
agent-4: 46.79999999568153
agent-5: 52.79999999568153
Extrinsic Rewards:
4
5
9
2
8
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2571428571428571
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 353.21551317437917
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1211
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.62
    dispatch_time_ms: 6.233
    learner:
      cur_lr: 0.0009567370289005339
      grad_gnorm: 14.061574935913086
      policy_entropy: 37.501007080078125
      policy_loss: -2.665689468383789
      var_gnorm: 23.020545959472656
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.1514841616153717
    num_steps_sampled: 6060000
    num_steps_trained: 6060000
    wait_time_ms: 77.97
  iterations_since_restore: 1212
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10627.830582380295
  time_this_iter_s: 8.60769248008728
  time_total_s: 10627.830582380295
  timestamp: 1594859163
  timesteps_since_restore: 6060000
  timesteps_this_iter: 5000
  timesteps_total: 6060000
  training_iteration: 1212
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10627 s, 1212 iter, 6060000 ts, 353 rew

agent-1: 75.59999999091828
agent-2: 72.59999999091829
agent-3: 71.59999999091825
agent-4: 74.59999999091829
agent-5: 74.59999999091829
Extrinsic Rewards:
10
7
6
9
9
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 6
Max Reward: 10
Gini Coefficient: 0.0975609756097561
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 351.3255132440847
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1212
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.583
    dispatch_time_ms: 9.455
    learner:
      cur_lr: 0.000956404022872448
      grad_gnorm: 39.999996185302734
      policy_entropy: 38.53937530517578
      policy_loss: 12.768586158752441
      var_gnorm: 23.028139114379883
      vf_explained_var: 0.0
      vf_loss: 4.0316948890686035
    num_steps_sampled: 6065000
    num_steps_trained: 6065000
    wait_time_ms: 74.064
  iterations_since_restore: 1213
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10636.374037265778
  time_this_iter_s: 8.543454885482788
  time_total_s: 10636.374037265778
  timestamp: 1594859171
  timesteps_since_restore: 6065000
  timesteps_this_iter: 5000
  timesteps_total: 6065000
  training_iteration: 1213
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10636 s, 1213 iter, 6065000 ts, 351 rew

agent-1: 42.39999999696162
agent-2: 40.399999996961604
agent-3: 43.399999996961625
agent-4: 50.39999999696163
agent-5: 39.399999996961604
Extrinsic Rewards:
4
2
5
12
1
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.4166666666666667
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 351.5955132439652
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1213
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.759
    dispatch_time_ms: 9.433
    learner:
      cur_lr: 0.000956071016844362
      grad_gnorm: 13.43454647064209
      policy_entropy: 47.64809036254883
      policy_loss: -3.411221504211426
      var_gnorm: 23.04355812072754
      vf_explained_var: 0.0
      vf_loss: 0.13474494218826294
    num_steps_sampled: 6070000
    num_steps_trained: 6070000
    wait_time_ms: 76.065
  iterations_since_restore: 1214
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10644.972914457321
  time_this_iter_s: 8.598877191543579
  time_total_s: 10644.972914457321
  timestamp: 1594859180
  timesteps_since_restore: 6070000
  timesteps_this_iter: 5000
  timesteps_total: 6070000
  training_iteration: 1214
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10644 s, 1214 iter, 6070000 ts, 352 rew

agent-1: 52.199999994129065
agent-2: 52.199999994129065
agent-3: 59.19999999412906
agent-4: 65.19999999412896
agent-5: 59.199999994129065
Extrinsic Rewards:
1
1
8
14
8
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.4125
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 346.5606998863966
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1214
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.058
    dispatch_time_ms: 7.126
    learner:
      cur_lr: 0.0009557380108162761
      grad_gnorm: 40.0
      policy_entropy: 54.303829193115234
      policy_loss: 23.975685119628906
      var_gnorm: 23.060495376586914
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.614199161529541
    num_steps_sampled: 6075000
    num_steps_trained: 6075000
    wait_time_ms: 78.982
  iterations_since_restore: 1215
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10653.701835632324
  time_this_iter_s: 8.728921175003052
  time_total_s: 10653.701835632324
  timestamp: 1594859189
  timesteps_since_restore: 6075000
  timesteps_this_iter: 5000
  timesteps_total: 6075000
  training_iteration: 1215
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10653 s, 1215 iter, 6075000 ts, 347 rew

agent-1: 35.79999999915146
agent-2: 32.799999999151474
agent-3: 31.799999999151318
agent-4: 32.799999999151474
agent-5: 28.799999999151318
Extrinsic Rewards:
7
4
3
4
0
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.3333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 344.5806998883587
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1215
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.572
    dispatch_time_ms: 10.063
    learner:
      cur_lr: 0.0009554050047881901
      grad_gnorm: 22.091323852539062
      policy_entropy: 51.367042541503906
      policy_loss: -4.522243499755859
      var_gnorm: 23.05368995666504
      vf_explained_var: 0.0
      vf_loss: 0.3146058917045593
    num_steps_sampled: 6080000
    num_steps_trained: 6080000
    wait_time_ms: 72.386
  iterations_since_restore: 1216
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10662.304230451584
  time_this_iter_s: 8.602394819259644
  time_total_s: 10662.304230451584
  timestamp: 1594859197
  timesteps_since_restore: 6080000
  timesteps_this_iter: 5000
  timesteps_total: 6080000
  training_iteration: 1216
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10662 s, 1216 iter, 6080000 ts, 345 rew

agent-1: 62.599999991307676
agent-2: 54.599999991307705
agent-3: 54.59999999130771
agent-4: 52.59999999130771
agent-5: 54.599999991307705
Extrinsic Rewards:
13
5
5
3
5
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.25806451612903225
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 345.03069988818874
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1216
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.745
    dispatch_time_ms: 9.304
    learner:
      cur_lr: 0.0009550719987601042
      grad_gnorm: 16.553653717041016
      policy_entropy: 45.566627502441406
      policy_loss: -3.4598703384399414
      var_gnorm: 23.047388076782227
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.17694467306137085
    num_steps_sampled: 6085000
    num_steps_trained: 6085000
    wait_time_ms: 74.899
  iterations_since_restore: 1217
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10670.959352493286
  time_this_iter_s: 8.65512204170227
  time_total_s: 10670.959352493286
  timestamp: 1594859206
  timesteps_since_restore: 6085000
  timesteps_this_iter: 5000
  timesteps_total: 6085000
  training_iteration: 1217
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10670 s, 1217 iter, 6085000 ts, 345 rew

agent-1: 56.59999999618276
agent-2: 54.59999999618276
agent-3: 60.59999999618276
agent-4: 52.59999999618276
agent-5: 54.599999996182774
Extrinsic Rewards:
7
5
11
3
5
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.23225806451612904
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-26-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 344.4906998943406
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1217
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.588
    dispatch_time_ms: 6.387
    learner:
      cur_lr: 0.0009547389927320182
      grad_gnorm: 5.618099212646484
      policy_entropy: 51.756675720214844
      policy_loss: -1.3264058828353882
      var_gnorm: 23.052486419677734
      vf_explained_var: 0.0
      vf_loss: 0.021832939237356186
    num_steps_sampled: 6090000
    num_steps_trained: 6090000
    wait_time_ms: 77.504
  iterations_since_restore: 1218
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10679.537808895111
  time_this_iter_s: 8.578456401824951
  time_total_s: 10679.537808895111
  timestamp: 1594859215
  timesteps_since_restore: 6090000
  timesteps_this_iter: 5000
  timesteps_total: 6090000
  training_iteration: 1218
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10679 s, 1218 iter, 6090000 ts, 344 rew

agent-1: 50.399999997020686
agent-2: 51.399999997020686
agent-3: 51.399999997020686
agent-4: 53.39999999702069
agent-5: 54.399999997020686
Extrinsic Rewards:
4
5
5
7
8
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 4
Max Reward: 8
Gini Coefficient: 0.13793103448275862
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 343.41069989511715
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1218
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 5.802
    learner:
      cur_lr: 0.0009544059867039323
      grad_gnorm: 15.0322904586792
      policy_entropy: 54.444698333740234
      policy_loss: -3.9023380279541016
      var_gnorm: 23.058534622192383
      vf_explained_var: 0.0
      vf_loss: 0.16837088763713837
    num_steps_sampled: 6095000
    num_steps_trained: 6095000
    wait_time_ms: 81.362
  iterations_since_restore: 1219
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10688.179581165314
  time_this_iter_s: 8.641772270202637
  time_total_s: 10688.179581165314
  timestamp: 1594859223
  timesteps_since_restore: 6095000
  timesteps_this_iter: 5000
  timesteps_total: 6095000
  training_iteration: 1219
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10688 s, 1219 iter, 6095000 ts, 343 rew

agent-1: 54.19999999173514
agent-2: 63.19999999173514
agent-3: 52.19999999173515
agent-4: 62.19999999173514
agent-5: 56.19999999173515
Extrinsic Rewards:
3
12
1
11
5
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.375
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 344.58069989473245
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1219
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 6.929
    learner:
      cur_lr: 0.0009540729806758463
      grad_gnorm: 14.531652450561523
      policy_entropy: 33.19070816040039
      policy_loss: -1.5624676942825317
      var_gnorm: 23.04853630065918
      vf_explained_var: 0.0
      vf_loss: 0.14850841462612152
    num_steps_sampled: 6100000
    num_steps_trained: 6100000
    wait_time_ms: 79.444
  iterations_since_restore: 1220
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10696.81261587143
  time_this_iter_s: 8.633034706115723
  time_total_s: 10696.81261587143
  timestamp: 1594859232
  timesteps_since_restore: 6100000
  timesteps_this_iter: 5000
  timesteps_total: 6100000
  training_iteration: 1220
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10696 s, 1220 iter, 6100000 ts, 345 rew

agent-1: 53.79999999495851
agent-2: 47.7999999949585
agent-3: 53.7999999949585
agent-4: 47.7999999949585
agent-5: 48.7999999949585
Extrinsic Rewards:
9
3
9
3
4
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.2571428571428571
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 344.76069989456636
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1220
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.475
    dispatch_time_ms: 8.084
    learner:
      cur_lr: 0.0009537399746477604
      grad_gnorm: 40.0
      policy_entropy: 21.270994186401367
      policy_loss: 8.736934661865234
      var_gnorm: 23.049015045166016
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 13.379154205322266
    num_steps_sampled: 6105000
    num_steps_trained: 6105000
    wait_time_ms: 75.632
  iterations_since_restore: 1221
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10705.458822011948
  time_this_iter_s: 8.646206140518188
  time_total_s: 10705.458822011948
  timestamp: 1594859241
  timesteps_since_restore: 6105000
  timesteps_this_iter: 5000
  timesteps_total: 6105000
  training_iteration: 1221
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10705 s, 1221 iter, 6105000 ts, 345 rew

agent-1: 51.79999999745486
agent-2: 54.79999999745486
agent-3: 53.799999997454876
agent-4: 46.799999997454876
agent-5: 44.799999997454876
Extrinsic Rewards:
7
10
9
2
0
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.38571428571428573
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 344.13069989467397
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1221
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.778
    dispatch_time_ms: 10.124
    learner:
      cur_lr: 0.0009534070268273354
      grad_gnorm: 40.0
      policy_entropy: 26.56825065612793
      policy_loss: -3.775562047958374
      var_gnorm: 23.056238174438477
      vf_explained_var: 0.0
      vf_loss: 2.793825149536133
    num_steps_sampled: 6110000
    num_steps_trained: 6110000
    wait_time_ms: 70.594
  iterations_since_restore: 1222
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10714.018829345703
  time_this_iter_s: 8.560007333755493
  time_total_s: 10714.018829345703
  timestamp: 1594859249
  timesteps_since_restore: 6110000
  timesteps_this_iter: 5000
  timesteps_total: 6110000
  training_iteration: 1222
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10714 s, 1222 iter, 6110000 ts, 344 rew

agent-1: 140.5999698490966
agent-2: 136.5999698490965
agent-3: 145.5999698490966
agent-4: 130.59996984909648
agent-5: 130.59996984909648
Extrinsic Rewards:
19
15
24
9
9
Sum Reward: 76
Avg Reward: 15.2
Min Reward: 9
Max Reward: 24
Gini Coefficient: 0.21052631578947367
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 348.1806983873865
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1222
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 6.068
    learner:
      cur_lr: 0.0009530740207992494
      grad_gnorm: 28.901100158691406
      policy_entropy: 54.344215393066406
      policy_loss: -7.7985453605651855
      var_gnorm: 23.058963775634766
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.6447364091873169
    num_steps_sampled: 6115000
    num_steps_trained: 6115000
    wait_time_ms: 75.258
  iterations_since_restore: 1223
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10722.494735002518
  time_this_iter_s: 8.475905656814575
  time_total_s: 10722.494735002518
  timestamp: 1594859258
  timesteps_since_restore: 6115000
  timesteps_this_iter: 5000
  timesteps_total: 6115000
  training_iteration: 1223
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10722 s, 1223 iter, 6115000 ts, 348 rew

agent-1: 114.59999897429539
agent-2: 108.59999897429535
agent-3: 118.59999897429536
agent-4: 132.59999897429518
agent-5: 119.59999897429539
Extrinsic Rewards:
9
3
13
27
14
Sum Reward: 66
Avg Reward: 13.2
Min Reward: 3
Max Reward: 27
Gini Coefficient: 0.3212121212121212
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-27-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 352.4106983361331
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1223
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 7.487
    learner:
      cur_lr: 0.0009527410147711635
      grad_gnorm: 14.02169132232666
      policy_entropy: 52.140811920166016
      policy_loss: -4.1760687828063965
      var_gnorm: 23.061538696289062
      vf_explained_var: 0.0
      vf_loss: 0.13521404564380646
    num_steps_sampled: 6120000
    num_steps_trained: 6120000
    wait_time_ms: 72.999
  iterations_since_restore: 1224
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10730.94325709343
  time_this_iter_s: 8.448522090911865
  time_total_s: 10730.94325709343
  timestamp: 1594859266
  timesteps_since_restore: 6120000
  timesteps_this_iter: 5000
  timesteps_total: 6120000
  training_iteration: 1224
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10730 s, 1224 iter, 6120000 ts, 352 rew

agent-1: 38.19999999816265
agent-2: 44.19999999816267
agent-3: 39.19999999816266
agent-4: 37.19999999816266
agent-5: 39.19999999816266
Extrinsic Rewards:
3
9
4
2
4
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2727272727272727
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 352.5906983361263
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1224
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 13.346
    learner:
      cur_lr: 0.0009524080087430775
      grad_gnorm: 8.861893653869629
      policy_entropy: 47.19938659667969
      policy_loss: -2.0496222972869873
      var_gnorm: 23.060447692871094
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.06073281541466713
    num_steps_sampled: 6125000
    num_steps_trained: 6125000
    wait_time_ms: 45.76
  iterations_since_restore: 1225
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10751.137238502502
  time_this_iter_s: 20.193981409072876
  time_total_s: 10751.137238502502
  timestamp: 1594859287
  timesteps_since_restore: 6125000
  timesteps_this_iter: 5000
  timesteps_total: 6125000
  training_iteration: 1225
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10751 s, 1225 iter, 6125000 ts, 353 rew

agent-1: 47.19999999926158
agent-2: 37.1999999992616
agent-3: 37.1999999992616
agent-4: 35.19999999926161
agent-5: 41.199999999261586
Extrinsic Rewards:
12
2
2
0
6
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.509090909090909
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 352.7706983361807
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1225
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.345
    dispatch_time_ms: 9.591
    learner:
      cur_lr: 0.0009520750027149916
      grad_gnorm: 12.558399200439453
      policy_entropy: 49.79011917114258
      policy_loss: -3.4516236782073975
      var_gnorm: 23.0631103515625
      vf_explained_var: 0.0
      vf_loss: 0.11258906126022339
    num_steps_sampled: 6130000
    num_steps_trained: 6130000
    wait_time_ms: 73.247
  iterations_since_restore: 1226
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10759.621634721756
  time_this_iter_s: 8.48439621925354
  time_total_s: 10759.621634721756
  timestamp: 1594859295
  timesteps_since_restore: 6130000
  timesteps_this_iter: 5000
  timesteps_total: 6130000
  training_iteration: 1226
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10759 s, 1226 iter, 6130000 ts, 353 rew

agent-1: 46.79999999807082
agent-2: 48.79999999807081
agent-3: 48.79999999807082
agent-4: 55.799999998070795
agent-5: 51.799999998070795
Extrinsic Rewards:
2
4
4
11
7
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.3
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 353.4006983361474
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1226
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.597
    dispatch_time_ms: 7.62
    learner:
      cur_lr: 0.0009517419966869056
      grad_gnorm: 39.99999237060547
      policy_entropy: 44.065040588378906
      policy_loss: 36.932037353515625
      var_gnorm: 23.065731048583984
      vf_explained_var: 0.0
      vf_loss: 18.38947105407715
    num_steps_sampled: 6135000
    num_steps_trained: 6135000
    wait_time_ms: 74.497
  iterations_since_restore: 1227
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10768.14375948906
  time_this_iter_s: 8.522124767303467
  time_total_s: 10768.14375948906
  timestamp: 1594859304
  timesteps_since_restore: 6135000
  timesteps_this_iter: 5000
  timesteps_total: 6135000
  training_iteration: 1227
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10768 s, 1227 iter, 6135000 ts, 353 rew

agent-1: 41.399999995179186
agent-2: 43.39999999517919
agent-3: 46.39999999517918
agent-4: 41.39999999517919
agent-5: 43.399999995179186
Extrinsic Rewards:
3
5
8
3
5
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 3
Max Reward: 8
Gini Coefficient: 0.2
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 353.490698336006
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1227
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.162
    dispatch_time_ms: 7.471
    learner:
      cur_lr: 0.0009514089906588197
      grad_gnorm: 16.907752990722656
      policy_entropy: 54.61915969848633
      policy_loss: -4.727652549743652
      var_gnorm: 23.061866760253906
      vf_explained_var: 0.0
      vf_loss: 0.1996259242296219
    num_steps_sampled: 6140000
    num_steps_trained: 6140000
    wait_time_ms: 73.845
  iterations_since_restore: 1228
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10776.618789196014
  time_this_iter_s: 8.475029706954956
  time_total_s: 10776.618789196014
  timestamp: 1594859312
  timesteps_since_restore: 6140000
  timesteps_this_iter: 5000
  timesteps_total: 6140000
  training_iteration: 1228
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10776 s, 1228 iter, 6140000 ts, 353 rew

agent-1: 57.599999991106415
agent-2: 57.5999999911064
agent-3: 55.599999991106415
agent-4: 52.599999991106415
agent-5: 55.59999999110643
Extrinsic Rewards:
8
8
6
3
6
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 8
Gini Coefficient: 0.15483870967741936
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 354.48069833559754
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1228
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.916
    dispatch_time_ms: 23.551
    learner:
      cur_lr: 0.0009510759846307337
      grad_gnorm: 13.443952560424805
      policy_entropy: 52.224979400634766
      policy_loss: -2.347498893737793
      var_gnorm: 23.06304168701172
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.13958756625652313
    num_steps_sampled: 6145000
    num_steps_trained: 6145000
    wait_time_ms: 66.738
  iterations_since_restore: 1229
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10785.603079557419
  time_this_iter_s: 8.984290361404419
  time_total_s: 10785.603079557419
  timestamp: 1594859321
  timesteps_since_restore: 6145000
  timesteps_this_iter: 5000
  timesteps_total: 6145000
  training_iteration: 1229
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10785 s, 1229 iter, 6145000 ts, 354 rew

agent-1: 49.199999997488646
agent-2: 50.19999999748865
agent-3: 47.19999999748864
agent-4: 50.199999997488646
agent-5: 46.19999999748865
Extrinsic Rewards:
6
7
4
7
3
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.16296296296296298
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 355.11069833550937
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1229
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.73
    dispatch_time_ms: 26.196
    learner:
      cur_lr: 0.0009507429786026478
      grad_gnorm: 18.472604751586914
      policy_entropy: 43.6387825012207
      policy_loss: -4.593203067779541
      var_gnorm: 23.064882278442383
      vf_explained_var: 0.0
      vf_loss: 0.2617166340351105
    num_steps_sampled: 6150000
    num_steps_trained: 6150000
    wait_time_ms: 58.535
  iterations_since_restore: 1230
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10794.577535390854
  time_this_iter_s: 8.974455833435059
  time_total_s: 10794.577535390854
  timestamp: 1594859330
  timesteps_since_restore: 6150000
  timesteps_this_iter: 5000
  timesteps_total: 6150000
  training_iteration: 1230
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10794 s, 1230 iter, 6150000 ts, 355 rew

agent-1: 44.19999999307613
agent-2: 51.19999999307613
agent-3: 47.19999999307613
agent-4: 55.199999993076105
agent-5: 45.19999999307612
Extrinsic Rewards:
1
8
4
12
2
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.4148148148148148
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-28-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 355.3806983352335
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1230
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.868
    dispatch_time_ms: 43.782
    learner:
      cur_lr: 0.0009504099725745618
      grad_gnorm: 12.202110290527344
      policy_entropy: 35.394622802734375
      policy_loss: -1.4982585906982422
      var_gnorm: 23.067258834838867
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.1145644560456276
    num_steps_sampled: 6155000
    num_steps_trained: 6155000
    wait_time_ms: 45.651
  iterations_since_restore: 1231
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10803.710528612137
  time_this_iter_s: 9.132993221282959
  time_total_s: 10803.710528612137
  timestamp: 1594859339
  timesteps_since_restore: 6155000
  timesteps_this_iter: 5000
  timesteps_total: 6155000
  training_iteration: 1231
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10803 s, 1231 iter, 6155000 ts, 355 rew

agent-1: 39.19999999689968
agent-2: 45.199999996899685
agent-3: 41.199999996899685
agent-4: 35.19999999689969
agent-5: 37.19999999689968
Extrinsic Rewards:
4
10
6
0
2
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.43636363636363634
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 355.02069833516924
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1231
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.029
    dispatch_time_ms: 30.67
    learner:
      cur_lr: 0.0009500770247541368
      grad_gnorm: 14.851174354553223
      policy_entropy: 32.84777069091797
      policy_loss: -3.225454568862915
      var_gnorm: 23.066850662231445
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.16872374713420868
    num_steps_sampled: 6160000
    num_steps_trained: 6160000
    wait_time_ms: 56.982
  iterations_since_restore: 1232
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10812.885016441345
  time_this_iter_s: 9.174487829208374
  time_total_s: 10812.885016441345
  timestamp: 1594859349
  timesteps_since_restore: 6160000
  timesteps_this_iter: 5000
  timesteps_total: 6160000
  training_iteration: 1232
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10812 s, 1232 iter, 6160000 ts, 355 rew

agent-1: 37.19999999922596
agent-2: 38.199999999225945
agent-3: 39.19999999922595
agent-4: 42.19999999922595
agent-5: 41.199999999225945
Extrinsic Rewards:
2
3
4
7
6
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.23636363636363636
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 352.95069833618254
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1232
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.286
    dispatch_time_ms: 28.147
    learner:
      cur_lr: 0.0009497440187260509
      grad_gnorm: 12.146794319152832
      policy_entropy: 30.86953353881836
      policy_loss: -0.5996092557907104
      var_gnorm: 23.06848907470703
      vf_explained_var: 0.0
      vf_loss: 0.11236004531383514
    num_steps_sampled: 6165000
    num_steps_trained: 6165000
    wait_time_ms: 59.614
  iterations_since_restore: 1233
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10822.005910634995
  time_this_iter_s: 9.120894193649292
  time_total_s: 10822.005910634995
  timestamp: 1594859358
  timesteps_since_restore: 6165000
  timesteps_this_iter: 5000
  timesteps_total: 6165000
  training_iteration: 1233
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10822 s, 1233 iter, 6165000 ts, 353 rew

agent-1: 30.59999999813756
agent-2: 27.599999998137566
agent-3: 31.59999999813756
agent-4: 25.599999998137566
agent-5: 28.599999998137566
Extrinsic Rewards:
5
2
6
0
3
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.375
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 344.6871873553461
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1233
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.31
    dispatch_time_ms: 24.476
    learner:
      cur_lr: 0.0009494110126979649
      grad_gnorm: 17.96650505065918
      policy_entropy: 49.392494201660156
      policy_loss: -6.017666816711426
      var_gnorm: 23.06642723083496
      vf_explained_var: 0.0
      vf_loss: 0.23933173716068268
    num_steps_sampled: 6170000
    num_steps_trained: 6170000
    wait_time_ms: 63.518
  iterations_since_restore: 1234
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10831.140410900116
  time_this_iter_s: 9.13450026512146
  time_total_s: 10831.140410900116
  timestamp: 1594859367
  timesteps_since_restore: 6170000
  timesteps_this_iter: 5000
  timesteps_total: 6170000
  training_iteration: 1234
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10831 s, 1234 iter, 6170000 ts, 345 rew

agent-1: 39.39999999610833
agent-2: 38.39999999610833
agent-3: 47.39999999610829
agent-4: 45.3999999961083
agent-5: 45.3999999961083
Extrinsic Rewards:
1
0
9
7
7
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 343.78718735699675
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1234
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 23.34
    learner:
      cur_lr: 0.000949078006669879
      grad_gnorm: 13.309650421142578
      policy_entropy: 26.581714630126953
      policy_loss: -1.8404275178909302
      var_gnorm: 23.069019317626953
      vf_explained_var: 0.0
      vf_loss: 0.13145339488983154
    num_steps_sampled: 6175000
    num_steps_trained: 6175000
    wait_time_ms: 63.914
  iterations_since_restore: 1235
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10840.454580068588
  time_this_iter_s: 9.31416916847229
  time_total_s: 10840.454580068588
  timestamp: 1594859376
  timesteps_since_restore: 6175000
  timesteps_this_iter: 5000
  timesteps_total: 6175000
  training_iteration: 1235
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10840 s, 1235 iter, 6175000 ts, 344 rew

agent-1: 46.79999999471769
agent-2: 51.79999999471767
agent-3: 46.79999999471769
agent-4: 52.799999994717666
agent-5: 53.79999999471768
Extrinsic Rewards:
2
7
2
8
9
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2857142857142857
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 336.3810132763715
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1235
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.97
    dispatch_time_ms: 25.139
    learner:
      cur_lr: 0.000948745000641793
      grad_gnorm: 40.0
      policy_entropy: 32.3740234375
      policy_loss: 26.411184310913086
      var_gnorm: 23.085590362548828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 17.17890167236328
    num_steps_sampled: 6180000
    num_steps_trained: 6180000
    wait_time_ms: 67.757
  iterations_since_restore: 1236
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10849.597069740295
  time_this_iter_s: 9.142489671707153
  time_total_s: 10849.597069740295
  timestamp: 1594859385
  timesteps_since_restore: 6180000
  timesteps_this_iter: 5000
  timesteps_total: 6180000
  training_iteration: 1236
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10849 s, 1236 iter, 6180000 ts, 336 rew

agent-1: 252.56365704268433
agent-2: 259.56365704268467
agent-3: 236.56365704268438
agent-4: 248.5636570426843
agent-5: 243.56365704268435
Extrinsic Rewards:
32
39
16
28
23
Sum Reward: 138
Avg Reward: 27.6
Min Reward: 16
Max Reward: 39
Gini Coefficient: 0.15942028985507245
20:20 Ratio: 2.4375
Max-min Ratio: 2.4375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-29-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1259.5391031904178
  episode_reward_mean: 344.01919620804546
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1236
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.924
    dispatch_time_ms: 7.179
    learner:
      cur_lr: 0.0009484119946137071
      grad_gnorm: 40.0
      policy_entropy: 22.45170783996582
      policy_loss: 21.086822509765625
      var_gnorm: 23.138694763183594
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 30.570507049560547
    num_steps_sampled: 6185000
    num_steps_trained: 6185000
    wait_time_ms: 78.84
  iterations_since_restore: 1237
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10858.384183645248
  time_this_iter_s: 8.787113904953003
  time_total_s: 10858.384183645248
  timestamp: 1594859394
  timesteps_since_restore: 6185000
  timesteps_this_iter: 5000
  timesteps_total: 6185000
  training_iteration: 1237
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10858 s, 1237 iter, 6185000 ts, 344 rew

agent-1: 264.23456382523295
agent-2: 265.23456382523307
agent-3: 279.2345638252331
agent-4: 278.2345638252331
agent-5: 262.23456382523295
Extrinsic Rewards:
25
26
40
39
23
Sum Reward: 153
Avg Reward: 30.6
Min Reward: 23
Max Reward: 40
Gini Coefficient: 0.12549019607843137
20:20 Ratio: 1.7391304347826086
Max-min Ratio: 1.7391304347826086
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 355.8909243993384
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1237
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 11.289
    learner:
      cur_lr: 0.0009480789885856211
      grad_gnorm: 40.0
      policy_entropy: 28.120468139648438
      policy_loss: -13.3470458984375
      var_gnorm: 23.211883544921875
      vf_explained_var: 0.0
      vf_loss: 8.554243087768555
    num_steps_sampled: 6190000
    num_steps_trained: 6190000
    wait_time_ms: 72.556
  iterations_since_restore: 1238
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10866.859033823013
  time_this_iter_s: 8.474850177764893
  time_total_s: 10866.859033823013
  timestamp: 1594859403
  timesteps_since_restore: 6190000
  timesteps_this_iter: 5000
  timesteps_total: 6190000
  training_iteration: 1238
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10866 s, 1238 iter, 6190000 ts, 356 rew

agent-1: 208.5965806708152
agent-2: 203.59658067081517
agent-3: 208.5965806708152
agent-4: 219.59658067081514
agent-5: 203.5965806708152
Extrinsic Rewards:
23
18
23
34
18
Sum Reward: 116
Avg Reward: 23.2
Min Reward: 18
Max Reward: 34
Gini Coefficient: 0.12758620689655173
20:20 Ratio: 1.8888888888888888
Max-min Ratio: 1.8888888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 363.27075343317404
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1238
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.511
    dispatch_time_ms: 7.667
    learner:
      cur_lr: 0.0009477459825575352
      grad_gnorm: 40.000003814697266
      policy_entropy: 51.06980895996094
      policy_loss: -46.452667236328125
      var_gnorm: 23.15521240234375
      vf_explained_var: 0.0
      vf_loss: 25.1302547454834
    num_steps_sampled: 6195000
    num_steps_trained: 6195000
    wait_time_ms: 73.423
  iterations_since_restore: 1239
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10875.418508768082
  time_this_iter_s: 8.55947494506836
  time_total_s: 10875.418508768082
  timestamp: 1594859411
  timesteps_since_restore: 6195000
  timesteps_this_iter: 5000
  timesteps_total: 6195000
  training_iteration: 1239
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10875 s, 1239 iter, 6195000 ts, 363 rew

agent-1: 102.79999651446607
agent-2: 104.79999651446609
agent-3: 99.79999651446607
agent-4: 111.79999651446609
agent-5: 102.79999651446609
Extrinsic Rewards:
10
12
7
19
10
Sum Reward: 58
Avg Reward: 11.6
Min Reward: 7
Max Reward: 19
Gini Coefficient: 0.1793103448275862
20:20 Ratio: 2.7142857142857144
Max-min Ratio: 2.7142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 365.4307532598869
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1239
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.939
    dispatch_time_ms: 8.043
    learner:
      cur_lr: 0.0009474129765294492
      grad_gnorm: 40.000003814697266
      policy_entropy: 50.53520202636719
      policy_loss: 45.85365676879883
      var_gnorm: 23.152233123779297
      vf_explained_var: 0.0
      vf_loss: 24.078041076660156
    num_steps_sampled: 6200000
    num_steps_trained: 6200000
    wait_time_ms: 76.776
  iterations_since_restore: 1240
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10883.958480834961
  time_this_iter_s: 8.539972066879272
  time_total_s: 10883.958480834961
  timestamp: 1594859420
  timesteps_since_restore: 6200000
  timesteps_this_iter: 5000
  timesteps_total: 6200000
  training_iteration: 1240
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10883 s, 1240 iter, 6200000 ts, 365 rew

agent-1: 156.17190367072448
agent-2: 167.17190367072442
agent-3: 152.1719036707245
agent-4: 154.17190367072448
agent-5: 153.17190367072448
Extrinsic Rewards:
17
28
13
15
14
Sum Reward: 87
Avg Reward: 17.4
Min Reward: 13
Max Reward: 28
Gini Coefficient: 0.15172413793103448
20:20 Ratio: 2.1538461538461537
Max-min Ratio: 2.1538461538461537
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 368.0393484871614
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1240
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.731
    dispatch_time_ms: 9.393
    learner:
      cur_lr: 0.0009470800287090242
      grad_gnorm: 40.000003814697266
      policy_entropy: 53.42667007446289
      policy_loss: -34.29129409790039
      var_gnorm: 23.125110626220703
      vf_explained_var: 0.0
      vf_loss: 12.252226829528809
    num_steps_sampled: 6205000
    num_steps_trained: 6205000
    wait_time_ms: 74.693
  iterations_since_restore: 1241
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10892.589417219162
  time_this_iter_s: 8.63093638420105
  time_total_s: 10892.589417219162
  timestamp: 1594859429
  timesteps_since_restore: 6205000
  timesteps_this_iter: 5000
  timesteps_total: 6205000
  training_iteration: 1241
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10892 s, 1241 iter, 6205000 ts, 368 rew

agent-1: 106.19999869110622
agent-2: 110.19999869110622
agent-3: 112.19999869110622
agent-4: 117.19999869110617
agent-5: 112.1999986911062
Extrinsic Rewards:
7
11
13
18
13
Sum Reward: 62
Avg Reward: 12.4
Min Reward: 7
Max Reward: 18
Gini Coefficient: 0.15483870967741936
20:20 Ratio: 2.5714285714285716
Max-min Ratio: 2.5714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 371.90934842175454
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1241
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.542
    dispatch_time_ms: 7.022
    learner:
      cur_lr: 0.0009467470226809382
      grad_gnorm: 39.999996185302734
      policy_entropy: 28.240345001220703
      policy_loss: -13.357552528381348
      var_gnorm: 23.089075088500977
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.505024433135986
    num_steps_sampled: 6210000
    num_steps_trained: 6210000
    wait_time_ms: 82.354
  iterations_since_restore: 1242
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10901.313019752502
  time_this_iter_s: 8.723602533340454
  time_total_s: 10901.313019752502
  timestamp: 1594859437
  timesteps_since_restore: 6210000
  timesteps_this_iter: 5000
  timesteps_total: 6210000
  training_iteration: 1242
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10901 s, 1242 iter, 6210000 ts, 372 rew

agent-1: 34.399999999187564
agent-2: 41.39999999918758
agent-3: 30.399999999187514
agent-4: 34.399999999187564
agent-5: 30.399999999187514
Extrinsic Rewards:
4
11
0
4
0
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.5473684210526316
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 371.81934842176497
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1242
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.868
    dispatch_time_ms: 8.495
    learner:
      cur_lr: 0.0009464140166528523
      grad_gnorm: 40.0
      policy_entropy: 42.71791458129883
      policy_loss: -12.870467185974121
      var_gnorm: 23.075462341308594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.169915199279785
    num_steps_sampled: 6215000
    num_steps_trained: 6215000
    wait_time_ms: 76.574
  iterations_since_restore: 1243
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10910.002026557922
  time_this_iter_s: 8.689006805419922
  time_total_s: 10910.002026557922
  timestamp: 1594859446
  timesteps_since_restore: 6215000
  timesteps_this_iter: 5000
  timesteps_total: 6215000
  training_iteration: 1243
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10910 s, 1243 iter, 6215000 ts, 372 rew

agent-1: 102.99999692310097
agent-2: 94.99999692310098
agent-3: 89.99999692310095
agent-4: 97.99999692310095
agent-5: 108.999996923101
Extrinsic Rewards:
15
7
2
10
21
Sum Reward: 55
Avg Reward: 11.0
Min Reward: 2
Max Reward: 21
Gini Coefficient: 0.33454545454545453
20:20 Ratio: 10.5
Max-min Ratio: 10.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-30-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 374.6093482680482
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1243
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.77
    dispatch_time_ms: 8.12
    learner:
      cur_lr: 0.0009460810106247663
      grad_gnorm: 31.36918830871582
      policy_entropy: 41.76444625854492
      policy_loss: -6.737637042999268
      var_gnorm: 23.067188262939453
      vf_explained_var: 0.0
      vf_loss: 0.7038848996162415
    num_steps_sampled: 6220000
    num_steps_trained: 6220000
    wait_time_ms: 77.135
  iterations_since_restore: 1244
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10918.590435028076
  time_this_iter_s: 8.588408470153809
  time_total_s: 10918.590435028076
  timestamp: 1594859455
  timesteps_since_restore: 6220000
  timesteps_this_iter: 5000
  timesteps_total: 6220000
  training_iteration: 1244
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10918 s, 1244 iter, 6220000 ts, 375 rew

agent-1: 35.59999999901371
agent-2: 39.59999999901369
agent-3: 35.599999999013704
agent-4: 39.59999999901369
agent-5: 38.59999999901369
Extrinsic Rewards:
2
6
2
6
5
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.22857142857142856
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 374.5193482680811
  episode_reward_min: 134.99999999718602
  episodes_this_iter: 1
  episodes_total: 1244
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.019
    dispatch_time_ms: 6.517
    learner:
      cur_lr: 0.0009457480045966804
      grad_gnorm: 40.0
      policy_entropy: 46.19636154174805
      policy_loss: 28.63358497619629
      var_gnorm: 23.06697654724121
      vf_explained_var: 0.0
      vf_loss: 13.917594909667969
    num_steps_sampled: 6225000
    num_steps_trained: 6225000
    wait_time_ms: 76.0
  iterations_since_restore: 1245
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10927.325103998184
  time_this_iter_s: 8.734668970108032
  time_total_s: 10927.325103998184
  timestamp: 1594859463
  timesteps_since_restore: 6225000
  timesteps_this_iter: 5000
  timesteps_total: 6225000
  training_iteration: 1245
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10927 s, 1245 iter, 6225000 ts, 375 rew

agent-1: 66.5999999887991
agent-2: 65.59999998879908
agent-3: 61.59999998879908
agent-4: 68.59999998879907
agent-5: 61.59999998879909
Extrinsic Rewards:
9
8
4
11
4
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 4
Max Reward: 11
Gini Coefficient: 0.2111111111111111
20:20 Ratio: 2.75
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 376.4093482675492
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1245
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.26
    dispatch_time_ms: 10.117
    learner:
      cur_lr: 0.0009454149985685945
      grad_gnorm: 40.0
      policy_entropy: 38.7617301940918
      policy_loss: 15.047616958618164
      var_gnorm: 23.06683921813965
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.8940205574035645
    num_steps_sampled: 6230000
    num_steps_trained: 6230000
    wait_time_ms: 75.738
  iterations_since_restore: 1246
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10936.070935249329
  time_this_iter_s: 8.74583125114441
  time_total_s: 10936.070935249329
  timestamp: 1594859472
  timesteps_since_restore: 6230000
  timesteps_this_iter: 5000
  timesteps_total: 6230000
  training_iteration: 1246
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10936 s, 1246 iter, 6230000 ts, 376 rew

agent-1: 48.399999993802204
agent-2: 51.39999999380221
agent-3: 51.39999999380222
agent-4: 61.39999999380222
agent-5: 48.39999999380221
Extrinsic Rewards:
2
5
5
15
2
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.4
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 373.79934828299656
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1246
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.814
    dispatch_time_ms: 7.628
    learner:
      cur_lr: 0.0009450819925405085
      grad_gnorm: 15.73300838470459
      policy_entropy: 34.74208068847656
      policy_loss: -2.8418378829956055
      var_gnorm: 23.067075729370117
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.18040132522583008
    num_steps_sampled: 6235000
    num_steps_trained: 6235000
    wait_time_ms: 74.047
  iterations_since_restore: 1247
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10944.655484199524
  time_this_iter_s: 8.584548950195312
  time_total_s: 10944.655484199524
  timestamp: 1594859481
  timesteps_since_restore: 6235000
  timesteps_this_iter: 5000
  timesteps_total: 6235000
  training_iteration: 1247
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10944 s, 1247 iter, 6235000 ts, 374 rew

agent-1: 102.19999972647096
agent-2: 97.19999972647094
agent-3: 109.19999972647096
agent-4: 104.19999972647099
agent-5: 100.19999972647094
Extrinsic Rewards:
11
6
18
13
9
Sum Reward: 57
Avg Reward: 11.4
Min Reward: 6
Max Reward: 18
Gini Coefficient: 0.19649122807017544
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 371.99934953043027
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1247
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.413
    dispatch_time_ms: 9.288
    learner:
      cur_lr: 0.0009447489865124226
      grad_gnorm: 15.899433135986328
      policy_entropy: 37.415199279785156
      policy_loss: -3.089200258255005
      var_gnorm: 23.067533493041992
      vf_explained_var: 0.0
      vf_loss: 0.19550363719463348
    num_steps_sampled: 6240000
    num_steps_trained: 6240000
    wait_time_ms: 74.705
  iterations_since_restore: 1248
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10953.351825237274
  time_this_iter_s: 8.696341037750244
  time_total_s: 10953.351825237274
  timestamp: 1594859490
  timesteps_since_restore: 6240000
  timesteps_this_iter: 5000
  timesteps_total: 6240000
  training_iteration: 1248
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10953 s, 1248 iter, 6240000 ts, 372 rew

agent-1: 58.199999997203825
agent-2: 62.19999999720381
agent-3: 53.199999997203825
agent-4: 57.199999997203825
agent-5: 57.19999999720381
Extrinsic Rewards:
7
11
2
6
6
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.2375
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 372.17934953059705
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1248
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 6.908
    learner:
      cur_lr: 0.0009444159804843366
      grad_gnorm: 14.703381538391113
      policy_entropy: 52.030517578125
      policy_loss: 3.757629871368408
      var_gnorm: 23.069843292236328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.1654638797044754
    num_steps_sampled: 6245000
    num_steps_trained: 6245000
    wait_time_ms: 76.692
  iterations_since_restore: 1249
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10962.016906738281
  time_this_iter_s: 8.66508150100708
  time_total_s: 10962.016906738281
  timestamp: 1594859498
  timesteps_since_restore: 6245000
  timesteps_this_iter: 5000
  timesteps_total: 6245000
  training_iteration: 1249
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10962 s, 1249 iter, 6245000 ts, 372 rew

agent-1: 35.59999999855533
agent-2: 42.59999999855533
agent-3: 34.599999998555354
agent-4: 36.599999998555326
agent-5: 39.59999999855533
Extrinsic Rewards:
2
9
1
3
6
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.38095238095238093
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 369.7493689042437
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1249
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.512
    dispatch_time_ms: 6.585
    learner:
      cur_lr: 0.0009440829744562507
      grad_gnorm: 13.692666053771973
      policy_entropy: 49.47282791137695
      policy_loss: -3.1212286949157715
      var_gnorm: 23.07424545288086
      vf_explained_var: 0.0
      vf_loss: 0.13381655514240265
    num_steps_sampled: 6250000
    num_steps_trained: 6250000
    wait_time_ms: 81.24
  iterations_since_restore: 1250
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10970.69399857521
  time_this_iter_s: 8.677091836929321
  time_total_s: 10970.69399857521
  timestamp: 1594859507
  timesteps_since_restore: 6250000
  timesteps_this_iter: 5000
  timesteps_total: 6250000
  training_iteration: 1250
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10970 s, 1250 iter, 6250000 ts, 370 rew

agent-1: 34.99999999938421
agent-2: 34.99999999938421
agent-3: 37.99999999938421
agent-4: 35.99999999938421
agent-5: 35.99999999938421
Extrinsic Rewards:
3
3
6
4
4
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 3
Max Reward: 6
Gini Coefficient: 0.14
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-31-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 367.4993689198946
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1250
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.038
    dispatch_time_ms: 8.688
    learner:
      cur_lr: 0.0009437500266358256
      grad_gnorm: 40.0
      policy_entropy: 52.63759994506836
      policy_loss: 74.5298843383789
      var_gnorm: 23.07380485534668
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 69.08789825439453
    num_steps_sampled: 6255000
    num_steps_trained: 6255000
    wait_time_ms: 74.45
  iterations_since_restore: 1251
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10979.293159246445
  time_this_iter_s: 8.59916067123413
  time_total_s: 10979.293159246445
  timestamp: 1594859516
  timesteps_since_restore: 6255000
  timesteps_this_iter: 5000
  timesteps_total: 6255000
  training_iteration: 1251
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10979 s, 1251 iter, 6255000 ts, 367 rew

agent-1: 34.399999998394456
agent-2: 31.39999999839442
agent-3: 37.399999998394456
agent-4: 31.39999999839442
agent-5: 36.399999998394456
Extrinsic Rewards:
4
1
7
1
6
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.35789473684210527
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 366.05936892033554
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1251
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 6.858
    learner:
      cur_lr: 0.0009434170206077397
      grad_gnorm: 16.789438247680664
      policy_entropy: 46.241634368896484
      policy_loss: -4.151587963104248
      var_gnorm: 23.069459915161133
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.19984786212444305
    num_steps_sampled: 6260000
    num_steps_trained: 6260000
    wait_time_ms: 77.881
  iterations_since_restore: 1252
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10987.947637557983
  time_this_iter_s: 8.654478311538696
  time_total_s: 10987.947637557983
  timestamp: 1594859524
  timesteps_since_restore: 6260000
  timesteps_this_iter: 5000
  timesteps_total: 6260000
  training_iteration: 1252
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10987 s, 1252 iter, 6260000 ts, 366 rew

agent-1: 44.19999998940742
agent-2: 48.19999998940742
agent-3: 55.19999998940741
agent-4: 46.19999998940741
agent-5: 49.199999989407424
Extrinsic Rewards:
1
5
12
3
6
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.37037037037037035
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 364.34936898635294
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1252
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 6.012
    learner:
      cur_lr: 0.0009430840145796537
      grad_gnorm: 11.324568748474121
      policy_entropy: 49.86391830444336
      policy_loss: -2.7578160762786865
      var_gnorm: 23.071746826171875
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.09804490953683853
    num_steps_sampled: 6265000
    num_steps_trained: 6265000
    wait_time_ms: 79.896
  iterations_since_restore: 1253
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 10996.566123962402
  time_this_iter_s: 8.618486404418945
  time_total_s: 10996.566123962402
  timestamp: 1594859533
  timesteps_since_restore: 6265000
  timesteps_this_iter: 5000
  timesteps_total: 6265000
  training_iteration: 1253
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 10996 s, 1253 iter, 6265000 ts, 364 rew

agent-1: 58.19999999838057
agent-2: 46.199999998380584
agent-3: 46.199999998380584
agent-4: 47.19999999838057
agent-5: 45.199999998380584
Extrinsic Rewards:
15
3
3
4
2
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.4
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 364.25936898631574
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1253
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.809
    dispatch_time_ms: 7.698
    learner:
      cur_lr: 0.0009427510085515678
      grad_gnorm: 14.27761173248291
      policy_entropy: 54.044349670410156
      policy_loss: -4.427300453186035
      var_gnorm: 23.071998596191406
      vf_explained_var: 0.0
      vf_loss: 0.15174700319766998
    num_steps_sampled: 6270000
    num_steps_trained: 6270000
    wait_time_ms: 76.403
  iterations_since_restore: 1254
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11005.555946826935
  time_this_iter_s: 8.98982286453247
  time_total_s: 11005.555946826935
  timestamp: 1594859542
  timesteps_since_restore: 6270000
  timesteps_this_iter: 5000
  timesteps_total: 6270000
  training_iteration: 1254
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11005 s, 1254 iter, 6270000 ts, 364 rew

agent-1: 54.79999999715333
agent-2: 44.79999999715333
agent-3: 47.799999997153336
agent-4: 51.799999997153336
agent-5: 52.79999999715333
Extrinsic Rewards:
10
0
3
7
8
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.35714285714285715
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 364.16936898637016
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1254
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.931
    dispatch_time_ms: 7.866
    learner:
      cur_lr: 0.0009424180025234818
      grad_gnorm: 40.0
      policy_entropy: 52.061073303222656
      policy_loss: 66.90480041503906
      var_gnorm: 23.071096420288086
      vf_explained_var: 0.0
      vf_loss: 56.41465377807617
    num_steps_sampled: 6275000
    num_steps_trained: 6275000
    wait_time_ms: 74.556
  iterations_since_restore: 1255
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11014.193264961243
  time_this_iter_s: 8.637318134307861
  time_total_s: 11014.193264961243
  timestamp: 1594859551
  timesteps_since_restore: 6275000
  timesteps_this_iter: 5000
  timesteps_total: 6275000
  training_iteration: 1255
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11014 s, 1255 iter, 6275000 ts, 364 rew

agent-1: 42.79999999766703
agent-2: 46.79999999766703
agent-3: 36.79999999766705
agent-4: 41.79999999766703
agent-5: 38.799999997667044
Extrinsic Rewards:
6
10
0
5
2
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.41739130434782606
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 362.2793689927687
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1255
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.412
    dispatch_time_ms: 5.792
    learner:
      cur_lr: 0.0009420849964953959
      grad_gnorm: 30.839271545410156
      policy_entropy: 47.53449249267578
      policy_loss: -6.828792095184326
      var_gnorm: 23.070858001708984
      vf_explained_var: 0.0
      vf_loss: 0.6870286464691162
    num_steps_sampled: 6280000
    num_steps_trained: 6280000
    wait_time_ms: 82.061
  iterations_since_restore: 1256
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11022.8444211483
  time_this_iter_s: 8.651156187057495
  time_total_s: 11022.8444211483
  timestamp: 1594859559
  timesteps_since_restore: 6280000
  timesteps_this_iter: 5000
  timesteps_total: 6280000
  training_iteration: 1256
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11022 s, 1256 iter, 6280000 ts, 362 rew

agent-1: 57.79999999319196
agent-2: 60.79999999319196
agent-3: 52.79999999319195
agent-4: 66.79999999319183
agent-5: 58.79999999319196
Extrinsic Rewards:
5
8
0
14
6
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.37575757575757573
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 360.9293689942456
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1256
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.618
    dispatch_time_ms: 8.352
    learner:
      cur_lr: 0.00094175199046731
      grad_gnorm: 40.0
      policy_entropy: 39.024044036865234
      policy_loss: 83.69243621826172
      var_gnorm: 23.07133674621582
      vf_explained_var: 0.0
      vf_loss: 134.32742309570312
    num_steps_sampled: 6285000
    num_steps_trained: 6285000
    wait_time_ms: 76.792
  iterations_since_restore: 1257
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11031.427987098694
  time_this_iter_s: 8.583565950393677
  time_total_s: 11031.427987098694
  timestamp: 1594859568
  timesteps_since_restore: 6285000
  timesteps_this_iter: 5000
  timesteps_total: 6285000
  training_iteration: 1257
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11031 s, 1257 iter, 6285000 ts, 361 rew

agent-1: 126.79999890804388
agent-2: 118.7999989080439
agent-3: 130.79999890804353
agent-4: 115.79999890804388
agent-5: 119.7999989080439
Extrinsic Rewards:
18
10
22
7
11
Sum Reward: 68
Avg Reward: 13.6
Min Reward: 7
Max Reward: 22
Gini Coefficient: 0.2235294117647059
20:20 Ratio: 3.142857142857143
Max-min Ratio: 3.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-32-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 364.97936893972144
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1257
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.485
    dispatch_time_ms: 6.295
    learner:
      cur_lr: 0.000941418984439224
      grad_gnorm: 18.152212142944336
      policy_entropy: 32.604736328125
      policy_loss: -2.6197357177734375
      var_gnorm: 23.07036018371582
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.24020834267139435
    num_steps_sampled: 6290000
    num_steps_trained: 6290000
    wait_time_ms: 81.869
  iterations_since_restore: 1258
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11040.139422416687
  time_this_iter_s: 8.711435317993164
  time_total_s: 11040.139422416687
  timestamp: 1594859577
  timesteps_since_restore: 6290000
  timesteps_this_iter: 5000
  timesteps_total: 6290000
  training_iteration: 1258
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11040 s, 1258 iter, 6290000 ts, 365 rew

agent-1: 56.39999998690222
agent-2: 60.39999998690222
agent-3: 64.3999999869023
agent-4: 63.39999998690224
agent-5: 61.39999998690222
Extrinsic Rewards:
2
6
10
9
7
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.2235294117647059
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 363.98936895187234
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1258
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.252
    dispatch_time_ms: 7.851
    learner:
      cur_lr: 0.0009410859784111381
      grad_gnorm: 40.0
      policy_entropy: 37.41093063354492
      policy_loss: 36.9755744934082
      var_gnorm: 23.072418212890625
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 24.030654907226562
    num_steps_sampled: 6295000
    num_steps_trained: 6295000
    wait_time_ms: 78.207
  iterations_since_restore: 1259
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11048.829798460007
  time_this_iter_s: 8.690376043319702
  time_total_s: 11048.829798460007
  timestamp: 1594859585
  timesteps_since_restore: 6295000
  timesteps_this_iter: 5000
  timesteps_total: 6295000
  training_iteration: 1259
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11048 s, 1259 iter, 6295000 ts, 364 rew

agent-1: 32.39999999786836
agent-2: 36.399999997868356
agent-3: 31.39999999786842
agent-4: 31.39999999786842
agent-5: 39.399999997868356
Extrinsic Rewards:
2
6
1
1
9
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.4421052631578947
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 362.0093689534377
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1259
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.413
    dispatch_time_ms: 5.961
    learner:
      cur_lr: 0.0009407529723830521
      grad_gnorm: 28.571481704711914
      policy_entropy: 37.027767181396484
      policy_loss: -5.235280513763428
      var_gnorm: 23.074871063232422
      vf_explained_var: 0.0
      vf_loss: 0.6269845366477966
    num_steps_sampled: 6300000
    num_steps_trained: 6300000
    wait_time_ms: 81.45
  iterations_since_restore: 1260
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11057.488199234009
  time_this_iter_s: 8.658400774002075
  time_total_s: 11057.488199234009
  timestamp: 1594859594
  timesteps_since_restore: 6300000
  timesteps_this_iter: 5000
  timesteps_total: 6300000
  training_iteration: 1260
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11057 s, 1260 iter, 6300000 ts, 362 rew

agent-1: 47.39999999641586
agent-2: 56.399999996415836
agent-3: 51.39999999641584
agent-4: 52.399999996415836
agent-5: 53.39999999641584
Extrinsic Rewards:
1
10
5
6
7
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.27586206896551724
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 362.00936895352135
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1260
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.759
    dispatch_time_ms: 7.97
    learner:
      cur_lr: 0.0009404200245626271
      grad_gnorm: 15.353777885437012
      policy_entropy: 22.850629806518555
      policy_loss: -1.21487295627594
      var_gnorm: 23.07200813293457
      vf_explained_var: 0.0
      vf_loss: 0.1790200173854828
    num_steps_sampled: 6305000
    num_steps_trained: 6305000
    wait_time_ms: 76.477
  iterations_since_restore: 1261
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11066.099479436874
  time_this_iter_s: 8.6112802028656
  time_total_s: 11066.099479436874
  timestamp: 1594859603
  timesteps_since_restore: 6305000
  timesteps_this_iter: 5000
  timesteps_total: 6305000
  training_iteration: 1261
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11066 s, 1261 iter, 6305000 ts, 362 rew

agent-1: 104.19999811897922
agent-2: 124.1999981189792
agent-3: 110.1999981189792
agent-4: 106.19999811897922
agent-5: 113.19999811897922
Extrinsic Rewards:
5
25
11
7
14
Sum Reward: 62
Avg Reward: 12.4
Min Reward: 5
Max Reward: 25
Gini Coefficient: 0.3032258064516129
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 363.26936886159194
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1261
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.294
    dispatch_time_ms: 9.622
    learner:
      cur_lr: 0.0009400870185345411
      grad_gnorm: 40.0
      policy_entropy: 14.789043426513672
      policy_loss: -5.0948052406311035
      var_gnorm: 23.08315086364746
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.2717130184173584
    num_steps_sampled: 6310000
    num_steps_trained: 6310000
    wait_time_ms: 73.835
  iterations_since_restore: 1262
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11074.710848093033
  time_this_iter_s: 8.611368656158447
  time_total_s: 11074.710848093033
  timestamp: 1594859611
  timesteps_since_restore: 6310000
  timesteps_this_iter: 5000
  timesteps_total: 6310000
  training_iteration: 1262
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11074 s, 1262 iter, 6310000 ts, 363 rew

agent-1: 123.79997792581179
agent-2: 123.79997792581173
agent-3: 117.79997792581179
agent-4: 115.79997792581175
agent-5: 130.79997792581165
Extrinsic Rewards:
15
15
9
7
22
Sum Reward: 68
Avg Reward: 13.6
Min Reward: 7
Max Reward: 22
Gini Coefficient: 0.21176470588235294
20:20 Ratio: 3.142857142857143
Max-min Ratio: 3.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 366.0593677587053
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1262
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.593
    dispatch_time_ms: 7.365
    learner:
      cur_lr: 0.0009397540125064552
      grad_gnorm: 14.716024398803711
      policy_entropy: 22.506441116333008
      policy_loss: -1.4872455596923828
      var_gnorm: 23.071199417114258
      vf_explained_var: 0.0
      vf_loss: 0.1665177345275879
    num_steps_sampled: 6315000
    num_steps_trained: 6315000
    wait_time_ms: 79.654
  iterations_since_restore: 1263
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11083.483006954193
  time_this_iter_s: 8.772158861160278
  time_total_s: 11083.483006954193
  timestamp: 1594859620
  timesteps_since_restore: 6315000
  timesteps_this_iter: 5000
  timesteps_total: 6315000
  training_iteration: 1263
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11083 s, 1263 iter, 6315000 ts, 366 rew

agent-1: 80.99999996896372
agent-2: 76.99999996896372
agent-3: 88.99999996896376
agent-4: 80.99999996896372
agent-5: 76.99999996896372
Extrinsic Rewards:
9
5
17
9
5
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 5
Max Reward: 17
Gini Coefficient: 0.24888888888888888
20:20 Ratio: 3.4
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 366.2393677589505
  episode_reward_min: 134.99999999815032
  episodes_this_iter: 1
  episodes_total: 1263
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.195
    dispatch_time_ms: 8.554
    learner:
      cur_lr: 0.0009394210064783692
      grad_gnorm: 10.036787033081055
      policy_entropy: 25.802051544189453
      policy_loss: -1.6264593601226807
      var_gnorm: 23.072118759155273
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.07484978437423706
    num_steps_sampled: 6320000
    num_steps_trained: 6320000
    wait_time_ms: 74.325
  iterations_since_restore: 1264
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11092.126922607422
  time_this_iter_s: 8.64391565322876
  time_total_s: 11092.126922607422
  timestamp: 1594859629
  timesteps_since_restore: 6320000
  timesteps_this_iter: 5000
  timesteps_total: 6320000
  training_iteration: 1264
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11092 s, 1264 iter, 6320000 ts, 366 rew

agent-1: 37.3999999993954
agent-2: 37.399999999395405
agent-3: 30.39999999939548
agent-4: 33.399999999395426
agent-5: 32.3999999993954
Extrinsic Rewards:
7
7
0
3
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-33-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 366.5993677589388
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1264
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.953
    dispatch_time_ms: 8.271
    learner:
      cur_lr: 0.0009390880004502833
      grad_gnorm: 40.0
      policy_entropy: 24.383630752563477
      policy_loss: 20.645465850830078
      var_gnorm: 23.07106590270996
      vf_explained_var: 0.0
      vf_loss: 35.44258499145508
    num_steps_sampled: 6325000
    num_steps_trained: 6325000
    wait_time_ms: 74.32
  iterations_since_restore: 1265
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11100.795193910599
  time_this_iter_s: 8.66827130317688
  time_total_s: 11100.795193910599
  timestamp: 1594859638
  timesteps_since_restore: 6325000
  timesteps_this_iter: 5000
  timesteps_total: 6325000
  training_iteration: 1265
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11100 s, 1265 iter, 6325000 ts, 367 rew

agent-1: 81.79999997518988
agent-2: 75.79999997518988
agent-3: 73.79999997518993
agent-4: 77.7999999751899
agent-5: 77.7999999751899
Extrinsic Rewards:
13
7
5
9
9
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 5
Max Reward: 13
Gini Coefficient: 0.16744186046511628
20:20 Ratio: 2.6
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 357.8739767257942
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1265
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 9.936
    learner:
      cur_lr: 0.0009387549944221973
      grad_gnorm: 40.000003814697266
      policy_entropy: 37.54279327392578
      policy_loss: -10.127262115478516
      var_gnorm: 23.077804565429688
      vf_explained_var: 0.0
      vf_loss: 1.7703174352645874
    num_steps_sampled: 6330000
    num_steps_trained: 6330000
    wait_time_ms: 76.067
  iterations_since_restore: 1266
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11109.419848442078
  time_this_iter_s: 8.624654531478882
  time_total_s: 11109.419848442078
  timestamp: 1594859646
  timesteps_since_restore: 6330000
  timesteps_this_iter: 5000
  timesteps_total: 6330000
  training_iteration: 1266
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11109 s, 1266 iter, 6330000 ts, 358 rew

agent-1: 109.1999983083907
agent-2: 110.19999830839068
agent-3: 109.1999983083907
agent-4: 121.19999830839065
agent-5: 108.19999830839068
Extrinsic Rewards:
10
11
10
22
9
Sum Reward: 62
Avg Reward: 12.4
Min Reward: 9
Max Reward: 22
Gini Coefficient: 0.17419354838709677
20:20 Ratio: 2.4444444444444446
Max-min Ratio: 2.4444444444444446
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 360.5739766415473
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1266
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.892
    dispatch_time_ms: 7.087
    learner:
      cur_lr: 0.0009384219883941114
      grad_gnorm: 11.465543746948242
      policy_entropy: 31.677879333496094
      policy_loss: -1.2469100952148438
      var_gnorm: 23.073291778564453
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.09583025425672531
    num_steps_sampled: 6335000
    num_steps_trained: 6335000
    wait_time_ms: 74.317
  iterations_since_restore: 1267
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11117.955948591232
  time_this_iter_s: 8.536100149154663
  time_total_s: 11117.955948591232
  timestamp: 1594859655
  timesteps_since_restore: 6335000
  timesteps_this_iter: 5000
  timesteps_total: 6335000
  training_iteration: 1267
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11117 s, 1267 iter, 6335000 ts, 361 rew

agent-1: 74.99999997478156
agent-2: 67.99999997478157
agent-3: 68.99999997478156
agent-4: 78.99999997478153
agent-5: 68.99999997478155
Extrinsic Rewards:
11
4
5
15
5
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 4
Max Reward: 15
Gini Coefficient: 0.28
20:20 Ratio: 3.75
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 355.628201229198
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1267
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 6.058
    learner:
      cur_lr: 0.0009380889823660254
      grad_gnorm: 27.688642501831055
      policy_entropy: 19.47180938720703
      policy_loss: -3.8453116416931152
      var_gnorm: 23.07624053955078
      vf_explained_var: 0.0
      vf_loss: 0.5837711691856384
    num_steps_sampled: 6340000
    num_steps_trained: 6340000
    wait_time_ms: 78.641
  iterations_since_restore: 1268
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11126.49283671379
  time_this_iter_s: 8.536888122558594
  time_total_s: 11126.49283671379
  timestamp: 1594859663
  timesteps_since_restore: 6340000
  timesteps_this_iter: 5000
  timesteps_total: 6340000
  training_iteration: 1268
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11126 s, 1268 iter, 6340000 ts, 356 rew

agent-1: 66.59999974319474
agent-2: 75.59999974319474
agent-3: 71.59999974319473
agent-4: 70.59999974319472
agent-5: 84.59999974319474
Extrinsic Rewards:
1
10
6
5
19
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 1
Max Reward: 19
Gini Coefficient: 0.4
20:20 Ratio: 19.0
Max-min Ratio: 19.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 354.9082012274832
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1268
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.85
    dispatch_time_ms: 9.42
    learner:
      cur_lr: 0.0009377559763379395
      grad_gnorm: 8.012370109558105
      policy_entropy: 16.965742111206055
      policy_loss: -0.48229992389678955
      var_gnorm: 23.074663162231445
      vf_explained_var: 0.0
      vf_loss: 0.049467653036117554
    num_steps_sampled: 6345000
    num_steps_trained: 6345000
    wait_time_ms: 70.469
  iterations_since_restore: 1269
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11134.840116500854
  time_this_iter_s: 8.347279787063599
  time_total_s: 11134.840116500854
  timestamp: 1594859672
  timesteps_since_restore: 6345000
  timesteps_this_iter: 5000
  timesteps_total: 6345000
  training_iteration: 1269
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11134 s, 1269 iter, 6345000 ts, 355 rew

agent-1: 46.59999999705871
agent-2: 52.59999999705871
agent-3: 43.59999999705871
agent-4: 42.599999997058724
agent-5: 48.59999999705871
Extrinsic Rewards:
5
11
2
1
7
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.38461538461538464
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 355.8082012273606
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1269
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.109
    dispatch_time_ms: 9.413
    learner:
      cur_lr: 0.0009374230285175145
      grad_gnorm: 40.0
      policy_entropy: 37.30528259277344
      policy_loss: 56.006412506103516
      var_gnorm: 23.082073211669922
      vf_explained_var: 0.0
      vf_loss: 61.941070556640625
    num_steps_sampled: 6350000
    num_steps_trained: 6350000
    wait_time_ms: 72.476
  iterations_since_restore: 1270
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11143.21632361412
  time_this_iter_s: 8.376207113265991
  time_total_s: 11143.21632361412
  timestamp: 1594859680
  timesteps_since_restore: 6350000
  timesteps_this_iter: 5000
  timesteps_total: 6350000
  training_iteration: 1270
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11143 s, 1270 iter, 6350000 ts, 356 rew

agent-1: 78.3999870094576
agent-2: 77.3999870094576
agent-3: 87.39998700945765
agent-4: 71.39998700945758
agent-5: 81.39998700945765
Extrinsic Rewards:
8
7
17
1
11
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 1
Max Reward: 17
Gini Coefficient: 0.32727272727272727
20:20 Ratio: 17.0
Max-min Ratio: 17.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 357.1582005781295
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1270
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.879
    dispatch_time_ms: 9.235
    learner:
      cur_lr: 0.0009370900224894285
      grad_gnorm: 40.000003814697266
      policy_entropy: 38.121036529541016
      policy_loss: 36.74937438964844
      var_gnorm: 23.076030731201172
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 26.637630462646484
    num_steps_sampled: 6355000
    num_steps_trained: 6355000
    wait_time_ms: 72.644
  iterations_since_restore: 1271
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11151.750660896301
  time_this_iter_s: 8.534337282180786
  time_total_s: 11151.750660896301
  timestamp: 1594859689
  timesteps_since_restore: 6355000
  timesteps_this_iter: 5000
  timesteps_total: 6355000
  training_iteration: 1271
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11151 s, 1271 iter, 6355000 ts, 357 rew

agent-1: 82.9999991508406
agent-2: 80.99999915084055
agent-3: 80.99999915084058
agent-4: 83.99999915084058
agent-5: 75.99999915084058
Extrinsic Rewards:
11
9
9
12
4
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.16
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-34-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 357.87820054953437
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1271
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 7.214
    learner:
      cur_lr: 0.0009367570164613426
      grad_gnorm: 4.037732124328613
      policy_entropy: 16.7388973236084
      policy_loss: 0.1889169067144394
      var_gnorm: 23.08223533630371
      vf_explained_var: 0.0
      vf_loss: 0.017713872715830803
    num_steps_sampled: 6360000
    num_steps_trained: 6360000
    wait_time_ms: 79.293
  iterations_since_restore: 1272
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11160.305919885635
  time_this_iter_s: 8.555258989334106
  time_total_s: 11160.305919885635
  timestamp: 1594859697
  timesteps_since_restore: 6360000
  timesteps_this_iter: 5000
  timesteps_total: 6360000
  training_iteration: 1272
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11160 s, 1272 iter, 6360000 ts, 358 rew

agent-1: 67.9999988305333
agent-2: 59.99999883053333
agent-3: 59.99999883053333
agent-4: 63.99999883053333
agent-5: 62.99999883053333
Extrinsic Rewards:
12
4
4
8
7
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.22857142857142856
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 356.4382007454882
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1272
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.101
    dispatch_time_ms: 7.894
    learner:
      cur_lr: 0.0009364240104332566
      grad_gnorm: 40.0
      policy_entropy: 36.71708679199219
      policy_loss: 66.58328247070312
      var_gnorm: 23.076398849487305
      vf_explained_var: 0.0
      vf_loss: 124.28668975830078
    num_steps_sampled: 6365000
    num_steps_trained: 6365000
    wait_time_ms: 73.561
  iterations_since_restore: 1273
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11168.702594041824
  time_this_iter_s: 8.396674156188965
  time_total_s: 11168.702594041824
  timestamp: 1594859706
  timesteps_since_restore: 6365000
  timesteps_this_iter: 5000
  timesteps_total: 6365000
  training_iteration: 1273
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11168 s, 1273 iter, 6365000 ts, 356 rew

agent-1: 136.5071649835494
agent-2: 155.50716498354927
agent-3: 128.50716498354907
agent-4: 134.50716498354927
agent-5: 145.5071649835493
Extrinsic Rewards:
12
31
4
10
21
Sum Reward: 78
Avg Reward: 15.6
Min Reward: 4
Max Reward: 31
Gini Coefficient: 0.3333333333333333
20:20 Ratio: 7.75
Max-min Ratio: 7.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 361.37355899471686
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1273
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.966
    dispatch_time_ms: 8.552
    learner:
      cur_lr: 0.0009360910044051707
      grad_gnorm: 40.0
      policy_entropy: 26.069011688232422
      policy_loss: -3.4305214881896973
      var_gnorm: 23.076807022094727
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.3156228065490723
    num_steps_sampled: 6370000
    num_steps_trained: 6370000
    wait_time_ms: 75.575
  iterations_since_restore: 1274
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11177.326760292053
  time_this_iter_s: 8.624166250228882
  time_total_s: 11177.326760292053
  timestamp: 1594859714
  timesteps_since_restore: 6370000
  timesteps_this_iter: 5000
  timesteps_total: 6370000
  training_iteration: 1274
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11177 s, 1274 iter, 6370000 ts, 361 rew

agent-1: 44.79999998119369
agent-2: 41.799999981193686
agent-3: 37.799999981193714
agent-4: 38.799999981193714
agent-5: 43.79999998119369
Extrinsic Rewards:
8
5
1
2
7
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.33043478260869563
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 361.013558994029
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1274
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.6
    dispatch_time_ms: 9.261
    learner:
      cur_lr: 0.0009357579983770847
      grad_gnorm: 40.0
      policy_entropy: 19.2443904876709
      policy_loss: 6.556694507598877
      var_gnorm: 23.070615768432617
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 6.7351508140563965
    num_steps_sampled: 6375000
    num_steps_trained: 6375000
    wait_time_ms: 76.555
  iterations_since_restore: 1275
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11185.954855203629
  time_this_iter_s: 8.628094911575317
  time_total_s: 11185.954855203629
  timestamp: 1594859723
  timesteps_since_restore: 6375000
  timesteps_this_iter: 5000
  timesteps_total: 6375000
  training_iteration: 1275
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11185 s, 1275 iter, 6375000 ts, 361 rew

agent-1: 58.799999989922135
agent-2: 59.799999989922135
agent-3: 64.79999998992227
agent-4: 59.79999998992215
agent-5: 53.79999998992215
Extrinsic Rewards:
6
7
12
7
1
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.2787878787878788
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 361.10355899397206
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1275
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.565
    dispatch_time_ms: 6.998
    learner:
      cur_lr: 0.0009354249923489988
      grad_gnorm: 15.895512580871582
      policy_entropy: 15.445655822753906
      policy_loss: -0.5673900246620178
      var_gnorm: 23.068784713745117
      vf_explained_var: 0.0
      vf_loss: 0.1882006973028183
    num_steps_sampled: 6380000
    num_steps_trained: 6380000
    wait_time_ms: 74.753
  iterations_since_restore: 1276
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11194.468008518219
  time_this_iter_s: 8.513153314590454
  time_total_s: 11194.468008518219
  timestamp: 1594859732
  timesteps_since_restore: 6380000
  timesteps_this_iter: 5000
  timesteps_total: 6380000
  training_iteration: 1276
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11194 s, 1276 iter, 6380000 ts, 361 rew

agent-1: 43.79999999760305
agent-2: 37.799999997603045
agent-3: 40.79999999760304
agent-4: 36.79999999760305
agent-5: 47.79999999760304
Extrinsic Rewards:
7
1
4
0
11
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.48695652173913045
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 361.73355899387934
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1276
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.781
    dispatch_time_ms: 9.122
    learner:
      cur_lr: 0.0009350919863209128
      grad_gnorm: 40.0
      policy_entropy: 22.973533630371094
      policy_loss: 6.998525142669678
      var_gnorm: 23.069231033325195
      vf_explained_var: 0.0
      vf_loss: 3.716278553009033
    num_steps_sampled: 6385000
    num_steps_trained: 6385000
    wait_time_ms: 73.73
  iterations_since_restore: 1277
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11202.991575717926
  time_this_iter_s: 8.523567199707031
  time_total_s: 11202.991575717926
  timestamp: 1594859740
  timesteps_since_restore: 6385000
  timesteps_this_iter: 5000
  timesteps_total: 6385000
  training_iteration: 1277
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11202 s, 1277 iter, 6385000 ts, 362 rew

agent-1: 46.39999999760461
agent-2: 42.39999999760462
agent-3: 47.39999999760461
agent-4: 39.399999997604624
agent-5: 40.399999997604624
Extrinsic Rewards:
8
4
9
1
2
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.36666666666666664
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 361.1035589941337
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1277
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.928
    dispatch_time_ms: 9.288
    learner:
      cur_lr: 0.0009347589802928269
      grad_gnorm: 15.85234546661377
      policy_entropy: 18.400745391845703
      policy_loss: -1.6906285285949707
      var_gnorm: 23.06930923461914
      vf_explained_var: 0.0
      vf_loss: 0.1944272518157959
    num_steps_sampled: 6390000
    num_steps_trained: 6390000
    wait_time_ms: 74.388
  iterations_since_restore: 1278
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11211.501349687576
  time_this_iter_s: 8.509773969650269
  time_total_s: 11211.501349687576
  timestamp: 1594859749
  timesteps_since_restore: 6390000
  timesteps_this_iter: 5000
  timesteps_total: 6390000
  training_iteration: 1278
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11211 s, 1278 iter, 6390000 ts, 361 rew

agent-1: 50.99999999803205
agent-2: 53.99999999803206
agent-3: 49.999999998032045
agent-4: 59.99999999803207
agent-5: 54.99999999803207
Extrinsic Rewards:
3
6
2
12
7
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.32
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-35-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 362.18355899407294
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1278
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.471
    dispatch_time_ms: 7.903
    learner:
      cur_lr: 0.0009344259742647409
      grad_gnorm: 10.91492748260498
      policy_entropy: 20.654150009155273
      policy_loss: -0.8777025938034058
      var_gnorm: 23.071414947509766
      vf_explained_var: 0.0
      vf_loss: 0.09223277866840363
    num_steps_sampled: 6395000
    num_steps_trained: 6395000
    wait_time_ms: 73.665
  iterations_since_restore: 1279
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11220.030914068222
  time_this_iter_s: 8.529564380645752
  time_total_s: 11220.030914068222
  timestamp: 1594859757
  timesteps_since_restore: 6395000
  timesteps_this_iter: 5000
  timesteps_total: 6395000
  training_iteration: 1279
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11220 s, 1279 iter, 6395000 ts, 362 rew

agent-1: 40.79999999803395
agent-2: 42.79999999803395
agent-3: 40.799999998033954
agent-4: 39.79999999803394
agent-5: 42.79999999803395
Extrinsic Rewards:
4
6
4
3
6
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 3
Max Reward: 6
Gini Coefficient: 0.1391304347826087
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 362.183558994104
  episode_reward_min: 134.9999999982209
  episodes_this_iter: 1
  episodes_total: 1279
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 8.246
    learner:
      cur_lr: 0.0009340930264443159
      grad_gnorm: 22.905485153198242
      policy_entropy: 14.119939804077148
      policy_loss: -0.5282469987869263
      var_gnorm: 23.07551383972168
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.3941236436367035
    num_steps_sampled: 6400000
    num_steps_trained: 6400000
    wait_time_ms: 74.57
  iterations_since_restore: 1280
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11228.546478748322
  time_this_iter_s: 8.515564680099487
  time_total_s: 11228.546478748322
  timestamp: 1594859766
  timesteps_since_restore: 6400000
  timesteps_this_iter: 5000
  timesteps_total: 6400000
  training_iteration: 1280
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11228 s, 1280 iter, 6400000 ts, 362 rew

agent-1: 27.999999999360732
agent-2: 23.999999999360735
agent-3: 29.999999999360735
agent-4: 26.999999999360732
agent-5: 25.999999999360735
Extrinsic Rewards:
4
0
6
3
2
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.37333333333333335
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 358.67355912645894
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1280
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.995
    dispatch_time_ms: 8.106
    learner:
      cur_lr: 0.00093376002041623
      grad_gnorm: 39.99999237060547
      policy_entropy: 24.27227783203125
      policy_loss: 33.533199310302734
      var_gnorm: 23.071517944335938
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 53.3272590637207
    num_steps_sampled: 6405000
    num_steps_trained: 6405000
    wait_time_ms: 73.854
  iterations_since_restore: 1281
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11237.04481267929
  time_this_iter_s: 8.498333930969238
  time_total_s: 11237.04481267929
  timestamp: 1594859774
  timesteps_since_restore: 6405000
  timesteps_this_iter: 5000
  timesteps_total: 6405000
  training_iteration: 1281
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11237 s, 1281 iter, 6405000 ts, 359 rew

agent-1: 58.79999997652938
agent-2: 65.79999997652946
agent-3: 56.799999976529385
agent-4: 60.799999976529385
agent-5: 54.79999997652938
Extrinsic Rewards:
6
13
4
8
2
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.3151515151515151
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 358.4935591562897
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1281
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.15
    dispatch_time_ms: 7.167
    learner:
      cur_lr: 0.000933427014388144
      grad_gnorm: 13.734936714172363
      policy_entropy: 24.101181030273438
      policy_loss: -1.7218472957611084
      var_gnorm: 23.067201614379883
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.14399826526641846
    num_steps_sampled: 6410000
    num_steps_trained: 6410000
    wait_time_ms: 76.539
  iterations_since_restore: 1282
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11254.22102022171
  time_this_iter_s: 17.176207542419434
  time_total_s: 11254.22102022171
  timestamp: 1594859792
  timesteps_since_restore: 6410000
  timesteps_this_iter: 5000
  timesteps_total: 6410000
  training_iteration: 1282
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11254 s, 1282 iter, 6410000 ts, 358 rew

agent-1: 82.9999999732483
agent-2: 78.99999997324828
agent-3: 83.99999997324831
agent-4: 82.99999997324831
agent-5: 75.99999997324828
Extrinsic Rewards:
11
7
12
11
4
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.17777777777777778
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 360.0235591550372
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1282
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.607
    dispatch_time_ms: 7.939
    learner:
      cur_lr: 0.0009330940083600581
      grad_gnorm: 9.998477935791016
      policy_entropy: 23.77859115600586
      policy_loss: -0.7991101145744324
      var_gnorm: 23.065641403198242
      vf_explained_var: 0.0
      vf_loss: 0.07449717819690704
    num_steps_sampled: 6415000
    num_steps_trained: 6415000
    wait_time_ms: 74.112
  iterations_since_restore: 1283
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11262.696361780167
  time_this_iter_s: 8.475341558456421
  time_total_s: 11262.696361780167
  timestamp: 1594859800
  timesteps_since_restore: 6415000
  timesteps_this_iter: 5000
  timesteps_total: 6415000
  training_iteration: 1283
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11262 s, 1283 iter, 6415000 ts, 360 rew

agent-1: 32.99999999919496
agent-2: 33.99999999919497
agent-3: 34.99999999919497
agent-4: 36.99999999919498
agent-5: 40.99999999919499
Extrinsic Rewards:
1
2
3
5
9
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.38
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 358.9435591554773
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1283
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.549
    dispatch_time_ms: 7.636
    learner:
      cur_lr: 0.0009327610023319721
      grad_gnorm: 12.902460098266602
      policy_entropy: 29.55760955810547
      policy_loss: -1.8032046556472778
      var_gnorm: 23.06446075439453
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.12510423362255096
    num_steps_sampled: 6420000
    num_steps_trained: 6420000
    wait_time_ms: 73.904
  iterations_since_restore: 1284
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11271.275073051453
  time_this_iter_s: 8.57871127128601
  time_total_s: 11271.275073051453
  timestamp: 1594859809
  timesteps_since_restore: 6420000
  timesteps_this_iter: 5000
  timesteps_total: 6420000
  training_iteration: 1284
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11271 s, 1284 iter, 6420000 ts, 359 rew

agent-1: 25.999999999675946
agent-2: 28.99999999967595
agent-3: 25.999999999675943
agent-4: 23.999999999675943
agent-5: 29.99999999967595
Extrinsic Rewards:
2
5
2
0
6
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-36-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 358.94355915547897
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1284
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.242
    dispatch_time_ms: 7.45
    learner:
      cur_lr: 0.0009324279963038862
      grad_gnorm: 10.811044692993164
      policy_entropy: 35.78609848022461
      policy_loss: 2.30937123298645
      var_gnorm: 23.06501007080078
      vf_explained_var: 0.0
      vf_loss: 0.09276971966028214
    num_steps_sampled: 6425000
    num_steps_trained: 6425000
    wait_time_ms: 75.911
  iterations_since_restore: 1285
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11279.913087368011
  time_this_iter_s: 8.638014316558838
  time_total_s: 11279.913087368011
  timestamp: 1594859817
  timesteps_since_restore: 6425000
  timesteps_this_iter: 5000
  timesteps_total: 6425000
  training_iteration: 1285
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11279 s, 1285 iter, 6425000 ts, 359 rew

agent-1: 53.79999999822679
agent-2: 46.799999998226774
agent-3: 48.799999998226774
agent-4: 45.799999998226774
agent-5: 56.79999999822679
Extrinsic Rewards:
9
2
4
1
12
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.4142857142857143
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 359.7535591554375
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1285
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.026
    dispatch_time_ms: 7.138
    learner:
      cur_lr: 0.0009320949902758002
      grad_gnorm: 17.948652267456055
      policy_entropy: 34.922847747802734
      policy_loss: -3.1378588676452637
      var_gnorm: 23.063037872314453
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.15046872198581696
    num_steps_sampled: 6430000
    num_steps_trained: 6430000
    wait_time_ms: 78.225
  iterations_since_restore: 1286
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11288.601195573807
  time_this_iter_s: 8.688108205795288
  time_total_s: 11288.601195573807
  timestamp: 1594859826
  timesteps_since_restore: 6430000
  timesteps_this_iter: 5000
  timesteps_total: 6430000
  training_iteration: 1286
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11288 s, 1286 iter, 6430000 ts, 360 rew

agent-1: 30.5999999995836
agent-2: 27.599999999583606
agent-3: 28.599999999583606
agent-4: 29.5999999995836
agent-5: 27.599999999583606
Extrinsic Rewards:
5
2
3
4
2
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.2
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 357.5935591560763
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1286
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.53
    dispatch_time_ms: 7.85
    learner:
      cur_lr: 0.0009317619842477143
      grad_gnorm: 11.447489738464355
      policy_entropy: 31.52696990966797
      policy_loss: -0.7804774045944214
      var_gnorm: 23.062231063842773
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.09825222194194794
    num_steps_sampled: 6435000
    num_steps_trained: 6435000
    wait_time_ms: 76.736
  iterations_since_restore: 1287
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11297.195000171661
  time_this_iter_s: 8.593804597854614
  time_total_s: 11297.195000171661
  timestamp: 1594859835
  timesteps_since_restore: 6435000
  timesteps_this_iter: 5000
  timesteps_total: 6435000
  training_iteration: 1287
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11297 s, 1287 iter, 6435000 ts, 358 rew

agent-1: 36.999999998051166
agent-2: 36.999999998051166
agent-3: 34.99999999805116
agent-4: 35.99999999805116
agent-5: 34.99999999805115
Extrinsic Rewards:
5
5
3
4
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 3
Max Reward: 5
Gini Coefficient: 0.12
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 351.3835611115278
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1287
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.902
    dispatch_time_ms: 7.288
    learner:
      cur_lr: 0.0009314289782196283
      grad_gnorm: 22.589860916137695
      policy_entropy: 35.1571044921875
      policy_loss: -4.32321310043335
      var_gnorm: 23.062236785888672
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.3883471190929413
    num_steps_sampled: 6440000
    num_steps_trained: 6440000
    wait_time_ms: 75.571
  iterations_since_restore: 1288
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11305.909993886948
  time_this_iter_s: 8.714993715286255
  time_total_s: 11305.909993886948
  timestamp: 1594859844
  timesteps_since_restore: 6440000
  timesteps_this_iter: 5000
  timesteps_total: 6440000
  training_iteration: 1288
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11305 s, 1288 iter, 6440000 ts, 351 rew

agent-1: 43.59999993313895
agent-2: 47.599999933138946
agent-3: 50.59999993313896
agent-4: 49.59999993313896
agent-5: 42.59999993313894
Extrinsic Rewards:
2
6
9
8
1
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3384615384615385
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 351.47356110824774
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1288
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 6.536
    learner:
      cur_lr: 0.0009310959721915424
      grad_gnorm: 40.00000762939453
      policy_entropy: 34.77063751220703
      policy_loss: 39.89553451538086
      var_gnorm: 23.05792808532715
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 28.264265060424805
    num_steps_sampled: 6445000
    num_steps_trained: 6445000
    wait_time_ms: 75.839
  iterations_since_restore: 1289
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11314.4115254879
  time_this_iter_s: 8.501531600952148
  time_total_s: 11314.4115254879
  timestamp: 1594859852
  timesteps_since_restore: 6445000
  timesteps_this_iter: 5000
  timesteps_total: 6445000
  training_iteration: 1289
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11314 s, 1289 iter, 6445000 ts, 351 rew

agent-1: 40.399999997313074
agent-2: 40.399999997313074
agent-3: 42.399999997313074
agent-4: 46.399999997313074
agent-5: 46.399999997313074
Extrinsic Rewards:
2
2
4
8
8
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.3
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 350.75356110899634
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1289
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.874
    dispatch_time_ms: 9.686
    learner:
      cur_lr: 0.0009307630243711174
      grad_gnorm: 15.474895477294922
      policy_entropy: 34.353797912597656
      policy_loss: -3.319391965866089
      var_gnorm: 23.061017990112305
      vf_explained_var: 0.0
      vf_loss: 0.17877747118473053
    num_steps_sampled: 6450000
    num_steps_trained: 6450000
    wait_time_ms: 74.199
  iterations_since_restore: 1290
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11322.994970083237
  time_this_iter_s: 8.583444595336914
  time_total_s: 11322.994970083237
  timestamp: 1594859861
  timesteps_since_restore: 6450000
  timesteps_this_iter: 5000
  timesteps_total: 6450000
  training_iteration: 1290
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11322 s, 1290 iter, 6450000 ts, 351 rew

agent-1: 63.999999986917125
agent-2: 61.99999998691712
agent-3: 65.9999999869172
agent-4: 60.99999998691711
agent-5: 61.9999999869171
Extrinsic Rewards:
8
6
10
5
6
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 5
Max Reward: 10
Gini Coefficient: 0.13714285714285715
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 349.58356111502843
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1290
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 7.983
    learner:
      cur_lr: 0.0009304300183430314
      grad_gnorm: 40.0
      policy_entropy: 33.17576599121094
      policy_loss: 24.515779495239258
      var_gnorm: 23.062103271484375
      vf_explained_var: 2.980232238769531e-07
      vf_loss: 18.257596969604492
    num_steps_sampled: 6455000
    num_steps_trained: 6455000
    wait_time_ms: 72.814
  iterations_since_restore: 1291
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11331.618031978607
  time_this_iter_s: 8.623061895370483
  time_total_s: 11331.618031978607
  timestamp: 1594859869
  timesteps_since_restore: 6455000
  timesteps_this_iter: 5000
  timesteps_total: 6455000
  training_iteration: 1291
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11331 s, 1291 iter, 6455000 ts, 350 rew

agent-1: 36.9999999985316
agent-2: 33.9999999985316
agent-3: 36.9999999985316
agent-4: 37.999999998531614
agent-5: 33.999999998531585
Extrinsic Rewards:
5
2
5
6
2
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.22
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-37-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 347.5135611167742
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1291
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.986
    dispatch_time_ms: 6.739
    learner:
      cur_lr: 0.0009300970123149455
      grad_gnorm: 28.243141174316406
      policy_entropy: 24.272836685180664
      policy_loss: -3.6604676246643066
      var_gnorm: 23.06260108947754
      vf_explained_var: 0.0
      vf_loss: 0.615155816078186
    num_steps_sampled: 6460000
    num_steps_trained: 6460000
    wait_time_ms: 75.01
  iterations_since_restore: 1292
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11340.250962257385
  time_this_iter_s: 8.632930278778076
  time_total_s: 11340.250962257385
  timestamp: 1594859878
  timesteps_since_restore: 6460000
  timesteps_this_iter: 5000
  timesteps_total: 6460000
  training_iteration: 1292
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11340 s, 1292 iter, 6460000 ts, 348 rew

agent-1: 61.999999968923305
agent-2: 59.99999996892329
agent-3: 62.99999996892328
agent-4: 68.99999996892352
agent-5: 60.99999996892329
Extrinsic Rewards:
6
4
7
13
5
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 4
Max Reward: 13
Gini Coefficient: 0.22857142857142856
20:20 Ratio: 3.25
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 348.4135611152748
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1292
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.117
    dispatch_time_ms: 7.077
    learner:
      cur_lr: 0.0009297640062868595
      grad_gnorm: 10.841955184936523
      policy_entropy: 27.83141326904297
      policy_loss: -0.6702451705932617
      var_gnorm: 23.06017303466797
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.0850520208477974
    num_steps_sampled: 6465000
    num_steps_trained: 6465000
    wait_time_ms: 76.758
  iterations_since_restore: 1293
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11348.886758327484
  time_this_iter_s: 8.635796070098877
  time_total_s: 11348.886758327484
  timestamp: 1594859887
  timesteps_since_restore: 6465000
  timesteps_this_iter: 5000
  timesteps_total: 6465000
  training_iteration: 1293
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11348 s, 1293 iter, 6465000 ts, 348 rew

agent-1: 64.19999999036715
agent-2: 69.19999999036717
agent-3: 71.19999999036715
agent-4: 65.19999999036715
agent-5: 63.199999990367225
Extrinsic Rewards:
5
10
12
6
4
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.22702702702702704
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 349.49356111487555
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1293
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.279
    dispatch_time_ms: 7.74
    learner:
      cur_lr: 0.0009294310002587736
      grad_gnorm: 25.953693389892578
      policy_entropy: 35.160255432128906
      policy_loss: -4.013642311096191
      var_gnorm: 23.06133460998535
      vf_explained_var: 0.0
      vf_loss: 0.44947996735572815
    num_steps_sampled: 6470000
    num_steps_trained: 6470000
    wait_time_ms: 74.323
  iterations_since_restore: 1294
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11357.498686790466
  time_this_iter_s: 8.611928462982178
  time_total_s: 11357.498686790466
  timestamp: 1594859895
  timesteps_since_restore: 6470000
  timesteps_this_iter: 5000
  timesteps_total: 6470000
  training_iteration: 1294
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11357 s, 1294 iter, 6470000 ts, 349 rew

agent-1: 63.399999995897744
agent-2: 60.399999995897744
agent-3: 57.39999999589776
agent-4: 66.39999999589786
agent-5: 58.39999999589776
Extrinsic Rewards:
9
6
3
12
4
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.27058823529411763
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 345.89356128085177
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1294
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.372
    dispatch_time_ms: 36.184
    learner:
      cur_lr: 0.0009290979942306876
      grad_gnorm: 13.286518096923828
      policy_entropy: 30.633493423461914
      policy_loss: 3.137258529663086
      var_gnorm: 23.058542251586914
      vf_explained_var: 0.0
      vf_loss: 0.14198793470859528
    num_steps_sampled: 6475000
    num_steps_trained: 6475000
    wait_time_ms: 52.802
  iterations_since_restore: 1295
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11366.357842683792
  time_this_iter_s: 8.859155893325806
  time_total_s: 11366.357842683792
  timestamp: 1594859904
  timesteps_since_restore: 6475000
  timesteps_this_iter: 5000
  timesteps_total: 6475000
  training_iteration: 1295
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11366 s, 1295 iter, 6475000 ts, 346 rew

agent-1: 60.39999998981637
agent-2: 61.399999989816386
agent-3: 57.39999998981639
agent-4: 68.39999998981662
agent-5: 58.399999989816386
Extrinsic Rewards:
6
7
3
14
4
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.29411764705882354
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 340.9440245720759
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1295
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.687
    dispatch_time_ms: 23.739
    learner:
      cur_lr: 0.0009287649882026017
      grad_gnorm: 11.298375129699707
      policy_entropy: 16.238866806030273
      policy_loss: -2.945866107940674
      var_gnorm: 23.059310913085938
      vf_explained_var: 0.0
      vf_loss: 0.07509219646453857
    num_steps_sampled: 6480000
    num_steps_trained: 6480000
    wait_time_ms: 65.914
  iterations_since_restore: 1296
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11375.540017604828
  time_this_iter_s: 9.182174921035767
  time_total_s: 11375.540017604828
  timestamp: 1594859913
  timesteps_since_restore: 6480000
  timesteps_this_iter: 5000
  timesteps_total: 6480000
  training_iteration: 1296
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11375 s, 1296 iter, 6480000 ts, 341 rew

agent-1: 29.199999999535084
agent-2: 32.199999999535024
agent-3: 29.199999999535084
agent-4: 32.199999999535024
agent-5: 30.199999999535077
Extrinsic Rewards:
2
5
2
5
3
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.21176470588235294
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 337.79402457862767
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1296
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.949
    dispatch_time_ms: 25.209
    learner:
      cur_lr: 0.0009284319821745157
      grad_gnorm: 9.243246078491211
      policy_entropy: 20.479522705078125
      policy_loss: -0.08823485672473907
      var_gnorm: 23.06140899658203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.06608843803405762
    num_steps_sampled: 6485000
    num_steps_trained: 6485000
    wait_time_ms: 56.625
  iterations_since_restore: 1297
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11384.62586593628
  time_this_iter_s: 9.085848331451416
  time_total_s: 11384.62586593628
  timestamp: 1594859923
  timesteps_since_restore: 6485000
  timesteps_this_iter: 5000
  timesteps_total: 6485000
  training_iteration: 1297
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11384 s, 1297 iter, 6485000 ts, 338 rew

agent-1: 31.39999999916053
agent-2: 35.39999999916055
agent-3: 31.399999999160535
agent-4: 34.39999999916057
agent-5: 38.39999999916053
Extrinsic Rewards:
1
5
1
4
8
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.37894736842105264
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-38-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 336.7140245790751
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1297
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.572
    dispatch_time_ms: 42.663
    learner:
      cur_lr: 0.0009280989761464298
      grad_gnorm: 40.0
      policy_entropy: 15.156810760498047
      policy_loss: 28.991802215576172
      var_gnorm: 23.088459014892578
      vf_explained_var: 0.0
      vf_loss: 40.56922912597656
    num_steps_sampled: 6490000
    num_steps_trained: 6490000
    wait_time_ms: 38.576
  iterations_since_restore: 1298
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11393.681461572647
  time_this_iter_s: 9.055595636367798
  time_total_s: 11393.681461572647
  timestamp: 1594859932
  timesteps_since_restore: 6490000
  timesteps_this_iter: 5000
  timesteps_total: 6490000
  training_iteration: 1298
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11393 s, 1298 iter, 6490000 ts, 337 rew

agent-1: 189.82021930642227
agent-2: 182.82021930642227
agent-3: 196.82021930642227
agent-4: 195.8202193064223
agent-5: 188.8202193064223
Extrinsic Rewards:
21
14
28
27
20
Sum Reward: 110
Avg Reward: 22.0
Min Reward: 14
Max Reward: 28
Gini Coefficient: 0.12727272727272726
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 343.5550355474319
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1298
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.671
    dispatch_time_ms: 33.96
    learner:
      cur_lr: 0.0009277660283260047
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.35752010345459
      policy_loss: 47.397186279296875
      var_gnorm: 23.099977493286133
      vf_explained_var: 0.0
      vf_loss: 162.24822998046875
    num_steps_sampled: 6495000
    num_steps_trained: 6495000
    wait_time_ms: 52.711
  iterations_since_restore: 1299
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11402.698315143585
  time_this_iter_s: 9.01685357093811
  time_total_s: 11402.698315143585
  timestamp: 1594859941
  timesteps_since_restore: 6495000
  timesteps_this_iter: 5000
  timesteps_total: 6495000
  training_iteration: 1299
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11402 s, 1299 iter, 6495000 ts, 344 rew

agent-1: 146.19969224806877
agent-2: 137.19969224806874
agent-3: 130.1996922480688
agent-4: 137.19969224806877
agent-5: 142.1996922480688
Extrinsic Rewards:
23
14
7
14
19
Sum Reward: 77
Avg Reward: 15.4
Min Reward: 7
Max Reward: 23
Gini Coefficient: 0.19220779220779222
20:20 Ratio: 3.2857142857142856
Max-min Ratio: 3.2857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 339.44465907287383
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1299
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.479
    dispatch_time_ms: 23.938
    learner:
      cur_lr: 0.0009274330222979188
      grad_gnorm: 40.0
      policy_entropy: 10.427370071411133
      policy_loss: -9.453875541687012
      var_gnorm: 23.097633361816406
      vf_explained_var: 0.0
      vf_loss: 4.903683185577393
    num_steps_sampled: 6500000
    num_steps_trained: 6500000
    wait_time_ms: 71.551
  iterations_since_restore: 1300
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11411.868048906326
  time_this_iter_s: 9.169733762741089
  time_total_s: 11411.868048906326
  timestamp: 1594859950
  timesteps_since_restore: 6500000
  timesteps_this_iter: 5000
  timesteps_total: 6500000
  training_iteration: 1300
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11411 s, 1300 iter, 6500000 ts, 339 rew

agent-1: 87.79999998519801
agent-2: 73.79999998519801
agent-3: 77.79999998519801
agent-4: 78.799999985198
agent-5: 68.79999998519799
Extrinsic Rewards:
19
5
9
10
0
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 0
Max Reward: 19
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 340.1646590725234
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1300
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 39.247
    learner:
      cur_lr: 0.0009271000162698328
      grad_gnorm: 5.559391498565674
      policy_entropy: 4.167511463165283
      policy_loss: -0.04260120168328285
      var_gnorm: 23.080158233642578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.029220424592494965
    num_steps_sampled: 6505000
    num_steps_trained: 6505000
    wait_time_ms: 43.087
  iterations_since_restore: 1301
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11420.63589644432
  time_this_iter_s: 8.767847537994385
  time_total_s: 11420.63589644432
  timestamp: 1594859959
  timesteps_since_restore: 6505000
  timesteps_this_iter: 5000
  timesteps_total: 6505000
  training_iteration: 1301
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11420 s, 1301 iter, 6505000 ts, 340 rew

agent-1: 72.19999999076651
agent-2: 61.199999990766464
agent-3: 64.1999999907665
agent-4: 67.19999999076651
agent-5: 68.19999999076653
Extrinsic Rewards:
13
2
5
8
9
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.2810810810810811
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 338.634659079801
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1301
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.109
    dispatch_time_ms: 39.372
    learner:
      cur_lr: 0.0009267670102417469
      grad_gnorm: 40.0
      policy_entropy: 30.067153930664062
      policy_loss: 45.89262008666992
      var_gnorm: 23.10406494140625
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 47.2442512512207
    num_steps_sampled: 6510000
    num_steps_trained: 6510000
    wait_time_ms: 35.894
  iterations_since_restore: 1302
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11429.377659320831
  time_this_iter_s: 8.74176287651062
  time_total_s: 11429.377659320831
  timestamp: 1594859968
  timesteps_since_restore: 6510000
  timesteps_this_iter: 5000
  timesteps_total: 6510000
  training_iteration: 1302
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11429 s, 1302 iter, 6510000 ts, 339 rew

agent-1: 112.5111810917229
agent-2: 117.5111810917229
agent-3: 99.5111810917229
agent-4: 103.51118109172289
agent-5: 115.51118109172293
Extrinsic Rewards:
15
20
2
6
18
Sum Reward: 61
Avg Reward: 12.2
Min Reward: 2
Max Reward: 20
Gini Coefficient: 0.31475409836065577
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 338.090219511085
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1302
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.014
    dispatch_time_ms: 28.81
    learner:
      cur_lr: 0.000926434004213661
      grad_gnorm: 40.0
      policy_entropy: 45.440765380859375
      policy_loss: -14.354984283447266
      var_gnorm: 23.110458374023438
      vf_explained_var: 0.0
      vf_loss: 3.2022805213928223
    num_steps_sampled: 6515000
    num_steps_trained: 6515000
    wait_time_ms: 55.101
  iterations_since_restore: 1303
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11438.457577943802
  time_this_iter_s: 9.079918622970581
  time_total_s: 11438.457577943802
  timestamp: 1594859977
  timesteps_since_restore: 6515000
  timesteps_this_iter: 5000
  timesteps_total: 6515000
  training_iteration: 1303
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11438 s, 1303 iter, 6515000 ts, 338 rew

agent-1: 86.19996607539893
agent-2: 77.199966075399
agent-3: 89.19996607539895
agent-4: 84.19996607539893
agent-5: 86.19996607539893
Extrinsic Rewards:
11
2
14
9
11
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.22127659574468084
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 340.70021781488447
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1303
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.713
    dispatch_time_ms: 30.595
    learner:
      cur_lr: 0.000926100998185575
      grad_gnorm: 40.0
      policy_entropy: 12.154692649841309
      policy_loss: -4.2085862159729
      var_gnorm: 23.10865592956543
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 3.334505319595337
    num_steps_sampled: 6520000
    num_steps_trained: 6520000
    wait_time_ms: 62.77
  iterations_since_restore: 1304
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11447.591672897339
  time_this_iter_s: 9.134094953536987
  time_total_s: 11447.591672897339
  timestamp: 1594859986
  timesteps_since_restore: 6520000
  timesteps_this_iter: 5000
  timesteps_total: 6520000
  training_iteration: 1304
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11447 s, 1304 iter, 6520000 ts, 341 rew

agent-1: 56.19999990090086
agent-2: 63.19999990090086
agent-3: 54.19999990090087
agent-4: 57.19999990090088
agent-5: 57.19999990090086
Extrinsic Rewards:
5
12
3
6
6
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.2375
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-39-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 341.9602178099872
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1304
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.144
    dispatch_time_ms: 31.774
    learner:
      cur_lr: 0.0009257679921574891
      grad_gnorm: 40.0
      policy_entropy: 20.1968936920166
      policy_loss: -4.108131408691406
      var_gnorm: 23.098447799682617
      vf_explained_var: 0.0
      vf_loss: 2.0576319694519043
    num_steps_sampled: 6525000
    num_steps_trained: 6525000
    wait_time_ms: 60.414
  iterations_since_restore: 1305
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11456.697397470474
  time_this_iter_s: 9.105724573135376
  time_total_s: 11456.697397470474
  timestamp: 1594859995
  timesteps_since_restore: 6525000
  timesteps_this_iter: 5000
  timesteps_total: 6525000
  training_iteration: 1305
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11456 s, 1305 iter, 6525000 ts, 342 rew

agent-1: 169.77833524752896
agent-2: 179.7783352475289
agent-3: 162.77833524752896
agent-4: 156.7783352475289
agent-5: 167.77833524752896
Extrinsic Rewards:
21
31
14
8
19
Sum Reward: 93
Avg Reward: 18.6
Min Reward: 8
Max Reward: 31
Gini Coefficient: 0.22795698924731184
20:20 Ratio: 3.875
Max-min Ratio: 3.875
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 348.5291345723996
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1305
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.48
    dispatch_time_ms: 36.672
    learner:
      cur_lr: 0.0009254349861294031
      grad_gnorm: 25.777244567871094
      policy_entropy: 31.329021453857422
      policy_loss: 2.5646727085113525
      var_gnorm: 23.11195182800293
      vf_explained_var: 0.0
      vf_loss: 0.4971156418323517
    num_steps_sampled: 6530000
    num_steps_trained: 6530000
    wait_time_ms: 56.841
  iterations_since_restore: 1306
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11465.827163934708
  time_this_iter_s: 9.129766464233398
  time_total_s: 11465.827163934708
  timestamp: 1594860004
  timesteps_since_restore: 6530000
  timesteps_this_iter: 5000
  timesteps_total: 6530000
  training_iteration: 1306
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11465 s, 1306 iter, 6530000 ts, 349 rew

agent-1: 182.79954696936804
agent-2: 188.7995469693681
agent-3: 182.7995469693681
agent-4: 193.79954696936804
agent-5: 178.79954696936815
Extrinsic Rewards:
18
24
18
29
14
Sum Reward: 103
Avg Reward: 20.6
Min Reward: 14
Max Reward: 29
Gini Coefficient: 0.13980582524271845
20:20 Ratio: 2.0714285714285716
Max-min Ratio: 2.0714285714285716
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 355.6391119209155
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1306
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.846
    dispatch_time_ms: 29.53
    learner:
      cur_lr: 0.0009251019801013172
      grad_gnorm: 40.0
      policy_entropy: 22.885404586791992
      policy_loss: 12.85382080078125
      var_gnorm: 23.086748123168945
      vf_explained_var: 0.0
      vf_loss: 13.933710098266602
    num_steps_sampled: 6535000
    num_steps_trained: 6535000
    wait_time_ms: 60.324
  iterations_since_restore: 1307
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11474.9866065979
  time_this_iter_s: 9.159442663192749
  time_total_s: 11474.9866065979
  timestamp: 1594860013
  timesteps_since_restore: 6535000
  timesteps_this_iter: 5000
  timesteps_total: 6535000
  training_iteration: 1307
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11474 s, 1307 iter, 6535000 ts, 356 rew

agent-1: 54.39999999509974
agent-2: 50.39999999509974
agent-3: 53.399999995099726
agent-4: 52.39999999509973
agent-5: 50.39999999509973
Extrinsic Rewards:
8
4
7
6
4
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 4
Max Reward: 8
Gini Coefficient: 0.15172413793103448
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 356.44911192070117
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1307
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.644
    dispatch_time_ms: 22.92
    learner:
      cur_lr: 0.0009247689740732312
      grad_gnorm: 40.0
      policy_entropy: 30.730009078979492
      policy_loss: 65.84053802490234
      var_gnorm: 23.097230911254883
      vf_explained_var: 0.0
      vf_loss: 74.28367614746094
    num_steps_sampled: 6540000
    num_steps_trained: 6540000
    wait_time_ms: 55.867
  iterations_since_restore: 1308
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11483.825607061386
  time_this_iter_s: 8.839000463485718
  time_total_s: 11483.825607061386
  timestamp: 1594860022
  timesteps_since_restore: 6540000
  timesteps_this_iter: 5000
  timesteps_total: 6540000
  training_iteration: 1308
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11483 s, 1308 iter, 6540000 ts, 356 rew

agent-1: 125.99772134800986
agent-2: 136.99772134800997
agent-3: 142.99772134801003
agent-4: 137.99772134801
agent-5: 130.99772134800997
Extrinsic Rewards:
6
17
23
18
11
Sum Reward: 75
Avg Reward: 15.0
Min Reward: 6
Max Reward: 23
Gini Coefficient: 0.21866666666666668
20:20 Ratio: 3.8333333333333335
Max-min Ratio: 3.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 360.4989979974936
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1308
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.197
    dispatch_time_ms: 35.118
    learner:
      cur_lr: 0.0009244360262528062
      grad_gnorm: 39.999996185302734
      policy_entropy: 36.89325714111328
      policy_loss: -12.983805656433105
      var_gnorm: 23.093807220458984
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.8461334705352783
    num_steps_sampled: 6545000
    num_steps_trained: 6545000
    wait_time_ms: 55.509
  iterations_since_restore: 1309
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11492.81730055809
  time_this_iter_s: 8.991693496704102
  time_total_s: 11492.81730055809
  timestamp: 1594860031
  timesteps_since_restore: 6545000
  timesteps_this_iter: 5000
  timesteps_total: 6545000
  training_iteration: 1309
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11492 s, 1309 iter, 6545000 ts, 360 rew

agent-1: 119.99990690486908
agent-2: 118.99990690486906
agent-3: 113.99990690486902
agent-4: 115.9999069048691
agent-5: 115.9999069048691
Extrinsic Rewards:
16
15
10
12
12
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 10
Max Reward: 16
Gini Coefficient: 0.09230769230769231
20:20 Ratio: 1.6
Max-min Ratio: 1.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 363.7389933431265
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1309
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.241
    dispatch_time_ms: 8.7
    learner:
      cur_lr: 0.0009241030202247202
      grad_gnorm: 40.0
      policy_entropy: 23.3293514251709
      policy_loss: -6.259584903717041
      var_gnorm: 23.081295013427734
      vf_explained_var: 0.0
      vf_loss: 2.2152721881866455
    num_steps_sampled: 6550000
    num_steps_trained: 6550000
    wait_time_ms: 75.112
  iterations_since_restore: 1310
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11502.00340795517
  time_this_iter_s: 9.186107397079468
  time_total_s: 11502.00340795517
  timestamp: 1594860040
  timesteps_since_restore: 6550000
  timesteps_this_iter: 5000
  timesteps_total: 6550000
  training_iteration: 1310
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11502 s, 1310 iter, 6550000 ts, 364 rew

agent-1: 79.39999996748517
agent-2: 73.3999999674852
agent-3: 78.39999996748514
agent-4: 89.39999996748516
agent-5: 75.39999996748517
Extrinsic Rewards:
9
3
8
19
5
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 3
Max Reward: 19
Gini Coefficient: 0.32727272727272727
20:20 Ratio: 6.333333333333333
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 361.2190178706576
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1310
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.83
    dispatch_time_ms: 6.798
    learner:
      cur_lr: 0.0009237700141966343
      grad_gnorm: 40.0
      policy_entropy: 31.80364227294922
      policy_loss: 66.07778930664062
      var_gnorm: 23.07059097290039
      vf_explained_var: 0.0
      vf_loss: 128.81785583496094
    num_steps_sampled: 6555000
    num_steps_trained: 6555000
    wait_time_ms: 77.987
  iterations_since_restore: 1311
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11510.693717956543
  time_this_iter_s: 8.690310001373291
  time_total_s: 11510.693717956543
  timestamp: 1594860049
  timesteps_since_restore: 6555000
  timesteps_this_iter: 5000
  timesteps_total: 6555000
  training_iteration: 1311
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11510 s, 1311 iter, 6555000 ts, 361 rew

agent-1: 46.599999998275266
agent-2: 49.59999999827526
agent-3: 42.59999999827526
agent-4: 46.599999998275266
agent-5: 48.599999998275266
Extrinsic Rewards:
5
8
1
5
7
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.24615384615384617
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-40-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 361.03901787078723
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1311
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 7.468
    learner:
      cur_lr: 0.0009234370081685483
      grad_gnorm: 40.000003814697266
      policy_entropy: 32.09520721435547
      policy_loss: 9.9546480178833
      var_gnorm: 23.072460174560547
      vf_explained_var: 0.0
      vf_loss: 3.411219358444214
    num_steps_sampled: 6560000
    num_steps_trained: 6560000
    wait_time_ms: 77.731
  iterations_since_restore: 1312
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11519.181391716003
  time_this_iter_s: 8.48767375946045
  time_total_s: 11519.181391716003
  timestamp: 1594860058
  timesteps_since_restore: 6560000
  timesteps_this_iter: 5000
  timesteps_total: 6560000
  training_iteration: 1312
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11519 s, 1312 iter, 6560000 ts, 361 rew

agent-1: 64.99999999312827
agent-2: 60.99999999312835
agent-3: 59.999999993128355
agent-4: 59.99999999312836
agent-5: 68.99999999312824
Extrinsic Rewards:
9
5
4
4
13
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 4
Max Reward: 13
Gini Coefficient: 0.26285714285714284
20:20 Ratio: 3.25
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 360.49901787089766
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1312
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 7.602
    learner:
      cur_lr: 0.0009231040021404624
      grad_gnorm: 9.662599563598633
      policy_entropy: 29.659555435180664
      policy_loss: -1.4083607196807861
      var_gnorm: 23.06971549987793
      vf_explained_var: 0.0
      vf_loss: 0.07166866958141327
    num_steps_sampled: 6565000
    num_steps_trained: 6565000
    wait_time_ms: 77.451
  iterations_since_restore: 1313
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11527.687402248383
  time_this_iter_s: 8.50601053237915
  time_total_s: 11527.687402248383
  timestamp: 1594860066
  timesteps_since_restore: 6565000
  timesteps_this_iter: 5000
  timesteps_total: 6565000
  training_iteration: 1313
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11527 s, 1313 iter, 6565000 ts, 360 rew

agent-1: 93.79999971002027
agent-2: 88.79999971002023
agent-3: 86.79999971002023
agent-4: 80.79999971002027
agent-5: 81.79999971002024
Extrinsic Rewards:
17
12
10
4
5
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 4
Max Reward: 17
Gini Coefficient: 0.275
20:20 Ratio: 4.25
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 362.6590178565506
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1313
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.753
    dispatch_time_ms: 8.948
    learner:
      cur_lr: 0.0009227709961123765
      grad_gnorm: 28.399658203125
      policy_entropy: 32.62157440185547
      policy_loss: -5.352897644042969
      var_gnorm: 23.070720672607422
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.5601855516433716
    num_steps_sampled: 6570000
    num_steps_trained: 6570000
    wait_time_ms: 74.28
  iterations_since_restore: 1314
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11536.212329387665
  time_this_iter_s: 8.524927139282227
  time_total_s: 11536.212329387665
  timestamp: 1594860075
  timesteps_since_restore: 6570000
  timesteps_this_iter: 5000
  timesteps_total: 6570000
  training_iteration: 1314
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11536 s, 1314 iter, 6570000 ts, 363 rew

agent-1: 80.39999973337424
agent-2: 82.39999973337426
agent-3: 74.39999973337426
agent-4: 70.39999973337423
agent-5: 88.3999997333743
Extrinsic Rewards:
10
12
4
0
18
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 0
Max Reward: 18
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 363.73901784351284
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1314
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 6.649
    learner:
      cur_lr: 0.0009224379900842905
      grad_gnorm: 39.999996185302734
      policy_entropy: 31.134571075439453
      policy_loss: 60.17390060424805
      var_gnorm: 23.070594787597656
      vf_explained_var: 0.0
      vf_loss: 114.94558715820312
    num_steps_sampled: 6575000
    num_steps_trained: 6575000
    wait_time_ms: 77.601
  iterations_since_restore: 1315
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11544.806657075882
  time_this_iter_s: 8.594327688217163
  time_total_s: 11544.806657075882
  timestamp: 1594860083
  timesteps_since_restore: 6575000
  timesteps_this_iter: 5000
  timesteps_total: 6575000
  training_iteration: 1315
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11544 s, 1315 iter, 6575000 ts, 364 rew

agent-1: 41.99999999607748
agent-2: 49.999999996077484
agent-3: 43.99999999607749
agent-4: 40.99999999607748
agent-5: 47.999999996077484
Extrinsic Rewards:
2
10
4
1
8
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.384
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 364.3690178433592
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1315
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.617
    dispatch_time_ms: 5.877
    learner:
      cur_lr: 0.0009221049840562046
      grad_gnorm: 20.691267013549805
      policy_entropy: 33.829288482666016
      policy_loss: -3.9055514335632324
      var_gnorm: 23.075803756713867
      vf_explained_var: 0.0
      vf_loss: 0.2995773255825043
    num_steps_sampled: 6580000
    num_steps_trained: 6580000
    wait_time_ms: 76.25
  iterations_since_restore: 1316
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11553.363314628601
  time_this_iter_s: 8.556657552719116
  time_total_s: 11553.363314628601
  timestamp: 1594860092
  timesteps_since_restore: 6580000
  timesteps_this_iter: 5000
  timesteps_total: 6580000
  training_iteration: 1316
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11553 s, 1316 iter, 6580000 ts, 364 rew

agent-1: 54.999999989285605
agent-2: 47.999999989285605
agent-3: 55.99999998928562
agent-4: 51.99999998928562
agent-5: 58.999999989285605
Extrinsic Rewards:
7
0
8
4
11
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.3466666666666667
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 364.2790178432581
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1316
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.079
    dispatch_time_ms: 7.633
    learner:
      cur_lr: 0.0009217719780281186
      grad_gnorm: 7.865374565124512
      policy_entropy: 35.812408447265625
      policy_loss: -1.1308399438858032
      var_gnorm: 23.074190139770508
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.04590095579624176
    num_steps_sampled: 6585000
    num_steps_trained: 6585000
    wait_time_ms: 77.369
  iterations_since_restore: 1317
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11562.053570747375
  time_this_iter_s: 8.690256118774414
  time_total_s: 11562.053570747375
  timestamp: 1594860101
  timesteps_since_restore: 6585000
  timesteps_this_iter: 5000
  timesteps_total: 6585000
  training_iteration: 1317
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11562 s, 1317 iter, 6585000 ts, 364 rew

agent-1: 72.7999999929994
agent-2: 82.79999999299939
agent-3: 75.79999999299937
agent-4: 76.79999999299937
agent-5: 78.79999999299937
Extrinsic Rewards:
4
14
7
8
10
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 4
Max Reward: 14
Gini Coefficient: 0.21395348837209302
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 365.3590178430989
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1317
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 7.698
    learner:
      cur_lr: 0.0009214389720000327
      grad_gnorm: 13.668627738952637
      policy_entropy: 32.51593017578125
      policy_loss: -2.0124311447143555
      var_gnorm: 23.070390701293945
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.13230855762958527
    num_steps_sampled: 6590000
    num_steps_trained: 6590000
    wait_time_ms: 78.279
  iterations_since_restore: 1318
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11570.648005008698
  time_this_iter_s: 8.594434261322021
  time_total_s: 11570.648005008698
  timestamp: 1594860109
  timesteps_since_restore: 6590000
  timesteps_this_iter: 5000
  timesteps_total: 6590000
  training_iteration: 1318
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11570 s, 1318 iter, 6590000 ts, 365 rew

agent-1: 36.799999999224795
agent-2: 29.799999999224852
agent-3: 33.799999999224774
agent-4: 32.799999999224774
agent-5: 28.799999999224852
Extrinsic Rewards:
8
1
5
4
0
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4444444444444444
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-41-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 364.36901784320906
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1318
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.961
    dispatch_time_ms: 9.668
    learner:
      cur_lr: 0.0009211060241796076
      grad_gnorm: 7.7850022315979
      policy_entropy: 31.542591094970703
      policy_loss: -1.1003447771072388
      var_gnorm: 23.07036590576172
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.046930789947509766
    num_steps_sampled: 6595000
    num_steps_trained: 6595000
    wait_time_ms: 73.906
  iterations_since_restore: 1319
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11579.323243618011
  time_this_iter_s: 8.675238609313965
  time_total_s: 11579.323243618011
  timestamp: 1594860118
  timesteps_since_restore: 6595000
  timesteps_this_iter: 5000
  timesteps_total: 6595000
  training_iteration: 1319
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11579 s, 1319 iter, 6595000 ts, 364 rew

agent-1: 57.999999998415234
agent-2: 53.999999998415234
agent-3: 54.999999998415234
agent-4: 53.999999998415234
agent-5: 48.999999998415234
Extrinsic Rewards:
10
6
7
6
1
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.25333333333333335
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 364.1890178435431
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1319
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.513
    dispatch_time_ms: 9.759
    learner:
      cur_lr: 0.0009207730181515217
      grad_gnorm: 13.385123252868652
      policy_entropy: 21.17466926574707
      policy_loss: -2.2289910316467285
      var_gnorm: 23.067935943603516
      vf_explained_var: 0.0
      vf_loss: 0.13767218589782715
    num_steps_sampled: 6600000
    num_steps_trained: 6600000
    wait_time_ms: 75.179
  iterations_since_restore: 1320
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11587.981621265411
  time_this_iter_s: 8.658377647399902
  time_total_s: 11587.981621265411
  timestamp: 1594860127
  timesteps_since_restore: 6600000
  timesteps_this_iter: 5000
  timesteps_total: 6600000
  training_iteration: 1320
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11587 s, 1320 iter, 6600000 ts, 364 rew

agent-1: 34.59999999574209
agent-2: 35.599999995742074
agent-3: 40.59999999574208
agent-4: 40.59999999574208
agent-5: 37.599999995742074
Extrinsic Rewards:
1
2
7
7
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.3238095238095238
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 363.55901784358224
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1320
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.715
    dispatch_time_ms: 6.118
    learner:
      cur_lr: 0.0009204400121234357
      grad_gnorm: 7.733822345733643
      policy_entropy: 21.46965980529785
      policy_loss: -0.6974071860313416
      var_gnorm: 23.06658172607422
      vf_explained_var: 0.0
      vf_loss: 0.046273816376924515
    num_steps_sampled: 6605000
    num_steps_trained: 6605000
    wait_time_ms: 78.718
  iterations_since_restore: 1321
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11596.642888307571
  time_this_iter_s: 8.661267042160034
  time_total_s: 11596.642888307571
  timestamp: 1594860136
  timesteps_since_restore: 6605000
  timesteps_this_iter: 5000
  timesteps_total: 6605000
  training_iteration: 1321
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11596 s, 1321 iter, 6605000 ts, 364 rew

agent-1: 53.99999999898917
agent-2: 39.99999999898919
agent-3: 42.999999998989196
agent-4: 46.99999999898918
agent-5: 40.999999998989196
Extrinsic Rewards:
14
0
3
7
1
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.544
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 363.28901784365894
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1321
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 8.113
    learner:
      cur_lr: 0.0009201070060953498
      grad_gnorm: 28.494478225708008
      policy_entropy: 23.15390968322754
      policy_loss: -3.687098503112793
      var_gnorm: 23.0675048828125
      vf_explained_var: 0.0
      vf_loss: 0.6196770668029785
    num_steps_sampled: 6610000
    num_steps_trained: 6610000
    wait_time_ms: 76.247
  iterations_since_restore: 1322
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11605.292674064636
  time_this_iter_s: 8.64978575706482
  time_total_s: 11605.292674064636
  timestamp: 1594860144
  timesteps_since_restore: 6610000
  timesteps_this_iter: 5000
  timesteps_total: 6610000
  training_iteration: 1322
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11605 s, 1322 iter, 6610000 ts, 363 rew

agent-1: 72.19999960176695
agent-2: 73.19999960176693
agent-3: 80.19999960176695
agent-4: 71.19999960176696
agent-5: 81.19999960176693
Extrinsic Rewards:
5
6
13
4
14
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 4
Max Reward: 14
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 360.22901933129236
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1322
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.145
    dispatch_time_ms: 6.928
    learner:
      cur_lr: 0.0009197740000672638
      grad_gnorm: 8.101653099060059
      policy_entropy: 20.044233322143555
      policy_loss: -0.6494814157485962
      var_gnorm: 23.06858253479004
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.05083034560084343
    num_steps_sampled: 6615000
    num_steps_trained: 6615000
    wait_time_ms: 72.255
  iterations_since_restore: 1323
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11613.877726316452
  time_this_iter_s: 8.585052251815796
  time_total_s: 11613.877726316452
  timestamp: 1594860153
  timesteps_since_restore: 6615000
  timesteps_this_iter: 5000
  timesteps_total: 6615000
  training_iteration: 1323
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11613 s, 1323 iter, 6615000 ts, 360 rew

agent-1: 58.79999999738143
agent-2: 48.7999999973814
agent-3: 47.7999999973814
agent-4: 45.79999999738141
agent-5: 50.79999999738141
Extrinsic Rewards:
14
4
3
1
6
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.4142857142857143
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 356.80901938244676
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1323
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.156
    dispatch_time_ms: 8.438
    learner:
      cur_lr: 0.0009194409940391779
      grad_gnorm: 40.0
      policy_entropy: 20.302204132080078
      policy_loss: 7.2658538818359375
      var_gnorm: 23.078277587890625
      vf_explained_var: 0.0
      vf_loss: 8.540894508361816
    num_steps_sampled: 6620000
    num_steps_trained: 6620000
    wait_time_ms: 74.338
  iterations_since_restore: 1324
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11622.531624555588
  time_this_iter_s: 8.653898239135742
  time_total_s: 11622.531624555588
  timestamp: 1594860162
  timesteps_since_restore: 6620000
  timesteps_this_iter: 5000
  timesteps_total: 6620000
  training_iteration: 1324
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11622 s, 1324 iter, 6620000 ts, 357 rew

agent-1: 156.9988589011847
agent-2: 145.9988589011848
agent-3: 153.9988589011847
agent-4: 158.9988589011847
agent-5: 148.99885890118472
Extrinsic Rewards:
21
10
18
23
13
Sum Reward: 85
Avg Reward: 17.0
Min Reward: 10
Max Reward: 23
Gini Coefficient: 0.16
20:20 Ratio: 2.3
Max-min Ratio: 2.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 362.47896232759797
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1324
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 6.75
    learner:
      cur_lr: 0.000919107988011092
      grad_gnorm: 39.999996185302734
      policy_entropy: 13.202605247497559
      policy_loss: 7.143316745758057
      var_gnorm: 23.067012786865234
      vf_explained_var: 0.0
      vf_loss: 7.4825849533081055
    num_steps_sampled: 6625000
    num_steps_trained: 6625000
    wait_time_ms: 75.841
  iterations_since_restore: 1325
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11631.186805486679
  time_this_iter_s: 8.655180931091309
  time_total_s: 11631.186805486679
  timestamp: 1594860170
  timesteps_since_restore: 6625000
  timesteps_this_iter: 5000
  timesteps_total: 6625000
  training_iteration: 1325
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11631 s, 1325 iter, 6625000 ts, 362 rew

agent-1: 39.19999999894045
agent-2: 40.19999999894044
agent-3: 37.19999999894046
agent-4: 44.199999998940456
agent-5: 37.199999998940456
Extrinsic Rewards:
4
5
2
9
2
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.3090909090909091
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-42-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 362.47896232758177
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1325
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 8.51
    learner:
      cur_lr: 0.000918774981983006
      grad_gnorm: 39.999996185302734
      policy_entropy: 12.297521591186523
      policy_loss: -9.223954200744629
      var_gnorm: 23.079071044921875
      vf_explained_var: 0.0
      vf_loss: 3.25252366065979
    num_steps_sampled: 6630000
    num_steps_trained: 6630000
    wait_time_ms: 76.216
  iterations_since_restore: 1326
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11639.788758277893
  time_this_iter_s: 8.60195279121399
  time_total_s: 11639.788758277893
  timestamp: 1594860179
  timesteps_since_restore: 6630000
  timesteps_this_iter: 5000
  timesteps_total: 6630000
  training_iteration: 1326
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11639 s, 1326 iter, 6630000 ts, 362 rew

agent-1: 183.95895287059216
agent-2: 179.95895287059219
agent-3: 183.9589528705922
agent-4: 185.95895287059219
agent-5: 181.9589528705922
Extrinsic Rewards:
22
18
22
24
20
Sum Reward: 106
Avg Reward: 21.2
Min Reward: 18
Max Reward: 24
Gini Coefficient: 0.052830188679245285
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 369.1169099712079
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1326
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.662
    dispatch_time_ms: 5.794
    learner:
      cur_lr: 0.00091844197595492
      grad_gnorm: 39.999996185302734
      policy_entropy: 20.520570755004883
      policy_loss: 21.85338592529297
      var_gnorm: 23.068553924560547
      vf_explained_var: 0.0
      vf_loss: 31.42466163635254
    num_steps_sampled: 6635000
    num_steps_trained: 6635000
    wait_time_ms: 79.857
  iterations_since_restore: 1327
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11648.413741827011
  time_this_iter_s: 8.624983549118042
  time_total_s: 11648.413741827011
  timestamp: 1594860187
  timesteps_since_restore: 6635000
  timesteps_this_iter: 5000
  timesteps_total: 6635000
  training_iteration: 1327
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11648 s, 1327 iter, 6635000 ts, 369 rew

agent-1: 54.19999999269073
agent-2: 69.19999999269062
agent-3: 60.199999992690714
agent-4: 53.19999999269073
agent-5: 51.19999999269073
Extrinsic Rewards:
3
18
9
2
0
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 0
Max Reward: 18
Gini Coefficient: 0.5375
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 369.83690997108357
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1327
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.531
    dispatch_time_ms: 6.4
    learner:
      cur_lr: 0.000918109028134495
      grad_gnorm: 34.45356369018555
      policy_entropy: 31.83269691467285
      policy_loss: -5.679300308227539
      var_gnorm: 23.06651496887207
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.8575683236122131
    num_steps_sampled: 6640000
    num_steps_trained: 6640000
    wait_time_ms: 78.936
  iterations_since_restore: 1328
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11656.975419521332
  time_this_iter_s: 8.561677694320679
  time_total_s: 11656.975419521332
  timestamp: 1594860196
  timesteps_since_restore: 6640000
  timesteps_this_iter: 5000
  timesteps_total: 6640000
  training_iteration: 1328
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11656 s, 1328 iter, 6640000 ts, 370 rew

agent-1: 51.19999999638981
agent-2: 45.19999999638983
agent-3: 50.19999999638981
agent-4: 52.19999999638981
agent-5: 44.19999999638981
Extrinsic Rewards:
8
2
7
9
1
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.32592592592592595
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 369.4769099713477
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1328
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.601
    dispatch_time_ms: 8.041
    learner:
      cur_lr: 0.0009177760221064091
      grad_gnorm: 40.000003814697266
      policy_entropy: 15.025077819824219
      policy_loss: 5.522849082946777
      var_gnorm: 23.065088272094727
      vf_explained_var: 0.0
      vf_loss: 7.360997676849365
    num_steps_sampled: 6645000
    num_steps_trained: 6645000
    wait_time_ms: 70.226
  iterations_since_restore: 1329
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11665.42001080513
  time_this_iter_s: 8.444591283798218
  time_total_s: 11665.42001080513
  timestamp: 1594860205
  timesteps_since_restore: 6645000
  timesteps_this_iter: 5000
  timesteps_total: 6645000
  training_iteration: 1329
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11665 s, 1329 iter, 6645000 ts, 369 rew

agent-1: 77.99999949330282
agent-2: 85.99999949330277
agent-3: 77.99999949330281
agent-4: 77.9999994933028
agent-5: 84.99999949330277
Extrinsic Rewards:
6
14
6
6
13
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 6
Max Reward: 14
Gini Coefficient: 0.20444444444444446
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 371.09690994613845
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1329
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 6.52
    learner:
      cur_lr: 0.0009174430160783231
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.15545082092285
      policy_loss: 5.645747184753418
      var_gnorm: 23.065427780151367
      vf_explained_var: 0.0
      vf_loss: 2.365537405014038
    num_steps_sampled: 6650000
    num_steps_trained: 6650000
    wait_time_ms: 78.218
  iterations_since_restore: 1330
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11673.76409316063
  time_this_iter_s: 8.344082355499268
  time_total_s: 11673.76409316063
  timestamp: 1594860213
  timesteps_since_restore: 6650000
  timesteps_this_iter: 5000
  timesteps_total: 6650000
  training_iteration: 1330
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11673 s, 1330 iter, 6650000 ts, 371 rew

agent-1: 77.39999664755533
agent-2: 65.39999664755545
agent-3: 67.39999664755544
agent-4: 66.39999664755544
agent-5: 74.39999664755538
Extrinsic Rewards:
15
3
5
4
12
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 3
Max Reward: 15
Gini Coefficient: 0.3282051282051282
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 372.1769097788624
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1330
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.039
    dispatch_time_ms: 9.246
    learner:
      cur_lr: 0.0009171100100502372
      grad_gnorm: 15.680475234985352
      policy_entropy: 27.460172653198242
      policy_loss: -2.4747097492218018
      var_gnorm: 23.062223434448242
      vf_explained_var: 0.0
      vf_loss: 0.16076302528381348
    num_steps_sampled: 6655000
    num_steps_trained: 6655000
    wait_time_ms: 73.152
  iterations_since_restore: 1331
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11682.264111280441
  time_this_iter_s: 8.500018119812012
  time_total_s: 11682.264111280441
  timestamp: 1594860221
  timesteps_since_restore: 6655000
  timesteps_this_iter: 5000
  timesteps_total: 6655000
  training_iteration: 1331
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11682 s, 1331 iter, 6655000 ts, 372 rew

agent-1: 104.79999975605739
agent-2: 101.7999997560574
agent-3: 102.79999975605743
agent-4: 107.79999975605742
agent-5: 104.79999975605739
Extrinsic Rewards:
12
9
10
15
12
Sum Reward: 58
Avg Reward: 11.6
Min Reward: 9
Max Reward: 15
Gini Coefficient: 0.09655172413793103
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 375.4169097668203
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1331
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.865
    dispatch_time_ms: 7.945
    learner:
      cur_lr: 0.0009167770040221512
      grad_gnorm: 14.180855751037598
      policy_entropy: 26.908388137817383
      policy_loss: -1.8969212770462036
      var_gnorm: 23.06047248840332
      vf_explained_var: 0.0
      vf_loss: 0.15558207035064697
    num_steps_sampled: 6660000
    num_steps_trained: 6660000
    wait_time_ms: 74.172
  iterations_since_restore: 1332
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11690.673019170761
  time_this_iter_s: 8.408907890319824
  time_total_s: 11690.673019170761
  timestamp: 1594860230
  timesteps_since_restore: 6660000
  timesteps_this_iter: 5000
  timesteps_total: 6660000
  training_iteration: 1332
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11690 s, 1332 iter, 6660000 ts, 375 rew

agent-1: 46.39999999738338
agent-2: 42.39999999738337
agent-3: 43.39999999738337
agent-4: 44.39999999738337
agent-5: 39.39999999738338
Extrinsic Rewards:
8
4
5
6
1
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-43-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 375.59690976672834
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1332
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.726
    dispatch_time_ms: 6.415
    learner:
      cur_lr: 0.0009164439979940653
      grad_gnorm: 40.0
      policy_entropy: 23.895368576049805
      policy_loss: 41.50440216064453
      var_gnorm: 23.062393188476562
      vf_explained_var: 0.0
      vf_loss: 63.166404724121094
    num_steps_sampled: 6665000
    num_steps_trained: 6665000
    wait_time_ms: 74.95
  iterations_since_restore: 1333
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11699.15315937996
  time_this_iter_s: 8.480140209197998
  time_total_s: 11699.15315937996
  timestamp: 1594860238
  timesteps_since_restore: 6665000
  timesteps_this_iter: 5000
  timesteps_total: 6665000
  training_iteration: 1333
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11699 s, 1333 iter, 6665000 ts, 376 rew

agent-1: 45.39999999890637
agent-2: 41.39999999890637
agent-3: 41.39999999890637
agent-4: 47.39999999890637
agent-5: 40.39999999890637
Extrinsic Rewards:
7
3
3
9
2
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.3
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 376.31690976676674
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1333
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.85
    dispatch_time_ms: 7.566
    learner:
      cur_lr: 0.0009161109919659793
      grad_gnorm: 18.295425415039062
      policy_entropy: 21.94886016845703
      policy_loss: -1.5671865940093994
      var_gnorm: 23.0711612701416
      vf_explained_var: 0.0
      vf_loss: 0.24874266982078552
    num_steps_sampled: 6670000
    num_steps_trained: 6670000
    wait_time_ms: 73.853
  iterations_since_restore: 1334
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11707.734183549881
  time_this_iter_s: 8.581024169921875
  time_total_s: 11707.734183549881
  timestamp: 1594860247
  timesteps_since_restore: 6670000
  timesteps_this_iter: 5000
  timesteps_total: 6670000
  training_iteration: 1334
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11707 s, 1334 iter, 6670000 ts, 376 rew

agent-1: 59.59999993684258
agent-2: 67.59999993684255
agent-3: 69.59999993684252
agent-4: 67.59999993684255
agent-5: 59.59999993684258
Extrinsic Rewards:
2
10
12
10
2
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.3111111111111111
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 377.3969097638034
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1334
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.594
    dispatch_time_ms: 6.095
    learner:
      cur_lr: 0.0009157779859378934
      grad_gnorm: 40.0
      policy_entropy: 16.330265045166016
      policy_loss: 43.560874938964844
      var_gnorm: 23.0682430267334
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 112.71267700195312
    num_steps_sampled: 6675000
    num_steps_trained: 6675000
    wait_time_ms: 75.195
  iterations_since_restore: 1335
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11716.211062669754
  time_this_iter_s: 8.476879119873047
  time_total_s: 11716.211062669754
  timestamp: 1594860256
  timesteps_since_restore: 6675000
  timesteps_this_iter: 5000
  timesteps_total: 6675000
  training_iteration: 1335
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11716 s, 1335 iter, 6675000 ts, 377 rew

agent-1: 33.59999999911951
agent-2: 34.599999999119504
agent-3: 39.599999999119476
agent-4: 41.599999999119476
agent-5: 39.599999999119476
Extrinsic Rewards:
0
1
6
8
6
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 376.7669097640235
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1335
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.531
    dispatch_time_ms: 5.485
    learner:
      cur_lr: 0.0009154449799098074
      grad_gnorm: 33.151695251464844
      policy_entropy: 19.87750816345215
      policy_loss: -2.4467217922210693
      var_gnorm: 23.062549591064453
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.8375279903411865
    num_steps_sampled: 6680000
    num_steps_trained: 6680000
    wait_time_ms: 78.501
  iterations_since_restore: 1336
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11724.700639247894
  time_this_iter_s: 8.489576578140259
  time_total_s: 11724.700639247894
  timestamp: 1594860264
  timesteps_since_restore: 6680000
  timesteps_this_iter: 5000
  timesteps_total: 6680000
  training_iteration: 1336
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11724 s, 1336 iter, 6680000 ts, 377 rew

agent-1: 74.19999996889798
agent-2: 69.19999996889797
agent-3: 79.199999968898
agent-4: 82.19999996889804
agent-5: 73.19999996889798
Extrinsic Rewards:
7
2
12
15
6
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.3047619047619048
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1349.1728191261573
  episode_reward_mean: 368.13872691033407
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1336
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 7.187
    learner:
      cur_lr: 0.0009151119738817215
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.87097930908203
      policy_loss: 11.57664680480957
      var_gnorm: 23.06368637084961
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.22005558013916
    num_steps_sampled: 6685000
    num_steps_trained: 6685000
    wait_time_ms: 73.761
  iterations_since_restore: 1337
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11733.120168209076
  time_this_iter_s: 8.41952896118164
  time_total_s: 11733.120168209076
  timestamp: 1594860272
  timesteps_since_restore: 6685000
  timesteps_this_iter: 5000
  timesteps_total: 6685000
  training_iteration: 1337
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11733 s, 1337 iter, 6685000 ts, 368 rew

agent-1: 112.19999401998076
agent-2: 130.19999401998086
agent-3: 130.19999401998083
agent-4: 113.19999401998079
agent-5: 117.19999401998076
Extrinsic Rewards:
5
23
23
6
10
Sum Reward: 67
Avg Reward: 13.4
Min Reward: 5
Max Reward: 23
Gini Coefficient: 0.3164179104477612
20:20 Ratio: 4.6
Max-min Ratio: 4.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9829033540764
  episode_reward_mean: 360.6769984200717
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1337
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.8
    dispatch_time_ms: 478.702
    learner:
      cur_lr: 0.0009147790260612965
      grad_gnorm: 20.436355590820312
      policy_entropy: 19.54885482788086
      policy_loss: -0.8629087805747986
      var_gnorm: 23.064144134521484
      vf_explained_var: 0.0
      vf_loss: 0.2823054790496826
    num_steps_sampled: 6690000
    num_steps_trained: 6690000
    wait_time_ms: 62.566
  iterations_since_restore: 1338
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11746.206592321396
  time_this_iter_s: 13.086424112319946
  time_total_s: 11746.206592321396
  timestamp: 1594860286
  timesteps_since_restore: 6690000
  timesteps_this_iter: 5000
  timesteps_total: 6690000
  training_iteration: 1338
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11746 s, 1338 iter, 6690000 ts, 361 rew

agent-1: 42.39999999821114
agent-2: 48.39999999821116
agent-3: 41.39999999821113
agent-4: 39.39999999821114
agent-5: 44.39999999821113
Extrinsic Rewards:
4
10
3
1
6
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.35
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-44-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 352.3971693864415
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1338
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.476
    dispatch_time_ms: 22.491
    learner:
      cur_lr: 0.0009144460200332105
      grad_gnorm: 40.000003814697266
      policy_entropy: 22.642742156982422
      policy_loss: 77.15838623046875
      var_gnorm: 23.0660343170166
      vf_explained_var: 0.0
      vf_loss: 279.0984802246094
    num_steps_sampled: 6695000
    num_steps_trained: 6695000
    wait_time_ms: 56.184
  iterations_since_restore: 1339
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11754.93290901184
  time_this_iter_s: 8.726316690444946
  time_total_s: 11754.93290901184
  timestamp: 1594860294
  timesteps_since_restore: 6695000
  timesteps_this_iter: 5000
  timesteps_total: 6695000
  training_iteration: 1339
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11754 s, 1339 iter, 6695000 ts, 352 rew

agent-1: 28.799999999406896
agent-2: 39.799999999406914
agent-3: 29.799999999406896
agent-4: 33.79999999940693
agent-5: 29.799999999406896
Extrinsic Rewards:
0
11
1
5
1
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.5777777777777777
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 348.79716956068864
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1339
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.803
    dispatch_time_ms: 21.763
    learner:
      cur_lr: 0.0009141130140051246
      grad_gnorm: 26.883790969848633
      policy_entropy: 26.895580291748047
      policy_loss: -3.326000452041626
      var_gnorm: 23.07134246826172
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.5595462322235107
    num_steps_sampled: 6700000
    num_steps_trained: 6700000
    wait_time_ms: 68.669
  iterations_since_restore: 1340
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11763.547747850418
  time_this_iter_s: 8.61483883857727
  time_total_s: 11763.547747850418
  timestamp: 1594860311
  timesteps_since_restore: 6700000
  timesteps_this_iter: 5000
  timesteps_total: 6700000
  training_iteration: 1340
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11763 s, 1340 iter, 6700000 ts, 349 rew

agent-1: 64.199999985505
agent-2: 63.19999998550513
agent-3: 66.19999998550503
agent-4: 70.19999998550509
agent-5: 69.19999998550507
Extrinsic Rewards:
5
4
7
11
10
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 4
Max Reward: 11
Gini Coefficient: 0.20540540540540542
20:20 Ratio: 2.75
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 344.29857437642767
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1340
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.639
    dispatch_time_ms: 30.971
    learner:
      cur_lr: 0.0009137800079770386
      grad_gnorm: 15.235921859741211
      policy_entropy: 14.69007682800293
      policy_loss: -0.5124821662902832
      var_gnorm: 23.07662010192871
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.1795991212129593
    num_steps_sampled: 6705000
    num_steps_trained: 6705000
    wait_time_ms: 56.69
  iterations_since_restore: 1341
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11772.636090755463
  time_this_iter_s: 9.088342905044556
  time_total_s: 11772.636090755463
  timestamp: 1594860320
  timesteps_since_restore: 6705000
  timesteps_this_iter: 5000
  timesteps_total: 6705000
  training_iteration: 1341
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11772 s, 1341 iter, 6705000 ts, 344 rew

agent-1: 93.79999905644803
agent-2: 103.79999905644806
agent-3: 87.79999905644806
agent-4: 100.79999905644803
agent-5: 90.79999905644806
Extrinsic Rewards:
9
19
3
16
6
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 3
Max Reward: 19
Gini Coefficient: 0.3169811320754717
20:20 Ratio: 6.333333333333333
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 343.48857439469475
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1341
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.938
    dispatch_time_ms: 8.186
    learner:
      cur_lr: 0.0009134470019489527
      grad_gnorm: 40.0
      policy_entropy: 33.306190490722656
      policy_loss: -6.715847015380859
      var_gnorm: 23.10130500793457
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.3377115726470947
    num_steps_sampled: 6710000
    num_steps_trained: 6710000
    wait_time_ms: 73.917
  iterations_since_restore: 1342
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11781.506085157394
  time_this_iter_s: 8.869994401931763
  time_total_s: 11781.506085157394
  timestamp: 1594860329
  timesteps_since_restore: 6710000
  timesteps_this_iter: 5000
  timesteps_total: 6710000
  training_iteration: 1342
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11781 s, 1342 iter, 6710000 ts, 343 rew

agent-1: 102.19999720510434
agent-2: 100.19999720510431
agent-3: 103.19999720510432
agent-4: 102.19999720510431
agent-5: 105.19999720510432
Extrinsic Rewards:
11
9
12
11
14
Sum Reward: 57
Avg Reward: 11.4
Min Reward: 9
Max Reward: 14
Gini Coefficient: 0.07719298245614035
20:20 Ratio: 1.5555555555555556
Max-min Ratio: 1.5555555555555556
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 346.9085742549906
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1342
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.384
    dispatch_time_ms: 5.416
    learner:
      cur_lr: 0.0009131139959208667
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.97174835205078
      policy_loss: 8.58492374420166
      var_gnorm: 23.079235076904297
      vf_explained_var: 0.0
      vf_loss: 6.294354438781738
    num_steps_sampled: 6715000
    num_steps_trained: 6715000
    wait_time_ms: 77.249
  iterations_since_restore: 1343
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11790.06549525261
  time_this_iter_s: 8.559410095214844
  time_total_s: 11790.06549525261
  timestamp: 1594860338
  timesteps_since_restore: 6715000
  timesteps_this_iter: 5000
  timesteps_total: 6715000
  training_iteration: 1343
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11790 s, 1343 iter, 6715000 ts, 347 rew

agent-1: 64.3999999950425
agent-2: 56.39999999504254
agent-3: 61.39999999504253
agent-4: 67.39999999504248
agent-5: 56.39999999504254
Extrinsic Rewards:
10
2
7
13
2
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.35294117647058826
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 345.0185744085876
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1343
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.223
    dispatch_time_ms: 8.222
    learner:
      cur_lr: 0.0009127809898927808
      grad_gnorm: 40.000003814697266
      policy_entropy: 31.113719940185547
      policy_loss: -8.96961784362793
      var_gnorm: 23.074167251586914
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.6217248439788818
    num_steps_sampled: 6720000
    num_steps_trained: 6720000
    wait_time_ms: 76.196
  iterations_since_restore: 1344
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11798.534627199173
  time_this_iter_s: 8.46913194656372
  time_total_s: 11798.534627199173
  timestamp: 1594860346
  timesteps_since_restore: 6720000
  timesteps_this_iter: 5000
  timesteps_total: 6720000
  training_iteration: 1344
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11798 s, 1344 iter, 6720000 ts, 345 rew

agent-1: 103.9999686653581
agent-2: 96.99996866535808
agent-3: 93.99996866535807
agent-4: 93.99996866535808
agent-5: 105.9999686653581
Extrinsic Rewards:
16
9
6
6
18
Sum Reward: 55
Avg Reward: 11.0
Min Reward: 6
Max Reward: 18
Gini Coefficient: 0.24727272727272728
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-45-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 348.07857284190476
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1344
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.084
    dispatch_time_ms: 6.835
    learner:
      cur_lr: 0.0009124479838646948
      grad_gnorm: 39.999996185302734
      policy_entropy: 34.32162094116211
      policy_loss: 40.0302734375
      var_gnorm: 23.060821533203125
      vf_explained_var: 0.0
      vf_loss: 39.65003967285156
    num_steps_sampled: 6725000
    num_steps_trained: 6725000
    wait_time_ms: 75.31
  iterations_since_restore: 1345
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11807.178488492966
  time_this_iter_s: 8.643861293792725
  time_total_s: 11807.178488492966
  timestamp: 1594860355
  timesteps_since_restore: 6725000
  timesteps_this_iter: 5000
  timesteps_total: 6725000
  training_iteration: 1345
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11807 s, 1345 iter, 6725000 ts, 348 rew

agent-1: 48.59999999704492
agent-2: 47.599999997044925
agent-3: 51.599999997044925
agent-4: 43.599999997044925
agent-5: 42.599999997044925
Extrinsic Rewards:
7
6
10
2
1
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.35384615384615387
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 347.17857284231707
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1345
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 9.798
    learner:
      cur_lr: 0.0009121149778366089
      grad_gnorm: 40.0
      policy_entropy: 31.169139862060547
      policy_loss: 24.45453453063965
      var_gnorm: 23.069658279418945
      vf_explained_var: 0.0
      vf_loss: 22.927749633789062
    num_steps_sampled: 6730000
    num_steps_trained: 6730000
    wait_time_ms: 75.875
  iterations_since_restore: 1346
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11815.90082859993
  time_this_iter_s: 8.722340106964111
  time_total_s: 11815.90082859993
  timestamp: 1594860364
  timesteps_since_restore: 6730000
  timesteps_this_iter: 5000
  timesteps_total: 6730000
  training_iteration: 1346
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11815 s, 1346 iter, 6730000 ts, 347 rew

agent-1: 65.39999999236896
agent-2: 54.39999999236894
agent-3: 62.39999999236894
agent-4: 61.39999999236894
agent-5: 62.399999992368926
Extrinsic Rewards:
11
0
8
7
8
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.27058823529411763
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 347.6285728422453
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1346
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.753
    dispatch_time_ms: 7.19
    learner:
      cur_lr: 0.0009117819718085229
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.242534637451172
      policy_loss: 8.517058372497559
      var_gnorm: 23.060359954833984
      vf_explained_var: 0.0
      vf_loss: 10.676682472229004
    num_steps_sampled: 6735000
    num_steps_trained: 6735000
    wait_time_ms: 75.529
  iterations_since_restore: 1347
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11824.44787311554
  time_this_iter_s: 8.547044515609741
  time_total_s: 11824.44787311554
  timestamp: 1594860372
  timesteps_since_restore: 6735000
  timesteps_this_iter: 5000
  timesteps_total: 6735000
  training_iteration: 1347
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11824 s, 1347 iter, 6735000 ts, 348 rew

agent-1: 86.39999974387268
agent-2: 95.39999974387268
agent-3: 83.39999974387271
agent-4: 88.39999974387267
agent-5: 87.39999974387268
Extrinsic Rewards:
8
17
5
10
9
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 5
Max Reward: 17
Gini Coefficient: 0.21224489795918366
20:20 Ratio: 3.4
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 346.9085728431154
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1347
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.64
    dispatch_time_ms: 5.995
    learner:
      cur_lr: 0.0009114490239880979
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.98895263671875
      policy_loss: 31.065649032592773
      var_gnorm: 23.06179428100586
      vf_explained_var: 0.0
      vf_loss: 102.60575103759766
    num_steps_sampled: 6740000
    num_steps_trained: 6740000
    wait_time_ms: 78.11
  iterations_since_restore: 1348
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11833.105688333511
  time_this_iter_s: 8.657815217971802
  time_total_s: 11833.105688333511
  timestamp: 1594860381
  timesteps_since_restore: 6740000
  timesteps_this_iter: 5000
  timesteps_total: 6740000
  training_iteration: 1348
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11833 s, 1348 iter, 6740000 ts, 347 rew

agent-1: 67.19999999577725
agent-2: 66.19999999577725
agent-3: 67.19999999577725
agent-4: 65.19999999577728
agent-5: 67.19999999577723
Extrinsic Rewards:
8
7
8
6
8
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 6
Max Reward: 8
Gini Coefficient: 0.05405405405405406
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 347.3585728430441
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1348
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.856
    dispatch_time_ms: 7.934
    learner:
      cur_lr: 0.000911116017960012
      grad_gnorm: 39.999996185302734
      policy_entropy: 14.59730339050293
      policy_loss: 13.62765884399414
      var_gnorm: 23.060651779174805
      vf_explained_var: 0.0
      vf_loss: 49.77606201171875
    num_steps_sampled: 6745000
    num_steps_trained: 6745000
    wait_time_ms: 73.646
  iterations_since_restore: 1349
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11841.815319299698
  time_this_iter_s: 8.709630966186523
  time_total_s: 11841.815319299698
  timestamp: 1594860390
  timesteps_since_restore: 6745000
  timesteps_this_iter: 5000
  timesteps_total: 6745000
  training_iteration: 1349
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11841 s, 1349 iter, 6745000 ts, 347 rew

agent-1: 125.79999309810218
agent-2: 117.79999309810218
agent-3: 122.79999309810218
agent-4: 121.79999309810215
agent-5: 123.79999309810218
Extrinsic Rewards:
17
9
14
13
15
Sum Reward: 68
Avg Reward: 13.6
Min Reward: 9
Max Reward: 17
Gini Coefficient: 0.10588235294117647
20:20 Ratio: 1.8888888888888888
Max-min Ratio: 1.8888888888888888
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 351.5885724980214
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1349
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.33
    dispatch_time_ms: 9.431
    learner:
      cur_lr: 0.000910783011931926
      grad_gnorm: 39.99999237060547
      policy_entropy: 21.226970672607422
      policy_loss: -4.638488292694092
      var_gnorm: 23.069326400756836
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 1.436635971069336
    num_steps_sampled: 6750000
    num_steps_trained: 6750000
    wait_time_ms: 76.316
  iterations_since_restore: 1350
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11850.4166097641
  time_this_iter_s: 8.601290464401245
  time_total_s: 11850.4166097641
  timestamp: 1594860398
  timesteps_since_restore: 6750000
  timesteps_this_iter: 5000
  timesteps_total: 6750000
  training_iteration: 1350
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11850 s, 1350 iter, 6750000 ts, 352 rew

agent-1: 103.19999920029737
agent-2: 107.19999920029737
agent-3: 114.19999920029738
agent-4: 129.19999920029778
agent-5: 104.19999920029737
Extrinsic Rewards:
4
8
15
30
5
Sum Reward: 62
Avg Reward: 12.4
Min Reward: 4
Max Reward: 30
Gini Coefficient: 0.4
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 355.3685724580671
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1350
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.903
    dispatch_time_ms: 8.374
    learner:
      cur_lr: 0.0009104500059038401
      grad_gnorm: 15.01622486114502
      policy_entropy: 30.725421905517578
      policy_loss: -2.4692320823669434
      var_gnorm: 23.066633224487305
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.15694506466388702
    num_steps_sampled: 6755000
    num_steps_trained: 6755000
    wait_time_ms: 74.866
  iterations_since_restore: 1351
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11859.16277885437
  time_this_iter_s: 8.746169090270996
  time_total_s: 11859.16277885437
  timestamp: 1594860407
  timesteps_since_restore: 6755000
  timesteps_this_iter: 5000
  timesteps_total: 6755000
  training_iteration: 1351
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11859 s, 1351 iter, 6755000 ts, 355 rew

agent-1: 81.79999997080779
agent-2: 81.7999999708078
agent-3: 83.79999997080779
agent-4: 93.7999999708078
agent-5: 90.79999997080783
Extrinsic Rewards:
5
5
7
17
14
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 5
Max Reward: 17
Gini Coefficient: 0.275
20:20 Ratio: 3.4
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-46-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 357.97857245668774
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1351
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.134
    dispatch_time_ms: 7.728
    learner:
      cur_lr: 0.0009101169998757541
      grad_gnorm: 21.074016571044922
      policy_entropy: 20.292320251464844
      policy_loss: -1.8189079761505127
      var_gnorm: 23.066871643066406
      vf_explained_var: 0.0
      vf_loss: 0.341614693403244
    num_steps_sampled: 6760000
    num_steps_trained: 6760000
    wait_time_ms: 75.667
  iterations_since_restore: 1352
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11867.739827394485
  time_this_iter_s: 8.577048540115356
  time_total_s: 11867.739827394485
  timestamp: 1594860416
  timesteps_since_restore: 6760000
  timesteps_this_iter: 5000
  timesteps_total: 6760000
  training_iteration: 1352
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11867 s, 1352 iter, 6760000 ts, 358 rew

agent-1: 33.19999999948765
agent-2: 34.19999999948766
agent-3: 27.19999999948765
agent-4: 28.19999999948765
agent-5: 30.19999999948765
Extrinsic Rewards:
6
7
0
1
3
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4470588235294118
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 357.07857245719174
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1352
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.526
    dispatch_time_ms: 6.614
    learner:
      cur_lr: 0.0009097839938476682
      grad_gnorm: 17.148468017578125
      policy_entropy: 18.67929458618164
      policy_loss: -1.224022626876831
      var_gnorm: 23.06111717224121
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.22714871168136597
    num_steps_sampled: 6765000
    num_steps_trained: 6765000
    wait_time_ms: 82.749
  iterations_since_restore: 1353
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11876.471086740494
  time_this_iter_s: 8.7312593460083
  time_total_s: 11876.471086740494
  timestamp: 1594860424
  timesteps_since_restore: 6765000
  timesteps_this_iter: 5000
  timesteps_total: 6765000
  training_iteration: 1353
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11876 s, 1353 iter, 6765000 ts, 357 rew

agent-1: 113.1999996560547
agent-2: 108.1999996560547
agent-3: 110.1999996560547
agent-4: 106.1999996560547
agent-5: 120.19999965605473
Extrinsic Rewards:
14
9
11
7
21
Sum Reward: 62
Avg Reward: 12.4
Min Reward: 7
Max Reward: 21
Gini Coefficient: 0.2129032258064516
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 360.22857244007565
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1353
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.855
    dispatch_time_ms: 8.789
    learner:
      cur_lr: 0.0009094509878195822
      grad_gnorm: 40.0
      policy_entropy: 11.972223281860352
      policy_loss: 4.594590187072754
      var_gnorm: 23.06206703186035
      vf_explained_var: 0.0
      vf_loss: 32.389678955078125
    num_steps_sampled: 6770000
    num_steps_trained: 6770000
    wait_time_ms: 74.212
  iterations_since_restore: 1354
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11885.1416285038
  time_this_iter_s: 8.670541763305664
  time_total_s: 11885.1416285038
  timestamp: 1594860433
  timesteps_since_restore: 6770000
  timesteps_this_iter: 5000
  timesteps_total: 6770000
  training_iteration: 1354
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11885 s, 1354 iter, 6770000 ts, 360 rew

agent-1: 66.5999999868409
agent-2: 73.59999998684096
agent-3: 76.59999998684094
agent-4: 79.59999998684097
agent-5: 72.59999998684094
Extrinsic Rewards:
1
8
11
14
7
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.2926829268292683
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 361.39857243956
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1354
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.921
    dispatch_time_ms: 7.433
    learner:
      cur_lr: 0.0009091179817914963
      grad_gnorm: 10.43947696685791
      policy_entropy: 30.29179573059082
      policy_loss: -0.8963346481323242
      var_gnorm: 23.063142776489258
      vf_explained_var: 0.0
      vf_loss: 0.07466057687997818
    num_steps_sampled: 6775000
    num_steps_trained: 6775000
    wait_time_ms: 76.402
  iterations_since_restore: 1355
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11893.705354690552
  time_this_iter_s: 8.56372618675232
  time_total_s: 11893.705354690552
  timestamp: 1594860442
  timesteps_since_restore: 6775000
  timesteps_this_iter: 5000
  timesteps_total: 6775000
  training_iteration: 1355
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11893 s, 1355 iter, 6775000 ts, 361 rew

agent-1: 182.57871754189915
agent-2: 187.57871754189912
agent-3: 182.57871754189918
agent-4: 170.5787175418991
agent-5: 185.57871754189915
Extrinsic Rewards:
21
26
21
9
24
Sum Reward: 101
Avg Reward: 20.2
Min Reward: 9
Max Reward: 26
Gini Coefficient: 0.14653465346534653
20:20 Ratio: 2.888888888888889
Max-min Ratio: 2.888888888888889
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 368.4175083167717
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1355
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.724
    dispatch_time_ms: 6.411
    learner:
      cur_lr: 0.0009087849757634103
      grad_gnorm: 22.85407066345215
      policy_entropy: 25.08019256591797
      policy_loss: -3.128216028213501
      var_gnorm: 23.056596755981445
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.4004402756690979
    num_steps_sampled: 6780000
    num_steps_trained: 6780000
    wait_time_ms: 77.47
  iterations_since_restore: 1356
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11902.421932697296
  time_this_iter_s: 8.716578006744385
  time_total_s: 11902.421932697296
  timestamp: 1594860450
  timesteps_since_restore: 6780000
  timesteps_this_iter: 5000
  timesteps_total: 6780000
  training_iteration: 1356
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11902 s, 1356 iter, 6780000 ts, 368 rew

agent-1: 36.999999999266166
agent-2: 34.99999999926616
agent-3: 35.999999999266166
agent-4: 36.999999999266166
agent-5: 34.99999999926615
Extrinsic Rewards:
5
3
4
5
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 3
Max Reward: 5
Gini Coefficient: 0.12
20:20 Ratio: 1.6666666666666667
Max-min Ratio: 1.6666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 367.24750831707547
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1356
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.589
    dispatch_time_ms: 6.596
    learner:
      cur_lr: 0.0009084520279429853
      grad_gnorm: 11.715073585510254
      policy_entropy: 33.56941223144531
      policy_loss: -1.725568413734436
      var_gnorm: 23.055110931396484
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.10623332113027573
    num_steps_sampled: 6785000
    num_steps_trained: 6785000
    wait_time_ms: 76.387
  iterations_since_restore: 1357
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11911.082739114761
  time_this_iter_s: 8.66080641746521
  time_total_s: 11911.082739114761
  timestamp: 1594860459
  timesteps_since_restore: 6785000
  timesteps_this_iter: 5000
  timesteps_total: 6785000
  training_iteration: 1357
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11911 s, 1357 iter, 6785000 ts, 367 rew

agent-1: 49.99999998838294
agent-2: 56.99999998838294
agent-3: 56.99999998838294
agent-4: 50.999999988382925
agent-5: 54.999999988382925
Extrinsic Rewards:
2
9
9
3
7
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 363.8275083710924
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1357
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.599
    dispatch_time_ms: 8.654
    learner:
      cur_lr: 0.0009081190219148993
      grad_gnorm: 10.248520851135254
      policy_entropy: 20.274639129638672
      policy_loss: -1.04970383644104
      var_gnorm: 23.05077362060547
      vf_explained_var: 0.0
      vf_loss: 0.08127550780773163
    num_steps_sampled: 6790000
    num_steps_trained: 6790000
    wait_time_ms: 73.944
  iterations_since_restore: 1358
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11919.677198410034
  time_this_iter_s: 8.594459295272827
  time_total_s: 11919.677198410034
  timestamp: 1594860468
  timesteps_since_restore: 6790000
  timesteps_this_iter: 5000
  timesteps_total: 6790000
  training_iteration: 1358
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11919 s, 1358 iter, 6790000 ts, 364 rew

agent-1: 33.39999999909727
agent-2: 36.39999999909727
agent-3: 36.39999999909727
agent-4: 34.399999999097254
agent-5: 30.399999999097272
Extrinsic Rewards:
3
6
6
4
0
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.3157894736842105
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-47-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 362.4775083717022
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1358
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.409
    dispatch_time_ms: 9.16
    learner:
      cur_lr: 0.0009077860158868134
      grad_gnorm: 10.727657318115234
      policy_entropy: 24.684146881103516
      policy_loss: -1.1749414205551147
      var_gnorm: 23.050458908081055
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.08903533220291138
    num_steps_sampled: 6795000
    num_steps_trained: 6795000
    wait_time_ms: 74.934
  iterations_since_restore: 1359
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11928.20753288269
  time_this_iter_s: 8.53033447265625
  time_total_s: 11928.20753288269
  timestamp: 1594860476
  timesteps_since_restore: 6795000
  timesteps_this_iter: 5000
  timesteps_total: 6795000
  training_iteration: 1359
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11928 s, 1359 iter, 6795000 ts, 362 rew

agent-1: 29.599999999477934
agent-2: 26.599999999477934
agent-3: 26.599999999477934
agent-4: 28.599999999477934
agent-5: 32.59999999947794
Extrinsic Rewards:
4
1
1
3
7
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.375
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 362.2075083717827
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1359
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.889
    dispatch_time_ms: 9.465
    learner:
      cur_lr: 0.0009074530098587275
      grad_gnorm: 22.714536666870117
      policy_entropy: 26.241756439208984
      policy_loss: -2.683751106262207
      var_gnorm: 23.052227020263672
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.3910421133041382
    num_steps_sampled: 6800000
    num_steps_trained: 6800000
    wait_time_ms: 75.04
  iterations_since_restore: 1360
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11936.882580041885
  time_this_iter_s: 8.675047159194946
  time_total_s: 11936.882580041885
  timestamp: 1594860485
  timesteps_since_restore: 6800000
  timesteps_this_iter: 5000
  timesteps_total: 6800000
  training_iteration: 1360
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11936 s, 1360 iter, 6800000 ts, 362 rew

agent-1: 81.39999985316012
agent-2: 98.39999985316012
agent-3: 100.39999985316012
agent-4: 79.39999985316014
agent-5: 81.39999985316012
Extrinsic Rewards:
3
20
22
1
3
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 1
Max Reward: 22
Gini Coefficient: 0.4816326530612245
20:20 Ratio: 22.0
Max-min Ratio: 22.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 364.00750836461987
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1360
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.621
    dispatch_time_ms: 6.226
    learner:
      cur_lr: 0.0009071200038306415
      grad_gnorm: 10.999053001403809
      policy_entropy: 33.306373596191406
      policy_loss: -1.563808798789978
      var_gnorm: 23.04742431640625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.09364847093820572
    num_steps_sampled: 6805000
    num_steps_trained: 6805000
    wait_time_ms: 77.297
  iterations_since_restore: 1361
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11945.438462018967
  time_this_iter_s: 8.555881977081299
  time_total_s: 11945.438462018967
  timestamp: 1594860494
  timesteps_since_restore: 6805000
  timesteps_this_iter: 5000
  timesteps_total: 6805000
  training_iteration: 1361
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11945 s, 1361 iter, 6805000 ts, 364 rew

agent-1: 46.999999998608516
agent-2: 39.99999999860851
agent-3: 45.99999999860852
agent-4: 48.999999998608516
agent-5: 42.99999999860851
Extrinsic Rewards:
7
0
6
9
3
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.352
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 360.6775084586013
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1361
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 6.872
    learner:
      cur_lr: 0.0009067869978025556
      grad_gnorm: 26.860612869262695
      policy_entropy: 32.981327056884766
      policy_loss: 4.119185924530029
      var_gnorm: 23.048648834228516
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.5734776854515076
    num_steps_sampled: 6810000
    num_steps_trained: 6810000
    wait_time_ms: 79.486
  iterations_since_restore: 1362
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11954.082292079926
  time_this_iter_s: 8.643830060958862
  time_total_s: 11954.082292079926
  timestamp: 1594860502
  timesteps_since_restore: 6810000
  timesteps_this_iter: 5000
  timesteps_total: 6810000
  training_iteration: 1362
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11954 s, 1362 iter, 6810000 ts, 361 rew

agent-1: 64.9999999732354
agent-2: 69.99999997323538
agent-3: 78.9999999732354
agent-4: 78.9999999732354
agent-5: 66.99999997323542
Extrinsic Rewards:
1
6
15
15
3
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 1
Max Reward: 15
Gini Coefficient: 0.4
20:20 Ratio: 15.0
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 358.1575095609725
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1362
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 5.853
    learner:
      cur_lr: 0.0009064539917744696
      grad_gnorm: 18.592479705810547
      policy_entropy: 29.907081604003906
      policy_loss: 2.9085001945495605
      var_gnorm: 23.047595977783203
      vf_explained_var: 0.0
      vf_loss: 0.2783065736293793
    num_steps_sampled: 6815000
    num_steps_trained: 6815000
    wait_time_ms: 78.748
  iterations_since_restore: 1363
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11962.654367923737
  time_this_iter_s: 8.572075843811035
  time_total_s: 11962.654367923737
  timestamp: 1594860511
  timesteps_since_restore: 6815000
  timesteps_this_iter: 5000
  timesteps_total: 6815000
  training_iteration: 1363
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11962 s, 1363 iter, 6815000 ts, 358 rew

agent-1: 71.399999892984
agent-2: 85.399999892984
agent-3: 72.39999989298398
agent-4: 80.39999989298401
agent-5: 86.39999989298397
Extrinsic Rewards:
1
15
2
10
16
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 1
Max Reward: 16
Gini Coefficient: 0.39090909090909093
20:20 Ratio: 16.0
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 358.0675095571735
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1363
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 6.706
    learner:
      cur_lr: 0.0009061209857463837
      grad_gnorm: 13.005250930786133
      policy_entropy: 22.040761947631836
      policy_loss: -1.5510509014129639
      var_gnorm: 23.04821014404297
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.13040900230407715
    num_steps_sampled: 6820000
    num_steps_trained: 6820000
    wait_time_ms: 80.372
  iterations_since_restore: 1364
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11971.33241558075
  time_this_iter_s: 8.67804765701294
  time_total_s: 11971.33241558075
  timestamp: 1594860520
  timesteps_since_restore: 6820000
  timesteps_this_iter: 5000
  timesteps_total: 6820000
  training_iteration: 1364
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11971 s, 1364 iter, 6820000 ts, 358 rew

agent-1: 33.59999999921939
agent-2: 37.59999999921938
agent-3: 39.59999999921938
agent-4: 42.59999999921936
agent-5: 35.5999999992194
Extrinsic Rewards:
0
4
6
9
2
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.41904761904761906
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 358.2475095571647
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1364
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.671
    dispatch_time_ms: 7.726
    learner:
      cur_lr: 0.0009057879797182977
      grad_gnorm: 5.470571517944336
      policy_entropy: 32.737003326416016
      policy_loss: 0.9341602921485901
      var_gnorm: 23.04703712463379
      vf_explained_var: 0.0
      vf_loss: 0.022152619436383247
    num_steps_sampled: 6825000
    num_steps_trained: 6825000
    wait_time_ms: 74.622
  iterations_since_restore: 1365
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11980.009103298187
  time_this_iter_s: 8.676687717437744
  time_total_s: 11980.009103298187
  timestamp: 1594860528
  timesteps_since_restore: 6825000
  timesteps_this_iter: 5000
  timesteps_total: 6825000
  training_iteration: 1365
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11980 s, 1365 iter, 6825000 ts, 358 rew

agent-1: 43.79999999883533
agent-2: 44.79999999883533
agent-3: 40.79999999883534
agent-4: 38.799999998835325
agent-5: 38.799999998835325
Extrinsic Rewards:
7
8
4
2
2
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2956521739130435
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-48-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 356.44750955834695
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1365
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.473
    dispatch_time_ms: 8.567
    learner:
      cur_lr: 0.0009054549736902118
      grad_gnorm: 10.43221378326416
      policy_entropy: 32.95170211791992
      policy_loss: -2.2233221530914307
      var_gnorm: 23.04708480834961
      vf_explained_var: 0.0
      vf_loss: 0.07898236811161041
    num_steps_sampled: 6830000
    num_steps_trained: 6830000
    wait_time_ms: 74.382
  iterations_since_restore: 1366
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 11988.632774829865
  time_this_iter_s: 8.623671531677246
  time_total_s: 11988.632774829865
  timestamp: 1594860537
  timesteps_since_restore: 6830000
  timesteps_this_iter: 5000
  timesteps_total: 6830000
  training_iteration: 1366
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 11988 s, 1366 iter, 6830000 ts, 356 rew

agent-1: 35.79999999947432
agent-2: 33.799999999474316
agent-3: 29.799999999474455
agent-4: 28.799999999474455
agent-5: 33.799999999474316
Extrinsic Rewards:
7
5
1
0
5
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 352.48750964290105
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1366
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.761
    dispatch_time_ms: 5.277
    learner:
      cur_lr: 0.0009051220258697867
      grad_gnorm: 22.529720306396484
      policy_entropy: 30.55328369140625
      policy_loss: 3.9262611865997314
      var_gnorm: 23.046672821044922
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.40638473629951477
    num_steps_sampled: 6835000
    num_steps_trained: 6835000
    wait_time_ms: 80.34
  iterations_since_restore: 1367
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12007.99143910408
  time_this_iter_s: 19.3586642742157
  time_total_s: 12007.99143910408
  timestamp: 1594860556
  timesteps_since_restore: 6835000
  timesteps_this_iter: 5000
  timesteps_total: 6835000
  training_iteration: 1367
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12007 s, 1367 iter, 6835000 ts, 352 rew

agent-1: 28.199999999350222
agent-2: 31.19999999935023
agent-3: 27.199999999350222
agent-4: 35.19999999935019
agent-5: 31.19999999935023
Extrinsic Rewards:
1
4
0
8
4
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4470588235294118
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 350.41750964412944
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1367
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.396
    dispatch_time_ms: 7.032
    learner:
      cur_lr: 0.0009047890198417008
      grad_gnorm: 9.926496505737305
      policy_entropy: 27.323638916015625
      policy_loss: -1.4532414674758911
      var_gnorm: 23.045061111450195
      vf_explained_var: 0.0
      vf_loss: 0.07379952818155289
    num_steps_sampled: 6840000
    num_steps_trained: 6840000
    wait_time_ms: 73.599
  iterations_since_restore: 1368
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12016.575710058212
  time_this_iter_s: 8.58427095413208
  time_total_s: 12016.575710058212
  timestamp: 1594860565
  timesteps_since_restore: 6840000
  timesteps_this_iter: 5000
  timesteps_total: 6840000
  training_iteration: 1368
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12016 s, 1368 iter, 6840000 ts, 350 rew

agent-1: 34.99999999886249
agent-2: 34.9999999988625
agent-3: 40.99999999886247
agent-4: 31.999999998862517
agent-5: 36.99999999886249
Extrinsic Rewards:
3
3
9
0
5
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 348.52750965691286
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1368
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.498
    dispatch_time_ms: 7.231
    learner:
      cur_lr: 0.0009044560138136148
      grad_gnorm: 40.0
      policy_entropy: 34.72754669189453
      policy_loss: 30.208770751953125
      var_gnorm: 23.049211502075195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 24.34967613220215
    num_steps_sampled: 6845000
    num_steps_trained: 6845000
    wait_time_ms: 76.219
  iterations_since_restore: 1369
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12025.127459049225
  time_this_iter_s: 8.551748991012573
  time_total_s: 12025.127459049225
  timestamp: 1594860574
  timesteps_since_restore: 6845000
  timesteps_this_iter: 5000
  timesteps_total: 6845000
  training_iteration: 1369
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12025 s, 1369 iter, 6845000 ts, 349 rew

agent-1: 28.19999999951326
agent-2: 27.19999999951326
agent-3: 33.1999999995132
agent-4: 32.19999999951321
agent-5: 32.1999999995132
Extrinsic Rewards:
1
0
6
5
5
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.3764705882352941
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 347.71750965703563
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1369
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.404
    dispatch_time_ms: 7.708
    learner:
      cur_lr: 0.0009041230077855289
      grad_gnorm: 11.94577407836914
      policy_entropy: 28.57110595703125
      policy_loss: -1.5234428644180298
      var_gnorm: 23.051132202148438
      vf_explained_var: 0.0
      vf_loss: 0.10833564400672913
    num_steps_sampled: 6850000
    num_steps_trained: 6850000
    wait_time_ms: 77.739
  iterations_since_restore: 1370
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12033.82977938652
  time_this_iter_s: 8.702320337295532
  time_total_s: 12033.82977938652
  timestamp: 1594860582
  timesteps_since_restore: 6850000
  timesteps_this_iter: 5000
  timesteps_total: 6850000
  training_iteration: 1370
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12033 s, 1370 iter, 6850000 ts, 348 rew

agent-1: 52.19999999395127
agent-2: 49.19999999395127
agent-3: 44.199999993951266
agent-4: 47.19999999395125
agent-5: 50.19999999395129
Extrinsic Rewards:
9
6
1
4
7
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.2814814814814815
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-49-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 346.1875103062604
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1370
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.887
    dispatch_time_ms: 7.279
    learner:
      cur_lr: 0.000903790001757443
      grad_gnorm: 13.42650318145752
      policy_entropy: 34.79074478149414
      policy_loss: -2.2860007286071777
      var_gnorm: 23.05113983154297
      vf_explained_var: 0.0
      vf_loss: 0.13659118115901947
    num_steps_sampled: 6855000
    num_steps_trained: 6855000
    wait_time_ms: 75.59
  iterations_since_restore: 1371
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12042.385310173035
  time_this_iter_s: 8.555530786514282
  time_total_s: 12042.385310173035
  timestamp: 1594860591
  timesteps_since_restore: 6855000
  timesteps_this_iter: 5000
  timesteps_total: 6855000
  training_iteration: 1371
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12042 s, 1371 iter, 6855000 ts, 346 rew

agent-1: 35.79999999941184
agent-2: 28.799999999411746
agent-3: 31.799999999411753
agent-4: 30.799999999411746
agent-5: 34.79999999941184
Extrinsic Rewards:
7
0
3
2
6
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 343.7575103486888
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1371
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.492
    dispatch_time_ms: 7.68
    learner:
      cur_lr: 0.000903456995729357
      grad_gnorm: 14.438029289245605
      policy_entropy: 33.791831970214844
      policy_loss: -2.6677629947662354
      var_gnorm: 23.04711151123047
      vf_explained_var: 0.0
      vf_loss: 0.1601380556821823
    num_steps_sampled: 6860000
    num_steps_trained: 6860000
    wait_time_ms: 73.416
  iterations_since_restore: 1372
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12051.060232877731
  time_this_iter_s: 8.674922704696655
  time_total_s: 12051.060232877731
  timestamp: 1594860600
  timesteps_since_restore: 6860000
  timesteps_this_iter: 5000
  timesteps_total: 6860000
  training_iteration: 1372
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12051 s, 1372 iter, 6860000 ts, 344 rew

agent-1: 58.199999993843335
agent-2: 56.199999993843335
agent-3: 61.199999993843335
agent-4: 55.199999993843335
agent-5: 57.19999999384335
Extrinsic Rewards:
7
5
10
4
6
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 4
Max Reward: 10
Gini Coefficient: 0.175
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 343.48751040685437
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1372
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 5.702
    learner:
      cur_lr: 0.0009031239897012711
      grad_gnorm: 26.890058517456055
      policy_entropy: 30.42620277404785
      policy_loss: 4.461307048797607
      var_gnorm: 23.043134689331055
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.5746657252311707
    num_steps_sampled: 6865000
    num_steps_trained: 6865000
    wait_time_ms: 81.049
  iterations_since_restore: 1373
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12059.635425806046
  time_this_iter_s: 8.575192928314209
  time_total_s: 12059.635425806046
  timestamp: 1594860608
  timesteps_since_restore: 6865000
  timesteps_this_iter: 5000
  timesteps_total: 6865000
  training_iteration: 1373
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12059 s, 1373 iter, 6865000 ts, 343 rew

agent-1: 45.99999999854355
agent-2: 41.99999999854355
agent-3: 50.99999999854354
agent-4: 39.99999999854355
agent-5: 45.99999999854355
Extrinsic Rewards:
6
2
11
0
6
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.416
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 338.732152157604
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1373
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.832
    dispatch_time_ms: 9.396
    learner:
      cur_lr: 0.0009027909836731851
      grad_gnorm: 17.318391799926758
      policy_entropy: 34.690818786621094
      policy_loss: -3.1853413581848145
      var_gnorm: 23.04300880432129
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.2294132262468338
    num_steps_sampled: 6870000
    num_steps_trained: 6870000
    wait_time_ms: 74.993
  iterations_since_restore: 1374
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12068.266559839249
  time_this_iter_s: 8.631134033203125
  time_total_s: 12068.266559839249
  timestamp: 1594860617
  timesteps_since_restore: 6870000
  timesteps_this_iter: 5000
  timesteps_total: 6870000
  training_iteration: 1374
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12068 s, 1374 iter, 6870000 ts, 339 rew

agent-1: 41.59999999831967
agent-2: 33.59999999831966
agent-3: 40.59999999831968
agent-4: 33.59999999831966
agent-5: 39.59999999831968
Extrinsic Rewards:
8
0
7
0
6
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4380952380952381
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 338.55215215846033
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1374
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.845
    dispatch_time_ms: 10.166
    learner:
      cur_lr: 0.0009024579776450992
      grad_gnorm: 40.0
      policy_entropy: 31.20453453063965
      policy_loss: 13.28238296508789
      var_gnorm: 23.042924880981445
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 5.995224475860596
    num_steps_sampled: 6875000
    num_steps_trained: 6875000
    wait_time_ms: 72.635
  iterations_since_restore: 1375
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12076.760406255722
  time_this_iter_s: 8.493846416473389
  time_total_s: 12076.760406255722
  timestamp: 1594860625
  timesteps_since_restore: 6875000
  timesteps_this_iter: 5000
  timesteps_total: 6875000
  training_iteration: 1375
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12076 s, 1375 iter, 6875000 ts, 339 rew

agent-1: 40.79999999741069
agent-2: 39.79999999741069
agent-3: 41.79999999741069
agent-4: 43.79999999741068
agent-5: 40.79999999741068
Extrinsic Rewards:
4
3
5
7
4
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.1565217391304348
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 337.6521521588347
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1375
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.913
    dispatch_time_ms: 11.613
    learner:
      cur_lr: 0.0009021249716170132
      grad_gnorm: 15.560613632202148
      policy_entropy: 33.13199234008789
      policy_loss: -2.772249937057495
      var_gnorm: 23.04290199279785
      vf_explained_var: 0.0
      vf_loss: 0.15935319662094116
    num_steps_sampled: 6880000
    num_steps_trained: 6880000
    wait_time_ms: 72.818
  iterations_since_restore: 1376
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12085.382299423218
  time_this_iter_s: 8.621893167495728
  time_total_s: 12085.382299423218
  timestamp: 1594860634
  timesteps_since_restore: 6880000
  timesteps_this_iter: 5000
  timesteps_total: 6880000
  training_iteration: 1376
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12085 s, 1376 iter, 6880000 ts, 338 rew

agent-1: 61.39999996525433
agent-2: 60.39999996525433
agent-3: 62.39999996525433
agent-4: 62.39999996525433
agent-5: 59.39999996525433
Extrinsic Rewards:
7
6
8
8
5
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 5
Max Reward: 8
Gini Coefficient: 0.09411764705882353
20:20 Ratio: 1.6
Max-min Ratio: 1.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 338.64215215721725
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1376
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 7.383
    learner:
      cur_lr: 0.0009017920237965882
      grad_gnorm: 40.0
      policy_entropy: 19.075904846191406
      policy_loss: 26.284690856933594
      var_gnorm: 23.04384994506836
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 100.34857940673828
    num_steps_sampled: 6885000
    num_steps_trained: 6885000
    wait_time_ms: 75.849
  iterations_since_restore: 1377
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12094.02612709999
  time_this_iter_s: 8.643827676773071
  time_total_s: 12094.02612709999
  timestamp: 1594860643
  timesteps_since_restore: 6885000
  timesteps_this_iter: 5000
  timesteps_total: 6885000
  training_iteration: 1377
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12094 s, 1377 iter, 6885000 ts, 339 rew

agent-1: 30.799999999512444
agent-2: 31.799999999512437
agent-3: 31.799999999512437
agent-4: 32.799999999512416
agent-5: 34.79999999951242
Extrinsic Rewards:
2
3
3
4
6
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.2
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-50-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 338.1021521573127
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1377
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.081
    dispatch_time_ms: 7.523
    learner:
      cur_lr: 0.0009014590177685022
      grad_gnorm: 40.0
      policy_entropy: 24.875774383544922
      policy_loss: -6.89531946182251
      var_gnorm: 23.0474796295166
      vf_explained_var: 0.0
      vf_loss: 1.5826201438903809
    num_steps_sampled: 6890000
    num_steps_trained: 6890000
    wait_time_ms: 78.99
  iterations_since_restore: 1378
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12102.621624708176
  time_this_iter_s: 8.595497608184814
  time_total_s: 12102.621624708176
  timestamp: 1594860651
  timesteps_since_restore: 6890000
  timesteps_this_iter: 5000
  timesteps_total: 6890000
  training_iteration: 1378
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12102 s, 1378 iter, 6890000 ts, 338 rew

agent-1: 108.7999990136866
agent-2: 109.79999901368663
agent-3: 117.7999990136866
agent-4: 113.7999990136866
agent-5: 116.7999990136866
Extrinsic Rewards:
8
9
17
13
16
Sum Reward: 63
Avg Reward: 12.6
Min Reward: 8
Max Reward: 17
Gini Coefficient: 0.15873015873015872
20:20 Ratio: 2.125
Max-min Ratio: 2.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 341.07215210809545
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1378
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.439
    dispatch_time_ms: 7.175
    learner:
      cur_lr: 0.0009011260117404163
      grad_gnorm: 10.757198333740234
      policy_entropy: 11.74479866027832
      policy_loss: -0.16968566179275513
      var_gnorm: 23.04480743408203
      vf_explained_var: 0.0
      vf_loss: 0.08468804508447647
    num_steps_sampled: 6895000
    num_steps_trained: 6895000
    wait_time_ms: 79.286
  iterations_since_restore: 1379
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12111.355896949768
  time_this_iter_s: 8.734272241592407
  time_total_s: 12111.355896949768
  timestamp: 1594860660
  timesteps_since_restore: 6895000
  timesteps_this_iter: 5000
  timesteps_total: 6895000
  training_iteration: 1379
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12111 s, 1379 iter, 6895000 ts, 341 rew

agent-1: 132.19999818009788
agent-2: 129.19999818009782
agent-3: 130.19999818009788
agent-4: 128.1999981800978
agent-5: 128.1999981800978
Extrinsic Rewards:
17
14
15
13
13
Sum Reward: 72
Avg Reward: 14.4
Min Reward: 13
Max Reward: 17
Gini Coefficient: 0.05555555555555555
20:20 Ratio: 1.3076923076923077
Max-min Ratio: 1.3076923076923077
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 345.4821520171986
  episode_reward_min: 134.99999999680438
  episodes_this_iter: 1
  episodes_total: 1379
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 9.227
    learner:
      cur_lr: 0.0009007930057123303
      grad_gnorm: 36.12464141845703
      policy_entropy: 30.730772018432617
      policy_loss: 6.01188325881958
      var_gnorm: 23.043434143066406
      vf_explained_var: 0.0
      vf_loss: 1.0265445709228516
    num_steps_sampled: 6900000
    num_steps_trained: 6900000
    wait_time_ms: 74.573
  iterations_since_restore: 1380
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12119.945050477982
  time_this_iter_s: 8.589153528213501
  time_total_s: 12119.945050477982
  timestamp: 1594860669
  timesteps_since_restore: 6900000
  timesteps_this_iter: 5000
  timesteps_total: 6900000
  training_iteration: 1380
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12119 s, 1380 iter, 6900000 ts, 345 rew

agent-1: 38.39999999937987
agent-2: 32.399999999379915
agent-3: 30.399999999379858
agent-4: 35.39999999937989
agent-5: 34.39999999937988
Extrinsic Rewards:
8
2
0
5
4
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 345.84215201719957
  episode_reward_min: 134.99999999837993
  episodes_this_iter: 1
  episodes_total: 1380
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 6.331
    learner:
      cur_lr: 0.0009004599996842444
      grad_gnorm: 14.740547180175781
      policy_entropy: 32.52389907836914
      policy_loss: -2.228743314743042
      var_gnorm: 23.053802490234375
      vf_explained_var: 0.0
      vf_loss: 0.16555055975914001
    num_steps_sampled: 6905000
    num_steps_trained: 6905000
    wait_time_ms: 74.017
  iterations_since_restore: 1381
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12128.522391796112
  time_this_iter_s: 8.577341318130493
  time_total_s: 12128.522391796112
  timestamp: 1594860677
  timesteps_since_restore: 6905000
  timesteps_this_iter: 5000
  timesteps_total: 6905000
  training_iteration: 1381
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12128 s, 1381 iter, 6905000 ts, 346 rew

agent-1: 88.99999994897496
agent-2: 92.99999994897497
agent-3: 93.99999994897496
agent-4: 86.99999994897499
agent-5: 86.99999994897499
Extrinsic Rewards:
9
13
14
7
7
Sum Reward: 50
Avg Reward: 10.0
Min Reward: 7
Max Reward: 14
Gini Coefficient: 0.16
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 347.3721520158218
  episode_reward_min: 134.99999999837993
  episodes_this_iter: 1
  episodes_total: 1381
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.734
    dispatch_time_ms: 9.475
    learner:
      cur_lr: 0.0009001269936561584
      grad_gnorm: 21.969181060791016
      policy_entropy: 28.50340461730957
      policy_loss: -3.63332200050354
      var_gnorm: 23.07285499572754
      vf_explained_var: 0.0
      vf_loss: 0.3243339955806732
    num_steps_sampled: 6910000
    num_steps_trained: 6910000
    wait_time_ms: 74.207
  iterations_since_restore: 1382
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12137.178035259247
  time_this_iter_s: 8.655643463134766
  time_total_s: 12137.178035259247
  timestamp: 1594860686
  timesteps_since_restore: 6910000
  timesteps_this_iter: 5000
  timesteps_total: 6910000
  training_iteration: 1382
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12137 s, 1382 iter, 6910000 ts, 347 rew

agent-1: 83.99999996107434
agent-2: 80.99999996107434
agent-3: 75.99999996107437
agent-4: 86.99999996107437
agent-5: 76.99999996107437
Extrinsic Rewards:
12
9
4
15
5
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 4
Max Reward: 15
Gini Coefficient: 0.2577777777777778
20:20 Ratio: 3.75
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 347.37215201521326
  episode_reward_min: 134.99999999837993
  episodes_this_iter: 1
  episodes_total: 1382
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.561
    dispatch_time_ms: 7.365
    learner:
      cur_lr: 0.0008997939876280725
      grad_gnorm: 13.223481178283691
      policy_entropy: 23.31984519958496
      policy_loss: -1.2012263536453247
      var_gnorm: 23.063236236572266
      vf_explained_var: 0.0
      vf_loss: 0.1346261352300644
    num_steps_sampled: 6915000
    num_steps_trained: 6915000
    wait_time_ms: 79.326
  iterations_since_restore: 1383
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12145.676314592361
  time_this_iter_s: 8.498279333114624
  time_total_s: 12145.676314592361
  timestamp: 1594860695
  timesteps_since_restore: 6915000
  timesteps_this_iter: 5000
  timesteps_total: 6915000
  training_iteration: 1383
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12145 s, 1383 iter, 6915000 ts, 347 rew

agent-1: 43.39999999841303
agent-2: 45.39999999841304
agent-3: 39.39999999841303
agent-4: 45.39999999841304
agent-5: 42.39999999841304
Extrinsic Rewards:
5
7
1
7
4
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.25
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 347.7321520151742
  episode_reward_min: 134.99999999837993
  episodes_this_iter: 1
  episodes_total: 1383
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 10.289
    learner:
      cur_lr: 0.0008994609815999866
      grad_gnorm: 24.10222053527832
      policy_entropy: 20.633445739746094
      policy_loss: -2.2996723651885986
      var_gnorm: 23.056238174438477
      vf_explained_var: 0.0
      vf_loss: 0.4492131173610687
    num_steps_sampled: 6920000
    num_steps_trained: 6920000
    wait_time_ms: 73.393
  iterations_since_restore: 1384
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12154.154381513596
  time_this_iter_s: 8.47806692123413
  time_total_s: 12154.154381513596
  timestamp: 1594860703
  timesteps_since_restore: 6920000
  timesteps_this_iter: 5000
  timesteps_total: 6920000
  training_iteration: 1384
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12154 s, 1384 iter, 6920000 ts, 348 rew

agent-1: 42.799999997218265
agent-2: 44.79999999721826
agent-3: 39.79999999721825
agent-4: 37.79999999721825
agent-5: 41.79999999721826
Extrinsic Rewards:
6
8
3
1
5
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.2956521739130435
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-51-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 348.45215201505124
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1384
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.482
    dispatch_time_ms: 7.984
    learner:
      cur_lr: 0.0008991279755719006
      grad_gnorm: 13.581270217895508
      policy_entropy: 20.469717025756836
      policy_loss: -0.8903619050979614
      var_gnorm: 23.05435562133789
      vf_explained_var: 0.0
      vf_loss: 0.13942795991897583
    num_steps_sampled: 6925000
    num_steps_trained: 6925000
    wait_time_ms: 74.327
  iterations_since_restore: 1385
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12162.660834789276
  time_this_iter_s: 8.506453275680542
  time_total_s: 12162.660834789276
  timestamp: 1594860712
  timesteps_since_restore: 6925000
  timesteps_this_iter: 5000
  timesteps_total: 6925000
  training_iteration: 1385
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12162 s, 1385 iter, 6925000 ts, 348 rew

agent-1: 55.19999997826005
agent-2: 62.19999997826006
agent-3: 59.19999997826006
agent-4: 54.19999997826006
agent-5: 57.19999997826006
Extrinsic Rewards:
4
11
8
3
6
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.25
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 348.81215201405286
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1385
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.531
    dispatch_time_ms: 10.324
    learner:
      cur_lr: 0.0008987950277514756
      grad_gnorm: 14.023320198059082
      policy_entropy: 34.80660629272461
      policy_loss: -2.4432125091552734
      var_gnorm: 23.0546932220459
      vf_explained_var: 0.0
      vf_loss: 0.14736826717853546
    num_steps_sampled: 6930000
    num_steps_trained: 6930000
    wait_time_ms: 71.73
  iterations_since_restore: 1386
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12171.200417995453
  time_this_iter_s: 8.539583206176758
  time_total_s: 12171.200417995453
  timestamp: 1594860720
  timesteps_since_restore: 6930000
  timesteps_this_iter: 5000
  timesteps_total: 6930000
  training_iteration: 1386
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12171 s, 1386 iter, 6930000 ts, 349 rew

agent-1: 30.399999999346406
agent-2: 34.39999999934643
agent-3: 35.39999999934642
agent-4: 34.39999999934643
agent-5: 36.39999999934645
Extrinsic Rewards:
0
4
5
4
6
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.2736842105263158
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 349.08215201404107
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1386
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.037
    dispatch_time_ms: 22.039
    learner:
      cur_lr: 0.0008984620217233896
      grad_gnorm: 40.0
      policy_entropy: 34.093074798583984
      policy_loss: 46.70816421508789
      var_gnorm: 23.054780960083008
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 55.209720611572266
    num_steps_sampled: 6935000
    num_steps_trained: 6935000
    wait_time_ms: 69.525
  iterations_since_restore: 1387
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12180.007270336151
  time_this_iter_s: 8.806852340698242
  time_total_s: 12180.007270336151
  timestamp: 1594860729
  timesteps_since_restore: 6935000
  timesteps_this_iter: 5000
  timesteps_total: 6935000
  training_iteration: 1387
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12180 s, 1387 iter, 6935000 ts, 349 rew

agent-1: 60.999999993091365
agent-2: 59.999999993091365
agent-3: 65.99999999309155
agent-4: 59.999999993091365
agent-5: 67.99999999309154
Extrinsic Rewards:
5
4
10
4
12
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.25142857142857145
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 350.4321520137931
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1387
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.065
    dispatch_time_ms: 35.387
    learner:
      cur_lr: 0.0008981290156953037
      grad_gnorm: 5.808652400970459
      policy_entropy: 25.75697898864746
      policy_loss: -2.1042890548706055
      var_gnorm: 23.04081916809082
      vf_explained_var: 0.0
      vf_loss: 0.07537785917520523
    num_steps_sampled: 6940000
    num_steps_trained: 6940000
    wait_time_ms: 63.681
  iterations_since_restore: 1388
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12189.119939565659
  time_this_iter_s: 9.112669229507446
  time_total_s: 12189.119939565659
  timestamp: 1594860738
  timesteps_since_restore: 6940000
  timesteps_this_iter: 5000
  timesteps_total: 6940000
  training_iteration: 1388
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12189 s, 1388 iter, 6940000 ts, 350 rew

agent-1: 85.79999996413896
agent-2: 76.79999996413895
agent-3: 73.79999996413895
agent-4: 77.79999996413895
agent-5: 72.79999996413893
Extrinsic Rewards:
17
8
5
9
4
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 4
Max Reward: 17
Gini Coefficient: 0.27906976744186046
20:20 Ratio: 4.25
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 351.96215201534307
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1388
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.563
    dispatch_time_ms: 26.93
    learner:
      cur_lr: 0.0008977960096672177
      grad_gnorm: 40.000003814697266
      policy_entropy: 34.388275146484375
      policy_loss: 49.97511672973633
      var_gnorm: 23.057497024536133
      vf_explained_var: 0.0
      vf_loss: 77.35710906982422
    num_steps_sampled: 6945000
    num_steps_trained: 6945000
    wait_time_ms: 60.153
  iterations_since_restore: 1389
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12197.973235845566
  time_this_iter_s: 8.853296279907227
  time_total_s: 12197.973235845566
  timestamp: 1594860747
  timesteps_since_restore: 6945000
  timesteps_this_iter: 5000
  timesteps_total: 6945000
  training_iteration: 1389
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12197 s, 1389 iter, 6945000 ts, 352 rew

agent-1: 42.59999999828449
agent-2: 36.5999999982845
agent-3: 35.599999998284495
agent-4: 36.5999999982845
agent-5: 37.59999999828451
Extrinsic Rewards:
9
3
2
3
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2857142857142857
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 351.69215201539174
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1389
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 36.672
    learner:
      cur_lr: 0.0008974630036391318
      grad_gnorm: 2.3754537105560303
      policy_entropy: 32.90444564819336
      policy_loss: -3.3813910484313965
      var_gnorm: 23.05500602722168
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.07485292851924896
    num_steps_sampled: 6950000
    num_steps_trained: 6950000
    wait_time_ms: 53.558
  iterations_since_restore: 1390
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12206.857846736908
  time_this_iter_s: 8.884610891342163
  time_total_s: 12206.857846736908
  timestamp: 1594860756
  timesteps_since_restore: 6950000
  timesteps_this_iter: 5000
  timesteps_total: 6950000
  training_iteration: 1390
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12206 s, 1390 iter, 6950000 ts, 352 rew

agent-1: 86.39999997455817
agent-2: 74.39999997455813
agent-3: 82.39999997455816
agent-4: 78.39999997455814
agent-5: 74.39999997455811
Extrinsic Rewards:
16
4
12
8
4
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 4
Max Reward: 16
Gini Coefficient: 0.2909090909090909
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 352.50215201477374
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1390
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.853
    dispatch_time_ms: 33.231
    learner:
      cur_lr: 0.0008971299976110458
      grad_gnorm: 40.0
      policy_entropy: 31.90068244934082
      policy_loss: 38.71574401855469
      var_gnorm: 23.055727005004883
      vf_explained_var: 0.0
      vf_loss: 33.47747802734375
    num_steps_sampled: 6955000
    num_steps_trained: 6955000
    wait_time_ms: 33.048
  iterations_since_restore: 1391
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12215.88188791275
  time_this_iter_s: 9.024041175842285
  time_total_s: 12215.88188791275
  timestamp: 1594860765
  timesteps_since_restore: 6955000
  timesteps_this_iter: 5000
  timesteps_total: 6955000
  training_iteration: 1391
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12215 s, 1391 iter, 6955000 ts, 353 rew

agent-1: 40.99999999740926
agent-2: 39.99999999740926
agent-3: 51.999999997409255
agent-4: 47.99999999740926
agent-5: 43.99999999740926
Extrinsic Rewards:
1
0
12
8
4
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.496
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-52-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 352.9521520147176
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1391
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 21.946
    learner:
      cur_lr: 0.0008967969915829599
      grad_gnorm: 19.47170639038086
      policy_entropy: 32.546905517578125
      policy_loss: -3.2936666011810303
      var_gnorm: 23.059097290039062
      vf_explained_var: 0.0
      vf_loss: 0.29286709427833557
    num_steps_sampled: 6960000
    num_steps_trained: 6960000
    wait_time_ms: 59.613
  iterations_since_restore: 1392
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12224.955105543137
  time_this_iter_s: 9.073217630386353
  time_total_s: 12224.955105543137
  timestamp: 1594860774
  timesteps_since_restore: 6960000
  timesteps_this_iter: 5000
  timesteps_total: 6960000
  training_iteration: 1392
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12224 s, 1392 iter, 6960000 ts, 353 rew

agent-1: 57.19999997552233
agent-2: 51.19999997552233
agent-3: 59.199999975522324
agent-4: 56.19999997552233
agent-5: 64.1999999755224
Extrinsic Rewards:
6
0
8
5
13
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.3625
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 352.68215201504756
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1392
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.168
    dispatch_time_ms: 29.129
    learner:
      cur_lr: 0.0008964639855548739
      grad_gnorm: 40.0
      policy_entropy: 32.42626190185547
      policy_loss: 18.62901496887207
      var_gnorm: 23.075944900512695
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 8.390571594238281
    num_steps_sampled: 6965000
    num_steps_trained: 6965000
    wait_time_ms: 66.528
  iterations_since_restore: 1393
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12234.198695421219
  time_this_iter_s: 9.243589878082275
  time_total_s: 12234.198695421219
  timestamp: 1594860784
  timesteps_since_restore: 6965000
  timesteps_this_iter: 5000
  timesteps_total: 6965000
  training_iteration: 1393
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12234 s, 1393 iter, 6965000 ts, 353 rew

agent-1: 42.999999998655625
agent-2: 45.99999999865561
agent-3: 48.999999998655625
agent-4: 41.999999998655625
agent-5: 44.999999998655625
Extrinsic Rewards:
3
6
9
2
5
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.272
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 351.60215201546197
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1393
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.167
    dispatch_time_ms: 27.182
    learner:
      cur_lr: 0.000896130979526788
      grad_gnorm: 30.743192672729492
      policy_entropy: 28.49860382080078
      policy_loss: -2.805432081222534
      var_gnorm: 23.0855770111084
      vf_explained_var: 0.0
      vf_loss: 0.6610475778579712
    num_steps_sampled: 6970000
    num_steps_trained: 6970000
    wait_time_ms: 60.543
  iterations_since_restore: 1394
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12243.210630655289
  time_this_iter_s: 9.011935234069824
  time_total_s: 12243.210630655289
  timestamp: 1594860793
  timesteps_since_restore: 6970000
  timesteps_this_iter: 5000
  timesteps_total: 6970000
  training_iteration: 1394
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12243 s, 1394 iter, 6970000 ts, 352 rew

agent-1: 54.59999994932119
agent-2: 63.59999994932119
agent-3: 57.59999994932119
agent-4: 49.59999994932117
agent-5: 53.59999994932119
Extrinsic Rewards:
5
14
8
0
4
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.4129032258064516
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 351.3321520131331
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1394
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.715
    dispatch_time_ms: 7.131
    learner:
      cur_lr: 0.000895797973498702
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.07129669189453
      policy_loss: 40.969295501708984
      var_gnorm: 23.082698822021484
      vf_explained_var: 0.0
      vf_loss: 90.49369812011719
    num_steps_sampled: 6975000
    num_steps_trained: 6975000
    wait_time_ms: 76.485
  iterations_since_restore: 1395
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12262.220796346664
  time_this_iter_s: 19.010165691375732
  time_total_s: 12262.220796346664
  timestamp: 1594860812
  timesteps_since_restore: 6975000
  timesteps_this_iter: 5000
  timesteps_total: 6975000
  training_iteration: 1395
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12262 s, 1395 iter, 6975000 ts, 351 rew

agent-1: 111.59999152761871
agent-2: 109.59999152761874
agent-3: 109.59999152761868
agent-4: 107.59999152761871
agent-5: 110.59999152761871
Extrinsic Rewards:
14
12
12
10
13
Sum Reward: 61
Avg Reward: 12.2
Min Reward: 10
Max Reward: 14
Gini Coefficient: 0.05901639344262295
20:20 Ratio: 1.4
Max-min Ratio: 1.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 353.7621515900233
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1395
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.973
    dispatch_time_ms: 6.516
    learner:
      cur_lr: 0.000895465025678277
      grad_gnorm: 40.0
      policy_entropy: 27.73448944091797
      policy_loss: -6.444421768188477
      var_gnorm: 23.072282791137695
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.7915480136871338
    num_steps_sampled: 6980000
    num_steps_trained: 6980000
    wait_time_ms: 78.675
  iterations_since_restore: 1396
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12270.860690116882
  time_this_iter_s: 8.639893770217896
  time_total_s: 12270.860690116882
  timestamp: 1594860820
  timesteps_since_restore: 6980000
  timesteps_this_iter: 5000
  timesteps_total: 6980000
  training_iteration: 1396
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12270 s, 1396 iter, 6980000 ts, 354 rew

agent-1: 116.79999452592156
agent-2: 120.79999452592159
agent-3: 126.79999452592173
agent-4: 118.79999452592159
agent-5: 128.79999452592125
Extrinsic Rewards:
8
12
18
10
20
Sum Reward: 68
Avg Reward: 13.6
Min Reward: 8
Max Reward: 20
Gini Coefficient: 0.18823529411764706
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 358.35215131634266
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1396
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.642
    dispatch_time_ms: 9.939
    learner:
      cur_lr: 0.0008951320196501911
      grad_gnorm: 40.00000762939453
      policy_entropy: 34.832664489746094
      policy_loss: 45.31998062133789
      var_gnorm: 23.056777954101562
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 56.76199722290039
    num_steps_sampled: 6985000
    num_steps_trained: 6985000
    wait_time_ms: 73.47
  iterations_since_restore: 1397
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12279.450532197952
  time_this_iter_s: 8.589842081069946
  time_total_s: 12279.450532197952
  timestamp: 1594860829
  timesteps_since_restore: 6985000
  timesteps_this_iter: 5000
  timesteps_total: 6985000
  training_iteration: 1397
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12279 s, 1397 iter, 6985000 ts, 358 rew

agent-1: 53.19999999570333
agent-2: 56.19999999570334
agent-3: 64.19999999570314
agent-4: 54.199999995703344
agent-5: 60.19999999570335
Extrinsic Rewards:
2
5
13
3
9
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.35
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-53-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 954.1010965321144
  episode_reward_mean: 359.5221513161697
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1397
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.003
    dispatch_time_ms: 8.43
    learner:
      cur_lr: 0.0008947990136221051
      grad_gnorm: 17.97423553466797
      policy_entropy: 31.90452003479004
      policy_loss: -3.0645549297332764
      var_gnorm: 23.055849075317383
      vf_explained_var: 0.0
      vf_loss: 0.2444104701280594
    num_steps_sampled: 6990000
    num_steps_trained: 6990000
    wait_time_ms: 76.432
  iterations_since_restore: 1398
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12288.039509057999
  time_this_iter_s: 8.588976860046387
  time_total_s: 12288.039509057999
  timestamp: 1594860838
  timesteps_since_restore: 6990000
  timesteps_this_iter: 5000
  timesteps_total: 6990000
  training_iteration: 1398
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12288 s, 1398 iter, 6990000 ts, 360 rew

agent-1: 73.1999999896756
agent-2: 83.19999998967563
agent-3: 76.19999998967563
agent-4: 76.19999998967563
agent-5: 69.19999998967565
Extrinsic Rewards:
6
16
9
9
2
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.29523809523809524
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9977348468434
  episode_reward_mean: 353.76114035033237
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1398
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.82
    dispatch_time_ms: 8.753
    learner:
      cur_lr: 0.0008944660075940192
      grad_gnorm: 40.0
      policy_entropy: 28.56849479675293
      policy_loss: 37.51536178588867
      var_gnorm: 23.053512573242188
      vf_explained_var: 0.0
      vf_loss: 70.60277557373047
    num_steps_sampled: 6995000
    num_steps_trained: 6995000
    wait_time_ms: 73.695
  iterations_since_restore: 1399
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12296.662076234818
  time_this_iter_s: 8.622567176818848
  time_total_s: 12296.662076234818
  timestamp: 1594860846
  timesteps_since_restore: 6995000
  timesteps_this_iter: 5000
  timesteps_total: 6995000
  training_iteration: 1399
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12296 s, 1399 iter, 6995000 ts, 354 rew

agent-1: 45.999999996310706
agent-2: 43.999999996310706
agent-3: 45.99999999631069
agent-4: 45.9999999963107
agent-5: 42.999999996310706
Extrinsic Rewards:
6
4
6
6
3
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 3
Max Reward: 6
Gini Coefficient: 0.128
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9977348468434
  episode_reward_mean: 349.08115573774444
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1399
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.531
    dispatch_time_ms: 9.667
    learner:
      cur_lr: 0.0008941330015659332
      grad_gnorm: 20.689964294433594
      policy_entropy: 19.204853057861328
      policy_loss: -2.053367853164673
      var_gnorm: 23.050813674926758
      vf_explained_var: 0.0
      vf_loss: 0.32982558012008667
    num_steps_sampled: 7000000
    num_steps_trained: 7000000
    wait_time_ms: 75.083
  iterations_since_restore: 1400
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12305.24522304535
  time_this_iter_s: 8.583146810531616
  time_total_s: 12305.24522304535
  timestamp: 1594860855
  timesteps_since_restore: 7000000
  timesteps_this_iter: 5000
  timesteps_total: 7000000
  training_iteration: 1400
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12305 s, 1400 iter, 7000000 ts, 349 rew

agent-1: 79.99999993151656
agent-2: 83.9999999315165
agent-3: 79.99999993151653
agent-4: 82.9999999315165
agent-5: 77.99999993151656
Extrinsic Rewards:
8
12
8
11
6
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 6
Max Reward: 12
Gini Coefficient: 0.13333333333333333
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9977348468434
  episode_reward_mean: 349.26115573506036
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1400
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.938
    dispatch_time_ms: 10.204
    learner:
      cur_lr: 0.0008937999955378473
      grad_gnorm: 39.99999237060547
      policy_entropy: 31.885746002197266
      policy_loss: 27.227907180786133
      var_gnorm: 23.04960823059082
      vf_explained_var: 0.0
      vf_loss: 19.46822738647461
    num_steps_sampled: 7005000
    num_steps_trained: 7005000
    wait_time_ms: 74.38
  iterations_since_restore: 1401
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12313.959535360336
  time_this_iter_s: 8.714312314987183
  time_total_s: 12313.959535360336
  timestamp: 1594860864
  timesteps_since_restore: 7005000
  timesteps_this_iter: 5000
  timesteps_total: 7005000
  training_iteration: 1401
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12313 s, 1401 iter, 7005000 ts, 349 rew

agent-1: 48.19999999739873
agent-2: 54.19999999739873
agent-3: 43.19999999739873
agent-4: 50.19999999739871
agent-5: 47.19999999739871
Extrinsic Rewards:
5
11
0
7
4
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.37037037037037035
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9977348468434
  episode_reward_mean: 348.36115573539195
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1401
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.598
    dispatch_time_ms: 9.455
    learner:
      cur_lr: 0.0008934669895097613
      grad_gnorm: 14.803423881530762
      policy_entropy: 18.846887588500977
      policy_loss: -1.314861536026001
      var_gnorm: 23.04999351501465
      vf_explained_var: 0.0
      vf_loss: 0.1683613806962967
    num_steps_sampled: 7010000
    num_steps_trained: 7010000
    wait_time_ms: 76.162
  iterations_since_restore: 1402
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12322.596599817276
  time_this_iter_s: 8.637064456939697
  time_total_s: 12322.596599817276
  timestamp: 1594860872
  timesteps_since_restore: 7010000
  timesteps_this_iter: 5000
  timesteps_total: 7010000
  training_iteration: 1402
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12322 s, 1402 iter, 7010000 ts, 348 rew

agent-1: 67.19999999457845
agent-2: 73.19999999457842
agent-3: 67.19999999457845
agent-4: 63.19999999457846
agent-5: 62.199999994578455
Extrinsic Rewards:
8
14
8
4
3
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.2810810810810811
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9977348468434
  episode_reward_mean: 346.2055966805346
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1402
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.919
    dispatch_time_ms: 9.593
    learner:
      cur_lr: 0.0008931339834816754
      grad_gnorm: 11.800431251525879
      policy_entropy: 20.565309524536133
      policy_loss: -0.9384860992431641
      var_gnorm: 23.050024032592773
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.10569438338279724
    num_steps_sampled: 7015000
    num_steps_trained: 7015000
    wait_time_ms: 74.85
  iterations_since_restore: 1403
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12331.24331331253
  time_this_iter_s: 8.646713495254517
  time_total_s: 12331.24331331253
  timestamp: 1594860881
  timesteps_since_restore: 7015000
  timesteps_this_iter: 5000
  timesteps_total: 7015000
  training_iteration: 1403
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12331 s, 1403 iter, 7015000 ts, 346 rew

agent-1: 46.999999998563375
agent-2: 41.99999999856336
agent-3: 43.99999999856337
agent-4: 43.99999999856337
agent-5: 47.999999998563375
Extrinsic Rewards:
7
2
4
4
8
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.24
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9977348468434
  episode_reward_mean: 344.22559837669286
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1403
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.981
    dispatch_time_ms: 10.009
    learner:
      cur_lr: 0.0008928009774535894
      grad_gnorm: 12.395403861999512
      policy_entropy: 18.774166107177734
      policy_loss: -1.3932294845581055
      var_gnorm: 23.050168991088867
      vf_explained_var: 0.0
      vf_loss: 0.11861877143383026
    num_steps_sampled: 7020000
    num_steps_trained: 7020000
    wait_time_ms: 72.442
  iterations_since_restore: 1404
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12339.868772506714
  time_this_iter_s: 8.62545919418335
  time_total_s: 12339.868772506714
  timestamp: 1594860890
  timesteps_since_restore: 7020000
  timesteps_this_iter: 5000
  timesteps_total: 7020000
  training_iteration: 1404
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12339 s, 1404 iter, 7020000 ts, 344 rew

agent-1: 45.19999999548895
agent-2: 47.19999999548895
agent-3: 48.19999999548895
agent-4: 46.19999999548895
agent-5: 56.19999999548894
Extrinsic Rewards:
2
4
5
3
13
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.35555555555555557
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-54-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9977348468434
  episode_reward_mean: 343.77559838142224
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1404
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.963
    dispatch_time_ms: 9.362
    learner:
      cur_lr: 0.0008924679714255035
      grad_gnorm: 11.313370704650879
      policy_entropy: 16.090251922607422
      policy_loss: -0.5843994617462158
      var_gnorm: 23.050491333007812
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.09762769192457199
    num_steps_sampled: 7025000
    num_steps_trained: 7025000
    wait_time_ms: 74.621
  iterations_since_restore: 1405
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12348.504538297653
  time_this_iter_s: 8.635765790939331
  time_total_s: 12348.504538297653
  timestamp: 1594860898
  timesteps_since_restore: 7025000
  timesteps_this_iter: 5000
  timesteps_total: 7025000
  training_iteration: 1405
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12348 s, 1405 iter, 7025000 ts, 344 rew

agent-1: 37.19999999933137
agent-2: 40.199999999331375
agent-3: 39.19999999933137
agent-4: 38.19999999933136
agent-5: 43.19999999933138
Extrinsic Rewards:
2
5
4
3
8
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 926.9977348468434
  episode_reward_mean: 337.38668161901245
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1405
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.256
    dispatch_time_ms: 7.373
    learner:
      cur_lr: 0.0008921350236050785
      grad_gnorm: 12.24558162689209
      policy_entropy: 14.433086395263672
      policy_loss: -0.6063613891601562
      var_gnorm: 23.053823471069336
      vf_explained_var: 0.0
      vf_loss: 0.11472949385643005
    num_steps_sampled: 7030000
    num_steps_trained: 7030000
    wait_time_ms: 77.99
  iterations_since_restore: 1406
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12357.28627872467
  time_this_iter_s: 8.781740427017212
  time_total_s: 12357.28627872467
  timestamp: 1594860907
  timesteps_since_restore: 7030000
  timesteps_this_iter: 5000
  timesteps_total: 7030000
  training_iteration: 1406
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12357 s, 1406 iter, 7030000 ts, 337 rew

agent-1: 64.79999999352383
agent-2: 60.799999993523826
agent-3: 53.79999999352381
agent-4: 58.79999999352381
agent-5: 58.79999999352381
Extrinsic Rewards:
12
8
1
6
6
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.2909090909090909
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 915.7947643529685
  episode_reward_mean: 331.08670427022014
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1406
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 9.079
    learner:
      cur_lr: 0.0008918020175769925
      grad_gnorm: 11.560298919677734
      policy_entropy: 18.076438903808594
      policy_loss: -0.7703203558921814
      var_gnorm: 23.05376434326172
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.10175428539514542
    num_steps_sampled: 7035000
    num_steps_trained: 7035000
    wait_time_ms: 74.156
  iterations_since_restore: 1407
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12365.86738729477
  time_this_iter_s: 8.581108570098877
  time_total_s: 12365.86738729477
  timestamp: 1594860916
  timesteps_since_restore: 7035000
  timesteps_this_iter: 5000
  timesteps_total: 7035000
  training_iteration: 1407
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12365 s, 1407 iter, 7035000 ts, 331 rew

agent-1: 32.79999999938043
agent-2: 31.799999999380493
agent-3: 36.799999999380425
agent-4: 30.799999999380486
agent-5: 29.799999999380486
Extrinsic Rewards:
4
3
8
2
1
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.35555555555555557
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 915.7947643529685
  episode_reward_mean: 330.09670427043415
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1407
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.992
    dispatch_time_ms: 8.933
    learner:
      cur_lr: 0.0008914690115489066
      grad_gnorm: 17.40361213684082
      policy_entropy: 14.182963371276855
      policy_loss: -2.1921005249023438
      var_gnorm: 23.050212860107422
      vf_explained_var: 0.0
      vf_loss: 0.22221700847148895
    num_steps_sampled: 7040000
    num_steps_trained: 7040000
    wait_time_ms: 73.819
  iterations_since_restore: 1408
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12374.4798746109
  time_this_iter_s: 8.612487316131592
  time_total_s: 12374.4798746109
  timestamp: 1594860924
  timesteps_since_restore: 7040000
  timesteps_this_iter: 5000
  timesteps_total: 7040000
  training_iteration: 1408
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12374 s, 1408 iter, 7040000 ts, 330 rew

agent-1: 52.199999997148225
agent-2: 65.19999999714818
agent-3: 60.19999999714822
agent-4: 52.199999997148225
agent-5: 58.199999997148204
Extrinsic Rewards:
1
14
9
1
7
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.425
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 915.7947643529685
  episode_reward_mean: 326.22681820289114
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1408
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.159
    dispatch_time_ms: 9.525
    learner:
      cur_lr: 0.0008911360055208206
      grad_gnorm: 11.457265853881836
      policy_entropy: 14.966216087341309
      policy_loss: -0.9811525940895081
      var_gnorm: 23.04974937438965
      vf_explained_var: 0.0
      vf_loss: 0.10139454901218414
    num_steps_sampled: 7045000
    num_steps_trained: 7045000
    wait_time_ms: 73.44
  iterations_since_restore: 1409
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12383.124593496323
  time_this_iter_s: 8.644718885421753
  time_total_s: 12383.124593496323
  timestamp: 1594860933
  timesteps_since_restore: 7045000
  timesteps_this_iter: 5000
  timesteps_total: 7045000
  training_iteration: 1409
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 38.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12383 s, 1409 iter, 7045000 ts, 326 rew

agent-1: 61.79999999404243
agent-2: 65.79999999404231
agent-3: 58.79999999404242
agent-4: 55.79999999404242
agent-5: 54.79999999404242
Extrinsic Rewards:
9
13
6
3
2
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.3393939393939394
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 915.7947643529685
  episode_reward_mean: 323.3468228573499
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1409
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.575
    dispatch_time_ms: 8.644
    learner:
      cur_lr: 0.0008908029994927347
      grad_gnorm: 35.15769577026367
      policy_entropy: 17.817821502685547
      policy_loss: -2.9160451889038086
      var_gnorm: 23.051725387573242
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.9570761919021606
    num_steps_sampled: 7050000
    num_steps_trained: 7050000
    wait_time_ms: 76.542
  iterations_since_restore: 1410
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12391.858035087585
  time_this_iter_s: 8.733441591262817
  time_total_s: 12391.858035087585
  timestamp: 1594860942
  timesteps_since_restore: 7050000
  timesteps_this_iter: 5000
  timesteps_total: 7050000
  training_iteration: 1410
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12391 s, 1410 iter, 7050000 ts, 323 rew

agent-1: 53.99999993884965
agent-2: 51.999999938849655
agent-3: 51.99999993884965
agent-4: 54.99999993884964
agent-5: 56.999999938849655
Extrinsic Rewards:
6
4
4
7
9
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.17333333333333334
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 915.7947643529685
  episode_reward_mean: 322.0868228559181
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1410
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.782
    dispatch_time_ms: 9.457
    learner:
      cur_lr: 0.0008904699934646487
      grad_gnorm: 15.824285507202148
      policy_entropy: 28.871437072753906
      policy_loss: -2.4469926357269287
      var_gnorm: 23.049959182739258
      vf_explained_var: 0.0
      vf_loss: 0.1763947308063507
    num_steps_sampled: 7055000
    num_steps_trained: 7055000
    wait_time_ms: 75.342
  iterations_since_restore: 1411
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12400.571273803711
  time_this_iter_s: 8.713238716125488
  time_total_s: 12400.571273803711
  timestamp: 1594860951
  timesteps_since_restore: 7055000
  timesteps_this_iter: 5000
  timesteps_total: 7055000
  training_iteration: 1411
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12400 s, 1411 iter, 7055000 ts, 322 rew

agent-1: 70.99999933247913
agent-2: 68.99999933247913
agent-3: 72.99999933247918
agent-4: 71.99999933247916
agent-5: 74.99999933247918
Extrinsic Rewards:
7
5
9
8
11
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 5
Max Reward: 11
Gini Coefficient: 0.14
20:20 Ratio: 2.2
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-55-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 915.7947643529685
  episode_reward_mean: 323.3468228226282
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1411
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.837
    dispatch_time_ms: 7.974
    learner:
      cur_lr: 0.0008901369874365628
      grad_gnorm: 12.113260269165039
      policy_entropy: 19.740007400512695
      policy_loss: -1.3306455612182617
      var_gnorm: 23.04804801940918
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.11363088339567184
    num_steps_sampled: 7060000
    num_steps_trained: 7060000
    wait_time_ms: 77.131
  iterations_since_restore: 1412
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12409.26785492897
  time_this_iter_s: 8.6965811252594
  time_total_s: 12409.26785492897
  timestamp: 1594860959
  timesteps_since_restore: 7060000
  timesteps_this_iter: 5000
  timesteps_total: 7060000
  training_iteration: 1412
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12409 s, 1412 iter, 7060000 ts, 323 rew

agent-1: 43.999999999232585
agent-2: 35.99999999923257
agent-3: 34.999999999232564
agent-4: 32.99999999923258
agent-5: 31.9999999992326
Extrinsic Rewards:
12
4
3
1
0
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.54
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 915.7947643529685
  episode_reward_mean: 321.99682282293344
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1412
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.128
    dispatch_time_ms: 9.571
    learner:
      cur_lr: 0.0008898039814084768
      grad_gnorm: 11.22147274017334
      policy_entropy: 18.876657485961914
      policy_loss: -1.1957523822784424
      var_gnorm: 23.04826545715332
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.09701728820800781
    num_steps_sampled: 7065000
    num_steps_trained: 7065000
    wait_time_ms: 75.216
  iterations_since_restore: 1413
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12418.041688680649
  time_this_iter_s: 8.773833751678467
  time_total_s: 12418.041688680649
  timestamp: 1594860968
  timesteps_since_restore: 7065000
  timesteps_this_iter: 5000
  timesteps_total: 7065000
  training_iteration: 1413
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12418 s, 1413 iter, 7065000 ts, 322 rew

agent-1: 36.99999999912398
agent-2: 33.999999999123965
agent-3: 37.99999999912398
agent-4: 35.99999999912398
agent-5: 34.999999999123965
Extrinsic Rewards:
5
2
6
4
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.2
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 915.7947643529685
  episode_reward_mean: 319.4768228373886
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1413
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.575
    dispatch_time_ms: 8.978
    learner:
      cur_lr: 0.0008894709753803909
      grad_gnorm: 11.745467185974121
      policy_entropy: 25.43590545654297
      policy_loss: -1.5649974346160889
      var_gnorm: 23.050304412841797
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.10647770762443542
    num_steps_sampled: 7070000
    num_steps_trained: 7070000
    wait_time_ms: 75.166
  iterations_since_restore: 1414
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12426.64043021202
  time_this_iter_s: 8.59874153137207
  time_total_s: 12426.64043021202
  timestamp: 1594860977
  timesteps_since_restore: 7070000
  timesteps_this_iter: 5000
  timesteps_total: 7070000
  training_iteration: 1414
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12426 s, 1414 iter, 7070000 ts, 319 rew

agent-1: 41.39999999575729
agent-2: 39.399999995757284
agent-3: 47.399999995757305
agent-4: 43.39999999575729
agent-5: 44.39999999575729
Extrinsic Rewards:
3
1
9
5
6
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.31666666666666665
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 915.7947643529685
  episode_reward_mean: 317.6768228505078
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1414
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.427
    dispatch_time_ms: 32.996
    learner:
      cur_lr: 0.0008891380275599658
      grad_gnorm: 9.290583610534668
      policy_entropy: 28.264503479003906
      policy_loss: -0.026373524218797684
      var_gnorm: 23.05337905883789
      vf_explained_var: 0.0
      vf_loss: 0.06684235483407974
    num_steps_sampled: 7075000
    num_steps_trained: 7075000
    wait_time_ms: 59.696
  iterations_since_restore: 1415
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12435.880803823471
  time_this_iter_s: 9.240373611450195
  time_total_s: 12435.880803823471
  timestamp: 1594860986
  timesteps_since_restore: 7075000
  timesteps_this_iter: 5000
  timesteps_total: 7075000
  training_iteration: 1415
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12435 s, 1415 iter, 7075000 ts, 318 rew

agent-1: 33.39999999942563
agent-2: 30.399999999425567
agent-3: 33.39999999942563
agent-4: 32.39999999942562
agent-5: 41.39999999942567
Extrinsic Rewards:
3
0
3
2
11
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.4842105263157895
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 915.7947643529685
  episode_reward_mean: 317.1368228506753
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1415
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.014
    dispatch_time_ms: 21.532
    learner:
      cur_lr: 0.0008888050215318799
      grad_gnorm: 39.99999237060547
      policy_entropy: 18.749441146850586
      policy_loss: 12.542815208435059
      var_gnorm: 23.052799224853516
      vf_explained_var: 0.0
      vf_loss: 36.155765533447266
    num_steps_sampled: 7080000
    num_steps_trained: 7080000
    wait_time_ms: 66.95
  iterations_since_restore: 1416
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12445.002434253693
  time_this_iter_s: 9.121630430221558
  time_total_s: 12445.002434253693
  timestamp: 1594860995
  timesteps_since_restore: 7080000
  timesteps_this_iter: 5000
  timesteps_total: 7080000
  training_iteration: 1416
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12445 s, 1416 iter, 7080000 ts, 317 rew

agent-1: 32.799999999491554
agent-2: 32.799999999491554
agent-3: 34.799999999491575
agent-4: 28.799999999491344
agent-5: 32.79999999949155
Extrinsic Rewards:
4
4
6
0
4
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.26666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 915.7947643529685
  episode_reward_mean: 316.05682285118553
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1416
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.672
    dispatch_time_ms: 27.858
    learner:
      cur_lr: 0.000888472015503794
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.83544158935547
      policy_loss: 12.401398658752441
      var_gnorm: 23.05385398864746
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 12.794129371643066
    num_steps_sampled: 7085000
    num_steps_trained: 7085000
    wait_time_ms: 66.218
  iterations_since_restore: 1417
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12454.166639089584
  time_this_iter_s: 9.164204835891724
  time_total_s: 12454.166639089584
  timestamp: 1594861004
  timesteps_since_restore: 7085000
  timesteps_this_iter: 5000
  timesteps_total: 7085000
  training_iteration: 1417
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12454 s, 1417 iter, 7085000 ts, 316 rew

agent-1: 207.59865178402586
agent-2: 197.59865178402586
agent-3: 217.59865178402592
agent-4: 204.59865178402586
agent-5: 216.59865178402592
Extrinsic Rewards:
22
12
32
19
31
Sum Reward: 116
Avg Reward: 23.2
Min Reward: 12
Max Reward: 32
Gini Coefficient: 0.1793103448275862
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-56-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 322.6267554407369
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1417
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.507
    dispatch_time_ms: 23.854
    learner:
      cur_lr: 0.000888139009475708
      grad_gnorm: 33.4031982421875
      policy_entropy: 7.945039749145508
      policy_loss: -0.5581868886947632
      var_gnorm: 23.054840087890625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.855429470539093
    num_steps_sampled: 7090000
    num_steps_trained: 7090000
    wait_time_ms: 68.75
  iterations_since_restore: 1418
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12463.30774474144
  time_this_iter_s: 9.141105651855469
  time_total_s: 12463.30774474144
  timestamp: 1594861014
  timesteps_since_restore: 7090000
  timesteps_this_iter: 5000
  timesteps_total: 7090000
  training_iteration: 1418
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12463 s, 1418 iter, 7090000 ts, 323 rew

agent-1: 45.19999999746502
agent-2: 43.199999997465014
agent-3: 49.199999997465035
agent-4: 50.199999997465035
agent-5: 55.19999999746502
Extrinsic Rewards:
2
0
6
7
12
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.42962962962962964
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 323.4367554406489
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1418
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.693
    dispatch_time_ms: 24.161
    learner:
      cur_lr: 0.0008878060034476221
      grad_gnorm: 40.00000762939453
      policy_entropy: 17.65009117126465
      policy_loss: -1.9012196063995361
      var_gnorm: 23.043598175048828
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.2910007238388062
    num_steps_sampled: 7095000
    num_steps_trained: 7095000
    wait_time_ms: 66.685
  iterations_since_restore: 1419
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12472.295152664185
  time_this_iter_s: 8.987407922744751
  time_total_s: 12472.295152664185
  timestamp: 1594861023
  timesteps_since_restore: 7095000
  timesteps_this_iter: 5000
  timesteps_total: 7095000
  training_iteration: 1419
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12472 s, 1419 iter, 7095000 ts, 323 rew

agent-1: 138.3968506397045
agent-2: 138.39685063970444
agent-3: 131.39685063970455
agent-4: 128.3968506397045
agent-5: 129.39685063970447
Extrinsic Rewards:
20
20
13
10
11
Sum Reward: 74
Avg Reward: 14.8
Min Reward: 10
Max Reward: 20
Gini Coefficient: 0.15675675675675677
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 327.39659797271344
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1419
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 22.462
    learner:
      cur_lr: 0.0008874729974195361
      grad_gnorm: 40.0
      policy_entropy: 25.982139587402344
      policy_loss: -11.17977237701416
      var_gnorm: 23.04798126220703
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.0244600772857666
    num_steps_sampled: 7100000
    num_steps_trained: 7100000
    wait_time_ms: 64.122
  iterations_since_restore: 1420
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12481.350427627563
  time_this_iter_s: 9.055274963378906
  time_total_s: 12481.350427627563
  timestamp: 1594861032
  timesteps_since_restore: 7100000
  timesteps_this_iter: 5000
  timesteps_total: 7100000
  training_iteration: 1420
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12481 s, 1420 iter, 7100000 ts, 327 rew

agent-1: 87.39999951231201
agent-2: 89.39999951231201
agent-3: 89.39999951231201
agent-4: 88.39999951231201
agent-5: 86.39999951231201
Extrinsic Rewards:
9
11
11
10
8
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 8
Max Reward: 11
Gini Coefficient: 0.0653061224489796
20:20 Ratio: 1.375
Max-min Ratio: 1.375
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 329.9165979485419
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1420
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.638
    dispatch_time_ms: 32.602
    learner:
      cur_lr: 0.0008871399913914502
      grad_gnorm: 15.344512939453125
      policy_entropy: 5.843525409698486
      policy_loss: -0.45654910802841187
      var_gnorm: 23.04104995727539
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.18225201964378357
    num_steps_sampled: 7105000
    num_steps_trained: 7105000
    wait_time_ms: 46.866
  iterations_since_restore: 1421
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12490.215381860733
  time_this_iter_s: 8.864954233169556
  time_total_s: 12490.215381860733
  timestamp: 1594861041
  timesteps_since_restore: 7105000
  timesteps_this_iter: 5000
  timesteps_total: 7105000
  training_iteration: 1421
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12490 s, 1421 iter, 7105000 ts, 330 rew

agent-1: 84.59999995275953
agent-2: 80.59999995275957
agent-3: 78.59999995275953
agent-4: 83.59999995275955
agent-5: 86.59999995275956
Extrinsic Rewards:
11
7
5
10
13
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 5
Max Reward: 13
Gini Coefficient: 0.17391304347826086
20:20 Ratio: 2.6
Max-min Ratio: 2.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 331.80659794623045
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1421
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.017
    dispatch_time_ms: 28.501
    learner:
      cur_lr: 0.0008868069853633642
      grad_gnorm: 40.000003814697266
      policy_entropy: 27.217803955078125
      policy_loss: 32.5339469909668
      var_gnorm: 23.04853057861328
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 45.180511474609375
    num_steps_sampled: 7110000
    num_steps_trained: 7110000
    wait_time_ms: 57.768
  iterations_since_restore: 1422
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12499.072083950043
  time_this_iter_s: 8.856702089309692
  time_total_s: 12499.072083950043
  timestamp: 1594861049
  timesteps_since_restore: 7110000
  timesteps_this_iter: 5000
  timesteps_total: 7110000
  training_iteration: 1422
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12499 s, 1422 iter, 7110000 ts, 332 rew

agent-1: 123.59759987287575
agent-2: 113.59759987287575
agent-3: 108.5975998728757
agent-4: 129.5975998728757
agent-5: 118.59759987287573
Extrinsic Rewards:
18
8
3
24
13
Sum Reward: 66
Avg Reward: 13.2
Min Reward: 3
Max Reward: 24
Gini Coefficient: 0.3151515151515151
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 333.966477959786
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1422
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.607
    dispatch_time_ms: 14.661
    learner:
      cur_lr: 0.0008864739793352783
      grad_gnorm: 0.6278327703475952
      policy_entropy: 34.39677047729492
      policy_loss: -0.025964993983507156
      var_gnorm: 23.028413772583008
      vf_explained_var: 0.0
      vf_loss: 0.0024100246373564005
    num_steps_sampled: 7115000
    num_steps_trained: 7115000
    wait_time_ms: 42.235
  iterations_since_restore: 1423
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12508.369409561157
  time_this_iter_s: 9.297325611114502
  time_total_s: 12508.369409561157
  timestamp: 1594861059
  timesteps_since_restore: 7115000
  timesteps_this_iter: 5000
  timesteps_total: 7115000
  training_iteration: 1423
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12508 s, 1423 iter, 7115000 ts, 334 rew

agent-1: 72.19996434119608
agent-2: 61.1999643411961
agent-3: 69.19996434119612
agent-4: 63.19996434119609
agent-5: 67.19996434119614
Extrinsic Rewards:
13
2
10
4
8
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.3027027027027027
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 334.77647617697664
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1423
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.144
    dispatch_time_ms: 6.594
    learner:
      cur_lr: 0.0008861409733071923
      grad_gnorm: 15.171403884887695
      policy_entropy: 34.20943832397461
      policy_loss: -2.9363439083099365
      var_gnorm: 23.022722244262695
      vf_explained_var: 0.0
      vf_loss: 0.17813175916671753
    num_steps_sampled: 7120000
    num_steps_trained: 7120000
    wait_time_ms: 76.509
  iterations_since_restore: 1424
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12516.865629673004
  time_this_iter_s: 8.496220111846924
  time_total_s: 12516.865629673004
  timestamp: 1594861067
  timesteps_since_restore: 7120000
  timesteps_this_iter: 5000
  timesteps_total: 7120000
  training_iteration: 1424
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12516 s, 1424 iter, 7120000 ts, 335 rew

agent-1: 52.199999998348254
agent-2: 46.199999998348254
agent-3: 48.199999998348254
agent-4: 53.19999999834827
agent-5: 43.19999999834824
Extrinsic Rewards:
9
3
5
10
0
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.3851851851851852
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-57-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 329.55653323183486
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1424
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.649
    dispatch_time_ms: 8.371
    learner:
      cur_lr: 0.0008858080254867673
      grad_gnorm: 20.62069320678711
      policy_entropy: 34.42084503173828
      policy_loss: 3.5568182468414307
      var_gnorm: 23.022809982299805
      vf_explained_var: 0.0
      vf_loss: 0.324708491563797
    num_steps_sampled: 7125000
    num_steps_trained: 7125000
    wait_time_ms: 74.513
  iterations_since_restore: 1425
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12525.480559825897
  time_this_iter_s: 8.614930152893066
  time_total_s: 12525.480559825897
  timestamp: 1594861076
  timesteps_since_restore: 7125000
  timesteps_this_iter: 5000
  timesteps_total: 7125000
  training_iteration: 1425
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12525 s, 1425 iter, 7125000 ts, 330 rew

agent-1: 28.59999999949125
agent-2: 31.599999999491246
agent-3: 28.599999999491246
agent-4: 25.59999999949125
agent-5: 29.599999999491246
Extrinsic Rewards:
3
6
3
0
4
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.325
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 329.0165332318624
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1425
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.122
    dispatch_time_ms: 7.692
    learner:
      cur_lr: 0.0008854750194586813
      grad_gnorm: 15.086040496826172
      policy_entropy: 20.643024444580078
      policy_loss: -1.2422336339950562
      var_gnorm: 23.0236759185791
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.17248517274856567
    num_steps_sampled: 7130000
    num_steps_trained: 7130000
    wait_time_ms: 75.077
  iterations_since_restore: 1426
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12534.057975530624
  time_this_iter_s: 8.577415704727173
  time_total_s: 12534.057975530624
  timestamp: 1594861085
  timesteps_since_restore: 7130000
  timesteps_this_iter: 5000
  timesteps_total: 7130000
  training_iteration: 1426
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12534 s, 1426 iter, 7130000 ts, 329 rew

agent-1: 30.79999999903821
agent-2: 33.799999999038064
agent-3: 32.79999999903807
agent-4: 33.79999999903807
agent-5: 30.799999999038214
Extrinsic Rewards:
2
5
4
5
2
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.2
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 321.4785855882846
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1426
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 8.144
    learner:
      cur_lr: 0.0008851420134305954
      grad_gnorm: 40.0
      policy_entropy: 27.059473037719727
      policy_loss: 36.11593246459961
      var_gnorm: 23.023212432861328
      vf_explained_var: 0.0
      vf_loss: 31.114404678344727
    num_steps_sampled: 7135000
    num_steps_trained: 7135000
    wait_time_ms: 74.913
  iterations_since_restore: 1427
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12542.630092382431
  time_this_iter_s: 8.57211685180664
  time_total_s: 12542.630092382431
  timestamp: 1594861093
  timesteps_since_restore: 7135000
  timesteps_this_iter: 5000
  timesteps_total: 7135000
  training_iteration: 1427
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12542 s, 1427 iter, 7135000 ts, 321 rew

agent-1: 55.399999998188626
agent-2: 51.399999998188626
agent-3: 53.399999998188626
agent-4: 52.399999998188626
agent-5: 48.399999998188626
Extrinsic Rewards:
9
5
7
6
2
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2206896551724138
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 321.20858558855946
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1427
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.727
    dispatch_time_ms: 8.553
    learner:
      cur_lr: 0.0008848090074025095
      grad_gnorm: 40.0
      policy_entropy: 34.66486358642578
      policy_loss: 27.77898406982422
      var_gnorm: 23.026376724243164
      vf_explained_var: 0.0
      vf_loss: 20.642988204956055
    num_steps_sampled: 7140000
    num_steps_trained: 7140000
    wait_time_ms: 73.567
  iterations_since_restore: 1428
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12551.07840871811
  time_this_iter_s: 8.4483163356781
  time_total_s: 12551.07840871811
  timestamp: 1594861102
  timesteps_since_restore: 7140000
  timesteps_this_iter: 5000
  timesteps_total: 7140000
  training_iteration: 1428
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12551 s, 1428 iter, 7140000 ts, 321 rew

agent-1: 80.7999989126875
agent-2: 89.79999891268749
agent-3: 90.79999891268749
agent-4: 83.79999891268751
agent-5: 86.7999989126875
Extrinsic Rewards:
4
13
14
7
10
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 4
Max Reward: 14
Gini Coefficient: 0.21666666666666667
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 323.0985855343744
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1428
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.927
    dispatch_time_ms: 7.358
    learner:
      cur_lr: 0.0008844760013744235
      grad_gnorm: 36.880306243896484
      policy_entropy: 20.947574615478516
      policy_loss: -2.8203353881835938
      var_gnorm: 23.026002883911133
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.0228034257888794
    num_steps_sampled: 7145000
    num_steps_trained: 7145000
    wait_time_ms: 77.136
  iterations_since_restore: 1429
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12559.705697059631
  time_this_iter_s: 8.627288341522217
  time_total_s: 12559.705697059631
  timestamp: 1594861110
  timesteps_since_restore: 7145000
  timesteps_this_iter: 5000
  timesteps_total: 7145000
  training_iteration: 1429
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12559 s, 1429 iter, 7145000 ts, 323 rew

agent-1: 134.79996460577632
agent-2: 131.79996460577624
agent-3: 138.79996460577624
agent-4: 124.79996460577647
agent-5: 126.7999646057765
Extrinsic Rewards:
18
15
22
8
10
Sum Reward: 73
Avg Reward: 14.6
Min Reward: 8
Max Reward: 22
Gini Coefficient: 0.19726027397260273
20:20 Ratio: 2.75
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 325.6185837899982
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1429
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.879
    dispatch_time_ms: 7.7
    learner:
      cur_lr: 0.0008841429953463376
      grad_gnorm: 30.01209259033203
      policy_entropy: 18.09972381591797
      policy_loss: -2.304375648498535
      var_gnorm: 23.025047302246094
      vf_explained_var: 0.0
      vf_loss: 0.692656397819519
    num_steps_sampled: 7150000
    num_steps_trained: 7150000
    wait_time_ms: 75.15
  iterations_since_restore: 1430
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12568.39222407341
  time_this_iter_s: 8.686527013778687
  time_total_s: 12568.39222407341
  timestamp: 1594861119
  timesteps_since_restore: 7150000
  timesteps_this_iter: 5000
  timesteps_total: 7150000
  training_iteration: 1430
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12568 s, 1430 iter, 7150000 ts, 326 rew

agent-1: 90.99999995737484
agent-2: 83.99999995737484
agent-3: 97.99999995737485
agent-4: 84.99999995737485
agent-5: 91.99999995737485
Extrinsic Rewards:
11
4
18
5
12
Sum Reward: 50
Avg Reward: 10.0
Min Reward: 4
Max Reward: 18
Gini Coefficient: 0.28
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 326.6085839554891
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1430
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.087
    dispatch_time_ms: 9.735
    learner:
      cur_lr: 0.0008838099893182516
      grad_gnorm: 13.176909446716309
      policy_entropy: 31.32567596435547
      policy_loss: -1.9531795978546143
      var_gnorm: 23.02285385131836
      vf_explained_var: 0.0
      vf_loss: 0.1343161165714264
    num_steps_sampled: 7155000
    num_steps_trained: 7155000
    wait_time_ms: 73.607
  iterations_since_restore: 1431
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12577.113978385925
  time_this_iter_s: 8.721754312515259
  time_total_s: 12577.113978385925
  timestamp: 1594861128
  timesteps_since_restore: 7155000
  timesteps_this_iter: 5000
  timesteps_total: 7155000
  training_iteration: 1431
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12577 s, 1431 iter, 7155000 ts, 327 rew

agent-1: 44.599999992522804
agent-2: 44.5999999925228
agent-3: 42.599999992522804
agent-4: 51.599999992522804
agent-5: 50.599999992522804
Extrinsic Rewards:
3
3
1
10
9
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.36923076923076925
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-58-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 323.7285839673123
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1431
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.021
    dispatch_time_ms: 6.146
    learner:
      cur_lr: 0.0008834769832901657
      grad_gnorm: 10.646897315979004
      policy_entropy: 33.80929946899414
      policy_loss: -1.7814290523529053
      var_gnorm: 23.022762298583984
      vf_explained_var: 0.0
      vf_loss: 0.08778530359268188
    num_steps_sampled: 7160000
    num_steps_trained: 7160000
    wait_time_ms: 79.547
  iterations_since_restore: 1432
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12585.740864753723
  time_this_iter_s: 8.626886367797852
  time_total_s: 12585.740864753723
  timestamp: 1594861136
  timesteps_since_restore: 7160000
  timesteps_this_iter: 5000
  timesteps_total: 7160000
  training_iteration: 1432
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12585 s, 1432 iter, 7160000 ts, 324 rew

agent-1: 43.99999999889882
agent-2: 46.99999999889882
agent-3: 44.99999999889882
agent-4: 48.99999999889882
agent-5: 39.99999999889882
Extrinsic Rewards:
4
7
5
9
0
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.336
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 323.818583967388
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1432
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.136
    dispatch_time_ms: 8.372
    learner:
      cur_lr: 0.0008831439772620797
      grad_gnorm: 39.99999237060547
      policy_entropy: 31.766157150268555
      policy_loss: 18.792850494384766
      var_gnorm: 23.023202896118164
      vf_explained_var: 0.0
      vf_loss: 12.48997974395752
    num_steps_sampled: 7165000
    num_steps_trained: 7165000
    wait_time_ms: 74.769
  iterations_since_restore: 1433
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12594.34969496727
  time_this_iter_s: 8.608830213546753
  time_total_s: 12594.34969496727
  timestamp: 1594861145
  timesteps_since_restore: 7165000
  timesteps_this_iter: 5000
  timesteps_total: 7165000
  training_iteration: 1433
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12594 s, 1433 iter, 7165000 ts, 324 rew

agent-1: 31.199999999543216
agent-2: 29.199999999543216
agent-3: 28.199999999543216
agent-4: 33.19999999954322
agent-5: 31.199999999543213
Extrinsic Rewards:
4
2
1
6
4
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.2823529411764706
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 323.18858396741985
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1433
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.993
    dispatch_time_ms: 8.361
    learner:
      cur_lr: 0.0008828109712339938
      grad_gnorm: 40.0
      policy_entropy: 31.696340560913086
      policy_loss: 23.045740127563477
      var_gnorm: 23.02426528930664
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 15.819007873535156
    num_steps_sampled: 7170000
    num_steps_trained: 7170000
    wait_time_ms: 74.966
  iterations_since_restore: 1434
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12603.009335756302
  time_this_iter_s: 8.659640789031982
  time_total_s: 12603.009335756302
  timestamp: 1594861154
  timesteps_since_restore: 7170000
  timesteps_this_iter: 5000
  timesteps_total: 7170000
  training_iteration: 1434
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12603 s, 1434 iter, 7170000 ts, 323 rew

agent-1: 36.1999999834379
agent-2: 40.19999998343791
agent-3: 38.19999998343791
agent-4: 43.199999983437905
agent-5: 40.199999983437905
Extrinsic Rewards:
1
5
3
8
5
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.2909090909090909
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 321.9285839697497
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1434
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.96
    dispatch_time_ms: 7.353
    learner:
      cur_lr: 0.0008824780234135687
      grad_gnorm: 15.510780334472656
      policy_entropy: 27.33356475830078
      policy_loss: -1.5694708824157715
      var_gnorm: 23.023548126220703
      vf_explained_var: 0.0
      vf_loss: 0.17226894199848175
    num_steps_sampled: 7175000
    num_steps_trained: 7175000
    wait_time_ms: 74.702
  iterations_since_restore: 1435
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12611.63466835022
  time_this_iter_s: 8.625332593917847
  time_total_s: 12611.63466835022
  timestamp: 1594861162
  timesteps_since_restore: 7175000
  timesteps_this_iter: 5000
  timesteps_total: 7175000
  training_iteration: 1435
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12611 s, 1435 iter, 7175000 ts, 322 rew

agent-1: 93.39999985547516
agent-2: 92.39999985547516
agent-3: 98.39999985547519
agent-4: 96.39999985547516
agent-5: 105.3999998554752
Extrinsic Rewards:
7
6
12
10
19
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 6
Max Reward: 19
Gini Coefficient: 0.22962962962962963
20:20 Ratio: 3.1666666666666665
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 324.89858396256744
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1435
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.187
    dispatch_time_ms: 8.284
    learner:
      cur_lr: 0.0008821450173854828
      grad_gnorm: 2.9960744380950928
      policy_entropy: 17.22629165649414
      policy_loss: 0.3610135018825531
      var_gnorm: 23.024520874023438
      vf_explained_var: 0.0
      vf_loss: 0.008365444839000702
    num_steps_sampled: 7180000
    num_steps_trained: 7180000
    wait_time_ms: 74.919
  iterations_since_restore: 1436
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12620.252762317657
  time_this_iter_s: 8.618093967437744
  time_total_s: 12620.252762317657
  timestamp: 1594861171
  timesteps_since_restore: 7180000
  timesteps_this_iter: 5000
  timesteps_total: 7180000
  training_iteration: 1436
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12620 s, 1436 iter, 7180000 ts, 325 rew

agent-1: 34.39999999951777
agent-2: 30.399999999517718
agent-3: 34.39999999951777
agent-4: 39.39999999951776
agent-5: 32.399999999517796
Extrinsic Rewards:
4
0
4
9
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.42105263157894735
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 322.82858396409847
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1436
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 9.11
    learner:
      cur_lr: 0.0008818120113573968
      grad_gnorm: 14.188199043273926
      policy_entropy: 22.585115432739258
      policy_loss: -1.9137184619903564
      var_gnorm: 23.023653030395508
      vf_explained_var: 0.0
      vf_loss: 0.1449931263923645
    num_steps_sampled: 7185000
    num_steps_trained: 7185000
    wait_time_ms: 73.893
  iterations_since_restore: 1437
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12628.732721328735
  time_this_iter_s: 8.47995901107788
  time_total_s: 12628.732721328735
  timestamp: 1594861180
  timesteps_since_restore: 7185000
  timesteps_this_iter: 5000
  timesteps_total: 7185000
  training_iteration: 1437
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12628 s, 1437 iter, 7185000 ts, 323 rew

agent-1: 88.19999997938737
agent-2: 82.1999999793874
agent-3: 81.1999999793874
agent-4: 80.19999997938737
agent-5: 91.1999999793874
Extrinsic Rewards:
13
7
6
5
16
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 5
Max Reward: 16
Gini Coefficient: 0.24680851063829787
20:20 Ratio: 3.2
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 321.02858426206876
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1437
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.622
    dispatch_time_ms: 6.563
    learner:
      cur_lr: 0.0008814790053293109
      grad_gnorm: 14.132802963256836
      policy_entropy: 31.90812873840332
      policy_loss: -2.0781145095825195
      var_gnorm: 23.023469924926758
      vf_explained_var: 0.0
      vf_loss: 0.1509445160627365
    num_steps_sampled: 7190000
    num_steps_trained: 7190000
    wait_time_ms: 79.55
  iterations_since_restore: 1438
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12637.29618358612
  time_this_iter_s: 8.563462257385254
  time_total_s: 12637.29618358612
  timestamp: 1594861188
  timesteps_since_restore: 7190000
  timesteps_this_iter: 5000
  timesteps_total: 7190000
  training_iteration: 1438
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12637 s, 1438 iter, 7190000 ts, 321 rew

agent-1: 64.99999999502849
agent-2: 68.99999999502849
agent-3: 60.99999999502861
agent-4: 57.9999999950286
agent-5: 61.999999995028624
Extrinsic Rewards:
9
13
5
2
6
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.29714285714285715
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_20-59-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 322.0185842619097
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1438
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.498
    dispatch_time_ms: 8.053
    learner:
      cur_lr: 0.000881145999301225
      grad_gnorm: 11.834328651428223
      policy_entropy: 34.16326141357422
      policy_loss: -1.5867806673049927
      var_gnorm: 23.022769927978516
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.10835517197847366
    num_steps_sampled: 7195000
    num_steps_trained: 7195000
    wait_time_ms: 72.581
  iterations_since_restore: 1439
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12645.702761411667
  time_this_iter_s: 8.406577825546265
  time_total_s: 12645.702761411667
  timestamp: 1594861197
  timesteps_since_restore: 7195000
  timesteps_this_iter: 5000
  timesteps_total: 7195000
  training_iteration: 1439
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12645 s, 1439 iter, 7195000 ts, 322 rew

agent-1: 32.399999999156364
agent-2: 35.39999999915636
agent-3: 35.399999999156364
agent-4: 33.39999999915636
agent-5: 34.39999999915635
Extrinsic Rewards:
2
5
5
3
4
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.16842105263157894
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 322.1085842618972
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1439
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.202
    dispatch_time_ms: 8.804
    learner:
      cur_lr: 0.000880812993273139
      grad_gnorm: 13.3583402633667
      policy_entropy: 19.118377685546875
      policy_loss: -0.9583934545516968
      var_gnorm: 23.024023056030273
      vf_explained_var: 0.0
      vf_loss: 0.1329697221517563
    num_steps_sampled: 7200000
    num_steps_trained: 7200000
    wait_time_ms: 73.357
  iterations_since_restore: 1440
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12654.248170614243
  time_this_iter_s: 8.545409202575684
  time_total_s: 12654.248170614243
  timestamp: 1594861205
  timesteps_since_restore: 7200000
  timesteps_this_iter: 5000
  timesteps_total: 7200000
  training_iteration: 1440
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12654 s, 1440 iter, 7200000 ts, 322 rew

agent-1: 38.59999999867674
agent-2: 41.59999999867674
agent-3: 38.59999999867674
agent-4: 33.59999999867677
agent-5: 36.59999999867674
Extrinsic Rewards:
5
8
5
0
3
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.34285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 320.6685842625558
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1440
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.894
    dispatch_time_ms: 6.093
    learner:
      cur_lr: 0.000880479987245053
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.351055145263672
      policy_loss: 27.352476119995117
      var_gnorm: 23.023447036743164
      vf_explained_var: 0.0
      vf_loss: 88.59257507324219
    num_steps_sampled: 7205000
    num_steps_trained: 7205000
    wait_time_ms: 74.858
  iterations_since_restore: 1441
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12662.734214782715
  time_this_iter_s: 8.48604416847229
  time_total_s: 12662.734214782715
  timestamp: 1594861214
  timesteps_since_restore: 7205000
  timesteps_this_iter: 5000
  timesteps_total: 7205000
  training_iteration: 1441
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12662 s, 1441 iter, 7205000 ts, 321 rew

agent-1: 69.19999998637515
agent-2: 73.19999998637516
agent-3: 84.19999998637519
agent-4: 76.19999998637516
agent-5: 75.19999998637516
Extrinsic Rewards:
2
6
17
9
8
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 2
Max Reward: 17
Gini Coefficient: 0.3142857142857143
20:20 Ratio: 8.5
Max-min Ratio: 8.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 319.6785843090521
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1441
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 8.546
    learner:
      cur_lr: 0.0008801469812169671
      grad_gnorm: 40.000003814697266
      policy_entropy: 29.231904983520508
      policy_loss: -7.489299297332764
      var_gnorm: 23.030305862426758
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.271275281906128
    num_steps_sampled: 7210000
    num_steps_trained: 7210000
    wait_time_ms: 72.598
  iterations_since_restore: 1442
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12671.241569519043
  time_this_iter_s: 8.507354736328125
  time_total_s: 12671.241569519043
  timestamp: 1594861222
  timesteps_since_restore: 7210000
  timesteps_this_iter: 5000
  timesteps_total: 7210000
  training_iteration: 1442
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12671 s, 1442 iter, 7210000 ts, 320 rew

agent-1: 147.39992918024308
agent-2: 142.39992918024302
agent-3: 143.39992918024305
agent-4: 142.39992918024302
agent-5: 135.39992918024296
Extrinsic Rewards:
21
16
17
16
9
Sum Reward: 79
Avg Reward: 15.8
Min Reward: 9
Max Reward: 21
Gini Coefficient: 0.12658227848101267
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 321.658580907809
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1442
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.423
    dispatch_time_ms: 7.619
    learner:
      cur_lr: 0.0008798139751888812
      grad_gnorm: 30.265066146850586
      policy_entropy: 34.41415786743164
      policy_loss: 5.306146144866943
      var_gnorm: 23.02366828918457
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.7148265838623047
    num_steps_sampled: 7215000
    num_steps_trained: 7215000
    wait_time_ms: 73.577
  iterations_since_restore: 1443
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12679.719987154007
  time_this_iter_s: 8.47841763496399
  time_total_s: 12679.719987154007
  timestamp: 1594861231
  timesteps_since_restore: 7215000
  timesteps_this_iter: 5000
  timesteps_total: 7215000
  training_iteration: 1443
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12679 s, 1443 iter, 7215000 ts, 322 rew

agent-1: 51.59999999783954
agent-2: 43.59999999783951
agent-3: 51.59999999783955
agent-4: 43.59999999783952
agent-5: 43.59999999783952
Extrinsic Rewards:
10
2
10
2
2
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.36923076923076925
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 320.93858090794885
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1443
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.924
    dispatch_time_ms: 8.454
    learner:
      cur_lr: 0.0008794810273684561
      grad_gnorm: 13.738489151000977
      policy_entropy: 34.59247589111328
      policy_loss: -2.4517831802368164
      var_gnorm: 23.02387809753418
      vf_explained_var: 0.0
      vf_loss: 0.11752130836248398
    num_steps_sampled: 7220000
    num_steps_trained: 7220000
    wait_time_ms: 73.27
  iterations_since_restore: 1444
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12688.122034072876
  time_this_iter_s: 8.402046918869019
  time_total_s: 12688.122034072876
  timestamp: 1594861239
  timesteps_since_restore: 7220000
  timesteps_this_iter: 5000
  timesteps_total: 7220000
  training_iteration: 1444
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12688 s, 1444 iter, 7220000 ts, 321 rew

agent-1: 36.99999999859118
agent-2: 32.999999998591186
agent-3: 37.99999999859117
agent-4: 38.999999998591164
agent-5: 32.999999998591186
Extrinsic Rewards:
5
1
6
7
1
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.34
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 317.7885824746105
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1444
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.83
    dispatch_time_ms: 7.822
    learner:
      cur_lr: 0.0008791480213403702
      grad_gnorm: 9.690840721130371
      policy_entropy: 34.506351470947266
      policy_loss: -1.6213939189910889
      var_gnorm: 23.02436065673828
      vf_explained_var: 0.0
      vf_loss: 0.07133902609348297
    num_steps_sampled: 7225000
    num_steps_trained: 7225000
    wait_time_ms: 74.839
  iterations_since_restore: 1445
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12696.583504915237
  time_this_iter_s: 8.46147084236145
  time_total_s: 12696.583504915237
  timestamp: 1594861248
  timesteps_since_restore: 7225000
  timesteps_this_iter: 5000
  timesteps_total: 7225000
  training_iteration: 1445
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12696 s, 1445 iter, 7225000 ts, 318 rew

agent-1: 34.99999999874812
agent-2: 37.99999999874812
agent-3: 32.999999998748116
agent-4: 41.99999999874813
agent-5: 31.99999999874822
Extrinsic Rewards:
3
6
1
10
0
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.5
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-00-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 317.2485824746957
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1445
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.9
    dispatch_time_ms: 9.562
    learner:
      cur_lr: 0.0008788150153122842
      grad_gnorm: 15.53274154663086
      policy_entropy: 19.98914909362793
      policy_loss: -1.1562124490737915
      var_gnorm: 23.024869918823242
      vf_explained_var: 0.0
      vf_loss: 0.16805718839168549
    num_steps_sampled: 7230000
    num_steps_trained: 7230000
    wait_time_ms: 70.789
  iterations_since_restore: 1446
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12705.288999795914
  time_this_iter_s: 8.70549488067627
  time_total_s: 12705.288999795914
  timestamp: 1594861257
  timesteps_since_restore: 7230000
  timesteps_this_iter: 5000
  timesteps_total: 7230000
  training_iteration: 1446
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12705 s, 1446 iter, 7230000 ts, 317 rew

agent-1: 56.999999989090036
agent-2: 53.99999998909002
agent-3: 53.99999998909003
agent-4: 49.99999998909002
agent-5: 54.99999998909004
Extrinsic Rewards:
9
6
6
2
7
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 316.8885824745317
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1446
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.549
    dispatch_time_ms: 5.892
    learner:
      cur_lr: 0.0008784820092841983
      grad_gnorm: 40.0
      policy_entropy: 26.548898696899414
      policy_loss: 44.37800979614258
      var_gnorm: 23.024553298950195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 91.49029541015625
    num_steps_sampled: 7235000
    num_steps_trained: 7235000
    wait_time_ms: 75.572
  iterations_since_restore: 1447
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12713.991735458374
  time_this_iter_s: 8.702735662460327
  time_total_s: 12713.991735458374
  timestamp: 1594861265
  timesteps_since_restore: 7235000
  timesteps_this_iter: 5000
  timesteps_total: 7235000
  training_iteration: 1447
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12713 s, 1447 iter, 7235000 ts, 317 rew

agent-1: 32.39999999899373
agent-2: 33.39999999899376
agent-3: 35.399999998993756
agent-4: 32.39999999899373
agent-5: 37.39999999899376
Extrinsic Rewards:
2
3
5
2
7
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.2736842105263158
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 314.18858248728776
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1447
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.876
    dispatch_time_ms: 5.968
    learner:
      cur_lr: 0.0008781490032561123
      grad_gnorm: 36.819942474365234
      policy_entropy: 34.579246520996094
      policy_loss: -6.0955095291137695
      var_gnorm: 23.026527404785156
      vf_explained_var: 0.0
      vf_loss: 1.0148870944976807
    num_steps_sampled: 7240000
    num_steps_trained: 7240000
    wait_time_ms: 77.824
  iterations_since_restore: 1448
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12722.619413852692
  time_this_iter_s: 8.627678394317627
  time_total_s: 12722.619413852692
  timestamp: 1594861274
  timesteps_since_restore: 7240000
  timesteps_this_iter: 5000
  timesteps_total: 7240000
  training_iteration: 1448
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12722 s, 1448 iter, 7240000 ts, 314 rew

agent-1: 105.99999990721896
agent-2: 99.99999990721894
agent-3: 92.99999990721895
agent-4: 100.99999990721894
agent-5: 94.99999990721895
Extrinsic Rewards:
18
12
5
13
7
Sum Reward: 55
Avg Reward: 11.0
Min Reward: 5
Max Reward: 18
Gini Coefficient: 0.23272727272727273
20:20 Ratio: 3.6
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 315.80858248285983
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1448
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 7.902
    learner:
      cur_lr: 0.0008778159972280264
      grad_gnorm: 18.729490280151367
      policy_entropy: 21.458484649658203
      policy_loss: -1.4138555526733398
      var_gnorm: 23.025150299072266
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.263705313205719
    num_steps_sampled: 7245000
    num_steps_trained: 7245000
    wait_time_ms: 78.532
  iterations_since_restore: 1449
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12731.265853881836
  time_this_iter_s: 8.646440029144287
  time_total_s: 12731.265853881836
  timestamp: 1594861283
  timesteps_since_restore: 7245000
  timesteps_this_iter: 5000
  timesteps_total: 7245000
  training_iteration: 1449
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12731 s, 1449 iter, 7245000 ts, 316 rew

agent-1: 121.39999723626839
agent-2: 117.39999723626838
agent-3: 138.39999723626863
agent-4: 119.39999723626842
agent-5: 124.39999723626839
Extrinsic Rewards:
11
7
28
9
14
Sum Reward: 69
Avg Reward: 13.8
Min Reward: 7
Max Reward: 28
Gini Coefficient: 0.27246376811594203
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 315.8985826897681
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1449
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 6.281
    learner:
      cur_lr: 0.0008774829911999404
      grad_gnorm: 20.54231071472168
      policy_entropy: 31.87174415588379
      policy_loss: -3.141862154006958
      var_gnorm: 23.009918212890625
      vf_explained_var: 0.0
      vf_loss: 0.3019736707210541
    num_steps_sampled: 7250000
    num_steps_trained: 7250000
    wait_time_ms: 78.883
  iterations_since_restore: 1450
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12739.878598928452
  time_this_iter_s: 8.6127450466156
  time_total_s: 12739.878598928452
  timestamp: 1594861291
  timesteps_since_restore: 7250000
  timesteps_this_iter: 5000
  timesteps_total: 7250000
  training_iteration: 1450
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12739 s, 1450 iter, 7250000 ts, 316 rew

agent-1: 77.59999980066327
agent-2: 89.59999980066326
agent-3: 84.59999980066324
agent-4: 85.59999980066326
agent-5: 76.59999980066327
Extrinsic Rewards:
4
16
11
12
3
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 3
Max Reward: 16
Gini Coefficient: 0.2956521739130435
20:20 Ratio: 5.333333333333333
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 314.4585827197865
  episode_reward_min: 143.999999997389
  episodes_this_iter: 1
  episodes_total: 1450
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 7.651
    learner:
      cur_lr: 0.0008771499851718545
      grad_gnorm: 39.99999237060547
      policy_entropy: 34.6372184753418
      policy_loss: 8.532781600952148
      var_gnorm: 23.009538650512695
      vf_explained_var: 0.0
      vf_loss: 2.0153887271881104
    num_steps_sampled: 7255000
    num_steps_trained: 7255000
    wait_time_ms: 77.788
  iterations_since_restore: 1451
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12748.528610944748
  time_this_iter_s: 8.650012016296387
  time_total_s: 12748.528610944748
  timestamp: 1594861300
  timesteps_since_restore: 7255000
  timesteps_this_iter: 5000
  timesteps_total: 7255000
  training_iteration: 1451
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12748 s, 1451 iter, 7255000 ts, 314 rew

agent-1: 27.59999999944132
agent-2: 33.59999999944134
agent-3: 25.59999999944132
agent-4: 26.599999999441323
agent-5: 30.599999999441327
Extrinsic Rewards:
2
8
0
1
5
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.5
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 311.57858272121814
  episode_reward_min: 143.9999999972077
  episodes_this_iter: 1
  episodes_total: 1451
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 8.435
    learner:
      cur_lr: 0.0008768169791437685
      grad_gnorm: 24.951494216918945
      policy_entropy: 23.64105796813965
      policy_loss: -3.641667604446411
      var_gnorm: 23.010623931884766
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.4564714729785919
    num_steps_sampled: 7260000
    num_steps_trained: 7260000
    wait_time_ms: 77.215
  iterations_since_restore: 1452
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12757.572410106659
  time_this_iter_s: 9.04379916191101
  time_total_s: 12757.572410106659
  timestamp: 1594861309
  timesteps_since_restore: 7260000
  timesteps_this_iter: 5000
  timesteps_total: 7260000
  training_iteration: 1452
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12757 s, 1452 iter, 7260000 ts, 312 rew

agent-1: 32.799999996085816
agent-2: 29.799999996085685
agent-3: 32.79999999608581
agent-4: 31.799999996085685
agent-5: 34.79999999608581
Extrinsic Rewards:
4
1
4
3
6
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.24444444444444444
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-01-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 311.668582721048
  episode_reward_min: 143.9999999972077
  episodes_this_iter: 1
  episodes_total: 1452
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.652
    dispatch_time_ms: 7.695
    learner:
      cur_lr: 0.0008764839731156826
      grad_gnorm: 6.585991382598877
      policy_entropy: 32.925662994384766
      policy_loss: 1.2874113321304321
      var_gnorm: 23.009416580200195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.03567599505186081
    num_steps_sampled: 7265000
    num_steps_trained: 7265000
    wait_time_ms: 79.207
  iterations_since_restore: 1453
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12766.241765499115
  time_this_iter_s: 8.669355392456055
  time_total_s: 12766.241765499115
  timestamp: 1594861318
  timesteps_since_restore: 7265000
  timesteps_this_iter: 5000
  timesteps_total: 7265000
  training_iteration: 1453
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12766 s, 1453 iter, 7265000 ts, 312 rew

agent-1: 61.599999978052985
agent-2: 67.59999997805298
agent-3: 69.59999997805295
agent-4: 65.59999997805298
agent-5: 59.59999997805296
Extrinsic Rewards:
4
10
12
8
2
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.28888888888888886
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 309.32858273714794
  episode_reward_min: 143.9999999972077
  episodes_this_iter: 1
  episodes_total: 1453
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.778
    dispatch_time_ms: 5.978
    learner:
      cur_lr: 0.0008761510252952576
      grad_gnorm: 9.989612579345703
      policy_entropy: 31.69710350036621
      policy_loss: -1.6445119380950928
      var_gnorm: 23.00953483581543
      vf_explained_var: 0.0
      vf_loss: 0.07568059116601944
    num_steps_sampled: 7270000
    num_steps_trained: 7270000
    wait_time_ms: 77.147
  iterations_since_restore: 1454
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12774.87324810028
  time_this_iter_s: 8.631482601165771
  time_total_s: 12774.87324810028
  timestamp: 1594861326
  timesteps_since_restore: 7270000
  timesteps_this_iter: 5000
  timesteps_total: 7270000
  training_iteration: 1454
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12774 s, 1454 iter, 7270000 ts, 309 rew

agent-1: 27.99999999956813
agent-2: 26.999999999568132
agent-3: 28.99999999956813
agent-4: 24.999999999568136
agent-5: 25.999999999568136
Extrinsic Rewards:
4
3
5
1
2
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 1
Max Reward: 5
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 306.9885827377842
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1454
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.041
    dispatch_time_ms: 7.343
    learner:
      cur_lr: 0.0008758180192671716
      grad_gnorm: 10.64818286895752
      policy_entropy: 32.286094665527344
      policy_loss: -1.1910185813903809
      var_gnorm: 23.00979995727539
      vf_explained_var: 0.0
      vf_loss: 0.08729008585214615
    num_steps_sampled: 7275000
    num_steps_trained: 7275000
    wait_time_ms: 75.127
  iterations_since_restore: 1455
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12783.475111961365
  time_this_iter_s: 8.601863861083984
  time_total_s: 12783.475111961365
  timestamp: 1594861335
  timesteps_since_restore: 7275000
  timesteps_this_iter: 5000
  timesteps_total: 7275000
  training_iteration: 1455
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12783 s, 1455 iter, 7275000 ts, 307 rew

agent-1: 37.39999999932284
agent-2: 34.39999999932283
agent-3: 32.39999999932284
agent-4: 32.39999999932284
agent-5: 34.39999999932283
Extrinsic Rewards:
7
4
2
2
4
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.25263157894736843
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 299.6096468606554
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1455
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.584
    dispatch_time_ms: 9.298
    learner:
      cur_lr: 0.0008754850132390857
      grad_gnorm: 22.074121475219727
      policy_entropy: 17.234067916870117
      policy_loss: -2.4798836708068848
      var_gnorm: 23.01123046875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.3713383376598358
    num_steps_sampled: 7280000
    num_steps_trained: 7280000
    wait_time_ms: 75.938
  iterations_since_restore: 1456
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12792.06686258316
  time_this_iter_s: 8.591750621795654
  time_total_s: 12792.06686258316
  timestamp: 1594861344
  timesteps_since_restore: 7280000
  timesteps_this_iter: 5000
  timesteps_total: 7280000
  training_iteration: 1456
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12792 s, 1456 iter, 7280000 ts, 300 rew

agent-1: 52.79999999741602
agent-2: 56.79999999741602
agent-3: 61.79999999741604
agent-4: 65.79999999741592
agent-5: 59.79999999741604
Extrinsic Rewards:
0
4
9
13
7
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.37575757575757573
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 300.7796468605628
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1456
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.587
    dispatch_time_ms: 8.518
    learner:
      cur_lr: 0.0008751520072109997
      grad_gnorm: 11.748067855834961
      policy_entropy: 19.223390579223633
      policy_loss: -0.7161352634429932
      var_gnorm: 23.010358810424805
      vf_explained_var: 0.0
      vf_loss: 0.10524334013462067
    num_steps_sampled: 7285000
    num_steps_trained: 7285000
    wait_time_ms: 74.982
  iterations_since_restore: 1457
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12800.676914215088
  time_this_iter_s: 8.61005163192749
  time_total_s: 12800.676914215088
  timestamp: 1594861352
  timesteps_since_restore: 7285000
  timesteps_this_iter: 5000
  timesteps_total: 7285000
  training_iteration: 1457
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12800 s, 1457 iter, 7285000 ts, 301 rew

agent-1: 50.99999998937261
agent-2: 51.99999998937261
agent-3: 55.9999999893726
agent-4: 58.9999999893726
agent-5: 51.99999998937261
Extrinsic Rewards:
3
4
8
11
4
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 300.77964686061233
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1457
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.671
    dispatch_time_ms: 8.518
    learner:
      cur_lr: 0.0008748190011829138
      grad_gnorm: 32.87904739379883
      policy_entropy: 16.44586181640625
      policy_loss: -2.752208948135376
      var_gnorm: 23.012699127197266
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.8371366262435913
    num_steps_sampled: 7290000
    num_steps_trained: 7290000
    wait_time_ms: 76.775
  iterations_since_restore: 1458
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12809.432465791702
  time_this_iter_s: 8.75555157661438
  time_total_s: 12809.432465791702
  timestamp: 1594861361
  timesteps_since_restore: 7290000
  timesteps_this_iter: 5000
  timesteps_total: 7290000
  training_iteration: 1458
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12809 s, 1458 iter, 7290000 ts, 301 rew

agent-1: 83.79999991111491
agent-2: 83.79999991111491
agent-3: 89.79999991111495
agent-4: 88.79999991111492
agent-5: 85.79999991111492
Extrinsic Rewards:
7
7
13
12
9
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 7
Max Reward: 13
Gini Coefficient: 0.14166666666666666
20:20 Ratio: 1.8571428571428572
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 303.3896468562132
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1458
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 8.448
    learner:
      cur_lr: 0.0008744859951548278
      grad_gnorm: 40.0
      policy_entropy: 19.312877655029297
      policy_loss: 16.474346160888672
      var_gnorm: 23.01018524169922
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 26.98073959350586
    num_steps_sampled: 7295000
    num_steps_trained: 7295000
    wait_time_ms: 75.336
  iterations_since_restore: 1459
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12818.077847242355
  time_this_iter_s: 8.645381450653076
  time_total_s: 12818.077847242355
  timestamp: 1594861370
  timesteps_since_restore: 7295000
  timesteps_this_iter: 5000
  timesteps_total: 7295000
  training_iteration: 1459
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12818 s, 1459 iter, 7295000 ts, 303 rew

agent-1: 65.5999999582325
agent-2: 65.59999995823249
agent-3: 60.5999999582325
agent-4: 61.599999958232516
agent-5: 70.59999995823254
Extrinsic Rewards:
8
8
3
4
13
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-02-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 305.1896468541509
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1459
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.513
    dispatch_time_ms: 7.845
    learner:
      cur_lr: 0.0008741529891267419
      grad_gnorm: 39.999996185302734
      policy_entropy: 12.84995174407959
      policy_loss: 24.719579696655273
      var_gnorm: 23.01259994506836
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 104.75801849365234
    num_steps_sampled: 7300000
    num_steps_trained: 7300000
    wait_time_ms: 76.714
  iterations_since_restore: 1460
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12826.635799407959
  time_this_iter_s: 8.557952165603638
  time_total_s: 12826.635799407959
  timestamp: 1594861378
  timesteps_since_restore: 7300000
  timesteps_this_iter: 5000
  timesteps_total: 7300000
  training_iteration: 1460
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12826 s, 1460 iter, 7300000 ts, 305 rew

agent-1: 58.99999997944994
agent-2: 61.99999997944994
agent-3: 60.999999979449925
agent-4: 67.99999997944985
agent-5: 64.99999997944988
Extrinsic Rewards:
3
6
5
12
9
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.25142857142857145
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 303.9296468604654
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1460
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.528
    dispatch_time_ms: 7.706
    learner:
      cur_lr: 0.0008738199830986559
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.903871536254883
      policy_loss: 25.905517578125
      var_gnorm: 23.01068115234375
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 31.689247131347656
    num_steps_sampled: 7305000
    num_steps_trained: 7305000
    wait_time_ms: 76.477
  iterations_since_restore: 1461
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12835.359753131866
  time_this_iter_s: 8.72395372390747
  time_total_s: 12835.359753131866
  timestamp: 1594861387
  timesteps_since_restore: 7305000
  timesteps_this_iter: 5000
  timesteps_total: 7305000
  training_iteration: 1461
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12835 s, 1461 iter, 7305000 ts, 304 rew

agent-1: 95.79999405162079
agent-2: 91.79999405162079
agent-3: 102.79999405162073
agent-4: 95.79999405162076
agent-5: 90.79999405162076
Extrinsic Rewards:
11
7
18
11
6
Sum Reward: 53
Avg Reward: 10.6
Min Reward: 6
Max Reward: 18
Gini Coefficient: 0.21132075471698114
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 306.449646563116
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1461
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.555
    dispatch_time_ms: 7.373
    learner:
      cur_lr: 0.00087348697707057
      grad_gnorm: 17.52823257446289
      policy_entropy: 34.45005798339844
      policy_loss: -3.253994941711426
      var_gnorm: 23.01028823852539
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.22784143686294556
    num_steps_sampled: 7310000
    num_steps_trained: 7310000
    wait_time_ms: 77.004
  iterations_since_restore: 1462
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12843.977932453156
  time_this_iter_s: 8.618179321289062
  time_total_s: 12843.977932453156
  timestamp: 1594861396
  timesteps_since_restore: 7310000
  timesteps_this_iter: 5000
  timesteps_total: 7310000
  training_iteration: 1462
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12843 s, 1462 iter, 7310000 ts, 306 rew

agent-1: 55.39999999448856
agent-2: 54.39999999448857
agent-3: 54.39999999448855
agent-4: 50.39999999448854
agent-5: 46.39999999448854
Extrinsic Rewards:
9
8
8
4
0
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.30344827586206896
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 305.45964656417857
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1462
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.102
    dispatch_time_ms: 7.799
    learner:
      cur_lr: 0.000873153971042484
      grad_gnorm: 40.0
      policy_entropy: 34.58811950683594
      policy_loss: 14.119743347167969
      var_gnorm: 23.010175704956055
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.141289234161377
    num_steps_sampled: 7315000
    num_steps_trained: 7315000
    wait_time_ms: 75.136
  iterations_since_restore: 1463
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12852.507905006409
  time_this_iter_s: 8.529972553253174
  time_total_s: 12852.507905006409
  timestamp: 1594861404
  timesteps_since_restore: 7315000
  timesteps_this_iter: 5000
  timesteps_total: 7315000
  training_iteration: 1463
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12852 s, 1463 iter, 7315000 ts, 305 rew

agent-1: 50.99999999768888
agent-2: 45.99999999768888
agent-3: 43.99999999768887
agent-4: 43.99999999768886
agent-5: 39.99999999768886
Extrinsic Rewards:
11
6
4
4
0
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.384
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 303.7496465694138
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1463
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.13
    dispatch_time_ms: 9.732
    learner:
      cur_lr: 0.000872821023222059
      grad_gnorm: 16.809192657470703
      policy_entropy: 28.638263702392578
      policy_loss: -2.1413815021514893
      var_gnorm: 23.01084327697754
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.20664337277412415
    num_steps_sampled: 7320000
    num_steps_trained: 7320000
    wait_time_ms: 71.683
  iterations_since_restore: 1464
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12861.069576740265
  time_this_iter_s: 8.561671733856201
  time_total_s: 12861.069576740265
  timestamp: 1594861413
  timesteps_since_restore: 7320000
  timesteps_this_iter: 5000
  timesteps_total: 7320000
  training_iteration: 1464
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12861 s, 1464 iter, 7320000 ts, 304 rew

agent-1: 58.99999999771656
agent-2: 50.999999997716564
agent-3: 47.99999999771657
agent-4: 59.999999997716564
agent-5: 51.999999997716564
Extrinsic Rewards:
11
3
0
12
4
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.4266666666666667
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 304.5596465693387
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1464
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 8.898
    learner:
      cur_lr: 0.0008724880171939731
      grad_gnorm: 39.999996185302734
      policy_entropy: 33.72116470336914
      policy_loss: 16.112525939941406
      var_gnorm: 23.01042366027832
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.111898899078369
    num_steps_sampled: 7325000
    num_steps_trained: 7325000
    wait_time_ms: 74.764
  iterations_since_restore: 1465
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12869.62412238121
  time_this_iter_s: 8.554545640945435
  time_total_s: 12869.62412238121
  timestamp: 1594861422
  timesteps_since_restore: 7325000
  timesteps_this_iter: 5000
  timesteps_total: 7325000
  training_iteration: 1465
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12869 s, 1465 iter, 7325000 ts, 305 rew

agent-1: 43.799999995882764
agent-2: 38.79999999588277
agent-3: 45.799999995882764
agent-4: 40.799999995882786
agent-5: 37.79999999588278
Extrinsic Rewards:
7
2
9
4
1
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3652173913043478
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 304.55964656919105
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1465
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.642
    dispatch_time_ms: 9.562
    learner:
      cur_lr: 0.0008721550111658871
      grad_gnorm: 18.2064208984375
      policy_entropy: 34.659610748291016
      policy_loss: -3.328892469406128
      var_gnorm: 23.011011123657227
      vf_explained_var: 0.0
      vf_loss: 0.25580230355262756
    num_steps_sampled: 7330000
    num_steps_trained: 7330000
    wait_time_ms: 74.833
  iterations_since_restore: 1466
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12878.24727678299
  time_this_iter_s: 8.623154401779175
  time_total_s: 12878.24727678299
  timestamp: 1594861430
  timesteps_since_restore: 7330000
  timesteps_this_iter: 5000
  timesteps_total: 7330000
  training_iteration: 1466
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12878 s, 1466 iter, 7330000 ts, 305 rew

agent-1: 50.399999997363345
agent-2: 52.39999999736334
agent-3: 55.39999999736334
agent-4: 53.39999999736335
agent-5: 49.399999997363345
Extrinsic Rewards:
4
6
9
7
3
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.20689655172413793
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-03-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 305.54964656908555
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1466
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.475
    dispatch_time_ms: 7.978
    learner:
      cur_lr: 0.0008718220051378012
      grad_gnorm: 10.878386497497559
      policy_entropy: 33.610107421875
      policy_loss: -1.7071058750152588
      var_gnorm: 23.01101303100586
      vf_explained_var: 0.0
      vf_loss: 0.08845409005880356
    num_steps_sampled: 7335000
    num_steps_trained: 7335000
    wait_time_ms: 73.474
  iterations_since_restore: 1467
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12886.813177585602
  time_this_iter_s: 8.565900802612305
  time_total_s: 12886.813177585602
  timestamp: 1594861439
  timesteps_since_restore: 7335000
  timesteps_this_iter: 5000
  timesteps_total: 7335000
  training_iteration: 1467
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12886 s, 1467 iter, 7335000 ts, 306 rew

agent-1: 39.39999999652275
agent-2: 47.39999999652275
agent-3: 47.39999999652275
agent-4: 42.39999999652275
agent-5: 39.39999999652275
Extrinsic Rewards:
1
9
9
4
1
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 306.1796465689442
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1467
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.457
    dispatch_time_ms: 8.167
    learner:
      cur_lr: 0.0008714889991097152
      grad_gnorm: 40.0
      policy_entropy: 26.862911224365234
      policy_loss: -6.141570568084717
      var_gnorm: 23.0147762298584
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.3233894109725952
    num_steps_sampled: 7340000
    num_steps_trained: 7340000
    wait_time_ms: 74.626
  iterations_since_restore: 1468
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12895.350637435913
  time_this_iter_s: 8.53745985031128
  time_total_s: 12895.350637435913
  timestamp: 1594861447
  timesteps_since_restore: 7340000
  timesteps_this_iter: 5000
  timesteps_total: 7340000
  training_iteration: 1468
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12895 s, 1468 iter, 7340000 ts, 306 rew

agent-1: 121.19998024321096
agent-2: 130.19998024321094
agent-3: 113.19998024321093
agent-4: 118.19998024321096
agent-5: 120.19998024321093
Extrinsic Rewards:
14
23
6
11
13
Sum Reward: 67
Avg Reward: 13.4
Min Reward: 6
Max Reward: 23
Gini Coefficient: 0.2208955223880597
20:20 Ratio: 3.8333333333333335
Max-min Ratio: 3.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 310.40964558116156
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1468
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.804
    dispatch_time_ms: 7.899
    learner:
      cur_lr: 0.0008711559930816293
      grad_gnorm: 39.999996185302734
      policy_entropy: 22.484792709350586
      policy_loss: 6.922914505004883
      var_gnorm: 23.011173248291016
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.6222383975982666
    num_steps_sampled: 7345000
    num_steps_trained: 7345000
    wait_time_ms: 76.363
  iterations_since_restore: 1469
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12903.997918128967
  time_this_iter_s: 8.6472806930542
  time_total_s: 12903.997918128967
  timestamp: 1594861456
  timesteps_since_restore: 7345000
  timesteps_this_iter: 5000
  timesteps_total: 7345000
  training_iteration: 1469
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12903 s, 1469 iter, 7345000 ts, 310 rew

agent-1: 43.599999998960016
agent-2: 35.59999999895997
agent-3: 33.599999998959966
agent-4: 37.59999999895999
agent-5: 38.59999999895999
Extrinsic Rewards:
10
2
0
4
5
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.4380952380952381
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 310.7696455811339
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1469
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 6.824
    learner:
      cur_lr: 0.0008708229870535433
      grad_gnorm: 40.000003814697266
      policy_entropy: 16.3029727935791
      policy_loss: 47.050392150878906
      var_gnorm: 23.0128173828125
      vf_explained_var: 0.0
      vf_loss: 187.1209716796875
    num_steps_sampled: 7350000
    num_steps_trained: 7350000
    wait_time_ms: 76.413
  iterations_since_restore: 1470
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12912.643368721008
  time_this_iter_s: 8.645450592041016
  time_total_s: 12912.643368721008
  timestamp: 1594861465
  timesteps_since_restore: 7350000
  timesteps_this_iter: 5000
  timesteps_total: 7350000
  training_iteration: 1470
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12912 s, 1470 iter, 7350000 ts, 311 rew

agent-1: 41.59999999521685
agent-2: 47.59999999521686
agent-3: 51.59999999521685
agent-4: 47.59999999521685
agent-5: 45.59999999521686
Extrinsic Rewards:
0
6
10
6
4
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.3384615384615385
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 310.6796455811971
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1470
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.778
    dispatch_time_ms: 8.115
    learner:
      cur_lr: 0.0008704899810254574
      grad_gnorm: 15.679181098937988
      policy_entropy: 15.584463119506836
      policy_loss: -1.145778775215149
      var_gnorm: 23.011680603027344
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.19038882851600647
    num_steps_sampled: 7355000
    num_steps_trained: 7355000
    wait_time_ms: 76.634
  iterations_since_restore: 1471
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12921.322728395462
  time_this_iter_s: 8.679359674453735
  time_total_s: 12921.322728395462
  timestamp: 1594861473
  timesteps_since_restore: 7355000
  timesteps_this_iter: 5000
  timesteps_total: 7355000
  training_iteration: 1471
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12921 s, 1471 iter, 7355000 ts, 311 rew

agent-1: 120.99999912226366
agent-2: 106.99999912226369
agent-3: 114.99999912226366
agent-4: 128.99999912226343
agent-5: 112.99999912226366
Extrinsic Rewards:
17
3
11
25
9
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 3
Max Reward: 25
Gini Coefficient: 0.32
20:20 Ratio: 8.333333333333334
Max-min Ratio: 8.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 314.9096455373399
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1471
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.627
    dispatch_time_ms: 9.328
    learner:
      cur_lr: 0.0008701569749973714
      grad_gnorm: 18.118223190307617
      policy_entropy: 31.245609283447266
      policy_loss: -2.894016981124878
      var_gnorm: 23.011486053466797
      vf_explained_var: 0.0
      vf_loss: 0.2527298629283905
    num_steps_sampled: 7360000
    num_steps_trained: 7360000
    wait_time_ms: 76.657
  iterations_since_restore: 1472
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12930.058375597
  time_this_iter_s: 8.735647201538086
  time_total_s: 12930.058375597
  timestamp: 1594861482
  timesteps_since_restore: 7360000
  timesteps_this_iter: 5000
  timesteps_total: 7360000
  training_iteration: 1472
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12930 s, 1472 iter, 7360000 ts, 315 rew

agent-1: 34.99999999505649
agent-2: 32.9999999950565
agent-3: 38.99999999505649
agent-4: 32.9999999950565
agent-5: 39.99999999505648
Extrinsic Rewards:
3
1
7
1
8
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.4
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-04-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 313.82964553740055
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1472
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 5.684
    learner:
      cur_lr: 0.0008698240271769464
      grad_gnorm: 10.247152328491211
      policy_entropy: 34.02288055419922
      policy_loss: -1.2034367322921753
      var_gnorm: 23.01149559020996
      vf_explained_var: 0.0
      vf_loss: 0.08104585856199265
    num_steps_sampled: 7365000
    num_steps_trained: 7365000
    wait_time_ms: 77.118
  iterations_since_restore: 1473
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12938.650064468384
  time_this_iter_s: 8.591688871383667
  time_total_s: 12938.650064468384
  timestamp: 1594861491
  timesteps_since_restore: 7365000
  timesteps_this_iter: 5000
  timesteps_total: 7365000
  training_iteration: 1473
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12938 s, 1473 iter, 7365000 ts, 314 rew

agent-1: 43.99999999710486
agent-2: 44.999999997104865
agent-3: 41.99999999710486
agent-4: 45.999999997104865
agent-5: 47.99999999710486
Extrinsic Rewards:
4
5
2
6
8
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.224
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 313.8296455373286
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1473
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.036
    dispatch_time_ms: 8.474
    learner:
      cur_lr: 0.0008694910211488605
      grad_gnorm: 21.89383888244629
      policy_entropy: 34.26248550415039
      policy_loss: -3.8460941314697266
      var_gnorm: 23.01177215576172
      vf_explained_var: 0.0
      vf_loss: 0.35257208347320557
    num_steps_sampled: 7370000
    num_steps_trained: 7370000
    wait_time_ms: 76.451
  iterations_since_restore: 1474
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12947.172647476196
  time_this_iter_s: 8.5225830078125
  time_total_s: 12947.172647476196
  timestamp: 1594861500
  timesteps_since_restore: 7370000
  timesteps_this_iter: 5000
  timesteps_total: 7370000
  training_iteration: 1474
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12947 s, 1474 iter, 7370000 ts, 314 rew

agent-1: 81.39999996506138
agent-2: 78.3999999650614
agent-3: 80.39999996506138
agent-4: 72.39999996506138
agent-5: 83.39999996506138
Extrinsic Rewards:
11
8
10
2
13
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.22727272727272727
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 315.89964553566574
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1474
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.917
    dispatch_time_ms: 7.529
    learner:
      cur_lr: 0.0008691580151207745
      grad_gnorm: 6.948553562164307
      policy_entropy: 28.550518035888672
      policy_loss: -0.8090316653251648
      var_gnorm: 23.011798858642578
      vf_explained_var: 0.0
      vf_loss: 0.036932799965143204
    num_steps_sampled: 7375000
    num_steps_trained: 7375000
    wait_time_ms: 73.21
  iterations_since_restore: 1475
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12955.934880971909
  time_this_iter_s: 8.76223349571228
  time_total_s: 12955.934880971909
  timestamp: 1594861508
  timesteps_since_restore: 7375000
  timesteps_this_iter: 5000
  timesteps_total: 7375000
  training_iteration: 1475
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12955 s, 1475 iter, 7375000 ts, 316 rew

agent-1: 38.1999999974769
agent-2: 38.1999999974769
agent-3: 37.19999999747691
agent-4: 46.19999999747691
agent-5: 38.1999999974769
Extrinsic Rewards:
3
3
2
11
3
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.32727272727272727
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 315.80964553566906
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1475
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.596
    dispatch_time_ms: 6.649
    learner:
      cur_lr: 0.0008688250090926886
      grad_gnorm: 32.1415901184082
      policy_entropy: 31.62135887145996
      policy_loss: -5.910710334777832
      var_gnorm: 23.012590408325195
      vf_explained_var: 0.0
      vf_loss: 0.6737484335899353
    num_steps_sampled: 7380000
    num_steps_trained: 7380000
    wait_time_ms: 81.53
  iterations_since_restore: 1476
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12964.67208147049
  time_this_iter_s: 8.737200498580933
  time_total_s: 12964.67208147049
  timestamp: 1594861517
  timesteps_since_restore: 7380000
  timesteps_this_iter: 5000
  timesteps_total: 7380000
  training_iteration: 1476
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12964 s, 1476 iter, 7380000 ts, 316 rew

agent-1: 94.99999784599437
agent-2: 107.99999784599429
agent-3: 100.99999784599434
agent-4: 98.99999784599432
agent-5: 91.99999784599437
Extrinsic Rewards:
7
20
13
11
4
Sum Reward: 55
Avg Reward: 11.0
Min Reward: 4
Max Reward: 20
Gini Coefficient: 0.27636363636363637
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 317.699645429706
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1476
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.246
    dispatch_time_ms: 11.152
    learner:
      cur_lr: 0.0008684920030646026
      grad_gnorm: 11.635690689086914
      policy_entropy: 34.64237594604492
      policy_loss: -1.5986571311950684
      var_gnorm: 23.01218032836914
      vf_explained_var: 0.0
      vf_loss: 0.09874934703111649
    num_steps_sampled: 7385000
    num_steps_trained: 7385000
    wait_time_ms: 71.981
  iterations_since_restore: 1477
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12981.840260505676
  time_this_iter_s: 17.168179035186768
  time_total_s: 12981.840260505676
  timestamp: 1594861534
  timesteps_since_restore: 7385000
  timesteps_this_iter: 5000
  timesteps_total: 7385000
  training_iteration: 1477
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12981 s, 1477 iter, 7385000 ts, 318 rew

agent-1: 40.79999999876363
agent-2: 40.79999999876363
agent-3: 42.79999999876363
agent-4: 38.79999999876362
agent-5: 43.79999999876363
Extrinsic Rewards:
4
4
6
2
7
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.20869565217391303
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 318.1496454296685
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1477
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 10.016
    learner:
      cur_lr: 0.0008681589970365167
      grad_gnorm: 17.46425437927246
      policy_entropy: 28.193302154541016
      policy_loss: -2.895530939102173
      var_gnorm: 23.012279510498047
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.2330409735441208
    num_steps_sampled: 7390000
    num_steps_trained: 7390000
    wait_time_ms: 78.067
  iterations_since_restore: 1478
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12990.566272497177
  time_this_iter_s: 8.726011991500854
  time_total_s: 12990.566272497177
  timestamp: 1594861543
  timesteps_since_restore: 7390000
  timesteps_this_iter: 5000
  timesteps_total: 7390000
  training_iteration: 1478
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12990 s, 1478 iter, 7390000 ts, 318 rew

agent-1: 90.99999996856292
agent-2: 73.99999996856288
agent-3: 74.99999996856288
agent-4: 87.99999996856292
agent-5: 76.9999999685629
Extrinsic Rewards:
19
2
3
16
5
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 2
Max Reward: 19
Gini Coefficient: 0.4177777777777778
20:20 Ratio: 9.5
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-05-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 316.5296454774123
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1478
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.008
    dispatch_time_ms: 8.309
    learner:
      cur_lr: 0.0008678259910084307
      grad_gnorm: 40.0
      policy_entropy: 33.99718475341797
      policy_loss: 62.43803405761719
      var_gnorm: 23.012252807617188
      vf_explained_var: 0.0
      vf_loss: 112.65996551513672
    num_steps_sampled: 7395000
    num_steps_trained: 7395000
    wait_time_ms: 74.372
  iterations_since_restore: 1479
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 12999.404098272324
  time_this_iter_s: 8.837825775146484
  time_total_s: 12999.404098272324
  timestamp: 1594861552
  timesteps_since_restore: 7395000
  timesteps_this_iter: 5000
  timesteps_total: 7395000
  training_iteration: 1479
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 12999 s, 1479 iter, 7395000 ts, 317 rew

agent-1: 33.39999999879027
agent-2: 41.399999998790264
agent-3: 30.39999999879026
agent-4: 33.39999999879027
agent-5: 32.399999998790285
Extrinsic Rewards:
3
11
0
3
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.4842105263157895
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 311.7596455683469
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1479
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.991
    dispatch_time_ms: 19.997
    learner:
      cur_lr: 0.0008674929849803448
      grad_gnorm: 40.00000762939453
      policy_entropy: 34.66017532348633
      policy_loss: 22.805753707885742
      var_gnorm: 23.012752532958984
      vf_explained_var: 0.0
      vf_loss: 13.683523178100586
    num_steps_sampled: 7400000
    num_steps_trained: 7400000
    wait_time_ms: 66.464
  iterations_since_restore: 1480
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13011.7016851902
  time_this_iter_s: 12.297586917877197
  time_total_s: 13011.7016851902
  timestamp: 1594861564
  timesteps_since_restore: 7400000
  timesteps_this_iter: 5000
  timesteps_total: 7400000
  training_iteration: 1480
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13011 s, 1480 iter, 7400000 ts, 312 rew

agent-1: 65.59999998283077
agent-2: 59.59999998283089
agent-3: 62.5999999828309
agent-4: 61.599999982830894
agent-5: 74.59999998283082
Extrinsic Rewards:
8
2
5
4
17
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 2
Max Reward: 17
Gini Coefficient: 0.37777777777777777
20:20 Ratio: 8.5
Max-min Ratio: 8.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 313.2896455675195
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1480
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.47
    dispatch_time_ms: 37.079
    learner:
      cur_lr: 0.0008671599789522588
      grad_gnorm: 39.037723541259766
      policy_entropy: 23.7195987701416
      policy_loss: 6.307243824005127
      var_gnorm: 23.012264251708984
      vf_explained_var: 0.0
      vf_loss: 1.285936713218689
    num_steps_sampled: 7405000
    num_steps_trained: 7405000
    wait_time_ms: 64.368
  iterations_since_restore: 1481
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13020.785126209259
  time_this_iter_s: 9.083441019058228
  time_total_s: 13020.785126209259
  timestamp: 1594861573
  timesteps_since_restore: 7405000
  timesteps_this_iter: 5000
  timesteps_total: 7405000
  training_iteration: 1481
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13020 s, 1481 iter, 7405000 ts, 313 rew

agent-1: 109.39999753260348
agent-2: 117.3999975326035
agent-3: 118.3999975326035
agent-4: 113.39999753260348
agent-5: 117.39999753260348
Extrinsic Rewards:
7
15
16
11
15
Sum Reward: 64
Avg Reward: 12.8
Min Reward: 7
Max Reward: 16
Gini Coefficient: 0.1375
20:20 Ratio: 2.2857142857142856
Max-min Ratio: 2.2857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 314.549645446701
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1481
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.3
    dispatch_time_ms: 26.105
    learner:
      cur_lr: 0.0008668269729241729
      grad_gnorm: 25.040666580200195
      policy_entropy: 27.958192825317383
      policy_loss: -3.6747307777404785
      var_gnorm: 23.012311935424805
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.45164555311203003
    num_steps_sampled: 7410000
    num_steps_trained: 7410000
    wait_time_ms: 60.025
  iterations_since_restore: 1482
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13029.80323934555
  time_this_iter_s: 9.018113136291504
  time_total_s: 13029.80323934555
  timestamp: 1594861583
  timesteps_since_restore: 7410000
  timesteps_this_iter: 5000
  timesteps_total: 7410000
  training_iteration: 1482
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13029 s, 1482 iter, 7410000 ts, 315 rew

agent-1: 49.199999998822804
agent-2: 47.19999999882281
agent-3: 50.1999999988228
agent-4: 49.1999999988228
agent-5: 47.19999999882281
Extrinsic Rewards:
6
4
7
6
4
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 4
Max Reward: 7
Gini Coefficient: 0.11851851851851852
20:20 Ratio: 1.75
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 312.9296454485883
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1482
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 50.521
    learner:
      cur_lr: 0.0008664940251037478
      grad_gnorm: 18.829435348510742
      policy_entropy: 33.56500244140625
      policy_loss: -1.8309847116470337
      var_gnorm: 22.995010375976562
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.24236005544662476
    num_steps_sampled: 7415000
    num_steps_trained: 7415000
    wait_time_ms: 42.89
  iterations_since_restore: 1483
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13039.061173677444
  time_this_iter_s: 9.257934331893921
  time_total_s: 13039.061173677444
  timestamp: 1594861592
  timesteps_since_restore: 7415000
  timesteps_this_iter: 5000
  timesteps_total: 7415000
  training_iteration: 1483
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13039 s, 1483 iter, 7415000 ts, 313 rew

agent-1: 124.39999814952374
agent-2: 116.39999814952371
agent-3: 128.39999814952384
agent-4: 133.39999814952407
agent-5: 118.39999814952374
Extrinsic Rewards:
14
6
18
23
8
Sum Reward: 69
Avg Reward: 13.8
Min Reward: 6
Max Reward: 23
Gini Coefficient: 0.25507246376811593
20:20 Ratio: 3.8333333333333335
Max-min Ratio: 3.8333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 316.9796453561439
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1483
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.513
    dispatch_time_ms: 31.801
    learner:
      cur_lr: 0.0008661610190756619
      grad_gnorm: 24.11771011352539
      policy_entropy: 32.23781204223633
      policy_loss: -3.688793182373047
      var_gnorm: 22.99580955505371
      vf_explained_var: 0.0
      vf_loss: 0.44007259607315063
    num_steps_sampled: 7420000
    num_steps_trained: 7420000
    wait_time_ms: 50.937
  iterations_since_restore: 1484
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13047.98403263092
  time_this_iter_s: 8.922858953475952
  time_total_s: 13047.98403263092
  timestamp: 1594861601
  timesteps_since_restore: 7420000
  timesteps_this_iter: 5000
  timesteps_total: 7420000
  training_iteration: 1484
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13047 s, 1484 iter, 7420000 ts, 317 rew

agent-1: 42.39999999897403
agent-2: 42.39999999897403
agent-3: 47.399999998974025
agent-4: 41.39999999897403
agent-5: 42.39999999897403
Extrinsic Rewards:
4
4
9
3
4
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.2
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 317.0696453562317
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1484
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 32.113
    learner:
      cur_lr: 0.000865828013047576
      grad_gnorm: 10.029420852661133
      policy_entropy: 27.289031982421875
      policy_loss: -0.7216230630874634
      var_gnorm: 22.99554443359375
      vf_explained_var: 0.0
      vf_loss: 0.077438585460186
    num_steps_sampled: 7425000
    num_steps_trained: 7425000
    wait_time_ms: 58.715
  iterations_since_restore: 1485
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13056.969147443771
  time_this_iter_s: 8.985114812850952
  time_total_s: 13056.969147443771
  timestamp: 1594861610
  timesteps_since_restore: 7425000
  timesteps_this_iter: 5000
  timesteps_total: 7425000
  training_iteration: 1485
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13056 s, 1485 iter, 7425000 ts, 317 rew

agent-1: 52.99999995725836
agent-2: 60.99999995725837
agent-3: 48.9999999572584
agent-4: 50.99999995725837
agent-5: 55.99999995725837
Extrinsic Rewards:
5
13
1
3
8
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.38666666666666666
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-06-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 316.8896453551816
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1485
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.848
    dispatch_time_ms: 33.776
    learner:
      cur_lr: 0.00086549500701949
      grad_gnorm: 40.0
      policy_entropy: 34.310550689697266
      policy_loss: 55.500885009765625
      var_gnorm: 23.006168365478516
      vf_explained_var: 0.0
      vf_loss: 74.52445220947266
    num_steps_sampled: 7430000
    num_steps_trained: 7430000
    wait_time_ms: 57.13
  iterations_since_restore: 1486
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13065.832498073578
  time_this_iter_s: 8.863350629806519
  time_total_s: 13065.832498073578
  timestamp: 1594861619
  timesteps_since_restore: 7430000
  timesteps_this_iter: 5000
  timesteps_total: 7430000
  training_iteration: 1486
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13065 s, 1486 iter, 7430000 ts, 317 rew

agent-1: 108.19489937993724
agent-2: 105.19489937993718
agent-3: 118.19489937993724
agent-4: 112.19489937993724
agent-5: 114.19489937993716
Extrinsic Rewards:
9
6
19
13
15
Sum Reward: 62
Avg Reward: 12.4
Min Reward: 6
Max Reward: 19
Gini Coefficient: 0.2064516129032258
20:20 Ratio: 3.1666666666666665
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 320.7593903242112
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1486
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.908
    dispatch_time_ms: 26.616
    learner:
      cur_lr: 0.0008651620009914041
      grad_gnorm: 40.000003814697266
      policy_entropy: 20.56609535217285
      policy_loss: 31.672502517700195
      var_gnorm: 23.002958297729492
      vf_explained_var: 0.0
      vf_loss: 63.643253326416016
    num_steps_sampled: 7435000
    num_steps_trained: 7435000
    wait_time_ms: 58.612
  iterations_since_restore: 1487
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13074.947131156921
  time_this_iter_s: 9.114633083343506
  time_total_s: 13074.947131156921
  timestamp: 1594861628
  timesteps_since_restore: 7435000
  timesteps_this_iter: 5000
  timesteps_total: 7435000
  training_iteration: 1487
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13074 s, 1487 iter, 7435000 ts, 321 rew

agent-1: 104.79999198999151
agent-2: 115.79999198999151
agent-3: 114.79999198999151
agent-4: 112.79999198999151
agent-5: 118.79999198999151
Extrinsic Rewards:
4
15
14
12
18
Sum Reward: 63
Avg Reward: 12.6
Min Reward: 4
Max Reward: 18
Gini Coefficient: 0.19682539682539682
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 323.2793899240562
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1487
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.072
    dispatch_time_ms: 27.938
    learner:
      cur_lr: 0.0008648289949633181
      grad_gnorm: 40.0
      policy_entropy: 26.310039520263672
      policy_loss: -6.239449501037598
      var_gnorm: 22.99759864807129
      vf_explained_var: 0.0
      vf_loss: 1.2767047882080078
    num_steps_sampled: 7440000
    num_steps_trained: 7440000
    wait_time_ms: 56.501
  iterations_since_restore: 1488
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13084.196378231049
  time_this_iter_s: 9.249247074127197
  time_total_s: 13084.196378231049
  timestamp: 1594861637
  timesteps_since_restore: 7440000
  timesteps_this_iter: 5000
  timesteps_total: 7440000
  training_iteration: 1488
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13084 s, 1488 iter, 7440000 ts, 323 rew

agent-1: 56.99999998594224
agent-2: 62.99999998594224
agent-3: 68.99999998594228
agent-4: 67.99999998594231
agent-5: 57.99999998594224
Extrinsic Rewards:
1
7
13
12
2
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.38857142857142857
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 322.55938992514626
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1488
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.731
    dispatch_time_ms: 22.027
    learner:
      cur_lr: 0.0008644959889352322
      grad_gnorm: 12.891554832458496
      policy_entropy: 13.870706558227539
      policy_loss: -0.08457781374454498
      var_gnorm: 22.99504280090332
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.1279391199350357
    num_steps_sampled: 7445000
    num_steps_trained: 7445000
    wait_time_ms: 30.284
  iterations_since_restore: 1489
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13093.513918161392
  time_this_iter_s: 9.317539930343628
  time_total_s: 13093.513918161392
  timestamp: 1594861646
  timesteps_since_restore: 7445000
  timesteps_this_iter: 5000
  timesteps_total: 7445000
  training_iteration: 1489
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13093 s, 1489 iter, 7445000 ts, 323 rew

agent-1: 66.79999998985438
agent-2: 64.79999998985441
agent-3: 65.7999999898544
agent-4: 73.79999998985438
agent-5: 70.79999998985438
Extrinsic Rewards:
6
4
5
13
10
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 4
Max Reward: 13
Gini Coefficient: 0.24210526315789474
20:20 Ratio: 3.25
Max-min Ratio: 3.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 324.0893899247248
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1489
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 27.243
    learner:
      cur_lr: 0.0008641629829071462
      grad_gnorm: 4.50282621383667
      policy_entropy: 34.402835845947266
      policy_loss: -4.233266353607178
      var_gnorm: 22.995071411132812
      vf_explained_var: 0.0
      vf_loss: 0.1109163761138916
    num_steps_sampled: 7450000
    num_steps_trained: 7450000
    wait_time_ms: 58.594
  iterations_since_restore: 1490
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13102.600294828415
  time_this_iter_s: 9.086376667022705
  time_total_s: 13102.600294828415
  timestamp: 1594861656
  timesteps_since_restore: 7450000
  timesteps_this_iter: 5000
  timesteps_total: 7450000
  training_iteration: 1490
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13102 s, 1490 iter, 7450000 ts, 324 rew

agent-1: 99.99999940273291
agent-2: 102.99999940273291
agent-3: 112.99999940273291
agent-4: 114.99999940273294
agent-5: 108.99999940273291
Extrinsic Rewards:
4
7
17
19
13
Sum Reward: 60
Avg Reward: 12.0
Min Reward: 4
Max Reward: 19
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 4.75
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 325.5293898961335
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1490
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.027
    dispatch_time_ms: 7.145
    learner:
      cur_lr: 0.0008638299768790603
      grad_gnorm: 40.0
      policy_entropy: 33.67097854614258
      policy_loss: 13.350865364074707
      var_gnorm: 22.995126724243164
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.9667181968688965
    num_steps_sampled: 7455000
    num_steps_trained: 7455000
    wait_time_ms: 74.569
  iterations_since_restore: 1491
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13111.409803152084
  time_this_iter_s: 8.809508323669434
  time_total_s: 13111.409803152084
  timestamp: 1594861664
  timesteps_since_restore: 7455000
  timesteps_this_iter: 5000
  timesteps_total: 7455000
  training_iteration: 1491
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13111 s, 1491 iter, 7455000 ts, 326 rew

agent-1: 37.39999999910337
agent-2: 30.399999999103347
agent-3: 34.39999999910335
agent-4: 31.39999999910334
agent-5: 37.39999999910337
Extrinsic Rewards:
7
0
4
1
7
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.42105263157894735
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-07-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 324.98938989621826
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1491
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.401
    dispatch_time_ms: 35.691
    learner:
      cur_lr: 0.0008634970290586352
      grad_gnorm: 12.600892066955566
      policy_entropy: 33.802207946777344
      policy_loss: -2.5614640712738037
      var_gnorm: 22.99518585205078
      vf_explained_var: 0.0
      vf_loss: 0.11658051609992981
    num_steps_sampled: 7460000
    num_steps_trained: 7460000
    wait_time_ms: 57.647
  iterations_since_restore: 1492
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13120.0236723423
  time_this_iter_s: 8.613869190216064
  time_total_s: 13120.0236723423
  timestamp: 1594861673
  timesteps_since_restore: 7460000
  timesteps_this_iter: 5000
  timesteps_total: 7460000
  training_iteration: 1492
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13120 s, 1492 iter, 7460000 ts, 325 rew

agent-1: 54.799999997538926
agent-2: 46.79999999753891
agent-3: 55.799999997538926
agent-4: 45.79999999753891
agent-5: 48.79999999753891
Extrinsic Rewards:
10
2
11
1
4
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.4
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 324.6293898973191
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1492
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.587
    dispatch_time_ms: 35.749
    learner:
      cur_lr: 0.0008631640230305493
      grad_gnorm: 21.663814544677734
      policy_entropy: 34.45671844482422
      policy_loss: -1.618608832359314
      var_gnorm: 22.995756149291992
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.30229446291923523
    num_steps_sampled: 7465000
    num_steps_trained: 7465000
    wait_time_ms: 55.406
  iterations_since_restore: 1493
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13129.026186227798
  time_this_iter_s: 9.002513885498047
  time_total_s: 13129.026186227798
  timestamp: 1594861682
  timesteps_since_restore: 7465000
  timesteps_this_iter: 5000
  timesteps_total: 7465000
  training_iteration: 1493
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13129 s, 1493 iter, 7465000 ts, 325 rew

agent-1: 40.799999999235304
agent-2: 41.799999999235304
agent-3: 39.79999999923531
agent-4: 40.799999999235304
agent-5: 43.799999999235304
Extrinsic Rewards:
4
5
3
4
7
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.1565217391304348
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 324.44938989734806
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1493
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.094
    dispatch_time_ms: 18.391
    learner:
      cur_lr: 0.0008628310170024633
      grad_gnorm: 18.977783203125
      policy_entropy: 28.564857482910156
      policy_loss: -4.210163116455078
      var_gnorm: 22.995779037475586
      vf_explained_var: 0.0
      vf_loss: 0.27845534682273865
    num_steps_sampled: 7470000
    num_steps_trained: 7470000
    wait_time_ms: 57.647
  iterations_since_restore: 1494
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13137.861630439758
  time_this_iter_s: 8.835444211959839
  time_total_s: 13137.861630439758
  timestamp: 1594861691
  timesteps_since_restore: 7470000
  timesteps_this_iter: 5000
  timesteps_total: 7470000
  training_iteration: 1494
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13137 s, 1494 iter, 7470000 ts, 324 rew

agent-1: 50.59999999269153
agent-2: 42.59999999269155
agent-3: 46.59999999269153
agent-4: 47.59999999269156
agent-5: 46.59999999269154
Extrinsic Rewards:
9
1
5
6
5
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.26153846153846155
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 323.9993898995166
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1494
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.775
    dispatch_time_ms: 29.562
    learner:
      cur_lr: 0.0008624980109743774
      grad_gnorm: 40.0
      policy_entropy: 32.98147964477539
      policy_loss: 66.25321197509766
      var_gnorm: 22.996116638183594
      vf_explained_var: 0.0
      vf_loss: 134.10150146484375
    num_steps_sampled: 7475000
    num_steps_trained: 7475000
    wait_time_ms: 53.295
  iterations_since_restore: 1495
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13146.829156637192
  time_this_iter_s: 8.967526197433472
  time_total_s: 13146.829156637192
  timestamp: 1594861700
  timesteps_since_restore: 7475000
  timesteps_this_iter: 5000
  timesteps_total: 7475000
  training_iteration: 1495
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13146 s, 1495 iter, 7475000 ts, 324 rew

agent-1: 44.999999996869
agent-2: 43.999999996869015
agent-3: 45.999999996869
agent-4: 39.999999996869015
agent-5: 49.999999996869
Extrinsic Rewards:
5
4
6
0
10
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.352
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 320.7593903229791
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1495
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.706
    dispatch_time_ms: 28.098
    learner:
      cur_lr: 0.0008621650049462914
      grad_gnorm: 24.1708984375
      policy_entropy: 17.483177185058594
      policy_loss: -4.063708305358887
      var_gnorm: 22.99691390991211
      vf_explained_var: 0.0
      vf_loss: 0.4523637592792511
    num_steps_sampled: 7480000
    num_steps_trained: 7480000
    wait_time_ms: 61.4
  iterations_since_restore: 1496
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13155.676164627075
  time_this_iter_s: 8.847007989883423
  time_total_s: 13155.676164627075
  timestamp: 1594861709
  timesteps_since_restore: 7480000
  timesteps_this_iter: 5000
  timesteps_total: 7480000
  training_iteration: 1496
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13155 s, 1496 iter, 7480000 ts, 321 rew

agent-1: 81.19999959393871
agent-2: 80.1999995939387
agent-3: 83.19999959393873
agent-4: 93.19999959393874
agent-5: 85.19999959393873
Extrinsic Rewards:
6
5
8
18
10
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 5
Max Reward: 18
Gini Coefficient: 0.2553191489361702
20:20 Ratio: 3.6
Max-min Ratio: 3.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 318.86939057637994
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1496
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.126
    dispatch_time_ms: 33.332
    learner:
      cur_lr: 0.0008618319989182055
      grad_gnorm: 13.480615615844727
      policy_entropy: 24.565757751464844
      policy_loss: 0.7048006653785706
      var_gnorm: 22.996320724487305
      vf_explained_var: 0.0
      vf_loss: 0.1672218143939972
    num_steps_sampled: 7485000
    num_steps_trained: 7485000
    wait_time_ms: 51.454
  iterations_since_restore: 1497
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13164.475409030914
  time_this_iter_s: 8.799244403839111
  time_total_s: 13164.475409030914
  timestamp: 1594861718
  timesteps_since_restore: 7485000
  timesteps_this_iter: 5000
  timesteps_total: 7485000
  training_iteration: 1497
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13164 s, 1497 iter, 7485000 ts, 319 rew

agent-1: 35.599999998489345
agent-2: 37.59999999848934
agent-3: 34.59999999848934
agent-4: 38.599999998489324
agent-5: 42.59999999848934
Extrinsic Rewards:
2
4
1
5
9
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3619047619047619
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 317.8793905765193
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1497
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.358
    dispatch_time_ms: 28.629
    learner:
      cur_lr: 0.0008614989928901196
      grad_gnorm: 26.264328002929688
      policy_entropy: 24.137649536132812
      policy_loss: -5.176710605621338
      var_gnorm: 22.996231079101562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.46416354179382324
    num_steps_sampled: 7490000
    num_steps_trained: 7490000
    wait_time_ms: 60.528
  iterations_since_restore: 1498
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13173.435326576233
  time_this_iter_s: 8.959917545318604
  time_total_s: 13173.435326576233
  timestamp: 1594861727
  timesteps_since_restore: 7490000
  timesteps_this_iter: 5000
  timesteps_total: 7490000
  training_iteration: 1498
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13173 s, 1498 iter, 7490000 ts, 318 rew

agent-1: 44.799999619014855
agent-2: 49.79999961901488
agent-3: 58.79999961901488
agent-4: 50.79999961901487
agent-5: 47.79999961901486
Extrinsic Rewards:
0
5
14
6
3
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.44285714285714284
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-08-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 316.61939055798626
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1498
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.653
    dispatch_time_ms: 32.247
    learner:
      cur_lr: 0.0008611659868620336
      grad_gnorm: 40.0
      policy_entropy: 34.19269561767578
      policy_loss: 29.51634407043457
      var_gnorm: 22.995773315429688
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 24.02539825439453
    num_steps_sampled: 7495000
    num_steps_trained: 7495000
    wait_time_ms: 58.115
  iterations_since_restore: 1499
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13182.642344236374
  time_this_iter_s: 9.207017660140991
  time_total_s: 13182.642344236374
  timestamp: 1594861736
  timesteps_since_restore: 7495000
  timesteps_this_iter: 5000
  timesteps_total: 7495000
  training_iteration: 1499
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13182 s, 1499 iter, 7495000 ts, 317 rew

agent-1: 37.59999999805455
agent-2: 39.59999999805456
agent-3: 37.59999999805455
agent-4: 36.59999999805454
agent-5: 37.59999999805456
Extrinsic Rewards:
4
6
4
3
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 3
Max Reward: 6
Gini Coefficient: 0.11428571428571428
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 316.2593905580735
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1499
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.965
    dispatch_time_ms: 7.712
    learner:
      cur_lr: 0.0008608329808339477
      grad_gnorm: 12.697637557983398
      policy_entropy: 34.65345001220703
      policy_loss: -2.37872576713562
      var_gnorm: 22.995559692382812
      vf_explained_var: 0.0
      vf_loss: 0.1205676794052124
    num_steps_sampled: 7500000
    num_steps_trained: 7500000
    wait_time_ms: 76.812
  iterations_since_restore: 1500
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13191.507752656937
  time_this_iter_s: 8.865408420562744
  time_total_s: 13191.507752656937
  timestamp: 1594861745
  timesteps_since_restore: 7500000
  timesteps_this_iter: 5000
  timesteps_total: 7500000
  training_iteration: 1500
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13191 s, 1500 iter, 7500000 ts, 316 rew

agent-1: 50.599999996414624
agent-2: 50.59999999641464
agent-3: 45.599999996414624
agent-4: 43.599999996414624
agent-5: 43.599999996414624
Extrinsic Rewards:
9
9
4
2
2
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.3230769230769231
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 314.5493905613184
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1500
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 6.4
    learner:
      cur_lr: 0.0008604999748058617
      grad_gnorm: 40.0
      policy_entropy: 33.13674545288086
      policy_loss: 8.81755542755127
      var_gnorm: 22.99578285217285
      vf_explained_var: 0.0
      vf_loss: 2.372593879699707
    num_steps_sampled: 7505000
    num_steps_trained: 7505000
    wait_time_ms: 78.388
  iterations_since_restore: 1501
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13200.170184612274
  time_this_iter_s: 8.662431955337524
  time_total_s: 13200.170184612274
  timestamp: 1594861754
  timesteps_since_restore: 7505000
  timesteps_this_iter: 5000
  timesteps_total: 7505000
  training_iteration: 1501
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13200 s, 1501 iter, 7505000 ts, 315 rew

agent-1: 36.79999999909971
agent-2: 43.79999999909968
agent-3: 40.799999999099704
agent-4: 40.799999999099704
agent-5: 44.79999999909968
Extrinsic Rewards:
0
7
4
4
8
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.33043478260869563
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 314.1893905614034
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1501
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.723
    dispatch_time_ms: 10.123
    learner:
      cur_lr: 0.0008601670269854367
      grad_gnorm: 17.167648315429688
      policy_entropy: 34.053916931152344
      policy_loss: -2.8469090461730957
      var_gnorm: 22.996566772460938
      vf_explained_var: 0.0
      vf_loss: 0.21273072063922882
    num_steps_sampled: 7510000
    num_steps_trained: 7510000
    wait_time_ms: 74.973
  iterations_since_restore: 1502
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13208.783840417862
  time_this_iter_s: 8.613655805587769
  time_total_s: 13208.783840417862
  timestamp: 1594861762
  timesteps_since_restore: 7510000
  timesteps_this_iter: 5000
  timesteps_total: 7510000
  training_iteration: 1502
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13208 s, 1502 iter, 7510000 ts, 314 rew

agent-1: 40.19999999874494
agent-2: 42.19999999874494
agent-3: 36.199999998744964
agent-4: 41.19999999874494
agent-5: 38.199999998744964
Extrinsic Rewards:
5
7
1
6
3
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.2727272727272727
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 312.83939056161176
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1502
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.722
    dispatch_time_ms: 9.256
    learner:
      cur_lr: 0.0008598340209573507
      grad_gnorm: 40.000003814697266
      policy_entropy: 34.657474517822266
      policy_loss: 16.302833557128906
      var_gnorm: 22.996421813964844
      vf_explained_var: 0.0
      vf_loss: 7.1086106300354
    num_steps_sampled: 7515000
    num_steps_trained: 7515000
    wait_time_ms: 75.321
  iterations_since_restore: 1503
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13217.463985443115
  time_this_iter_s: 8.680145025253296
  time_total_s: 13217.463985443115
  timestamp: 1594861771
  timesteps_since_restore: 7515000
  timesteps_this_iter: 5000
  timesteps_total: 7515000
  training_iteration: 1503
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13217 s, 1503 iter, 7515000 ts, 313 rew

agent-1: 58.59999997855976
agent-2: 69.59999997855974
agent-3: 69.59999997855974
agent-4: 57.599999978559765
agent-5: 68.59999997855974
Extrinsic Rewards:
1
12
12
0
11
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.3888888888888889
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 313.82939056061156
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1503
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.283
    dispatch_time_ms: 8.204
    learner:
      cur_lr: 0.0008595010149292648
      grad_gnorm: 17.995370864868164
      policy_entropy: 34.474082946777344
      policy_loss: -3.085310459136963
      var_gnorm: 22.99643325805664
      vf_explained_var: 0.0
      vf_loss: 0.21613523364067078
    num_steps_sampled: 7520000
    num_steps_trained: 7520000
    wait_time_ms: 74.82
  iterations_since_restore: 1504
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13226.086498737335
  time_this_iter_s: 8.62251329421997
  time_total_s: 13226.086498737335
  timestamp: 1594861780
  timesteps_since_restore: 7520000
  timesteps_this_iter: 5000
  timesteps_total: 7520000
  training_iteration: 1504
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13226 s, 1504 iter, 7520000 ts, 314 rew

agent-1: 40.999999998806864
agent-2: 34.99999999880687
agent-3: 33.99999999880687
agent-4: 35.999999998806885
agent-5: 33.99999999880687
Extrinsic Rewards:
9
3
2
4
2
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.32
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 313.1993905607774
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1504
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 8.485
    learner:
      cur_lr: 0.0008591680089011788
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.481510162353516
      policy_loss: 12.234356880187988
      var_gnorm: 22.996828079223633
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.3841023445129395
    num_steps_sampled: 7525000
    num_steps_trained: 7525000
    wait_time_ms: 77.147
  iterations_since_restore: 1505
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13234.730497598648
  time_this_iter_s: 8.643998861312866
  time_total_s: 13234.730497598648
  timestamp: 1594861788
  timesteps_since_restore: 7525000
  timesteps_this_iter: 5000
  timesteps_total: 7525000
  training_iteration: 1505
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13234 s, 1505 iter, 7525000 ts, 313 rew

agent-1: 49.79999999522011
agent-2: 47.79999999522011
agent-3: 55.79999999522011
agent-4: 48.799999995220126
agent-5: 49.79999999522011
Extrinsic Rewards:
5
3
11
4
5
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.24285714285714285
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-09-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 313.7393905605718
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1505
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.638
    dispatch_time_ms: 8.704
    learner:
      cur_lr: 0.0008588350028730929
      grad_gnorm: 13.965163230895996
      policy_entropy: 32.66922378540039
      policy_loss: -2.3769350051879883
      var_gnorm: 22.99773597717285
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.14537940919399261
    num_steps_sampled: 7530000
    num_steps_trained: 7530000
    wait_time_ms: 74.728
  iterations_since_restore: 1506
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13243.301503896713
  time_this_iter_s: 8.571006298065186
  time_total_s: 13243.301503896713
  timestamp: 1594861797
  timesteps_since_restore: 7530000
  timesteps_this_iter: 5000
  timesteps_total: 7530000
  training_iteration: 1506
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13243 s, 1506 iter, 7530000 ts, 314 rew

agent-1: 33.39999999893412
agent-2: 30.399999998934117
agent-3: 34.39999999893411
agent-4: 34.39999999893411
agent-5: 38.39999999893411
Extrinsic Rewards:
3
0
4
4
8
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.35789473684210527
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 312.4793905608423
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1506
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.114
    dispatch_time_ms: 6.231
    learner:
      cur_lr: 0.0008585019968450069
      grad_gnorm: 39.999996185302734
      policy_entropy: 23.71976661682129
      policy_loss: 15.154570579528809
      var_gnorm: 22.997705459594727
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 15.245036125183105
    num_steps_sampled: 7535000
    num_steps_trained: 7535000
    wait_time_ms: 74.168
  iterations_since_restore: 1507
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13251.79541683197
  time_this_iter_s: 8.493912935256958
  time_total_s: 13251.79541683197
  timestamp: 1594861805
  timesteps_since_restore: 7535000
  timesteps_this_iter: 5000
  timesteps_total: 7535000
  training_iteration: 1507
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13251 s, 1507 iter, 7535000 ts, 312 rew

agent-1: 55.59999995333058
agent-2: 62.59999995333058
agent-3: 55.59999995333058
agent-4: 54.59999995333058
agent-5: 50.59999995333058
Extrinsic Rewards:
6
13
6
5
1
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 1
Max Reward: 13
Gini Coefficient: 0.3225806451612903
20:20 Ratio: 13.0
Max-min Ratio: 13.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 313.64939055853984
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1507
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 34.829
    learner:
      cur_lr: 0.000858168990816921
      grad_gnorm: 27.948532104492188
      policy_entropy: 31.81270408630371
      policy_loss: -9.432474136352539
      var_gnorm: 23.002490997314453
      vf_explained_var: 0.0
      vf_loss: 0.5760058164596558
    num_steps_sampled: 7540000
    num_steps_trained: 7540000
    wait_time_ms: 45.451
  iterations_since_restore: 1508
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13268.790044546127
  time_this_iter_s: 16.994627714157104
  time_total_s: 13268.790044546127
  timestamp: 1594861822
  timesteps_since_restore: 7540000
  timesteps_this_iter: 5000
  timesteps_total: 7540000
  training_iteration: 1508
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13268 s, 1508 iter, 7540000 ts, 314 rew

agent-1: 89.99999076872655
agent-2: 90.99999076872655
agent-3: 95.99999076872652
agent-4: 87.99999076872655
agent-5: 84.99999076872663
Extrinsic Rewards:
10
11
16
8
5
Sum Reward: 50
Avg Reward: 10.0
Min Reward: 5
Max Reward: 16
Gini Coefficient: 0.2
20:20 Ratio: 3.2
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 315.26939009711873
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1508
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.658
    dispatch_time_ms: 10.233
    learner:
      cur_lr: 0.000857835984788835
      grad_gnorm: 1.9185601472854614
      policy_entropy: 0.05594835802912712
      policy_loss: -6.404129089787602e-05
      var_gnorm: 23.00965118408203
      vf_explained_var: 0.0
      vf_loss: 0.002850687364116311
    num_steps_sampled: 7545000
    num_steps_trained: 7545000
    wait_time_ms: 77.438
  iterations_since_restore: 1509
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13276.749250888824
  time_this_iter_s: 7.9592063426971436
  time_total_s: 13276.749250888824
  timestamp: 1594861830
  timesteps_since_restore: 7545000
  timesteps_this_iter: 5000
  timesteps_total: 7545000
  training_iteration: 1509
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13276 s, 1509 iter, 7545000 ts, 315 rew

agent-1: 48.399999991528546
agent-2: 52.39999999152856
agent-3: 50.39999999152856
agent-4: 61.39999999152856
agent-5: 48.39999999152856
Extrinsic Rewards:
2
6
4
15
2
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.41379310344827586
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 314.90939009699304
  episode_reward_min: 134.99999999783876
  episodes_this_iter: 1
  episodes_total: 1509
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.039
    dispatch_time_ms: 37.658
    learner:
      cur_lr: 0.0008575029787607491
      grad_gnorm: 0.12388717383146286
      policy_entropy: 0.05565345287322998
      policy_loss: -5.7047291193157434e-06
      var_gnorm: 23.009658813476562
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.1885787898791023e-05
    num_steps_sampled: 7550000
    num_steps_trained: 7550000
    wait_time_ms: 45.307
  iterations_since_restore: 1510
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13285.64054608345
  time_this_iter_s: 8.891295194625854
  time_total_s: 13285.64054608345
  timestamp: 1594861839
  timesteps_since_restore: 7550000
  timesteps_this_iter: 5000
  timesteps_total: 7550000
  training_iteration: 1510
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13285 s, 1510 iter, 7550000 ts, 315 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 312.20939010005054
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1510
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.14
    dispatch_time_ms: 17.391
    learner:
      cur_lr: 0.0008571699727326632
      grad_gnorm: 0.029090479016304016
      policy_entropy: 0.055686503648757935
      policy_loss: 1.048108856593899e-06
      var_gnorm: 23.00967025756836
      vf_explained_var: 0.0
      vf_loss: 6.546038093802053e-07
    num_steps_sampled: 7555000
    num_steps_trained: 7555000
    wait_time_ms: 61.653
  iterations_since_restore: 1511
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13294.172725915909
  time_this_iter_s: 8.532179832458496
  time_total_s: 13294.172725915909
  timestamp: 1594861848
  timesteps_since_restore: 7555000
  timesteps_this_iter: 5000
  timesteps_total: 7555000
  training_iteration: 1511
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13294 s, 1511 iter, 7555000 ts, 312 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-10-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 308.6093901334266
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1511
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 8.842
    learner:
      cur_lr: 0.0008568370249122381
      grad_gnorm: 0.014753713272511959
      policy_entropy: 0.05573192611336708
      policy_loss: 4.4198949922247266e-07
      var_gnorm: 23.00968360900879
      vf_explained_var: 0.0
      vf_loss: 1.6857546825121972e-07
    num_steps_sampled: 7560000
    num_steps_trained: 7560000
    wait_time_ms: 70.441
  iterations_since_restore: 1512
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13302.347978591919
  time_this_iter_s: 8.175252676010132
  time_total_s: 13302.347978591919
  timestamp: 1594861856
  timesteps_since_restore: 7560000
  timesteps_this_iter: 5000
  timesteps_total: 7560000
  training_iteration: 1512
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13302 s, 1512 iter, 7560000 ts, 309 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 306.80939013346494
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1512
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.895
    dispatch_time_ms: 6.187
    learner:
      cur_lr: 0.0008565040188841522
      grad_gnorm: 0.05873940512537956
      policy_entropy: 0.055778827518224716
      policy_loss: 1.6044257336034207e-06
      var_gnorm: 23.00969696044922
      vf_explained_var: 0.0
      vf_loss: 2.6711136342782993e-06
    num_steps_sampled: 7565000
    num_steps_trained: 7565000
    wait_time_ms: 69.914
  iterations_since_restore: 1513
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13310.37619304657
  time_this_iter_s: 8.028214454650879
  time_total_s: 13310.37619304657
  timestamp: 1594861864
  timesteps_since_restore: 7565000
  timesteps_this_iter: 5000
  timesteps_total: 7565000
  training_iteration: 1513
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13310 s, 1513 iter, 7565000 ts, 307 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 305.00939013350876
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1513
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.66
    dispatch_time_ms: 9.925
    learner:
      cur_lr: 0.0008561710128560662
      grad_gnorm: 0.01238483376801014
      policy_entropy: 0.05582995340228081
      policy_loss: 4.6852991886225936e-07
      var_gnorm: 23.00971221923828
      vf_explained_var: 0.0
      vf_loss: 1.1869641980410961e-07
    num_steps_sampled: 7570000
    num_steps_trained: 7570000
    wait_time_ms: 71.062
  iterations_since_restore: 1514
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13318.477288007736
  time_this_iter_s: 8.101094961166382
  time_total_s: 13318.477288007736
  timestamp: 1594861872
  timesteps_since_restore: 7570000
  timesteps_this_iter: 5000
  timesteps_total: 7570000
  training_iteration: 1514
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13318 s, 1514 iter, 7570000 ts, 305 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 302.84939013372093
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1514
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.622
    dispatch_time_ms: 7.933
    learner:
      cur_lr: 0.0008558380068279803
      grad_gnorm: 0.061371006071567535
      policy_entropy: 0.05587761104106903
      policy_loss: 1.9643498490040656e-06
      var_gnorm: 23.00972557067871
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.916816356446361e-06
    num_steps_sampled: 7575000
    num_steps_trained: 7575000
    wait_time_ms: 70.577
  iterations_since_restore: 1515
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13326.557228565216
  time_this_iter_s: 8.079940557479858
  time_total_s: 13326.557228565216
  timestamp: 1594861880
  timesteps_since_restore: 7575000
  timesteps_this_iter: 5000
  timesteps_total: 7575000
  training_iteration: 1515
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13326 s, 1515 iter, 7575000 ts, 303 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 301.1393901337496
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1515
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 5.648
    learner:
      cur_lr: 0.0008555050007998943
      grad_gnorm: 0.009239082224667072
      policy_entropy: 0.05592700093984604
      policy_loss: 3.384539297712763e-07
      var_gnorm: 23.00973892211914
      vf_explained_var: 0.0
      vf_loss: 6.624085813200509e-08
    num_steps_sampled: 7580000
    num_steps_trained: 7580000
    wait_time_ms: 72.62
  iterations_since_restore: 1516
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13334.693957090378
  time_this_iter_s: 8.136728525161743
  time_total_s: 13334.693957090378
  timestamp: 1594861889
  timesteps_since_restore: 7580000
  timesteps_this_iter: 5000
  timesteps_total: 7580000
  training_iteration: 1516
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13334 s, 1516 iter, 7580000 ts, 301 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 1043.9932589201348
  episode_reward_mean: 299.519390133775
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1516
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.498
    dispatch_time_ms: 10.019
    learner:
      cur_lr: 0.0008551719947718084
      grad_gnorm: 0.06575325131416321
      policy_entropy: 0.05598287284374237
      policy_loss: 1.8037773088508402e-06
      var_gnorm: 23.009754180908203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.3485111998743378e-06
    num_steps_sampled: 7585000
    num_steps_trained: 7585000
    wait_time_ms: 67.301
  iterations_since_restore: 1517
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13342.809785366058
  time_this_iter_s: 8.115828275680542
  time_total_s: 13342.809785366058
  timestamp: 1594861897
  timesteps_since_restore: 7585000
  timesteps_this_iter: 5000
  timesteps_total: 7585000
  training_iteration: 1517
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13342 s, 1517 iter, 7585000 ts, 300 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 289.07945754457364
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1517
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.811
    dispatch_time_ms: 9.619
    learner:
      cur_lr: 0.0008548389887437224
      grad_gnorm: 0.005657485220581293
      policy_entropy: 0.056042205542325974
      policy_loss: 1.5499104222271853e-07
      var_gnorm: 23.009769439697266
      vf_explained_var: 0.0
      vf_loss: 2.471165672091047e-08
    num_steps_sampled: 7590000
    num_steps_trained: 7590000
    wait_time_ms: 68.918
  iterations_since_restore: 1518
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13350.864770889282
  time_this_iter_s: 8.054985523223877
  time_total_s: 13350.864770889282
  timestamp: 1594861905
  timesteps_since_restore: 7590000
  timesteps_this_iter: 5000
  timesteps_total: 7590000
  training_iteration: 1518
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13350 s, 1518 iter, 7590000 ts, 289 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-11-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 286.64945754470045
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1518
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.591
    dispatch_time_ms: 5.995
    learner:
      cur_lr: 0.0008545059827156365
      grad_gnorm: 0.06487749516963959
      policy_entropy: 0.056103914976119995
      policy_loss: 1.7835835706137004e-06
      var_gnorm: 23.009784698486328
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.260787934777909e-06
    num_steps_sampled: 7595000
    num_steps_trained: 7595000
    wait_time_ms: 77.709
  iterations_since_restore: 1519
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13359.045060634613
  time_this_iter_s: 8.18028974533081
  time_total_s: 13359.045060634613
  timestamp: 1594861913
  timesteps_since_restore: 7595000
  timesteps_this_iter: 5000
  timesteps_total: 7595000
  training_iteration: 1519
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13359 s, 1519 iter, 7595000 ts, 287 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 279.9896150127152
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1519
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 9.68
    learner:
      cur_lr: 0.0008541729766875505
      grad_gnorm: 0.0014432151801884174
      policy_entropy: 0.056166984140872955
      policy_loss: 7.172051397219548e-08
      var_gnorm: 23.00979995727539
      vf_explained_var: 0.0
      vf_loss: 1.4862897579348555e-09
    num_steps_sampled: 7600000
    num_steps_trained: 7600000
    wait_time_ms: 67.513
  iterations_since_restore: 1520
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13367.06708574295
  time_this_iter_s: 8.022025108337402
  time_total_s: 13367.06708574295
  timestamp: 1594861921
  timesteps_since_restore: 7600000
  timesteps_this_iter: 5000
  timesteps_total: 7600000
  training_iteration: 1520
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13367 s, 1520 iter, 7600000 ts, 280 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 275.57961503709964
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1520
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.603
    dispatch_time_ms: 8.014
    learner:
      cur_lr: 0.0008538400288671255
      grad_gnorm: 0.07201060652732849
      policy_entropy: 0.056245092302560806
      policy_loss: 2.1477715108630946e-06
      var_gnorm: 23.009811401367188
      vf_explained_var: 0.0
      vf_loss: 4.016152161057107e-06
    num_steps_sampled: 7605000
    num_steps_trained: 7605000
    wait_time_ms: 72.184
  iterations_since_restore: 1521
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13375.216138839722
  time_this_iter_s: 8.14905309677124
  time_total_s: 13375.216138839722
  timestamp: 1594861929
  timesteps_since_restore: 7605000
  timesteps_this_iter: 5000
  timesteps_total: 7605000
  training_iteration: 1521
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13375 s, 1521 iter, 7605000 ts, 276 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 271.4396150394616
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1521
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.709
    dispatch_time_ms: 7.61
    learner:
      cur_lr: 0.0008535070228390396
      grad_gnorm: 0.003681295784190297
      policy_entropy: 0.0563177764415741
      policy_loss: -1.0104218972628587e-07
      var_gnorm: 23.00982666015625
      vf_explained_var: 0.0
      vf_loss: 1.0322846577537348e-08
    num_steps_sampled: 7610000
    num_steps_trained: 7610000
    wait_time_ms: 70.938
  iterations_since_restore: 1522
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13383.277052879333
  time_this_iter_s: 8.060914039611816
  time_total_s: 13383.277052879333
  timestamp: 1594861937
  timesteps_since_restore: 7610000
  timesteps_this_iter: 5000
  timesteps_total: 7610000
  training_iteration: 1522
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13383 s, 1522 iter, 7610000 ts, 271 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 265.4997350458178
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1522
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.104
    dispatch_time_ms: 7.026
    learner:
      cur_lr: 0.0008531740168109536
      grad_gnorm: 0.07660709321498871
      policy_entropy: 0.0563926063477993
      policy_loss: 3.2479633773618843e-06
      var_gnorm: 23.009836196899414
      vf_explained_var: 0.0
      vf_loss: 4.5437473090714775e-06
    num_steps_sampled: 7615000
    num_steps_trained: 7615000
    wait_time_ms: 68.244
  iterations_since_restore: 1523
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13391.310570001602
  time_this_iter_s: 8.033517122268677
  time_total_s: 13391.310570001602
  timestamp: 1594861945
  timesteps_since_restore: 7615000
  timesteps_this_iter: 5000
  timesteps_total: 7615000
  training_iteration: 1523
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13391 s, 1523 iter, 7615000 ts, 265 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 262.169736828758
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1523
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 39.148
    learner:
      cur_lr: 0.0008528410107828677
      grad_gnorm: 0.0008545377058908343
      policy_entropy: 0.05647832527756691
      policy_loss: 4.739701466860424e-07
      var_gnorm: 23.009851455688477
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 9.681125234806132e-09
    num_steps_sampled: 7620000
    num_steps_trained: 7620000
    wait_time_ms: 38.612
  iterations_since_restore: 1524
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13399.546513080597
  time_this_iter_s: 8.235943078994751
  time_total_s: 13399.546513080597
  timestamp: 1594861954
  timesteps_since_restore: 7620000
  timesteps_this_iter: 5000
  timesteps_total: 7620000
  training_iteration: 1524
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13399 s, 1524 iter, 7620000 ts, 262 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 259.7397368288406
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1524
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.424
    dispatch_time_ms: 35.184
    learner:
      cur_lr: 0.0008525080047547817
      grad_gnorm: 0.02121383510529995
      policy_entropy: 0.056582044810056686
      policy_loss: 1.6698038507456658e-06
      var_gnorm: 23.009864807128906
      vf_explained_var: 0.0
      vf_loss: 4.814997396351828e-07
    num_steps_sampled: 7625000
    num_steps_trained: 7625000
    wait_time_ms: 50.191
  iterations_since_restore: 1525
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13408.193330049515
  time_this_iter_s: 8.646816968917847
  time_total_s: 13408.193330049515
  timestamp: 1594861962
  timesteps_since_restore: 7625000
  timesteps_this_iter: 5000
  timesteps_total: 7625000
  training_iteration: 1525
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13408 s, 1525 iter, 7625000 ts, 260 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-12-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 258.299736828866
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1525
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.759
    dispatch_time_ms: 42.913
    learner:
      cur_lr: 0.0008521749987266958
      grad_gnorm: 0.007114499807357788
      policy_entropy: 0.05667797103524208
      policy_loss: 9.675267165221157e-07
      var_gnorm: 23.009878158569336
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.1068330252328451e-07
    num_steps_sampled: 7630000
    num_steps_trained: 7630000
    wait_time_ms: 42.9
  iterations_since_restore: 1526
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13416.696412563324
  time_this_iter_s: 8.503082513809204
  time_total_s: 13416.696412563324
  timestamp: 1594861971
  timesteps_since_restore: 7630000
  timesteps_this_iter: 5000
  timesteps_total: 7630000
  training_iteration: 1526
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13416 s, 1526 iter, 7630000 ts, 258 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 256.6797368289141
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1526
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.282
    dispatch_time_ms: 48.698
    learner:
      cur_lr: 0.0008518419926986098
      grad_gnorm: 0.005130103323608637
      policy_entropy: 0.05676911398768425
      policy_loss: 1.9986209736089222e-06
      var_gnorm: 23.009891510009766
      vf_explained_var: 0.0
      vf_loss: 4.378664186788228e-07
    num_steps_sampled: 7635000
    num_steps_trained: 7635000
    wait_time_ms: 44.815
  iterations_since_restore: 1527
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13425.339955806732
  time_this_iter_s: 8.643543243408203
  time_total_s: 13425.339955806732
  timestamp: 1594861980
  timesteps_since_restore: 7635000
  timesteps_this_iter: 5000
  timesteps_total: 7635000
  training_iteration: 1527
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13425 s, 1527 iter, 7635000 ts, 257 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 254.06973682900468
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1527
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.289
    dispatch_time_ms: 9.165
    learner:
      cur_lr: 0.0008515089866705239
      grad_gnorm: 0.007440997287631035
      policy_entropy: 0.05686608701944351
      policy_loss: -1.9180809829322243e-07
      var_gnorm: 23.009906768798828
      vf_explained_var: 0.0
      vf_loss: 4.2971148417336735e-08
    num_steps_sampled: 7640000
    num_steps_trained: 7640000
    wait_time_ms: 68.643
  iterations_since_restore: 1528
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13433.640772104263
  time_this_iter_s: 8.300816297531128
  time_total_s: 13433.640772104263
  timestamp: 1594861988
  timesteps_since_restore: 7640000
  timesteps_this_iter: 5000
  timesteps_total: 7640000
  training_iteration: 1528
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13433 s, 1528 iter, 7640000 ts, 254 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 249.7497368833703
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1528
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.644
    dispatch_time_ms: 6.231
    learner:
      cur_lr: 0.0008511759806424379
      grad_gnorm: 0.06868506968021393
      policy_entropy: 0.05697356536984444
      policy_loss: 2.54957899414876e-06
      var_gnorm: 23.00992202758789
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.6531153000396444e-06
    num_steps_sampled: 7645000
    num_steps_trained: 7645000
    wait_time_ms: 71.974
  iterations_since_restore: 1529
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13441.672723054886
  time_this_iter_s: 8.031950950622559
  time_total_s: 13441.672723054886
  timestamp: 1594861996
  timesteps_since_restore: 7645000
  timesteps_this_iter: 5000
  timesteps_total: 7645000
  training_iteration: 1529
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13441 s, 1529 iter, 7645000 ts, 250 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 243.17973865308144
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1529
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.556
    dispatch_time_ms: 8.076
    learner:
      cur_lr: 0.000850842974614352
      grad_gnorm: 0.013173864223062992
      policy_entropy: 0.057083580642938614
      policy_loss: -4.436461154000426e-07
      var_gnorm: 23.009939193725586
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.346365507970404e-07
    num_steps_sampled: 7650000
    num_steps_trained: 7650000
    wait_time_ms: 71.534
  iterations_since_restore: 1530
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13449.750116825104
  time_this_iter_s: 8.077393770217896
  time_total_s: 13449.750116825104
  timestamp: 1594862004
  timesteps_since_restore: 7650000
  timesteps_this_iter: 5000
  timesteps_total: 7650000
  training_iteration: 1530
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13449 s, 1530 iter, 7650000 ts, 243 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 238.6797386552127
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1530
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 8.571
    learner:
      cur_lr: 0.000850510026793927
      grad_gnorm: 0.07810958474874496
      policy_entropy: 0.05720261484384537
      policy_loss: 2.9336933948798105e-06
      var_gnorm: 23.00994873046875
      vf_explained_var: 0.0
      vf_loss: 4.726160568679916e-06
    num_steps_sampled: 7655000
    num_steps_trained: 7655000
    wait_time_ms: 69.832
  iterations_since_restore: 1531
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13457.794865608215
  time_this_iter_s: 8.044748783111572
  time_total_s: 13457.794865608215
  timestamp: 1594862012
  timesteps_since_restore: 7655000
  timesteps_this_iter: 5000
  timesteps_total: 7655000
  training_iteration: 1531
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13457 s, 1531 iter, 7655000 ts, 239 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 236.33973865558656
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1531
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.032
    dispatch_time_ms: 8.813
    learner:
      cur_lr: 0.000850177020765841
      grad_gnorm: 0.012513723224401474
      policy_entropy: 0.05740094557404518
      policy_loss: -3.5270667808617873e-07
      var_gnorm: 23.009960174560547
      vf_explained_var: 0.0
      vf_loss: 1.2129069659749803e-07
    num_steps_sampled: 7660000
    num_steps_trained: 7660000
    wait_time_ms: 69.204
  iterations_since_restore: 1532
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13465.860559225082
  time_this_iter_s: 8.065693616867065
  time_total_s: 13465.860559225082
  timestamp: 1594862020
  timesteps_since_restore: 7660000
  timesteps_this_iter: 5000
  timesteps_total: 7660000
  training_iteration: 1532
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13465 s, 1532 iter, 7660000 ts, 236 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 234.08973865564164
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1532
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.573
    dispatch_time_ms: 9.253
    learner:
      cur_lr: 0.0008498440147377551
      grad_gnorm: 0.08181758970022202
      policy_entropy: 0.05754172429442406
      policy_loss: 3.183227363479091e-06
      var_gnorm: 23.009971618652344
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.184220299270237e-06
    num_steps_sampled: 7665000
    num_steps_trained: 7665000
    wait_time_ms: 69.766
  iterations_since_restore: 1533
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13474.025696277618
  time_this_iter_s: 8.16513705253601
  time_total_s: 13474.025696277618
  timestamp: 1594862029
  timesteps_since_restore: 7665000
  timesteps_this_iter: 5000
  timesteps_total: 7665000
  training_iteration: 1533
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13474 s, 1533 iter, 7665000 ts, 234 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-13-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 232.5597386556645
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1533
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.986
    dispatch_time_ms: 9.971
    learner:
      cur_lr: 0.0008495110087096691
      grad_gnorm: 0.0060622598975896835
      policy_entropy: 0.057676129043102264
      policy_loss: -3.90241098102706e-07
      var_gnorm: 23.009986877441406
      vf_explained_var: 0.0
      vf_loss: 2.8483860603500943e-08
    num_steps_sampled: 7670000
    num_steps_trained: 7670000
    wait_time_ms: 67.374
  iterations_since_restore: 1534
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13482.030415296555
  time_this_iter_s: 8.004719018936157
  time_total_s: 13482.030415296555
  timestamp: 1594862037
  timesteps_since_restore: 7670000
  timesteps_this_iter: 5000
  timesteps_total: 7670000
  training_iteration: 1534
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13482 s, 1534 iter, 7670000 ts, 233 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 230.57973865649257
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1534
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.741
    dispatch_time_ms: 8.623
    learner:
      cur_lr: 0.0008491780026815832
      grad_gnorm: 0.07620338350534439
      policy_entropy: 0.05782146006822586
      policy_loss: 2.6691668608691543e-06
      var_gnorm: 23.010000228881836
      vf_explained_var: 0.0
      vf_loss: 4.4971416173211765e-06
    num_steps_sampled: 7675000
    num_steps_trained: 7675000
    wait_time_ms: 69.546
  iterations_since_restore: 1535
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13490.190613985062
  time_this_iter_s: 8.16019868850708
  time_total_s: 13490.190613985062
  timestamp: 1594862045
  timesteps_since_restore: 7675000
  timesteps_this_iter: 5000
  timesteps_total: 7675000
  training_iteration: 1535
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13490 s, 1535 iter, 7675000 ts, 231 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 225.71973866371877
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1535
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.799
    dispatch_time_ms: 616.738
    learner:
      cur_lr: 0.0008488449966534972
      grad_gnorm: 0.0665895864367485
      policy_entropy: 0.05797870457172394
      policy_loss: -1.5788296536811686e-07
      var_gnorm: 23.010013580322266
      vf_explained_var: 0.0
      vf_loss: 2.725974809436593e-06
    num_steps_sampled: 7680000
    num_steps_trained: 7680000
    wait_time_ms: 56.11
  iterations_since_restore: 1536
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13504.136713266373
  time_this_iter_s: 13.946099281311035
  time_total_s: 13504.136713266373
  timestamp: 1594862059
  timesteps_since_restore: 7680000
  timesteps_this_iter: 5000
  timesteps_total: 7680000
  training_iteration: 1536
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13504 s, 1536 iter, 7680000 ts, 226 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 224.0097386637429
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1536
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.537
    dispatch_time_ms: 6.79
    learner:
      cur_lr: 0.0008485119906254113
      grad_gnorm: 0.07151045650243759
      policy_entropy: 0.05814652889966965
      policy_loss: 3.3126432299468433e-06
      var_gnorm: 23.010026931762695
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.962080882047303e-06
    num_steps_sampled: 7685000
    num_steps_trained: 7685000
    wait_time_ms: 71.166
  iterations_since_restore: 1537
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13511.854708433151
  time_this_iter_s: 7.7179951667785645
  time_total_s: 13511.854708433151
  timestamp: 1594862067
  timesteps_since_restore: 7685000
  timesteps_this_iter: 5000
  timesteps_total: 7685000
  training_iteration: 1537
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13511 s, 1537 iter, 7685000 ts, 224 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 219.77973866477353
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1537
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.89
    dispatch_time_ms: 6.536
    learner:
      cur_lr: 0.0008481789845973253
      grad_gnorm: 0.006999833509325981
      policy_entropy: 0.05831826478242874
      policy_loss: 5.9074952929449864e-08
      var_gnorm: 23.010042190551758
      vf_explained_var: 0.0
      vf_loss: 3.773487478042625e-08
    num_steps_sampled: 7690000
    num_steps_trained: 7690000
    wait_time_ms: 67.579
  iterations_since_restore: 1538
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13519.965284347534
  time_this_iter_s: 8.110575914382935
  time_total_s: 13519.965284347534
  timestamp: 1594862075
  timesteps_since_restore: 7690000
  timesteps_this_iter: 5000
  timesteps_total: 7690000
  training_iteration: 1538
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13519 s, 1538 iter, 7690000 ts, 220 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 216.62973866502202
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1538
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.189
    dispatch_time_ms: 7.966
    learner:
      cur_lr: 0.0008478459785692394
      grad_gnorm: 0.08121724426746368
      policy_entropy: 0.058501794934272766
      policy_loss: 2.3383186089631636e-06
      var_gnorm: 23.010053634643555
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.110131951369112e-06
    num_steps_sampled: 7695000
    num_steps_trained: 7695000
    wait_time_ms: 71.321
  iterations_since_restore: 1539
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13528.04444360733
  time_this_iter_s: 8.079159259796143
  time_total_s: 13528.04444360733
  timestamp: 1594862083
  timesteps_since_restore: 7695000
  timesteps_this_iter: 5000
  timesteps_total: 7695000
  training_iteration: 1539
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13528 s, 1539 iter, 7695000 ts, 217 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 214.91973866506422
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1539
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.507
    dispatch_time_ms: 9.103
    learner:
      cur_lr: 0.0008475129725411534
      grad_gnorm: 0.012529809027910233
      policy_entropy: 0.05869574099779129
      policy_loss: 1.8542817770139663e-07
      var_gnorm: 23.010066986083984
      vf_explained_var: 0.0
      vf_loss: 1.2133436655403784e-07
    num_steps_sampled: 7700000
    num_steps_trained: 7700000
    wait_time_ms: 65.999
  iterations_since_restore: 1540
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13536.10641670227
  time_this_iter_s: 8.061973094940186
  time_total_s: 13536.10641670227
  timestamp: 1594862091
  timesteps_since_restore: 7700000
  timesteps_this_iter: 5000
  timesteps_total: 7700000
  training_iteration: 1540
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13536 s, 1540 iter, 7700000 ts, 215 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-14-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 213.02973866513037
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1540
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.499
    dispatch_time_ms: 8.634
    learner:
      cur_lr: 0.0008471800247207284
      grad_gnorm: 0.06983540952205658
      policy_entropy: 0.05890218913555145
      policy_loss: 5.225796030572383e-06
      var_gnorm: 23.010082244873047
      vf_explained_var: 0.0
      vf_loss: 3.777334086407791e-06
    num_steps_sampled: 7705000
    num_steps_trained: 7705000
    wait_time_ms: 71.583
  iterations_since_restore: 1541
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13544.134655952454
  time_this_iter_s: 8.028239250183105
  time_total_s: 13544.134655952454
  timestamp: 1594862099
  timesteps_since_restore: 7705000
  timesteps_this_iter: 5000
  timesteps_total: 7705000
  training_iteration: 1541
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13544 s, 1541 iter, 7705000 ts, 213 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 710.9996459012082
  episode_reward_mean: 209.2497386658116
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1541
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 8.155
    learner:
      cur_lr: 0.0008468470186926425
      grad_gnorm: 0.019161049276590347
      policy_entropy: 0.05911928042769432
      policy_loss: 6.291755312304304e-07
      var_gnorm: 23.010095596313477
      vf_explained_var: 0.0
      vf_loss: 2.839869637227821e-07
    num_steps_sampled: 7710000
    num_steps_trained: 7710000
    wait_time_ms: 70.759
  iterations_since_restore: 1542
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13552.197636127472
  time_this_iter_s: 8.06298017501831
  time_total_s: 13552.197636127472
  timestamp: 1594862107
  timesteps_since_restore: 7710000
  timesteps_this_iter: 5000
  timesteps_total: 7710000
  training_iteration: 1542
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13552 s, 1542 iter, 7710000 ts, 209 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 202.13974220679953
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1542
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.173
    dispatch_time_ms: 7.533
    learner:
      cur_lr: 0.0008465140126645565
      grad_gnorm: 0.07171794772148132
      policy_entropy: 0.05934993550181389
      policy_loss: 3.971802925661905e-06
      var_gnorm: 23.010108947753906
      vf_explained_var: 0.0
      vf_loss: 3.98412748836563e-06
    num_steps_sampled: 7715000
    num_steps_trained: 7715000
    wait_time_ms: 72.774
  iterations_since_restore: 1543
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13560.313073635101
  time_this_iter_s: 8.115437507629395
  time_total_s: 13560.313073635101
  timestamp: 1594862115
  timesteps_since_restore: 7715000
  timesteps_this_iter: 5000
  timesteps_total: 7715000
  training_iteration: 1543
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13560 s, 1543 iter, 7715000 ts, 202 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 199.79974220690755
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1543
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 9.044
    learner:
      cur_lr: 0.0008461810066364706
      grad_gnorm: 0.018343066796660423
      policy_entropy: 0.059594254940748215
      policy_loss: 1.0752877415143303e-06
      var_gnorm: 23.010122299194336
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.605582096748549e-07
    num_steps_sampled: 7720000
    num_steps_trained: 7720000
    wait_time_ms: 70.501
  iterations_since_restore: 1544
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13568.364203214645
  time_this_iter_s: 8.051129579544067
  time_total_s: 13568.364203214645
  timestamp: 1594862123
  timesteps_since_restore: 7720000
  timesteps_this_iter: 5000
  timesteps_total: 7720000
  training_iteration: 1544
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13568 s, 1544 iter, 7720000 ts, 200 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 197.99974220697797
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1544
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.951
    dispatch_time_ms: 8.962
    learner:
      cur_lr: 0.0008458480006083846
      grad_gnorm: 0.036958254873752594
      policy_entropy: 0.0598454475402832
      policy_loss: 3.179818577336846e-06
      var_gnorm: 23.0101375579834
      vf_explained_var: 0.0
      vf_loss: 1.0574425459708436e-06
    num_steps_sampled: 7725000
    num_steps_trained: 7725000
    wait_time_ms: 68.395
  iterations_since_restore: 1545
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13576.420087575912
  time_this_iter_s: 8.05588436126709
  time_total_s: 13576.420087575912
  timestamp: 1594862131
  timesteps_since_restore: 7725000
  timesteps_this_iter: 5000
  timesteps_total: 7725000
  training_iteration: 1545
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13576 s, 1545 iter, 7725000 ts, 198 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 196.19974220704054
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1545
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.793
    dispatch_time_ms: 6.16
    learner:
      cur_lr: 0.0008455149945802987
      grad_gnorm: 0.013833817094564438
      policy_entropy: 0.06011858582496643
      policy_loss: 7.040072773634165e-07
      var_gnorm: 23.010150909423828
      vf_explained_var: 0.0
      vf_loss: 1.481846254591801e-07
    num_steps_sampled: 7730000
    num_steps_trained: 7730000
    wait_time_ms: 71.7
  iterations_since_restore: 1546
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13584.440750837326
  time_this_iter_s: 8.020663261413574
  time_total_s: 13584.440750837326
  timestamp: 1594862139
  timesteps_since_restore: 7730000
  timesteps_this_iter: 5000
  timesteps_total: 7730000
  training_iteration: 1546
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13584 s, 1546 iter, 7730000 ts, 196 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 193.4997422075861
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1546
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.648
    dispatch_time_ms: 6.562
    learner:
      cur_lr: 0.0008451819885522127
      grad_gnorm: 0.03369304537773132
      policy_entropy: 0.060429010540246964
      policy_loss: 5.892060016776668e-06
      var_gnorm: 23.010162353515625
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 8.796047268333496e-07
    num_steps_sampled: 7735000
    num_steps_trained: 7735000
    wait_time_ms: 73.366
  iterations_since_restore: 1547
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13592.453382968903
  time_this_iter_s: 8.012632131576538
  time_total_s: 13592.453382968903
  timestamp: 1594862147
  timesteps_since_restore: 7735000
  timesteps_this_iter: 5000
  timesteps_total: 7735000
  training_iteration: 1547
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13592 s, 1547 iter, 7735000 ts, 193 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-15-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 191.78974220763638
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1547
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.468
    dispatch_time_ms: 42.987
    learner:
      cur_lr: 0.0008448489825241268
      grad_gnorm: 0.01538910809904337
      policy_entropy: 0.0605633519589901
      policy_loss: 5.387537385104224e-06
      var_gnorm: 23.01018524169922
      vf_explained_var: 0.0
      vf_loss: 1.8324796258184506e-07
    num_steps_sampled: 7740000
    num_steps_trained: 7740000
    wait_time_ms: 25.542
  iterations_since_restore: 1548
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13600.592877388
  time_this_iter_s: 8.1394944190979
  time_total_s: 13600.592877388
  timestamp: 1594862156
  timesteps_since_restore: 7740000
  timesteps_this_iter: 5000
  timesteps_total: 7740000
  training_iteration: 1548
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13600 s, 1548 iter, 7740000 ts, 192 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 186.83974221227544
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1548
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.49
    dispatch_time_ms: 38.576
    learner:
      cur_lr: 0.0008445159764960408
      grad_gnorm: 0.03973233327269554
      policy_entropy: 0.060874707996845245
      policy_loss: 1.7287173932345468e-06
      var_gnorm: 23.010196685791016
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.1553501053640503e-06
    num_steps_sampled: 7745000
    num_steps_trained: 7745000
    wait_time_ms: 46.424
  iterations_since_restore: 1549
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13609.01619052887
  time_this_iter_s: 8.42331314086914
  time_total_s: 13609.01619052887
  timestamp: 1594862164
  timesteps_since_restore: 7745000
  timesteps_this_iter: 5000
  timesteps_total: 7745000
  training_iteration: 1549
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13609 s, 1549 iter, 7745000 ts, 187 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 180.62974235046204
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1549
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.762
    dispatch_time_ms: 38.362
    learner:
      cur_lr: 0.0008441830286756158
      grad_gnorm: 0.06783001869916916
      policy_entropy: 0.06126505881547928
      policy_loss: -4.428656666277675e-06
      var_gnorm: 23.01020622253418
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.5626455883175367e-06
    num_steps_sampled: 7750000
    num_steps_trained: 7750000
    wait_time_ms: 38.966
  iterations_since_restore: 1550
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13617.425466060638
  time_this_iter_s: 8.409275531768799
  time_total_s: 13617.425466060638
  timestamp: 1594862173
  timesteps_since_restore: 7750000
  timesteps_this_iter: 5000
  timesteps_total: 7750000
  training_iteration: 1550
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13617 s, 1550 iter, 7750000 ts, 181 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 176.48974236042886
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1550
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.029
    dispatch_time_ms: 50.07
    learner:
      cur_lr: 0.0008438500226475298
      grad_gnorm: 0.012196969240903854
      policy_entropy: 0.06215974688529968
      policy_loss: -1.4913062784671638e-07
      var_gnorm: 23.010189056396484
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 9.493597019627487e-08
    num_steps_sampled: 7755000
    num_steps_trained: 7755000
    wait_time_ms: 40.589
  iterations_since_restore: 1551
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13626.115183830261
  time_this_iter_s: 8.689717769622803
  time_total_s: 13626.115183830261
  timestamp: 1594862181
  timesteps_since_restore: 7755000
  timesteps_this_iter: 5000
  timesteps_total: 7755000
  training_iteration: 1551
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13626 s, 1551 iter, 7755000 ts, 176 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 175.04974236045678
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1551
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.553
    dispatch_time_ms: 35.731
    learner:
      cur_lr: 0.0008435170166194439
      grad_gnorm: 0.001779427519068122
      policy_entropy: 0.06267235428094864
      policy_loss: 1.5822082843897078e-07
      var_gnorm: 23.010194778442383
      vf_explained_var: 0.0
      vf_loss: 2.275714283683783e-09
    num_steps_sampled: 7760000
    num_steps_trained: 7760000
    wait_time_ms: 48.75
  iterations_since_restore: 1552
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13634.522597551346
  time_this_iter_s: 8.407413721084595
  time_total_s: 13634.522597551346
  timestamp: 1594862190
  timesteps_since_restore: 7760000
  timesteps_this_iter: 5000
  timesteps_total: 7760000
  training_iteration: 1552
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13634 s, 1552 iter, 7760000 ts, 175 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 173.42974236065248
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1552
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.765
    dispatch_time_ms: 31.518
    learner:
      cur_lr: 0.000843184010591358
      grad_gnorm: 0.19320520758628845
      policy_entropy: 0.06316837668418884
      policy_loss: 2.044521170319058e-05
      var_gnorm: 23.01020050048828
      vf_explained_var: 0.0
      vf_loss: 2.8909937100252137e-05
    num_steps_sampled: 7765000
    num_steps_trained: 7765000
    wait_time_ms: 48.961
  iterations_since_restore: 1553
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13643.013073444366
  time_this_iter_s: 8.49047589302063
  time_total_s: 13643.013073444366
  timestamp: 1594862198
  timesteps_since_restore: 7765000
  timesteps_this_iter: 5000
  timesteps_total: 7765000
  training_iteration: 1553
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13643 s, 1553 iter, 7765000 ts, 173 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 170.1897423617498
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1553
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.825
    dispatch_time_ms: 35.897
    learner:
      cur_lr: 0.000842851004563272
      grad_gnorm: 0.007940500974655151
      policy_entropy: 0.06384125351905823
      policy_loss: -2.883452054902591e-07
      var_gnorm: 23.010202407836914
      vf_explained_var: 0.0
      vf_loss: 5.486818110966851e-08
    num_steps_sampled: 7770000
    num_steps_trained: 7770000
    wait_time_ms: 52.095
  iterations_since_restore: 1554
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13651.457164287567
  time_this_iter_s: 8.444090843200684
  time_total_s: 13651.457164287567
  timestamp: 1594862207
  timesteps_since_restore: 7770000
  timesteps_this_iter: 5000
  timesteps_total: 7770000
  training_iteration: 1554
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13651 s, 1554 iter, 7770000 ts, 170 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-16-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 168.8397423617714
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1554
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.798
    dispatch_time_ms: 38.204
    learner:
      cur_lr: 0.000842517998535186
      grad_gnorm: 40.0
      policy_entropy: 0.06433409452438354
      policy_loss: 8.51429194881348e-06
      var_gnorm: 23.010208129882812
      vf_explained_var: 3.337860107421875e-06
      vf_loss: 1.3363583087921143
    num_steps_sampled: 7775000
    num_steps_trained: 7775000
    wait_time_ms: 49.336
  iterations_since_restore: 1555
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13660.17842245102
  time_this_iter_s: 8.721258163452148
  time_total_s: 13660.17842245102
  timestamp: 1594862215
  timesteps_since_restore: 7775000
  timesteps_this_iter: 5000
  timesteps_total: 7775000
  training_iteration: 1555
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13660 s, 1555 iter, 7775000 ts, 169 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
W0715 21:17:00.226254 26841 node_manager.cc:250] Last heartbeat was sent 623 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 167.12974236180528
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1555
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.847
    dispatch_time_ms: 15.483
    learner:
      cur_lr: 0.0008421849925071001
      grad_gnorm: 0.19372044503688812
      policy_entropy: 0.06513388454914093
      policy_loss: 9.412877261638641e-06
      var_gnorm: 23.010234832763672
      vf_explained_var: 0.0
      vf_loss: 2.9062002795399167e-05
    num_steps_sampled: 7780000
    num_steps_trained: 7780000
    wait_time_ms: 60.84
  iterations_since_restore: 1556
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13668.409905433655
  time_this_iter_s: 8.231482982635498
  time_total_s: 13668.409905433655
  timestamp: 1594862224
  timesteps_since_restore: 7780000
  timesteps_this_iter: 5000
  timesteps_total: 7780000
  training_iteration: 1556
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13668 s, 1556 iter, 7780000 ts, 167 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 164.1597423619345
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1556
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.999
    dispatch_time_ms: 7.776
    learner:
      cur_lr: 0.0008418519864790142
      grad_gnorm: 0.09197096526622772
      policy_entropy: 0.06566093116998672
      policy_loss: 3.0118274025880964e-06
      var_gnorm: 23.010251998901367
      vf_explained_var: 0.0
      vf_loss: 6.549674253619742e-06
    num_steps_sampled: 7785000
    num_steps_trained: 7785000
    wait_time_ms: 70.733
  iterations_since_restore: 1557
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13676.558647871017
  time_this_iter_s: 8.148742437362671
  time_total_s: 13676.558647871017
  timestamp: 1594862232
  timesteps_since_restore: 7785000
  timesteps_this_iter: 5000
  timesteps_total: 7785000
  training_iteration: 1557
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13676 s, 1557 iter, 7785000 ts, 164 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 161.45974236246585
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1557
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.901
    dispatch_time_ms: 7.411
    learner:
      cur_lr: 0.0008415189804509282
      grad_gnorm: 0.007523130625486374
      policy_entropy: 0.0662512555718422
      policy_loss: 5.856538365378583e-08
      var_gnorm: 23.010271072387695
      vf_explained_var: 0.0
      vf_loss: 4.3780499225931635e-08
    num_steps_sampled: 7790000
    num_steps_trained: 7790000
    wait_time_ms: 68.505
  iterations_since_restore: 1558
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13684.59017920494
  time_this_iter_s: 8.03153133392334
  time_total_s: 13684.59017920494
  timestamp: 1594862240
  timesteps_since_restore: 7790000
  timesteps_this_iter: 5000
  timesteps_total: 7790000
  training_iteration: 1558
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13684 s, 1558 iter, 7790000 ts, 161 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 157.13974236691013
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1558
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.566
    dispatch_time_ms: 7.877
    learner:
      cur_lr: 0.0008411859744228423
      grad_gnorm: 0.08716311305761337
      policy_entropy: 0.06689660251140594
      policy_loss: 5.945795237494167e-06
      var_gnorm: 23.010284423828125
      vf_explained_var: 0.0
      vf_loss: 5.884769961994607e-06
    num_steps_sampled: 7795000
    num_steps_trained: 7795000
    wait_time_ms: 69.687
  iterations_since_restore: 1559
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13692.732135772705
  time_this_iter_s: 8.141956567764282
  time_total_s: 13692.732135772705
  timestamp: 1594862248
  timesteps_since_restore: 7795000
  timesteps_this_iter: 5000
  timesteps_total: 7795000
  training_iteration: 1559
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13692 s, 1559 iter, 7795000 ts, 157 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 153.89974236899855
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1559
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.106
    dispatch_time_ms: 8.154
    learner:
      cur_lr: 0.0008408530266024172
      grad_gnorm: 0.012141533195972443
      policy_entropy: 0.06757114082574844
      policy_loss: 3.963308472521021e-07
      var_gnorm: 23.01030158996582
      vf_explained_var: 0.0
      vf_loss: 1.1390213217055134e-07
    num_steps_sampled: 7800000
    num_steps_trained: 7800000
    wait_time_ms: 70.093
  iterations_since_restore: 1560
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13700.791619300842
  time_this_iter_s: 8.059483528137207
  time_total_s: 13700.791619300842
  timestamp: 1594862256
  timesteps_since_restore: 7800000
  timesteps_this_iter: 5000
  timesteps_total: 7800000
  training_iteration: 1560
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13700 s, 1560 iter, 7800000 ts, 154 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 150.74974237002604
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1560
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.544
    dispatch_time_ms: 9.26
    learner:
      cur_lr: 0.0008405200205743313
      grad_gnorm: 0.07865411788225174
      policy_entropy: 0.06830597668886185
      policy_loss: 8.048628842516337e-06
      var_gnorm: 23.010316848754883
      vf_explained_var: 0.0
      vf_loss: 4.791207175003365e-06
    num_steps_sampled: 7805000
    num_steps_trained: 7805000
    wait_time_ms: 69.572
  iterations_since_restore: 1561
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13708.8588078022
  time_this_iter_s: 8.067188501358032
  time_total_s: 13708.8588078022
  timestamp: 1594862264
  timesteps_since_restore: 7805000
  timesteps_this_iter: 5000
  timesteps_total: 7805000
  training_iteration: 1561
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13708 s, 1561 iter, 7805000 ts, 151 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-17-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 145.97974266744498
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1561
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.968
    dispatch_time_ms: 8.867
    learner:
      cur_lr: 0.0008401870145462453
      grad_gnorm: 0.01876077987253666
      policy_entropy: 0.0690670982003212
      policy_loss: 6.738826527907804e-07
      var_gnorm: 23.01033592224121
      vf_explained_var: 0.0
      vf_loss: 2.720803138345218e-07
    num_steps_sampled: 7810000
    num_steps_trained: 7810000
    wait_time_ms: 69.645
  iterations_since_restore: 1562
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13716.955032587051
  time_this_iter_s: 8.096224784851074
  time_total_s: 13716.955032587051
  timestamp: 1594862273
  timesteps_since_restore: 7810000
  timesteps_this_iter: 5000
  timesteps_total: 7810000
  training_iteration: 1562
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13716 s, 1562 iter, 7810000 ts, 146 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 143.36974266772057
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1562
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.023
    dispatch_time_ms: 7.229
    learner:
      cur_lr: 0.0008398540085181594
      grad_gnorm: 0.06665083765983582
      policy_entropy: 0.0699152797460556
      policy_loss: 8.694821190147195e-06
      var_gnorm: 23.01034927368164
      vf_explained_var: 0.0
      vf_loss: 3.4401614357193466e-06
    num_steps_sampled: 7815000
    num_steps_trained: 7815000
    wait_time_ms: 70.323
  iterations_since_restore: 1563
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13725.03344321251
  time_this_iter_s: 8.078410625457764
  time_total_s: 13725.03344321251
  timestamp: 1594862281
  timesteps_since_restore: 7815000
  timesteps_this_iter: 5000
  timesteps_total: 7815000
  training_iteration: 1563
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13725 s, 1563 iter, 7815000 ts, 143 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 141.11974266783614
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1563
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.656
    dispatch_time_ms: 8.799
    learner:
      cur_lr: 0.0008395210024900734
      grad_gnorm: 0.016740744933485985
      policy_entropy: 0.07081670314073563
      policy_loss: 8.222225460485788e-07
      var_gnorm: 23.010366439819336
      vf_explained_var: 0.0
      vf_loss: 2.1721537279972836e-07
    num_steps_sampled: 7820000
    num_steps_trained: 7820000
    wait_time_ms: 70.746
  iterations_since_restore: 1564
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13733.185825824738
  time_this_iter_s: 8.152382612228394
  time_total_s: 13733.185825824738
  timestamp: 1594862289
  timesteps_since_restore: 7820000
  timesteps_this_iter: 5000
  timesteps_total: 7820000
  training_iteration: 1564
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13733 s, 1564 iter, 7820000 ts, 141 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 138.41974266795032
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1564
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.618
    dispatch_time_ms: 6.009
    learner:
      cur_lr: 0.0008391879964619875
      grad_gnorm: 0.04992390796542168
      policy_entropy: 0.07181276381015778
      policy_loss: 6.757913070032373e-06
      var_gnorm: 23.010379791259766
      vf_explained_var: 0.0
      vf_loss: 1.9306007743580267e-06
    num_steps_sampled: 7825000
    num_steps_trained: 7825000
    wait_time_ms: 68.606
  iterations_since_restore: 1565
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13747.644398450851
  time_this_iter_s: 14.458572626113892
  time_total_s: 13747.644398450851
  timestamp: 1594862303
  timesteps_since_restore: 7825000
  timesteps_this_iter: 5000
  timesteps_total: 7825000
  training_iteration: 1565
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13747 s, 1565 iter, 7825000 ts, 138 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 136.34974266815618
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1565
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.819
    dispatch_time_ms: 8.871
    learner:
      cur_lr: 0.0008388549904339015
      grad_gnorm: 0.008479567244648933
      policy_entropy: 0.07289153337478638
      policy_loss: 6.823233320574218e-07
      var_gnorm: 23.01039695739746
      vf_explained_var: 0.0
      vf_loss: 5.552091408844717e-08
    num_steps_sampled: 7830000
    num_steps_trained: 7830000
    wait_time_ms: 68.87
  iterations_since_restore: 1566
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13755.705029726028
  time_this_iter_s: 8.060631275177002
  time_total_s: 13755.705029726028
  timestamp: 1594862311
  timesteps_since_restore: 7830000
  timesteps_this_iter: 5000
  timesteps_total: 7830000
  training_iteration: 1566
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13755 s, 1566 iter, 7830000 ts, 136 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 133.73974266828802
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1566
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.154
    dispatch_time_ms: 8.192
    learner:
      cur_lr: 0.0008385219844058156
      grad_gnorm: 0.07190016657114029
      policy_entropy: 0.07403584569692612
      policy_loss: 1.174534554593265e-05
      var_gnorm: 23.010408401489258
      vf_explained_var: 0.0
      vf_loss: 4.0035542951954994e-06
    num_steps_sampled: 7835000
    num_steps_trained: 7835000
    wait_time_ms: 68.78
  iterations_since_restore: 1567
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13763.749770402908
  time_this_iter_s: 8.044740676879883
  time_total_s: 13763.749770402908
  timestamp: 1594862319
  timesteps_since_restore: 7835000
  timesteps_this_iter: 5000
  timesteps_total: 7835000
  training_iteration: 1567
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13763 s, 1567 iter, 7835000 ts, 134 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 131.57974266846185
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1567
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.594
    dispatch_time_ms: 11.49
    learner:
      cur_lr: 0.0008381889783777297
      grad_gnorm: 0.002538716420531273
      policy_entropy: 0.07525619864463806
      policy_loss: 3.500892944430234e-07
      var_gnorm: 23.010427474975586
      vf_explained_var: 0.0
      vf_loss: 4.7678119230454286e-09
    num_steps_sampled: 7840000
    num_steps_trained: 7840000
    wait_time_ms: 67.835
  iterations_since_restore: 1568
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13771.92927479744
  time_this_iter_s: 8.17950439453125
  time_total_s: 13771.92927479744
  timestamp: 1594862328
  timesteps_since_restore: 7840000
  timesteps_this_iter: 5000
  timesteps_total: 7840000
  training_iteration: 1568
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13771 s, 1568 iter, 7840000 ts, 132 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-18-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 125.5497436563013
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1568
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.871
    dispatch_time_ms: 6.692
    learner:
      cur_lr: 0.0008378559723496437
      grad_gnorm: 0.07505472749471664
      policy_entropy: 0.07660353183746338
      policy_loss: 2.9165610158088384e-06
      var_gnorm: 23.010438919067383
      vf_explained_var: 0.0
      vf_loss: 4.362059826235054e-06
    num_steps_sampled: 7845000
    num_steps_trained: 7845000
    wait_time_ms: 71.748
  iterations_since_restore: 1569
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13780.016128540039
  time_this_iter_s: 8.086853742599487
  time_total_s: 13780.016128540039
  timestamp: 1594862336
  timesteps_since_restore: 7845000
  timesteps_this_iter: 5000
  timesteps_total: 7845000
  training_iteration: 1569
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13780 s, 1569 iter, 7845000 ts, 126 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 123.65974365635331
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1569
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.705
    dispatch_time_ms: 8.763
    learner:
      cur_lr: 0.0008375230245292187
      grad_gnorm: 0.013872398063540459
      policy_entropy: 0.07805716246366501
      policy_loss: -1.9172397003330843e-07
      var_gnorm: 23.010456085205078
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.4896529876295972e-07
    num_steps_sampled: 7850000
    num_steps_trained: 7850000
    wait_time_ms: 69.586
  iterations_since_restore: 1570
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13788.027661085129
  time_this_iter_s: 8.011532545089722
  time_total_s: 13788.027661085129
  timestamp: 1594862344
  timesteps_since_restore: 7850000
  timesteps_this_iter: 5000
  timesteps_total: 7850000
  training_iteration: 1570
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.6/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13788 s, 1570 iter, 7850000 ts, 124 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 121.31974365659248
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1570
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 7.809
    learner:
      cur_lr: 0.0008371900185011327
      grad_gnorm: 0.08136811852455139
      policy_entropy: 0.07967323809862137
      policy_loss: 9.681538358563557e-06
      var_gnorm: 23.010465621948242
      vf_explained_var: 0.0
      vf_loss: 5.12767519467161e-06
    num_steps_sampled: 7855000
    num_steps_trained: 7855000
    wait_time_ms: 71.552
  iterations_since_restore: 1571
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13796.129122495651
  time_this_iter_s: 8.101461410522461
  time_total_s: 13796.129122495651
  timestamp: 1594862352
  timesteps_since_restore: 7855000
  timesteps_this_iter: 5000
  timesteps_total: 7855000
  training_iteration: 1571
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13796 s, 1571 iter, 7855000 ts, 121 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 115.46974370047923
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1571
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.207
    dispatch_time_ms: 8.056
    learner:
      cur_lr: 0.0008368570124730468
      grad_gnorm: 0.023051386699080467
      policy_entropy: 0.08155173808336258
      policy_loss: -9.608082791601191e-07
      var_gnorm: 23.01047706604004
      vf_explained_var: 0.0
      vf_loss: 4.1148047102979035e-07
    num_steps_sampled: 7860000
    num_steps_trained: 7860000
    wait_time_ms: 69.512
  iterations_since_restore: 1572
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13804.170550823212
  time_this_iter_s: 8.041428327560425
  time_total_s: 13804.170550823212
  timestamp: 1594862360
  timesteps_since_restore: 7860000
  timesteps_this_iter: 5000
  timesteps_total: 7860000
  training_iteration: 1572
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13804 s, 1572 iter, 7860000 ts, 115 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 113.66974370072641
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1572
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 6.977
    learner:
      cur_lr: 0.0008365240064449608
      grad_gnorm: 0.026703713461756706
      policy_entropy: 0.08353396505117416
      policy_loss: 1.1350970453349873e-05
      var_gnorm: 23.010488510131836
      vf_explained_var: 0.0
      vf_loss: 5.519407295651035e-07
    num_steps_sampled: 7865000
    num_steps_trained: 7865000
    wait_time_ms: 70.973
  iterations_since_restore: 1573
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13812.24014878273
  time_this_iter_s: 8.069597959518433
  time_total_s: 13812.24014878273
  timestamp: 1594862368
  timesteps_since_restore: 7865000
  timesteps_this_iter: 5000
  timesteps_total: 7865000
  training_iteration: 1573
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13812 s, 1573 iter, 7865000 ts, 114 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 111.41974370087117
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1573
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.597
    dispatch_time_ms: 8.552
    learner:
      cur_lr: 0.0008361910004168749
      grad_gnorm: 0.01920095644891262
      policy_entropy: 0.08564753830432892
      policy_loss: -1.8198478528574924e-06
      var_gnorm: 23.01050567626953
      vf_explained_var: 0.0
      vf_loss: 2.8485422376434144e-07
    num_steps_sampled: 7870000
    num_steps_trained: 7870000
    wait_time_ms: 70.732
  iterations_since_restore: 1574
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13820.339632749557
  time_this_iter_s: 8.099483966827393
  time_total_s: 13820.339632749557
  timestamp: 1594862376
  timesteps_since_restore: 7870000
  timesteps_this_iter: 5000
  timesteps_total: 7870000
  training_iteration: 1574
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13820 s, 1574 iter, 7870000 ts, 111 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 107.45974370261811
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1574
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.904
    dispatch_time_ms: 9.575
    learner:
      cur_lr: 0.0008358579943887889
      grad_gnorm: 0.006614477839320898
      policy_entropy: 0.08803239464759827
      policy_loss: 1.7981132259592414e-05
      var_gnorm: 23.010515213012695
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.37132171068788e-08
    num_steps_sampled: 7875000
    num_steps_trained: 7875000
    wait_time_ms: 68.676
  iterations_since_restore: 1575
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13828.415232896805
  time_this_iter_s: 8.075600147247314
  time_total_s: 13828.415232896805
  timestamp: 1594862384
  timesteps_since_restore: 7875000
  timesteps_this_iter: 5000
  timesteps_total: 7875000
  training_iteration: 1575
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13828 s, 1575 iter, 7875000 ts, 107 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-19-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 105.47974370274426
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1575
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.147
    dispatch_time_ms: 18.471
    learner:
      cur_lr: 0.000835524988360703
      grad_gnorm: 0.00856204703450203
      policy_entropy: 0.09064148366451263
      policy_loss: -2.570613560237689e-06
      var_gnorm: 23.010530471801758
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.747569176151046e-08
    num_steps_sampled: 7880000
    num_steps_trained: 7880000
    wait_time_ms: 73.587
  iterations_since_restore: 1576
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13836.681722640991
  time_this_iter_s: 8.266489744186401
  time_total_s: 13836.681722640991
  timestamp: 1594862393
  timesteps_since_restore: 7880000
  timesteps_this_iter: 5000
  timesteps_total: 7880000
  training_iteration: 1576
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13836 s, 1576 iter, 7880000 ts, 105 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 100.52974381044456
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1576
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.974
    dispatch_time_ms: 38.346
    learner:
      cur_lr: 0.000835191982332617
      grad_gnorm: 0.26989784836769104
      policy_entropy: 0.09359773993492126
      policy_loss: 9.012573173095006e-06
      var_gnorm: 23.010540008544922
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 7.333354733418673e-05
    num_steps_sampled: 7885000
    num_steps_trained: 7885000
    wait_time_ms: 42.667
  iterations_since_restore: 1577
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13845.153224468231
  time_this_iter_s: 8.47150182723999
  time_total_s: 13845.153224468231
  timestamp: 1594862401
  timesteps_since_restore: 7885000
  timesteps_this_iter: 5000
  timesteps_total: 7885000
  training_iteration: 1577
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13845 s, 1577 iter, 7885000 ts, 101 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 98.45974381050638
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1577
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.029
    dispatch_time_ms: 21.372
    learner:
      cur_lr: 0.0008348589763045311
      grad_gnorm: 0.0007718004053458571
      policy_entropy: 0.09654625505208969
      policy_loss: 8.339902990428527e-09
      var_gnorm: 23.010562896728516
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.3042818214348273e-10
    num_steps_sampled: 7890000
    num_steps_trained: 7890000
    wait_time_ms: 63.337
  iterations_since_restore: 1578
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13853.6870906353
  time_this_iter_s: 8.533866167068481
  time_total_s: 13853.6870906353
  timestamp: 1594862410
  timesteps_since_restore: 7890000
  timesteps_this_iter: 5000
  timesteps_total: 7890000
  training_iteration: 1578
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13853 s, 1578 iter, 7890000 ts, 98.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 94.40974381207826
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1578
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.366
    dispatch_time_ms: 32.292
    learner:
      cur_lr: 0.0008345260284841061
      grad_gnorm: 0.10434256494045258
      policy_entropy: 0.10047454386949539
      policy_loss: 1.6403959307353944e-05
      var_gnorm: 23.01056671142578
      vf_explained_var: 0.0
      vf_loss: 8.432828508375678e-06
    num_steps_sampled: 7895000
    num_steps_trained: 7895000
    wait_time_ms: 53.381
  iterations_since_restore: 1579
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13862.275592327118
  time_this_iter_s: 8.588501691818237
  time_total_s: 13862.275592327118
  timestamp: 1594862418
  timesteps_since_restore: 7895000
  timesteps_this_iter: 5000
  timesteps_total: 7895000
  training_iteration: 1579
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13862 s, 1579 iter, 7895000 ts, 94.4 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 92.69974381213873
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1579
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.702
    dispatch_time_ms: 32.919
    learner:
      cur_lr: 0.0008341930224560201
      grad_gnorm: 0.9638479948043823
      policy_entropy: 0.10597746819257736
      policy_loss: 0.00018131926481146365
      var_gnorm: 23.010540008544922
      vf_explained_var: 0.0
      vf_loss: 0.0007194664212875068
    num_steps_sampled: 7900000
    num_steps_trained: 7900000
    wait_time_ms: 56.188
  iterations_since_restore: 1580
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13871.040089845657
  time_this_iter_s: 8.764497518539429
  time_total_s: 13871.040089845657
  timestamp: 1594862427
  timesteps_since_restore: 7900000
  timesteps_this_iter: 5000
  timesteps_total: 7900000
  training_iteration: 1580
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13871 s, 1580 iter, 7900000 ts, 92.7 rew

agent-1: 1.306620857777077
agent-2: 1.306620857777077
agent-3: 2.3066208577770775
agent-4: 1.306620857777077
agent-5: 1.306620857777077
Extrinsic Rewards:
0
0
1
0
0
Sum Reward: 1
Avg Reward: 0.2
Min Reward: 0
Max Reward: 1
Gini Coefficient: 0.8
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 89.53507485588601
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1580
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.791
    dispatch_time_ms: 26.666
    learner:
      cur_lr: 0.0008338600164279342
      grad_gnorm: 0.10061951726675034
      policy_entropy: 2.739225387573242
      policy_loss: -0.00730108842253685
      var_gnorm: 23.002296447753906
      vf_explained_var: 0.0
      vf_loss: 2.963522227616977e-08
    num_steps_sampled: 7905000
    num_steps_trained: 7905000
    wait_time_ms: 57.655
  iterations_since_restore: 1581
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13879.69029545784
  time_this_iter_s: 8.650205612182617
  time_total_s: 13879.69029545784
  timestamp: 1594862436
  timesteps_since_restore: 7905000
  timesteps_this_iter: 5000
  timesteps_total: 7905000
  training_iteration: 1581
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13879 s, 1581 iter, 7905000 ts, 89.5 rew

agent-1: 3.8839042381260738
agent-2: 4.883904238126073
agent-3: 2.883904238126073
agent-4: 2.883904238126073
agent-5: 2.883904238126073
Extrinsic Rewards:
1
2
0
0
0
Sum Reward: 3
Avg Reward: 0.6
Min Reward: 0
Max Reward: 2
Gini Coefficient: 0.6666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 83.94927019116213
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1581
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.457
    dispatch_time_ms: 33.871
    learner:
      cur_lr: 0.0008335270103998482
      grad_gnorm: 40.00000762939453
      policy_entropy: 30.228586196899414
      policy_loss: -25.219011306762695
      var_gnorm: 23.043485641479492
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 14.593493461608887
    num_steps_sampled: 7910000
    num_steps_trained: 7910000
    wait_time_ms: 61.373
  iterations_since_restore: 1582
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13888.482037067413
  time_this_iter_s: 8.791741609573364
  time_total_s: 13888.482037067413
  timestamp: 1594862445
  timesteps_since_restore: 7910000
  timesteps_this_iter: 5000
  timesteps_total: 7910000
  training_iteration: 1582
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13888 s, 1582 iter, 7910000 ts, 83.9 rew

agent-1: 82.39994951135947
agent-2: 78.39994951135947
agent-3: 71.39994951135947
agent-4: 88.3999495113595
agent-5: 75.39994951135952
Extrinsic Rewards:
12
8
1
18
5
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 1
Max Reward: 18
Gini Coefficient: 0.37272727272727274
20:20 Ratio: 18.0
Max-min Ratio: 18.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-20-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 620.9999907476225
  episode_reward_mean: 85.47926766678897
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1582
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.834
    dispatch_time_ms: 46.965
    learner:
      cur_lr: 0.0008331940043717623
      grad_gnorm: 20.31915855407715
      policy_entropy: 0.007427472621202469
      policy_loss: -5.8667021221481264e-05
      var_gnorm: 23.001008987426758
      vf_explained_var: 0.0
      vf_loss: 0.3155730366706848
    num_steps_sampled: 7915000
    num_steps_trained: 7915000
    wait_time_ms: 45.679
  iterations_since_restore: 1583
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13897.437551736832
  time_this_iter_s: 8.955514669418335
  time_total_s: 13897.437551736832
  timestamp: 1594862454
  timesteps_since_restore: 7915000
  timesteps_this_iter: 5000
  timesteps_total: 7915000
  training_iteration: 1583
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13897 s, 1583 iter, 7915000 ts, 85.5 rew

agent-1: 79.59999991148472
agent-2: 68.59999991148472
agent-3: 88.59999991148473
agent-4: 65.5999999114847
agent-5: 66.59999991148469
Extrinsic Rewards:
14
3
23
0
1
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 0
Max Reward: 23
Gini Coefficient: 0.5756097560975609
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999599499542
  episode_reward_mean: 82.95926775488691
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1583
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.016
    dispatch_time_ms: 35.854
    learner:
      cur_lr: 0.0008328609983436763
      grad_gnorm: 0.9341205954551697
      policy_entropy: 0.007432525511831045
      policy_loss: -4.146587343711872e-06
      var_gnorm: 22.999988555908203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.0006757586379535496
    num_steps_sampled: 7920000
    num_steps_trained: 7920000
    wait_time_ms: 45.773
  iterations_since_restore: 1584
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13906.02667593956
  time_this_iter_s: 8.589124202728271
  time_total_s: 13906.02667593956
  timestamp: 1594862462
  timesteps_since_restore: 7920000
  timesteps_this_iter: 5000
  timesteps_total: 7920000
  training_iteration: 1584
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13906 s, 1584 iter, 7920000 ts, 83 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999599499542
  episode_reward_mean: 80.79926775493821
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1584
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.656
    dispatch_time_ms: 8.233
    learner:
      cur_lr: 0.0008325279923155904
      grad_gnorm: 0.07600722461938858
      policy_entropy: 0.007433774881064892
      policy_loss: 2.5301864070570446e-07
      var_gnorm: 22.999988555908203
      vf_explained_var: 0.0
      vf_loss: 4.4729495130013674e-06
    num_steps_sampled: 7925000
    num_steps_trained: 7925000
    wait_time_ms: 70.98
  iterations_since_restore: 1585
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13914.156698465347
  time_this_iter_s: 8.130022525787354
  time_total_s: 13914.156698465347
  timestamp: 1594862471
  timesteps_since_restore: 7925000
  timesteps_this_iter: 5000
  timesteps_total: 7925000
  training_iteration: 1585
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13914 s, 1585 iter, 7925000 ts, 80.8 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999599499542
  episode_reward_mean: 78.09926775707528
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1585
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.972
    dispatch_time_ms: 7.804
    learner:
      cur_lr: 0.0008321949862875044
      grad_gnorm: 0.0022325252648442984
      policy_entropy: 0.0074341450817883015
      policy_loss: -5.5864712855679954e-09
      var_gnorm: 23.0
      vf_explained_var: 0.0
      vf_loss: 3.844910168027127e-09
    num_steps_sampled: 7930000
    num_steps_trained: 7930000
    wait_time_ms: 69.455
  iterations_since_restore: 1586
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13922.285312652588
  time_this_iter_s: 8.1286141872406
  time_total_s: 13922.285312652588
  timestamp: 1594862479
  timesteps_since_restore: 7930000
  timesteps_this_iter: 5000
  timesteps_total: 7930000
  training_iteration: 1586
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13922 s, 1586 iter, 7930000 ts, 78.1 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 566.9999599499542
  episode_reward_mean: 72.51952278807836
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1586
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 9.065
    learner:
      cur_lr: 0.0008318619802594185
      grad_gnorm: 0.07323461771011353
      policy_entropy: 0.007434668950736523
      policy_loss: 2.680373825114657e-07
      var_gnorm: 23.000011444091797
      vf_explained_var: 0.0
      vf_loss: 4.153803274675738e-06
    num_steps_sampled: 7935000
    num_steps_trained: 7935000
    wait_time_ms: 67.405
  iterations_since_restore: 1587
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13930.308148145676
  time_this_iter_s: 8.022835493087769
  time_total_s: 13930.308148145676
  timestamp: 1594862487
  timesteps_since_restore: 7935000
  timesteps_this_iter: 5000
  timesteps_total: 7935000
  training_iteration: 1587
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13930 s, 1587 iter, 7935000 ts, 72.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.9999970136689
  episode_reward_mean: 66.84952318857881
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1587
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.775
    dispatch_time_ms: 8.39
    learner:
      cur_lr: 0.0008315289742313325
      grad_gnorm: 0.004241009708493948
      policy_entropy: 0.00743533531203866
      policy_loss: -1.2648362357481346e-08
      var_gnorm: 23.000022888183594
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.3968479706250037e-08
    num_steps_sampled: 7940000
    num_steps_trained: 7940000
    wait_time_ms: 71.54
  iterations_since_restore: 1588
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13938.460014343262
  time_this_iter_s: 8.15186619758606
  time_total_s: 13938.460014343262
  timestamp: 1594862495
  timesteps_since_restore: 7940000
  timesteps_this_iter: 5000
  timesteps_total: 7940000
  training_iteration: 1588
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13938 s, 1588 iter, 7940000 ts, 66.8 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.9999970136689
  episode_reward_mean: 63.69952318928172
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1588
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.654
    dispatch_time_ms: 8.831
    learner:
      cur_lr: 0.0008311960264109075
      grad_gnorm: 0.0818461999297142
      policy_entropy: 0.007437048014253378
      policy_loss: 2.6982385747942317e-07
      var_gnorm: 23.00003433227539
      vf_explained_var: 0.0
      vf_loss: 5.187157057662262e-06
    num_steps_sampled: 7945000
    num_steps_trained: 7945000
    wait_time_ms: 70.865
  iterations_since_restore: 1589
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13946.490900993347
  time_this_iter_s: 8.03088665008545
  time_total_s: 13946.490900993347
  timestamp: 1594862503
  timesteps_since_restore: 7945000
  timesteps_this_iter: 5000
  timesteps_total: 7945000
  training_iteration: 1589
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13946 s, 1589 iter, 7945000 ts, 63.7 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 539.9999970136689
  episode_reward_mean: 60.279523189789
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1589
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.973
    dispatch_time_ms: 6.818
    learner:
      cur_lr: 0.0008308630203828216
      grad_gnorm: 0.00574855599552393
      policy_entropy: 0.00743876164779067
      policy_loss: -2.0508867493163052e-08
      var_gnorm: 23.000049591064453
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 2.554608613536402e-08
    num_steps_sampled: 7950000
    num_steps_trained: 7950000
    wait_time_ms: 69.447
  iterations_since_restore: 1590
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13954.595448732376
  time_this_iter_s: 8.10454773902893
  time_total_s: 13954.595448732376
  timestamp: 1594862511
  timesteps_since_restore: 7950000
  timesteps_this_iter: 5000
  timesteps_total: 7950000
  training_iteration: 1590
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13954 s, 1590 iter, 7950000 ts, 60.3 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-21-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 54.87952321965231
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1590
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.041
    dispatch_time_ms: 8.688
    learner:
      cur_lr: 0.0008305300143547356
      grad_gnorm: 0.0824054405093193
      policy_entropy: 0.007440416608005762
      policy_loss: 2.9624442277054186e-07
      var_gnorm: 23.00006103515625
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 5.259406862023752e-06
    num_steps_sampled: 7955000
    num_steps_trained: 7955000
    wait_time_ms: 69.539
  iterations_since_restore: 1591
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13962.650247573853
  time_this_iter_s: 8.05479884147644
  time_total_s: 13962.650247573853
  timestamp: 1594862519
  timesteps_since_restore: 7955000
  timesteps_this_iter: 5000
  timesteps_total: 7955000
  training_iteration: 1591
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13962 s, 1591 iter, 7955000 ts, 54.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 53.16952321969713
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1591
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.941
    dispatch_time_ms: 7.633
    learner:
      cur_lr: 0.0008301970083266497
      grad_gnorm: 0.006853042170405388
      policy_entropy: 0.007442154455929995
      policy_loss: -3.383356883546185e-08
      var_gnorm: 23.000076293945312
      vf_explained_var: 0.0
      vf_loss: 3.615900823206175e-08
    num_steps_sampled: 7960000
    num_steps_trained: 7960000
    wait_time_ms: 68.892
  iterations_since_restore: 1592
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13970.749257802963
  time_this_iter_s: 8.099010229110718
  time_total_s: 13970.749257802963
  timestamp: 1594862527
  timesteps_since_restore: 7960000
  timesteps_this_iter: 5000
  timesteps_total: 7960000
  training_iteration: 1592
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13970 s, 1592 iter, 7960000 ts, 53.2 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 50.64952321982018
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1592
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 8.442
    learner:
      cur_lr: 0.0008298640022985637
      grad_gnorm: 0.08889642357826233
      policy_entropy: 0.007443846203386784
      policy_loss: 3.856203534269298e-07
      var_gnorm: 23.000089645385742
      vf_explained_var: 0.0
      vf_loss: 6.120913894847035e-06
    num_steps_sampled: 7965000
    num_steps_trained: 7965000
    wait_time_ms: 68.516
  iterations_since_restore: 1593
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13981.916493654251
  time_this_iter_s: 11.167235851287842
  time_total_s: 13981.916493654251
  timestamp: 1594862539
  timesteps_since_restore: 7965000
  timesteps_this_iter: 5000
  timesteps_total: 7965000
  training_iteration: 1593
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13981 s, 1593 iter, 7965000 ts, 50.6 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 48.57952321985844
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1593
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.767
    dispatch_time_ms: 8.606
    learner:
      cur_lr: 0.0008295309962704778
      grad_gnorm: 0.006380679085850716
      policy_entropy: 0.007445703726261854
      policy_loss: -1.9030551356991054e-08
      var_gnorm: 23.000102996826172
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.151606975393406e-08
    num_steps_sampled: 7970000
    num_steps_trained: 7970000
    wait_time_ms: 70.432
  iterations_since_restore: 1594
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13990.063534021378
  time_this_iter_s: 8.147040367126465
  time_total_s: 13990.063534021378
  timestamp: 1594862547
  timesteps_since_restore: 7970000
  timesteps_this_iter: 5000
  timesteps_total: 7970000
  training_iteration: 1594
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13990 s, 1594 iter, 7970000 ts, 48.6 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 46.23952322022387
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1594
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 8.665
    learner:
      cur_lr: 0.0008291979902423918
      grad_gnorm: 0.0964890569448471
      policy_entropy: 0.007447515614330769
      policy_loss: 3.7909117622803024e-07
      var_gnorm: 23.000118255615234
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.211807769635925e-06
    num_steps_sampled: 7975000
    num_steps_trained: 7975000
    wait_time_ms: 68.122
  iterations_since_restore: 1595
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 13998.067105054855
  time_this_iter_s: 8.003571033477783
  time_total_s: 13998.067105054855
  timestamp: 1594862555
  timesteps_since_restore: 7975000
  timesteps_this_iter: 5000
  timesteps_total: 7975000
  training_iteration: 1595
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 13998 s, 1595 iter, 7975000 ts, 46.2 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 43.98952322038041
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1595
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.818
    dispatch_time_ms: 9.873
    learner:
      cur_lr: 0.0008288649842143059
      grad_gnorm: 0.005431568715721369
      policy_entropy: 0.007449303288012743
      policy_loss: -2.3474806098988665e-08
      var_gnorm: 23.000133514404297
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.2772548291527528e-08
    num_steps_sampled: 7980000
    num_steps_trained: 7980000
    wait_time_ms: 67.029
  iterations_since_restore: 1596
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14006.14283490181
  time_this_iter_s: 8.075729846954346
  time_total_s: 14006.14283490181
  timestamp: 1594862563
  timesteps_since_restore: 7980000
  timesteps_this_iter: 5000
  timesteps_total: 7980000
  training_iteration: 1596
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14006 s, 1596 iter, 7980000 ts, 44 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 39.759523240683464
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1596
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.858
    dispatch_time_ms: 8.014
    learner:
      cur_lr: 0.0008285319781862199
      grad_gnorm: 0.09393098205327988
      policy_entropy: 0.00745117524638772
      policy_loss: 3.4067497267642466e-07
      var_gnorm: 23.00014877319336
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 6.8337999437062535e-06
    num_steps_sampled: 7985000
    num_steps_trained: 7985000
    wait_time_ms: 73.505
  iterations_since_restore: 1597
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14014.258473873138
  time_this_iter_s: 8.115638971328735
  time_total_s: 14014.258473873138
  timestamp: 1594862571
  timesteps_since_restore: 7985000
  timesteps_this_iter: 5000
  timesteps_total: 7985000
  training_iteration: 1597
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14014 s, 1597 iter, 7985000 ts, 39.8 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-22-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 37.869523240758994
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1597
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.403
    dispatch_time_ms: 8.088
    learner:
      cur_lr: 0.000828198972158134
      grad_gnorm: 0.0030927867628633976
      policy_entropy: 0.00745311938226223
      policy_loss: -1.788172987460257e-08
      var_gnorm: 23.000167846679688
      vf_explained_var: 0.0
      vf_loss: 7.423700321140814e-09
    num_steps_sampled: 7990000
    num_steps_trained: 7990000
    wait_time_ms: 65.267
  iterations_since_restore: 1598
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14022.335192203522
  time_this_iter_s: 8.0767183303833
  time_total_s: 14022.335192203522
  timestamp: 1594862579
  timesteps_since_restore: 7990000
  timesteps_this_iter: 5000
  timesteps_total: 7990000
  training_iteration: 1598
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14022 s, 1598 iter, 7990000 ts, 37.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 35.34952325980823
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1598
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.777
    dispatch_time_ms: 6.772
    learner:
      cur_lr: 0.000827866024337709
      grad_gnorm: 0.09468666464090347
      policy_entropy: 0.007461226545274258
      policy_loss: 2.8521179729068535e-07
      var_gnorm: 23.000181198120117
      vf_explained_var: 0.0
      vf_loss: 6.940350885997759e-06
    num_steps_sampled: 7995000
    num_steps_trained: 7995000
    wait_time_ms: 68.597
  iterations_since_restore: 1599
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14030.41151714325
  time_this_iter_s: 8.076324939727783
  time_total_s: 14030.41151714325
  timestamp: 1594862587
  timesteps_since_restore: 7995000
  timesteps_this_iter: 5000
  timesteps_total: 7995000
  training_iteration: 1599
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14030 s, 1599 iter, 7995000 ts, 35.3 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 33.45952325990549
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1599
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.024
    dispatch_time_ms: 6.623
    learner:
      cur_lr: 0.000827533018309623
      grad_gnorm: 0.0006656694458797574
      policy_entropy: 0.007463220506906509
      policy_loss: -1.4651917901176148e-08
      var_gnorm: 23.000200271606445
      vf_explained_var: 0.0
      vf_loss: 3.529437020421966e-10
    num_steps_sampled: 8000000
    num_steps_trained: 8000000
    wait_time_ms: 72.891
  iterations_since_restore: 1600
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14038.519641399384
  time_this_iter_s: 8.108124256134033
  time_total_s: 14038.519641399384
  timestamp: 1594862595
  timesteps_since_restore: 8000000
  timesteps_this_iter: 5000
  timesteps_total: 8000000
  training_iteration: 1600
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14038 s, 1600 iter, 8000000 ts, 33.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 31.11952326008478
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1600
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.635
    dispatch_time_ms: 9.824
    learner:
      cur_lr: 0.0008272000122815371
      grad_gnorm: 0.10957588255405426
      policy_entropy: 0.007465356960892677
      policy_loss: 3.3006057265083655e-07
      var_gnorm: 23.00021743774414
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 9.297768883698154e-06
    num_steps_sampled: 8005000
    num_steps_trained: 8005000
    wait_time_ms: 68.097
  iterations_since_restore: 1601
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14046.53982424736
  time_this_iter_s: 8.020182847976685
  time_total_s: 14046.53982424736
  timestamp: 1594862604
  timesteps_since_restore: 8005000
  timesteps_this_iter: 5000
  timesteps_total: 8005000
  training_iteration: 1601
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14046 s, 1601 iter, 8005000 ts, 31.1 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 29.04952326012979
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1601
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 8.649
    learner:
      cur_lr: 0.0008268670062534511
      grad_gnorm: 0.004325824324041605
      policy_entropy: 0.007468199357390404
      policy_loss: 1.3029086254334743e-08
      var_gnorm: 23.00023651123047
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.444834651920246e-08
    num_steps_sampled: 8010000
    num_steps_trained: 8010000
    wait_time_ms: 72.039
  iterations_since_restore: 1602
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14054.743048906326
  time_this_iter_s: 8.203224658966064
  time_total_s: 14054.743048906326
  timestamp: 1594862612
  timesteps_since_restore: 8010000
  timesteps_this_iter: 5000
  timesteps_total: 8010000
  training_iteration: 1602
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14054 s, 1602 iter, 8010000 ts, 29 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 27.069523260192565
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1602
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.02
    dispatch_time_ms: 7.978
    learner:
      cur_lr: 0.0008265340002253652
      grad_gnorm: 0.1006356030702591
      policy_entropy: 0.007471758872270584
      policy_loss: 4.04934468178908e-07
      var_gnorm: 23.000247955322266
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 7.843937964935321e-06
    num_steps_sampled: 8015000
    num_steps_trained: 8015000
    wait_time_ms: 68.466
  iterations_since_restore: 1603
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14062.71105337143
  time_this_iter_s: 7.968004465103149
  time_total_s: 14062.71105337143
  timestamp: 1594862620
  timesteps_since_restore: 8015000
  timesteps_this_iter: 5000
  timesteps_total: 8015000
  training_iteration: 1603
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14062 s, 1603 iter, 8015000 ts, 27.1 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 23.82952326126461
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1603
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.787
    dispatch_time_ms: 45.712
    learner:
      cur_lr: 0.0008262009941972792
      grad_gnorm: 0.006451489869505167
      policy_entropy: 0.0074753547087311745
      policy_loss: 5.491735954876731e-09
      var_gnorm: 23.00026512145996
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.60964547749154e-08
    num_steps_sampled: 8020000
    num_steps_trained: 8020000
    wait_time_ms: 38.7
  iterations_since_restore: 1604
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14070.702999353409
  time_this_iter_s: 7.99194598197937
  time_total_s: 14070.702999353409
  timestamp: 1594862628
  timesteps_since_restore: 8020000
  timesteps_this_iter: 5000
  timesteps_total: 8020000
  training_iteration: 1604
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14070 s, 1604 iter, 8020000 ts, 23.8 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-23-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 22.029523261324297
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1604
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.798
    dispatch_time_ms: 21.956
    learner:
      cur_lr: 0.0008258679881691933
      grad_gnorm: 0.017684275284409523
      policy_entropy: 0.007479050196707249
      policy_loss: 5.8314736151032776e-08
      var_gnorm: 23.000280380249023
      vf_explained_var: 0.0
      vf_loss: 2.420946714210004e-07
    num_steps_sampled: 8025000
    num_steps_trained: 8025000
    wait_time_ms: 57.296
  iterations_since_restore: 1605
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14079.1325507164
  time_this_iter_s: 8.429551362991333
  time_total_s: 14079.1325507164
  timestamp: 1594862636
  timesteps_since_restore: 8025000
  timesteps_this_iter: 5000
  timesteps_total: 8025000
  training_iteration: 1605
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14079 s, 1605 iter, 8025000 ts, 22 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 19.509523261563285
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1605
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.151
    dispatch_time_ms: 8.085
    learner:
      cur_lr: 0.0008255349821411073
      grad_gnorm: 0.010442430153489113
      policy_entropy: 0.00748277036473155
      policy_loss: 3.4394393111369936e-08
      var_gnorm: 23.00029945373535
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 8.446836829989479e-08
    num_steps_sampled: 8030000
    num_steps_trained: 8030000
    wait_time_ms: 69.354
  iterations_since_restore: 1606
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14087.01472234726
  time_this_iter_s: 7.882171630859375
  time_total_s: 14087.01472234726
  timestamp: 1594862644
  timesteps_since_restore: 8030000
  timesteps_this_iter: 5000
  timesteps_total: 8030000
  training_iteration: 1606
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14087 s, 1606 iter, 8030000 ts, 19.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 17.799523261616574
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1606
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.38
    dispatch_time_ms: 7.125
    learner:
      cur_lr: 0.0008252019761130214
      grad_gnorm: 0.10557863861322403
      policy_entropy: 0.007486447226256132
      policy_loss: 3.881525287852128e-07
      var_gnorm: 23.000316619873047
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 8.63155673869187e-06
    num_steps_sampled: 8035000
    num_steps_trained: 8035000
    wait_time_ms: 67.75
  iterations_since_restore: 1607
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14094.905065774918
  time_this_iter_s: 7.890343427658081
  time_total_s: 14094.905065774918
  timestamp: 1594862652
  timesteps_since_restore: 8035000
  timesteps_this_iter: 5000
  timesteps_total: 8035000
  training_iteration: 1607
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14094 s, 1607 iter, 8035000 ts, 17.8 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 449.99995384363115
  episode_reward_mean: 15.009523263950047
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1607
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.554
    dispatch_time_ms: 10.142
    learner:
      cur_lr: 0.0008248690282925963
      grad_gnorm: 0.014276689849793911
      policy_entropy: 0.007490362972021103
      policy_loss: 6.799152174608025e-08
      var_gnorm: 23.000335693359375
      vf_explained_var: 0.0
      vf_loss: 1.577682127162916e-07
    num_steps_sampled: 8040000
    num_steps_trained: 8040000
    wait_time_ms: 66.74
  iterations_since_restore: 1608
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14102.84382891655
  time_this_iter_s: 7.93876314163208
  time_total_s: 14102.84382891655
  timestamp: 1594862660
  timesteps_since_restore: 8040000
  timesteps_this_iter: 5000
  timesteps_total: 8040000
  training_iteration: 1608
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14102 s, 1608 iter, 8040000 ts, 15 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 10.509523725513736
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1608
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 10.179
    learner:
      cur_lr: 0.0008245360222645104
      grad_gnorm: 0.0850178450345993
      policy_entropy: 0.0074942586943507195
      policy_loss: 7.555863135166874e-07
      var_gnorm: 23.000354766845703
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.597816198132932e-06
    num_steps_sampled: 8045000
    num_steps_trained: 8045000
    wait_time_ms: 67.265
  iterations_since_restore: 1609
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14110.787513017654
  time_this_iter_s: 7.943684101104736
  time_total_s: 14110.787513017654
  timestamp: 1594862668
  timesteps_since_restore: 8045000
  timesteps_this_iter: 5000
  timesteps_total: 8045000
  training_iteration: 1609
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14110 s, 1609 iter, 8045000 ts, 10.5 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1609
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.815
    dispatch_time_ms: 7.815
    learner:
      cur_lr: 0.0008242030162364244
      grad_gnorm: 0.01219459343701601
      policy_entropy: 0.007498718798160553
      policy_loss: 1.0232015767996927e-07
      var_gnorm: 23.000377655029297
      vf_explained_var: 0.0
      vf_loss: 1.1511904318695088e-07
    num_steps_sampled: 8050000
    num_steps_trained: 8050000
    wait_time_ms: 72.044
  iterations_since_restore: 1610
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14118.750542640686
  time_this_iter_s: 7.963029623031616
  time_total_s: 14118.750542640686
  timestamp: 1594862676
  timesteps_since_restore: 8050000
  timesteps_this_iter: 5000
  timesteps_total: 8050000
  training_iteration: 1610
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14118 s, 1610 iter, 8050000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1610
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.473
    dispatch_time_ms: 5.678
    learner:
      cur_lr: 0.0008238700102083385
      grad_gnorm: 0.073129802942276
      policy_entropy: 0.0075040338560938835
      policy_loss: 4.161267384006351e-07
      var_gnorm: 23.00040054321289
      vf_explained_var: 0.0
      vf_loss: 4.140650617046049e-06
    num_steps_sampled: 8055000
    num_steps_trained: 8055000
    wait_time_ms: 72.979
  iterations_since_restore: 1611
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14126.71179652214
  time_this_iter_s: 7.961253881454468
  time_total_s: 14126.71179652214
  timestamp: 1594862684
  timesteps_since_restore: 8055000
  timesteps_this_iter: 5000
  timesteps_total: 8055000
  training_iteration: 1611
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14126 s, 1611 iter, 8055000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-24-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1611
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.625
    dispatch_time_ms: 7.27
    learner:
      cur_lr: 0.0008235370041802526
      grad_gnorm: 0.004776783753186464
      policy_entropy: 0.007509221322834492
      policy_loss: 3.885349997290177e-08
      var_gnorm: 23.00042724609375
      vf_explained_var: 0.0
      vf_loss: 1.7715475308932582e-08
    num_steps_sampled: 8060000
    num_steps_trained: 8060000
    wait_time_ms: 69.617
  iterations_since_restore: 1612
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14134.673823356628
  time_this_iter_s: 7.962026834487915
  time_total_s: 14134.673823356628
  timestamp: 1594862692
  timesteps_since_restore: 8060000
  timesteps_this_iter: 5000
  timesteps_total: 8060000
  training_iteration: 1612
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14134 s, 1612 iter, 8060000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1612
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.467
    dispatch_time_ms: 10.829
    learner:
      cur_lr: 0.0008232039981521666
      grad_gnorm: 0.038691017776727676
      policy_entropy: 0.0075145927257835865
      policy_loss: 9.971025747290696e-07
      var_gnorm: 23.000452041625977
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.1591357633733423e-06
    num_steps_sampled: 8065000
    num_steps_trained: 8065000
    wait_time_ms: 66.563
  iterations_since_restore: 1613
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14142.74121761322
  time_this_iter_s: 8.067394256591797
  time_total_s: 14142.74121761322
  timestamp: 1594862700
  timesteps_since_restore: 8065000
  timesteps_this_iter: 5000
  timesteps_total: 8065000
  training_iteration: 1613
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14142 s, 1613 iter, 8065000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1613
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.502
    dispatch_time_ms: 6.068
    learner:
      cur_lr: 0.0008228709921240807
      grad_gnorm: 0.0036601622123271227
      policy_entropy: 0.007519945967942476
      policy_loss: 6.118258966125723e-08
      var_gnorm: 23.00048065185547
      vf_explained_var: 0.0
      vf_loss: 1.039434049943111e-08
    num_steps_sampled: 8070000
    num_steps_trained: 8070000
    wait_time_ms: 72.924
  iterations_since_restore: 1614
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14150.778644323349
  time_this_iter_s: 8.037426710128784
  time_total_s: 14150.778644323349
  timestamp: 1594862708
  timesteps_since_restore: 8070000
  timesteps_this_iter: 5000
  timesteps_total: 8070000
  training_iteration: 1614
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14150 s, 1614 iter, 8070000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1614
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.88
    dispatch_time_ms: 25.276
    learner:
      cur_lr: 0.0008225379860959947
      grad_gnorm: 0.03975984826683998
      policy_entropy: 0.007531573995947838
      policy_loss: 1.359740622319805e-06
      var_gnorm: 23.00050926208496
      vf_explained_var: 0.0
      vf_loss: 1.2232992503413698e-06
    num_steps_sampled: 8075000
    num_steps_trained: 8075000
    wait_time_ms: 60.328
  iterations_since_restore: 1615
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14159.076563835144
  time_this_iter_s: 8.297919511795044
  time_total_s: 14159.076563835144
  timestamp: 1594862717
  timesteps_since_restore: 8075000
  timesteps_this_iter: 5000
  timesteps_total: 8075000
  training_iteration: 1615
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14159 s, 1615 iter, 8075000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1615
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.409
    dispatch_time_ms: 38.534
    learner:
      cur_lr: 0.0008222049800679088
      grad_gnorm: 0.0009745783754624426
      policy_entropy: 0.007537103723734617
      policy_loss: 9.819777879727098e-09
      var_gnorm: 23.000539779663086
      vf_explained_var: 0.0
      vf_loss: 7.448126004838684e-10
    num_steps_sampled: 8080000
    num_steps_trained: 8080000
    wait_time_ms: 54.786
  iterations_since_restore: 1616
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14167.693963050842
  time_this_iter_s: 8.617399215698242
  time_total_s: 14167.693963050842
  timestamp: 1594862725
  timesteps_since_restore: 8080000
  timesteps_this_iter: 5000
  timesteps_total: 8080000
  training_iteration: 1616
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14167 s, 1616 iter, 8080000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1616
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.525
    dispatch_time_ms: 8.483
    learner:
      cur_lr: 0.0008218719740398228
      grad_gnorm: 0.015785837545990944
      policy_entropy: 0.007542807143181562
      policy_loss: 4.831967430618533e-07
      var_gnorm: 23.000572204589844
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.9314047960961034e-07
    num_steps_sampled: 8085000
    num_steps_trained: 8085000
    wait_time_ms: 69.27
  iterations_since_restore: 1617
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14175.64803814888
  time_this_iter_s: 7.95407509803772
  time_total_s: 14175.64803814888
  timestamp: 1594862733
  timesteps_since_restore: 8085000
  timesteps_this_iter: 5000
  timesteps_total: 8085000
  training_iteration: 1617
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14175 s, 1617 iter, 8085000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1617
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.778
    dispatch_time_ms: 7.966
    learner:
      cur_lr: 0.0008215390262193978
      grad_gnorm: 0.02087579295039177
      policy_entropy: 0.0075417920015752316
      policy_loss: -6.769384697236092e-08
      var_gnorm: 23.0006103515625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.377486166300514e-07
    num_steps_sampled: 8090000
    num_steps_trained: 8090000
    wait_time_ms: 69.668
  iterations_since_restore: 1618
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14183.784622907639
  time_this_iter_s: 8.136584758758545
  time_total_s: 14183.784622907639
  timestamp: 1594862741
  timesteps_since_restore: 8090000
  timesteps_this_iter: 5000
  timesteps_total: 8090000
  training_iteration: 1618
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14183 s, 1618 iter, 8090000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1618
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.023
    dispatch_time_ms: 9.157
    learner:
      cur_lr: 0.0008212060201913118
      grad_gnorm: 0.015303123742341995
      policy_entropy: 0.00754763325676322
      policy_loss: 5.21218396443146e-07
      var_gnorm: 23.000646591186523
      vf_explained_var: 0.0
      vf_loss: 1.8169181714711158e-07
    num_steps_sampled: 8095000
    num_steps_trained: 8095000
    wait_time_ms: 67.606
  iterations_since_restore: 1619
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14191.848486423492
  time_this_iter_s: 8.063863515853882
  time_total_s: 14191.848486423492
  timestamp: 1594862750
  timesteps_since_restore: 8095000
  timesteps_this_iter: 5000
  timesteps_total: 8095000
  training_iteration: 1619
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14191 s, 1619 iter, 8095000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-25-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1619
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 7.719
    learner:
      cur_lr: 0.0008208730141632259
      grad_gnorm: 0.012533348985016346
      policy_entropy: 0.007554178591817617
      policy_loss: -4.7196916597158634e-08
      var_gnorm: 23.00068473815918
      vf_explained_var: 0.0
      vf_loss: 1.2167780027994013e-07
    num_steps_sampled: 8100000
    num_steps_trained: 8100000
    wait_time_ms: 70.698
  iterations_since_restore: 1620
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14199.89819765091
  time_this_iter_s: 8.049711227416992
  time_total_s: 14199.89819765091
  timestamp: 1594862758
  timesteps_since_restore: 8100000
  timesteps_this_iter: 5000
  timesteps_total: 8100000
  training_iteration: 1620
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14199 s, 1620 iter, 8100000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1620
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.183
    dispatch_time_ms: 19.214
    learner:
      cur_lr: 0.0008205400081351399
      grad_gnorm: 8.296117782592773
      policy_entropy: 0.007561467122286558
      policy_loss: -5.143012458574958e-06
      var_gnorm: 23.000728607177734
      vf_explained_var: -1.3113021850585938e-06
      vf_loss: 0.0422419048845768
    num_steps_sampled: 8105000
    num_steps_trained: 8105000
    wait_time_ms: 14.492
  iterations_since_restore: 1621
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14212.285957098007
  time_this_iter_s: 12.387759447097778
  time_total_s: 14212.285957098007
  timestamp: 1594862770
  timesteps_since_restore: 8105000
  timesteps_this_iter: 5000
  timesteps_total: 8105000
  training_iteration: 1621
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14212 s, 1621 iter, 8105000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1621
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.039
    dispatch_time_ms: 27.318
    learner:
      cur_lr: 0.000820207002107054
      grad_gnorm: 0.016866400837898254
      policy_entropy: 0.007567955646663904
      policy_loss: -2.0294924851782525e-08
      var_gnorm: 23.000764846801758
      vf_explained_var: 0.0
      vf_loss: 1.8174570470819162e-07
    num_steps_sampled: 8110000
    num_steps_trained: 8110000
    wait_time_ms: 57.768
  iterations_since_restore: 1622
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14220.808108091354
  time_this_iter_s: 8.522150993347168
  time_total_s: 14220.808108091354
  timestamp: 1594862779
  timesteps_since_restore: 8110000
  timesteps_this_iter: 5000
  timesteps_total: 8110000
  training_iteration: 1622
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14220 s, 1622 iter, 8110000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1622
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.286
    dispatch_time_ms: 7.433
    learner:
      cur_lr: 0.000819873996078968
      grad_gnorm: 0.06930085271596909
      policy_entropy: 0.007575611118227243
      policy_loss: 3.387551998912386e-07
      var_gnorm: 23.000812530517578
      vf_explained_var: 0.0
      vf_loss: 3.7192889976722654e-06
    num_steps_sampled: 8115000
    num_steps_trained: 8115000
    wait_time_ms: 70.448
  iterations_since_restore: 1623
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14228.975335597992
  time_this_iter_s: 8.167227506637573
  time_total_s: 14228.975335597992
  timestamp: 1594862787
  timesteps_since_restore: 8115000
  timesteps_this_iter: 5000
  timesteps_total: 8115000
  training_iteration: 1623
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14228 s, 1623 iter, 8115000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1623
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.885
    dispatch_time_ms: 7.044
    learner:
      cur_lr: 0.0008195409900508821
      grad_gnorm: 0.0012216337490826845
      policy_entropy: 0.0075844512321054935
      policy_loss: 3.7121210549884154e-09
      var_gnorm: 23.000856399536133
      vf_explained_var: 0.0
      vf_loss: 1.163019458516601e-09
    num_steps_sampled: 8120000
    num_steps_trained: 8120000
    wait_time_ms: 75.589
  iterations_since_restore: 1624
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14237.100965976715
  time_this_iter_s: 8.125630378723145
  time_total_s: 14237.100965976715
  timestamp: 1594862795
  timesteps_since_restore: 8120000
  timesteps_this_iter: 5000
  timesteps_total: 8120000
  training_iteration: 1624
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14237 s, 1624 iter, 8120000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1624
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 41.815
    learner:
      cur_lr: 0.0008192079840227962
      grad_gnorm: 2.7530789375305176
      policy_entropy: 0.007599664386361837
      policy_loss: -1.5714035725977737e-06
      var_gnorm: 23.000904083251953
      vf_explained_var: 4.5299530029296875e-06
      vf_loss: 0.004651669412851334
    num_steps_sampled: 8125000
    num_steps_trained: 8125000
    wait_time_ms: 50.913
  iterations_since_restore: 1625
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14245.700487613678
  time_this_iter_s: 8.59952163696289
  time_total_s: 14245.700487613678
  timestamp: 1594862804
  timesteps_since_restore: 8125000
  timesteps_this_iter: 5000
  timesteps_total: 8125000
  training_iteration: 1625
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14245 s, 1625 iter, 8125000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-26-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1625
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.589
    dispatch_time_ms: 5.685
    learner:
      cur_lr: 0.0008188749779947102
      grad_gnorm: 0.10839488357305527
      policy_entropy: 0.00761076807975769
      policy_loss: 7.307098712772131e-07
      var_gnorm: 23.000974655151367
      vf_explained_var: 0.0
      vf_loss: 9.09989648789633e-06
    num_steps_sampled: 8130000
    num_steps_trained: 8130000
    wait_time_ms: 73.581
  iterations_since_restore: 1626
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14254.226853132248
  time_this_iter_s: 8.526365518569946
  time_total_s: 14254.226853132248
  timestamp: 1594862812
  timesteps_since_restore: 8130000
  timesteps_this_iter: 5000
  timesteps_total: 8130000
  training_iteration: 1626
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14254 s, 1626 iter, 8130000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1626
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.592
    dispatch_time_ms: 7.826
    learner:
      cur_lr: 0.0008185419719666243
      grad_gnorm: 0.0693708136677742
      policy_entropy: 0.0076209139078855515
      policy_loss: 4.3074334143966553e-07
      var_gnorm: 23.00102996826172
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.726667046066723e-06
    num_steps_sampled: 8135000
    num_steps_trained: 8135000
    wait_time_ms: 71.199
  iterations_since_restore: 1627
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14262.264442682266
  time_this_iter_s: 8.03758955001831
  time_total_s: 14262.264442682266
  timestamp: 1594862820
  timesteps_since_restore: 8135000
  timesteps_this_iter: 5000
  timesteps_total: 8135000
  training_iteration: 1627
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14262 s, 1627 iter, 8135000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1627
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.909
    dispatch_time_ms: 7.94
    learner:
      cur_lr: 0.0008182090241461992
      grad_gnorm: 0.013898690231144428
      policy_entropy: 0.0076316832564771175
      policy_loss: 5.037111350247869e-08
      var_gnorm: 23.0010929107666
      vf_explained_var: 0.0
      vf_loss: 1.4976430406932195e-07
    num_steps_sampled: 8140000
    num_steps_trained: 8140000
    wait_time_ms: 68.645
  iterations_since_restore: 1628
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14270.286505699158
  time_this_iter_s: 8.02206301689148
  time_total_s: 14270.286505699158
  timestamp: 1594862828
  timesteps_since_restore: 8140000
  timesteps_this_iter: 5000
  timesteps_total: 8140000
  training_iteration: 1628
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14270 s, 1628 iter, 8140000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1628
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.574
    dispatch_time_ms: 6.43
    learner:
      cur_lr: 0.0008178760181181133
      grad_gnorm: 0.05842689424753189
      policy_entropy: 0.007643044926226139
      policy_loss: 5.199183306103805e-07
      var_gnorm: 23.00115394592285
      vf_explained_var: 0.0
      vf_loss: 2.643322204676224e-06
    num_steps_sampled: 8145000
    num_steps_trained: 8145000
    wait_time_ms: 72.499
  iterations_since_restore: 1629
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14278.35888171196
  time_this_iter_s: 8.072376012802124
  time_total_s: 14278.35888171196
  timestamp: 1594862836
  timesteps_since_restore: 8145000
  timesteps_this_iter: 5000
  timesteps_total: 8145000
  training_iteration: 1629
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14278 s, 1629 iter, 8145000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1629
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.398
    dispatch_time_ms: 6.502
    learner:
      cur_lr: 0.0008175430120900273
      grad_gnorm: 0.011128627695143223
      policy_entropy: 0.007654315792024136
      policy_loss: 4.646733131608016e-08
      var_gnorm: 23.001224517822266
      vf_explained_var: 0.0
      vf_loss: 9.599796157999663e-08
    num_steps_sampled: 8150000
    num_steps_trained: 8150000
    wait_time_ms: 71.11
  iterations_since_restore: 1630
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14286.421578884125
  time_this_iter_s: 8.062697172164917
  time_total_s: 14286.421578884125
  timestamp: 1594862845
  timesteps_since_restore: 8150000
  timesteps_this_iter: 5000
  timesteps_total: 8150000
  training_iteration: 1630
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14286 s, 1630 iter, 8150000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1630
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 6.583
    learner:
      cur_lr: 0.0008172100060619414
      grad_gnorm: 0.07857804000377655
      policy_entropy: 0.00767199182882905
      policy_loss: 2.436513284465036e-07
      var_gnorm: 23.00129508972168
      vf_explained_var: 0.0
      vf_loss: 4.781598363479134e-06
    num_steps_sampled: 8155000
    num_steps_trained: 8155000
    wait_time_ms: 69.623
  iterations_since_restore: 1631
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14294.473055124283
  time_this_iter_s: 8.051476240158081
  time_total_s: 14294.473055124283
  timestamp: 1594862853
  timesteps_since_restore: 8155000
  timesteps_this_iter: 5000
  timesteps_total: 8155000
  training_iteration: 1631
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14294 s, 1631 iter, 8155000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1631
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.216
    dispatch_time_ms: 8.338
    learner:
      cur_lr: 0.0008168770000338554
      grad_gnorm: 0.0017684822669252753
      policy_entropy: 0.0076847379095852375
      policy_loss: 3.84861493785138e-08
      var_gnorm: 23.001375198364258
      vf_explained_var: 0.0
      vf_loss: 2.426669976074436e-09
    num_steps_sampled: 8160000
    num_steps_trained: 8160000
    wait_time_ms: 67.994
  iterations_since_restore: 1632
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14302.552567243576
  time_this_iter_s: 8.079512119293213
  time_total_s: 14302.552567243576
  timestamp: 1594862861
  timesteps_since_restore: 8160000
  timesteps_this_iter: 5000
  timesteps_total: 8160000
  training_iteration: 1632
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14302 s, 1632 iter, 8160000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1632
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.78
    dispatch_time_ms: 8.177
    learner:
      cur_lr: 0.0008165439940057695
      grad_gnorm: 0.0644431784749031
      policy_entropy: 0.007697837892919779
      policy_loss: 4.2789662302311626e-07
      var_gnorm: 23.001455307006836
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 3.2165171433007345e-06
    num_steps_sampled: 8165000
    num_steps_trained: 8165000
    wait_time_ms: 69.603
  iterations_since_restore: 1633
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14310.606865644455
  time_this_iter_s: 8.054298400878906
  time_total_s: 14310.606865644455
  timestamp: 1594862869
  timesteps_since_restore: 8165000
  timesteps_this_iter: 5000
  timesteps_total: 8165000
  training_iteration: 1633
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14310 s, 1633 iter, 8165000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-27-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1633
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.061
    dispatch_time_ms: 8.884
    learner:
      cur_lr: 0.0008162109879776835
      grad_gnorm: 0.009836371056735516
      policy_entropy: 0.007712517399340868
      policy_loss: -5.329566121758944e-09
      var_gnorm: 23.001543045043945
      vf_explained_var: 0.0
      vf_loss: 7.496788612115779e-08
    num_steps_sampled: 8170000
    num_steps_trained: 8170000
    wait_time_ms: 67.792
  iterations_since_restore: 1634
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14318.719197034836
  time_this_iter_s: 8.11233139038086
  time_total_s: 14318.719197034836
  timestamp: 1594862877
  timesteps_since_restore: 8170000
  timesteps_this_iter: 5000
  timesteps_total: 8170000
  training_iteration: 1634
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14318 s, 1634 iter, 8170000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1634
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.829
    dispatch_time_ms: 5.72
    learner:
      cur_lr: 0.0008158779819495976
      grad_gnorm: 0.005362859461456537
      policy_entropy: 0.007733691483736038
      policy_loss: 7.475709935533814e-07
      var_gnorm: 23.001628875732422
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.2271892774483604e-08
    num_steps_sampled: 8175000
    num_steps_trained: 8175000
    wait_time_ms: 70.918
  iterations_since_restore: 1635
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14326.72632932663
  time_this_iter_s: 8.007132291793823
  time_total_s: 14326.72632932663
  timestamp: 1594862885
  timesteps_since_restore: 8175000
  timesteps_this_iter: 5000
  timesteps_total: 8175000
  training_iteration: 1635
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14326 s, 1635 iter, 8175000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1635
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.551
    dispatch_time_ms: 8.896
    learner:
      cur_lr: 0.0008155449759215117
      grad_gnorm: 0.01706738770008087
      policy_entropy: 0.007768177893012762
      policy_loss: -4.2788521170677996e-08
      var_gnorm: 23.00171661376953
      vf_explained_var: 0.0
      vf_loss: 2.252646140732395e-07
    num_steps_sampled: 8180000
    num_steps_trained: 8180000
    wait_time_ms: 69.602
  iterations_since_restore: 1636
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14334.7854616642
  time_this_iter_s: 8.05913233757019
  time_total_s: 14334.7854616642
  timestamp: 1594862893
  timesteps_since_restore: 8180000
  timesteps_this_iter: 5000
  timesteps_total: 8180000
  training_iteration: 1636
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14334 s, 1636 iter, 8180000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1636
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.164
    dispatch_time_ms: 8.161
    learner:
      cur_lr: 0.0008152120281010866
      grad_gnorm: 0.018441233783960342
      policy_entropy: 0.007789209950715303
      policy_loss: 3.5061631820099137e-07
      var_gnorm: 23.001815795898438
      vf_explained_var: 0.0
      vf_loss: 2.6344679326939513e-07
    num_steps_sampled: 8185000
    num_steps_trained: 8185000
    wait_time_ms: 69.947
  iterations_since_restore: 1637
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14342.860783815384
  time_this_iter_s: 8.075322151184082
  time_total_s: 14342.860783815384
  timestamp: 1594862901
  timesteps_since_restore: 8185000
  timesteps_this_iter: 5000
  timesteps_total: 8185000
  training_iteration: 1637
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14342 s, 1637 iter, 8185000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1637
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.013
    dispatch_time_ms: 8.853
    learner:
      cur_lr: 0.0008148790220730007
      grad_gnorm: 0.018195003271102905
      policy_entropy: 0.007814832031726837
      policy_loss: -6.425124610132116e-08
      var_gnorm: 23.001924514770508
      vf_explained_var: 0.0
      vf_loss: 2.5638860279286746e-07
    num_steps_sampled: 8190000
    num_steps_trained: 8190000
    wait_time_ms: 70.625
  iterations_since_restore: 1638
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14350.96855044365
  time_this_iter_s: 8.10776662826538
  time_total_s: 14350.96855044365
  timestamp: 1594862909
  timesteps_since_restore: 8190000
  timesteps_this_iter: 5000
  timesteps_total: 8190000
  training_iteration: 1638
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14350 s, 1638 iter, 8190000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1638
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.27
    dispatch_time_ms: 10.897
    learner:
      cur_lr: 0.0008145460160449147
      grad_gnorm: 0.0282088965177536
      policy_entropy: 0.007833709940314293
      policy_loss: 2.557225968757848e-07
      var_gnorm: 23.002038955688477
      vf_explained_var: 0.0
      vf_loss: 6.160497036944435e-07
    num_steps_sampled: 8195000
    num_steps_trained: 8195000
    wait_time_ms: 66.863
  iterations_since_restore: 1639
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14358.97851395607
  time_this_iter_s: 8.009963512420654
  time_total_s: 14358.97851395607
  timestamp: 1594862917
  timesteps_since_restore: 8195000
  timesteps_this_iter: 5000
  timesteps_total: 8195000
  training_iteration: 1639
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14358 s, 1639 iter, 8195000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1639
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.772
    dispatch_time_ms: 7.584
    learner:
      cur_lr: 0.0008142130100168288
      grad_gnorm: 0.007380285765975714
      policy_entropy: 0.007853846997022629
      policy_loss: -1.465040497805603e-07
      var_gnorm: 23.002166748046875
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 4.198238556796241e-08
    num_steps_sampled: 8200000
    num_steps_trained: 8200000
    wait_time_ms: 68.596
  iterations_since_restore: 1640
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14367.053975820541
  time_this_iter_s: 8.075461864471436
  time_total_s: 14367.053975820541
  timestamp: 1594862925
  timesteps_since_restore: 8200000
  timesteps_this_iter: 5000
  timesteps_total: 8200000
  training_iteration: 1640
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14367 s, 1640 iter, 8200000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-28-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1640
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.946
    dispatch_time_ms: 9.141
    learner:
      cur_lr: 0.0008138800039887428
      grad_gnorm: 0.029856504872441292
      policy_entropy: 0.00788108166307211
      policy_loss: 1.0281946742907166e-06
      var_gnorm: 23.002294540405273
      vf_explained_var: 0.0
      vf_loss: 6.908218210810446e-07
    num_steps_sampled: 8205000
    num_steps_trained: 8205000
    wait_time_ms: 69.586
  iterations_since_restore: 1641
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14375.07997584343
  time_this_iter_s: 8.026000022888184
  time_total_s: 14375.07997584343
  timestamp: 1594862934
  timesteps_since_restore: 8205000
  timesteps_this_iter: 5000
  timesteps_total: 8205000
  training_iteration: 1641
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14375 s, 1641 iter, 8205000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1641
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.657
    dispatch_time_ms: 7.457
    learner:
      cur_lr: 0.0008135469979606569
      grad_gnorm: 0.0060729412361979485
      policy_entropy: 0.007903559133410454
      policy_loss: -5.5382024299888144e-08
      var_gnorm: 23.0024356842041
      vf_explained_var: 0.0
      vf_loss: 2.851310298979115e-08
    num_steps_sampled: 8210000
    num_steps_trained: 8210000
    wait_time_ms: 71.163
  iterations_since_restore: 1642
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14383.156918287277
  time_this_iter_s: 8.076942443847656
  time_total_s: 14383.156918287277
  timestamp: 1594862942
  timesteps_since_restore: 8210000
  timesteps_this_iter: 5000
  timesteps_total: 8210000
  training_iteration: 1642
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14383 s, 1642 iter, 8210000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1642
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 6.845
    learner:
      cur_lr: 0.0008132139919325709
      grad_gnorm: 0.06490658223628998
      policy_entropy: 0.007932913489639759
      policy_loss: -2.0892638019631704e-07
      var_gnorm: 23.002586364746094
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 3.2626894608256407e-06
    num_steps_sampled: 8215000
    num_steps_trained: 8215000
    wait_time_ms: 70.988
  iterations_since_restore: 1643
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14391.252791166306
  time_this_iter_s: 8.09587287902832
  time_total_s: 14391.252791166306
  timestamp: 1594862950
  timesteps_since_restore: 8215000
  timesteps_this_iter: 5000
  timesteps_total: 8215000
  training_iteration: 1643
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14391 s, 1643 iter, 8215000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1643
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.455
    dispatch_time_ms: 7.861
    learner:
      cur_lr: 0.000812880985904485
      grad_gnorm: 0.011593995615839958
      policy_entropy: 0.007949449121952057
      policy_loss: 1.8733722129127273e-08
      var_gnorm: 23.00275230407715
      vf_explained_var: 0.0
      vf_loss: 1.0419066853728509e-07
    num_steps_sampled: 8220000
    num_steps_trained: 8220000
    wait_time_ms: 69.907
  iterations_since_restore: 1644
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14399.354357242584
  time_this_iter_s: 8.101566076278687
  time_total_s: 14399.354357242584
  timestamp: 1594862958
  timesteps_since_restore: 8220000
  timesteps_this_iter: 5000
  timesteps_total: 8220000
  training_iteration: 1644
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14399 s, 1644 iter, 8220000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-29-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1644
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.629
    dispatch_time_ms: 9.22
    learner:
      cur_lr: 0.000812547979876399
      grad_gnorm: 0.07100892812013626
      policy_entropy: 0.007975118234753609
      policy_loss: -2.2856916359614843e-07
      var_gnorm: 23.00292205810547
      vf_explained_var: 0.0
      vf_loss: 3.905576704710256e-06
    num_steps_sampled: 8225000
    num_steps_trained: 8225000
    wait_time_ms: 68.529
  iterations_since_restore: 1645
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14407.38586640358
  time_this_iter_s: 8.031509160995483
  time_total_s: 14407.38586640358
  timestamp: 1594862966
  timesteps_since_restore: 8225000
  timesteps_this_iter: 5000
  timesteps_total: 8225000
  training_iteration: 1645
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14407 s, 1645 iter, 8225000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1645
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 8.275
    learner:
      cur_lr: 0.0008122149738483131
      grad_gnorm: 0.014994594268500805
      policy_entropy: 0.008009743876755238
      policy_loss: 2.619079850774142e-07
      var_gnorm: 23.003114700317383
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.7406746621873026e-07
    num_steps_sampled: 8230000
    num_steps_trained: 8230000
    wait_time_ms: 69.422
  iterations_since_restore: 1646
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14452.073067426682
  time_this_iter_s: 44.68720102310181
  time_total_s: 14452.073067426682
  timestamp: 1594863011
  timesteps_since_restore: 8230000
  timesteps_this_iter: 5000
  timesteps_total: 8230000
  training_iteration: 1646
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14452 s, 1646 iter, 8230000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1646
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.612
    dispatch_time_ms: 5.715
    learner:
      cur_lr: 0.0008118820260278881
      grad_gnorm: 0.14310282468795776
      policy_entropy: 0.00803894829005003
      policy_loss: 3.926356839656364e-07
      var_gnorm: 23.003311157226562
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.5861365682212636e-05
    num_steps_sampled: 8235000
    num_steps_trained: 8235000
    wait_time_ms: 75.576
  iterations_since_restore: 1647
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14460.20227265358
  time_this_iter_s: 8.129205226898193
  time_total_s: 14460.20227265358
  timestamp: 1594863019
  timesteps_since_restore: 8235000
  timesteps_this_iter: 5000
  timesteps_total: 8235000
  training_iteration: 1647
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14460 s, 1647 iter, 8235000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1647
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.443
    dispatch_time_ms: 14.06
    learner:
      cur_lr: 0.0008115490199998021
      grad_gnorm: 0.004287602845579386
      policy_entropy: 0.008075959049165249
      policy_loss: 7.718849559523733e-08
      var_gnorm: 23.00352668762207
      vf_explained_var: 0.0
      vf_loss: 1.0043203957366131e-07
    num_steps_sampled: 8240000
    num_steps_trained: 8240000
    wait_time_ms: 78.616
  iterations_since_restore: 1648
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14468.4445977211
  time_this_iter_s: 8.242325067520142
  time_total_s: 14468.4445977211
  timestamp: 1594863027
  timesteps_since_restore: 8240000
  timesteps_this_iter: 5000
  timesteps_total: 8240000
  training_iteration: 1648
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14468 s, 1648 iter, 8240000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1648
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.722
    dispatch_time_ms: 32.135
    learner:
      cur_lr: 0.0008112160139717162
      grad_gnorm: 4.939661026000977
      policy_entropy: 0.00810952764004469
      policy_loss: 4.56182624475332e-06
      var_gnorm: 23.00375747680664
      vf_explained_var: 0.0
      vf_loss: 0.014997133985161781
    num_steps_sampled: 8245000
    num_steps_trained: 8245000
    wait_time_ms: 51.007
  iterations_since_restore: 1649
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14476.907821655273
  time_this_iter_s: 8.463223934173584
  time_total_s: 14476.907821655273
  timestamp: 1594863036
  timesteps_since_restore: 8245000
  timesteps_this_iter: 5000
  timesteps_total: 8245000
  training_iteration: 1649
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14476 s, 1649 iter, 8245000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-30-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1649
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.844
    dispatch_time_ms: 29.422
    learner:
      cur_lr: 0.0008108830079436302
      grad_gnorm: 1.8520567417144775
      policy_entropy: 0.008148523978888988
      policy_loss: 2.8369639039738104e-05
      var_gnorm: 23.004030227661133
      vf_explained_var: 0.0
      vf_loss: 0.0026565054431557655
    num_steps_sampled: 8250000
    num_steps_trained: 8250000
    wait_time_ms: 43.531
  iterations_since_restore: 1650
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14495.939284324646
  time_this_iter_s: 19.03146266937256
  time_total_s: 14495.939284324646
  timestamp: 1594863055
  timesteps_since_restore: 8250000
  timesteps_this_iter: 5000
  timesteps_total: 8250000
  training_iteration: 1650
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14495 s, 1650 iter, 8250000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1650
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.478
    dispatch_time_ms: 25.266
    learner:
      cur_lr: 0.0008105500019155443
      grad_gnorm: 0.09609194844961166
      policy_entropy: 0.008210026659071445
      policy_loss: -1.925968717841897e-06
      var_gnorm: 23.004337310791016
      vf_explained_var: 0.0
      vf_loss: 7.149596513045253e-06
    num_steps_sampled: 8255000
    num_steps_trained: 8255000
    wait_time_ms: 62.302
  iterations_since_restore: 1651
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14504.562837600708
  time_this_iter_s: 8.623553276062012
  time_total_s: 14504.562837600708
  timestamp: 1594863063
  timesteps_since_restore: 8255000
  timesteps_this_iter: 5000
  timesteps_total: 8255000
  training_iteration: 1651
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14504 s, 1651 iter, 8255000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1651
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.794
    dispatch_time_ms: 27.075
    learner:
      cur_lr: 0.0008102169958874583
      grad_gnorm: 0.0020167178008705378
      policy_entropy: 0.00825282372534275
      policy_loss: 1.753152112371481e-08
      var_gnorm: 23.004655838012695
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 3.078825860924894e-09
    num_steps_sampled: 8260000
    num_steps_trained: 8260000
    wait_time_ms: 64.165
  iterations_since_restore: 1652
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14513.198199033737
  time_this_iter_s: 8.635361433029175
  time_total_s: 14513.198199033737
  timestamp: 1594863072
  timesteps_since_restore: 8260000
  timesteps_this_iter: 5000
  timesteps_total: 8260000
  training_iteration: 1652
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14513 s, 1652 iter, 8260000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1652
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.615
    dispatch_time_ms: 21.339
    learner:
      cur_lr: 0.0008098839898593724
      grad_gnorm: 0.004153143148869276
      policy_entropy: 0.008301204070448875
      policy_loss: 4.4821254618909734e-07
      var_gnorm: 23.004976272583008
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.3356045158730012e-08
    num_steps_sampled: 8265000
    num_steps_trained: 8265000
    wait_time_ms: 65.654
  iterations_since_restore: 1653
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14521.75379037857
  time_this_iter_s: 8.555591344833374
  time_total_s: 14521.75379037857
  timestamp: 1594863081
  timesteps_since_restore: 8265000
  timesteps_this_iter: 5000
  timesteps_total: 8265000
  training_iteration: 1653
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14521 s, 1653 iter, 8265000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1653
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.926
    dispatch_time_ms: 31.236
    learner:
      cur_lr: 0.0008095509838312864
      grad_gnorm: 0.0008137279073707759
      policy_entropy: 0.008352747187018394
      policy_loss: 1.6413123304914734e-08
      var_gnorm: 23.00535011291504
      vf_explained_var: 0.0
      vf_loss: 5.16400422423402e-10
    num_steps_sampled: 8270000
    num_steps_trained: 8270000
    wait_time_ms: 52.072
  iterations_since_restore: 1654
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14530.297839403152
  time_this_iter_s: 8.54404902458191
  time_total_s: 14530.297839403152
  timestamp: 1594863089
  timesteps_since_restore: 8270000
  timesteps_this_iter: 5000
  timesteps_total: 8270000
  training_iteration: 1654
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14530 s, 1654 iter, 8270000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1654
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.695
    dispatch_time_ms: 44.94
    learner:
      cur_lr: 0.0008092179778032005
      grad_gnorm: 10.806133270263672
      policy_entropy: 0.008407169952988625
      policy_loss: -2.2256126612774096e-05
      var_gnorm: 23.0057430267334
      vf_explained_var: 7.748603820800781e-07
      vf_loss: 0.0716797485947609
    num_steps_sampled: 8275000
    num_steps_trained: 8275000
    wait_time_ms: 45.207
  iterations_since_restore: 1655
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14539.26159787178
  time_this_iter_s: 8.96375846862793
  time_total_s: 14539.26159787178
  timestamp: 1594863098
  timesteps_since_restore: 8275000
  timesteps_this_iter: 5000
  timesteps_total: 8275000
  training_iteration: 1655
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14539 s, 1655 iter, 8275000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1655
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.941
    dispatch_time_ms: 37.48
    learner:
      cur_lr: 0.0008088849717751145
      grad_gnorm: 0.22849830985069275
      policy_entropy: 0.008481873199343681
      policy_loss: 2.0770132778125117e-06
      var_gnorm: 23.00635528564453
      vf_explained_var: 0.0
      vf_loss: 4.043917579110712e-05
    num_steps_sampled: 8280000
    num_steps_trained: 8280000
    wait_time_ms: 50.122
  iterations_since_restore: 1656
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14547.434195756912
  time_this_iter_s: 8.172597885131836
  time_total_s: 14547.434195756912
  timestamp: 1594863106
  timesteps_since_restore: 8280000
  timesteps_this_iter: 5000
  timesteps_total: 8280000
  training_iteration: 1656
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14547 s, 1656 iter, 8280000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-31-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1656
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.754
    dispatch_time_ms: 29.752
    learner:
      cur_lr: 0.0008085520239546895
      grad_gnorm: 0.021924758329987526
      policy_entropy: 0.008538699708878994
      policy_loss: -4.858815145780682e-07
      var_gnorm: 23.0068302154541
      vf_explained_var: 0.0
      vf_loss: 3.720210486335418e-07
    num_steps_sampled: 8285000
    num_steps_trained: 8285000
    wait_time_ms: 41.499
  iterations_since_restore: 1657
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14556.069489955902
  time_this_iter_s: 8.635294198989868
  time_total_s: 14556.069489955902
  timestamp: 1594863115
  timesteps_since_restore: 8285000
  timesteps_this_iter: 5000
  timesteps_total: 8285000
  training_iteration: 1657
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14556 s, 1657 iter, 8285000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1657
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.082
    dispatch_time_ms: 26.507
    learner:
      cur_lr: 0.0008082190179266036
      grad_gnorm: 0.012714949436485767
      policy_entropy: 0.008601951412856579
      policy_loss: 6.040767175363726e-08
      var_gnorm: 23.007396697998047
      vf_explained_var: 0.0
      vf_loss: 1.2495858925376524e-07
    num_steps_sampled: 8290000
    num_steps_trained: 8290000
    wait_time_ms: 52.938
  iterations_since_restore: 1658
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14564.429682970047
  time_this_iter_s: 8.360193014144897
  time_total_s: 14564.429682970047
  timestamp: 1594863124
  timesteps_since_restore: 8290000
  timesteps_this_iter: 5000
  timesteps_total: 8290000
  training_iteration: 1658
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14564 s, 1658 iter, 8290000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1658
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.923
    dispatch_time_ms: 38.254
    learner:
      cur_lr: 0.0008078860118985176
      grad_gnorm: 0.006748265121132135
      policy_entropy: 0.008670546114444733
      policy_loss: 3.7066590152790013e-07
      var_gnorm: 23.008014678955078
      vf_explained_var: 0.0
      vf_loss: 1.1463761211416568e-06
    num_steps_sampled: 8295000
    num_steps_trained: 8295000
    wait_time_ms: 48.089
  iterations_since_restore: 1659
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14572.895843744278
  time_this_iter_s: 8.466160774230957
  time_total_s: 14572.895843744278
  timestamp: 1594863132
  timesteps_since_restore: 8295000
  timesteps_this_iter: 5000
  timesteps_total: 8295000
  training_iteration: 1659
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14572 s, 1659 iter, 8295000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1659
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.908
    dispatch_time_ms: 22.579
    learner:
      cur_lr: 0.0008075530058704317
      grad_gnorm: 0.0007483594818040729
      policy_entropy: 0.008741922676563263
      policy_loss: 1.4126213976339841e-08
      var_gnorm: 23.008739471435547
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.3068240640486977e-10
    num_steps_sampled: 8300000
    num_steps_trained: 8300000
    wait_time_ms: 61.024
  iterations_since_restore: 1660
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14581.366272449493
  time_this_iter_s: 8.470428705215454
  time_total_s: 14581.366272449493
  timestamp: 1594863141
  timesteps_since_restore: 8300000
  timesteps_this_iter: 5000
  timesteps_total: 8300000
  training_iteration: 1660
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14581 s, 1660 iter, 8300000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1660
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.241
    dispatch_time_ms: 6.017
    learner:
      cur_lr: 0.0008072199998423457
      grad_gnorm: 0.016869235783815384
      policy_entropy: 0.008819140493869781
      policy_loss: 8.239039317459174e-08
      var_gnorm: 23.00954246520996
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.2045108494239685e-07
    num_steps_sampled: 8305000
    num_steps_trained: 8305000
    wait_time_ms: 73.474
  iterations_since_restore: 1661
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14589.795380115509
  time_this_iter_s: 8.429107666015625
  time_total_s: 14589.795380115509
  timestamp: 1594863149
  timesteps_since_restore: 8305000
  timesteps_this_iter: 5000
  timesteps_total: 8305000
  training_iteration: 1661
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14589 s, 1661 iter, 8305000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1661
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.503
    dispatch_time_ms: 6.362
    learner:
      cur_lr: 0.0008068869938142598
      grad_gnorm: 0.0018116999417543411
      policy_entropy: 0.008900689892470837
      policy_loss: -8.819931451853336e-09
      var_gnorm: 23.010496139526367
      vf_explained_var: 0.0
      vf_loss: 2.5600106479117812e-09
    num_steps_sampled: 8310000
    num_steps_trained: 8310000
    wait_time_ms: 69.078
  iterations_since_restore: 1662
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14597.828835964203
  time_this_iter_s: 8.033455848693848
  time_total_s: 14597.828835964203
  timestamp: 1594863157
  timesteps_since_restore: 8310000
  timesteps_this_iter: 5000
  timesteps_total: 8310000
  training_iteration: 1662
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14597 s, 1662 iter, 8310000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1662
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.682
    dispatch_time_ms: 10.489
    learner:
      cur_lr: 0.0008065539877861738
      grad_gnorm: 0.08572884649038315
      policy_entropy: 0.008987609297037125
      policy_loss: 3.554908687419811e-07
      var_gnorm: 23.011581420898438
      vf_explained_var: 0.0
      vf_loss: 5.692170361726312e-06
    num_steps_sampled: 8315000
    num_steps_trained: 8315000
    wait_time_ms: 69.437
  iterations_since_restore: 1663
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14605.92314863205
  time_this_iter_s: 8.09431266784668
  time_total_s: 14605.92314863205
  timestamp: 1594863165
  timesteps_since_restore: 8315000
  timesteps_this_iter: 5000
  timesteps_total: 8315000
  training_iteration: 1663
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14605 s, 1663 iter, 8315000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-32-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1663
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.451
    dispatch_time_ms: 9.001
    learner:
      cur_lr: 0.0008062209817580879
      grad_gnorm: 0.004575574770569801
      policy_entropy: 0.009086152538657188
      policy_loss: 1.5161091937443416e-08
      var_gnorm: 23.012914657592773
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 1.6175400574525156e-08
    num_steps_sampled: 8320000
    num_steps_trained: 8320000
    wait_time_ms: 69.949
  iterations_since_restore: 1664
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14614.019038915634
  time_this_iter_s: 8.095890283584595
  time_total_s: 14614.019038915634
  timestamp: 1594863173
  timesteps_since_restore: 8320000
  timesteps_this_iter: 5000
  timesteps_total: 8320000
  training_iteration: 1664
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14614 s, 1664 iter, 8320000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1664
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 7.426
    learner:
      cur_lr: 0.0008058879757300019
      grad_gnorm: 0.08564403653144836
      policy_entropy: 0.009186439216136932
      policy_loss: 3.7246670103741053e-07
      var_gnorm: 23.01449966430664
      vf_explained_var: 0.0
      vf_loss: 5.679587047779933e-06
    num_steps_sampled: 8325000
    num_steps_trained: 8325000
    wait_time_ms: 71.877
  iterations_since_restore: 1665
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14622.12471318245
  time_this_iter_s: 8.105674266815186
  time_total_s: 14622.12471318245
  timestamp: 1594863181
  timesteps_since_restore: 8325000
  timesteps_this_iter: 5000
  timesteps_total: 8325000
  training_iteration: 1665
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14622 s, 1665 iter, 8325000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1665
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.521
    dispatch_time_ms: 6.066
    learner:
      cur_lr: 0.0008055550279095769
      grad_gnorm: 0.00681186281144619
      policy_entropy: 0.009298913180828094
      policy_loss: 2.4488135963451896e-08
      var_gnorm: 23.01654624938965
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 3.5880020732292905e-08
    num_steps_sampled: 8330000
    num_steps_trained: 8330000
    wait_time_ms: 74.262
  iterations_since_restore: 1666
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14630.23901629448
  time_this_iter_s: 8.11430311203003
  time_total_s: 14630.23901629448
  timestamp: 1594863190
  timesteps_since_restore: 8330000
  timesteps_this_iter: 5000
  timesteps_total: 8330000
  training_iteration: 1666
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14630 s, 1666 iter, 8330000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1666
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.686
    dispatch_time_ms: 7.789
    learner:
      cur_lr: 0.000805222021881491
      grad_gnorm: 0.08398809283971786
      policy_entropy: 0.0094212731346488
      policy_loss: 4.496174028645328e-07
      var_gnorm: 23.019189834594727
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 5.464657533593709e-06
    num_steps_sampled: 8335000
    num_steps_trained: 8335000
    wait_time_ms: 72.591
  iterations_since_restore: 1667
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14638.360759973526
  time_this_iter_s: 8.12174367904663
  time_total_s: 14638.360759973526
  timestamp: 1594863198
  timesteps_since_restore: 8335000
  timesteps_this_iter: 5000
  timesteps_total: 8335000
  training_iteration: 1667
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14638 s, 1667 iter, 8335000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1667
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.041
    dispatch_time_ms: 8.486
    learner:
      cur_lr: 0.000804889015853405
      grad_gnorm: 0.008992507122457027
      policy_entropy: 0.009554257616400719
      policy_loss: 4.0677978319081376e-08
      var_gnorm: 23.023040771484375
      vf_explained_var: 0.0
      vf_loss: 6.258846951823216e-08
    num_steps_sampled: 8340000
    num_steps_trained: 8340000
    wait_time_ms: 69.58
  iterations_since_restore: 1668
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14646.386656999588
  time_this_iter_s: 8.025897026062012
  time_total_s: 14646.386656999588
  timestamp: 1594863206
  timesteps_since_restore: 8340000
  timesteps_this_iter: 5000
  timesteps_total: 8340000
  training_iteration: 1668
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14646 s, 1668 iter, 8340000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1668
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.276
    dispatch_time_ms: 9.428
    learner:
      cur_lr: 0.000804556009825319
      grad_gnorm: 0.08063839375972748
      policy_entropy: 0.009707106277346611
      policy_loss: 7.826888008821697e-07
      var_gnorm: 23.029212951660156
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.036272796132835e-06
    num_steps_sampled: 8345000
    num_steps_trained: 8345000
    wait_time_ms: 69.696
  iterations_since_restore: 1669
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14654.483261823654
  time_this_iter_s: 8.096604824066162
  time_total_s: 14654.483261823654
  timestamp: 1594863214
  timesteps_since_restore: 8345000
  timesteps_this_iter: 5000
  timesteps_total: 8345000
  training_iteration: 1669
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14654 s, 1669 iter, 8345000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1669
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.654
    dispatch_time_ms: 7.502
    learner:
      cur_lr: 0.0008042230037972331
      grad_gnorm: 0.007324391510337591
      policy_entropy: 0.009954993613064289
      policy_loss: 3.935890902084793e-08
      var_gnorm: 23.044227600097656
      vf_explained_var: 0.0
      vf_loss: 4.1685566998239665e-08
    num_steps_sampled: 8350000
    num_steps_trained: 8350000
    wait_time_ms: 71.796
  iterations_since_restore: 1670
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14662.68024635315
  time_this_iter_s: 8.19698452949524
  time_total_s: 14662.68024635315
  timestamp: 1594863222
  timesteps_since_restore: 8350000
  timesteps_this_iter: 5000
  timesteps_total: 8350000
  training_iteration: 1670
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14662 s, 1670 iter, 8350000 ts, 7.9 rew

agent-1: 0.0
agent-2: 0.0
agent-3: 0.0
agent-4: 0.0
agent-5: 0.0
Extrinsic Rewards:
0
0
0
0
0
Sum Reward: 0
Avg Reward: 0.0
Min Reward: 0
Max Reward: 0
Gini Coefficient: nan
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 7.8995237259373035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1670
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.789
    dispatch_time_ms: 10.077
    learner:
      cur_lr: 0.0008038899977691472
      grad_gnorm: 40.00000762939453
      policy_entropy: 33.32021713256836
      policy_loss: 72.86583709716797
      var_gnorm: 23.295663833618164
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 168.05758666992188
    num_steps_sampled: 8355000
    num_steps_trained: 8355000
    wait_time_ms: 71.895
  iterations_since_restore: 1671
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14670.744858026505
  time_this_iter_s: 8.064611673355103
  time_total_s: 14670.744858026505
  timestamp: 1594863230
  timesteps_since_restore: 8355000
  timesteps_this_iter: 5000
  timesteps_total: 8355000
  training_iteration: 1671
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14670 s, 1671 iter, 8355000 ts, 7.9 rew

agent-1: 40.55472288456107
agent-2: 44.554722884561066
agent-3: 41.55472288456108
agent-4: 46.55472288456106
agent-5: 39.55472288456107
Extrinsic Rewards:
3
7
4
9
2
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.288
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-33-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 10.027259870165357
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1671
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.115
    dispatch_time_ms: 8.219
    learner:
      cur_lr: 0.0008035569917410612
      grad_gnorm: 40.0
      policy_entropy: 12.6414155960083
      policy_loss: -4.7973313331604
      var_gnorm: 23.30813980102539
      vf_explained_var: 0.0
      vf_loss: 3.1070170402526855
    num_steps_sampled: 8360000
    num_steps_trained: 8360000
    wait_time_ms: 74.739
  iterations_since_restore: 1672
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14679.324605226517
  time_this_iter_s: 8.579747200012207
  time_total_s: 14679.324605226517
  timestamp: 1594863239
  timesteps_since_restore: 8360000
  timesteps_this_iter: 5000
  timesteps_total: 8360000
  training_iteration: 1672
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14679 s, 1672 iter, 8360000 ts, 10 rew

agent-1: 47.79999979429036
agent-2: 53.799999794290365
agent-3: 53.799999794290365
agent-4: 45.79999979429034
agent-5: 50.79999979429037
Extrinsic Rewards:
3
9
9
1
6
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3142857142857143
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 395.9997475567983
  episode_reward_mean: 12.547259859879894
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1672
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.708
    dispatch_time_ms: 7.424
    learner:
      cur_lr: 0.0008032239857129753
      grad_gnorm: 40.000003814697266
      policy_entropy: 14.077024459838867
      policy_loss: -3.2244017124176025
      var_gnorm: 23.301897048950195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.318756103515625
    num_steps_sampled: 8365000
    num_steps_trained: 8365000
    wait_time_ms: 75.517
  iterations_since_restore: 1673
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14687.919675588608
  time_this_iter_s: 8.595070362091064
  time_total_s: 14687.919675588608
  timestamp: 1594863248
  timesteps_since_restore: 8365000
  timesteps_this_iter: 5000
  timesteps_total: 8365000
  training_iteration: 1673
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14687 s, 1673 iter, 8365000 ts, 12.5 rew

agent-1: 119.79511010649665
agent-2: 138.79511010649654
agent-3: 113.79511010649664
agent-4: 121.79511010649665
agent-5: 117.79511010649665
Extrinsic Rewards:
11
30
5
13
9
Sum Reward: 68
Avg Reward: 13.6
Min Reward: 5
Max Reward: 30
Gini Coefficient: 0.3176470588235294
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 611.9755505324786
  episode_reward_mean: 18.667015365204676
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1673
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.669
    dispatch_time_ms: 10.028
    learner:
      cur_lr: 0.0008028909796848893
      grad_gnorm: 40.0
      policy_entropy: 33.51302719116211
      policy_loss: -14.662070274353027
      var_gnorm: 23.321882247924805
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 5.594660758972168
    num_steps_sampled: 8370000
    num_steps_trained: 8370000
    wait_time_ms: 73.509
  iterations_since_restore: 1674
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14696.506262302399
  time_this_iter_s: 8.586586713790894
  time_total_s: 14696.506262302399
  timestamp: 1594863256
  timesteps_since_restore: 8370000
  timesteps_this_iter: 5000
  timesteps_total: 8370000
  training_iteration: 1674
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14696 s, 1674 iter, 8370000 ts, 18.7 rew

agent-1: 130.39998565374373
agent-2: 128.39998565374387
agent-3: 129.39998565374378
agent-4: 139.3999856537437
agent-5: 138.39998565374367
Extrinsic Rewards:
12
10
11
21
20
Sum Reward: 74
Avg Reward: 14.8
Min Reward: 10
Max Reward: 21
Gini Coefficient: 0.16756756756756758
20:20 Ratio: 2.1
Max-min Ratio: 2.1
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 25.327014647891883
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1674
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.393
    dispatch_time_ms: 8.973
    learner:
      cur_lr: 0.0008025579736568034
      grad_gnorm: 39.999996185302734
      policy_entropy: 31.349695205688477
      policy_loss: 49.25856018066406
      var_gnorm: 23.29754638671875
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 60.25212478637695
    num_steps_sampled: 8375000
    num_steps_trained: 8375000
    wait_time_ms: 74.218
  iterations_since_restore: 1675
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14705.08730506897
  time_this_iter_s: 8.581042766571045
  time_total_s: 14705.08730506897
  timestamp: 1594863265
  timesteps_since_restore: 8375000
  timesteps_this_iter: 5000
  timesteps_total: 8375000
  training_iteration: 1675
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14705 s, 1675 iter, 8375000 ts, 25.3 rew

agent-1: 75.59999983340376
agent-2: 85.59999983340377
agent-3: 89.59999983340376
agent-4: 81.59999983340376
agent-5: 81.59999983340377
Extrinsic Rewards:
2
12
16
8
8
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.2782608695652174
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 29.467014639562077
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1675
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.75
    dispatch_time_ms: 7.578
    learner:
      cur_lr: 0.0008022250258363783
      grad_gnorm: 17.713451385498047
      policy_entropy: 21.620731353759766
      policy_loss: -2.26788067817688
      var_gnorm: 23.298131942749023
      vf_explained_var: 0.0
      vf_loss: 0.24246394634246826
    num_steps_sampled: 8380000
    num_steps_trained: 8380000
    wait_time_ms: 78.158
  iterations_since_restore: 1676
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14713.770406007767
  time_this_iter_s: 8.683100938796997
  time_total_s: 14713.770406007767
  timestamp: 1594863274
  timesteps_since_restore: 8380000
  timesteps_this_iter: 5000
  timesteps_total: 8380000
  training_iteration: 1676
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14713 s, 1676 iter, 8380000 ts, 29.5 rew

agent-1: 56.399999984875976
agent-2: 61.39999998487596
agent-3: 58.399999984875976
agent-4: 62.399999984875976
agent-5: 67.39999998487576
Extrinsic Rewards:
2
7
4
8
13
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.3058823529411765
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-34-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 32.52701463880589
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1676
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.029
    dispatch_time_ms: 9.279
    learner:
      cur_lr: 0.0008018920198082924
      grad_gnorm: 40.0
      policy_entropy: 29.054536819458008
      policy_loss: 15.555233001708984
      var_gnorm: 23.297378540039062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 14.044122695922852
    num_steps_sampled: 8385000
    num_steps_trained: 8385000
    wait_time_ms: 72.917
  iterations_since_restore: 1677
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14722.236595630646
  time_this_iter_s: 8.466189622879028
  time_total_s: 14722.236595630646
  timestamp: 1594863282
  timesteps_since_restore: 8385000
  timesteps_this_iter: 5000
  timesteps_total: 8385000
  training_iteration: 1677
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14722 s, 1677 iter, 8385000 ts, 32.5 rew

agent-1: 47.79999999778419
agent-2: 53.799999997784184
agent-3: 51.7999999977842
agent-4: 53.79999999778419
agent-5: 44.799999997784205
Extrinsic Rewards:
3
9
7
9
0
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.34285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 35.04701463869511
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1677
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.62
    dispatch_time_ms: 11.532
    learner:
      cur_lr: 0.0008015590137802064
      grad_gnorm: 40.0
      policy_entropy: 34.61806869506836
      policy_loss: 8.352646827697754
      var_gnorm: 23.29615020751953
      vf_explained_var: 0.0
      vf_loss: 1.7214534282684326
    num_steps_sampled: 8390000
    num_steps_trained: 8390000
    wait_time_ms: 73.447
  iterations_since_restore: 1678
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14739.942719459534
  time_this_iter_s: 17.70612382888794
  time_total_s: 14739.942719459534
  timestamp: 1594863300
  timesteps_since_restore: 8390000
  timesteps_this_iter: 5000
  timesteps_total: 8390000
  training_iteration: 1678
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14739 s, 1678 iter, 8390000 ts, 35 rew

agent-1: 105.99987642926288
agent-2: 132.9998764292629
agent-3: 110.9998764292629
agent-4: 114.9998764292629
agent-5: 119.99987642926291
Extrinsic Rewards:
2
29
7
11
16
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 2
Max Reward: 29
Gini Coefficient: 0.38769230769230767
20:20 Ratio: 14.5
Max-min Ratio: 14.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 40.89700846015828
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1678
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.337
    dispatch_time_ms: 7.668
    learner:
      cur_lr: 0.0008012260077521205
      grad_gnorm: 40.0
      policy_entropy: 13.347992897033691
      policy_loss: 12.770496368408203
      var_gnorm: 23.282121658325195
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 19.309465408325195
    num_steps_sampled: 8395000
    num_steps_trained: 8395000
    wait_time_ms: 74.124
  iterations_since_restore: 1679
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14748.48861336708
  time_this_iter_s: 8.545893907546997
  time_total_s: 14748.48861336708
  timestamp: 1594863308
  timesteps_since_restore: 8395000
  timesteps_this_iter: 5000
  timesteps_total: 8395000
  training_iteration: 1679
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14748 s, 1679 iter, 8395000 ts, 40.9 rew

agent-1: 78.19999869554181
agent-2: 96.1999986955418
agent-3: 80.19999869554182
agent-4: 85.19999869554182
agent-5: 83.19999869554185
Extrinsic Rewards:
3
21
5
10
8
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 3
Max Reward: 21
Gini Coefficient: 0.34893617021276596
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 45.127008394935366
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1679
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.334
    dispatch_time_ms: 8.976
    learner:
      cur_lr: 0.0008008930017240345
      grad_gnorm: 40.0
      policy_entropy: 32.196781158447266
      policy_loss: -11.739761352539062
      var_gnorm: 23.291732788085938
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 2.894186496734619
    num_steps_sampled: 8400000
    num_steps_trained: 8400000
    wait_time_ms: 74.861
  iterations_since_restore: 1680
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14756.947334766388
  time_this_iter_s: 8.458721399307251
  time_total_s: 14756.947334766388
  timestamp: 1594863317
  timesteps_since_restore: 8400000
  timesteps_this_iter: 5000
  timesteps_total: 8400000
  training_iteration: 1680
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14756 s, 1680 iter, 8400000 ts, 45.1 rew

agent-1: 109.59997830731834
agent-2: 112.59997830731831
agent-3: 105.59997830731831
agent-4: 107.59997830731831
agent-5: 113.59997830731832
Extrinsic Rewards:
12
15
8
10
16
Sum Reward: 61
Avg Reward: 12.2
Min Reward: 8
Max Reward: 16
Gini Coefficient: 0.1377049180327869
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 50.541676267412534
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1680
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.602
    dispatch_time_ms: 52.506
    learner:
      cur_lr: 0.0008005599956959486
      grad_gnorm: 40.0
      policy_entropy: 33.0697021484375
      policy_loss: 26.53936195373535
      var_gnorm: 23.28082847595215
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 17.524578094482422
    num_steps_sampled: 8405000
    num_steps_trained: 8405000
    wait_time_ms: 29.959
  iterations_since_restore: 1681
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14765.647668838501
  time_this_iter_s: 8.700334072113037
  time_total_s: 14765.647668838501
  timestamp: 1594863326
  timesteps_since_restore: 8405000
  timesteps_this_iter: 5000
  timesteps_total: 8405000
  training_iteration: 1681
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14765 s, 1681 iter, 8405000 ts, 50.5 rew

agent-1: 65.99999998671576
agent-2: 58.99999998671571
agent-3: 59.99999998671569
agent-4: 62.99999998671569
agent-5: 66.99999998671576
Extrinsic Rewards:
10
3
4
7
11
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.25142857142857145
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 53.51748105484203
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1681
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.563
    dispatch_time_ms: 39.627
    learner:
      cur_lr: 0.0008002269896678627
      grad_gnorm: 2.6554062366485596
      policy_entropy: 30.833898544311523
      policy_loss: -1.511991262435913
      var_gnorm: 23.280933380126953
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.020119991153478622
    num_steps_sampled: 8410000
    num_steps_trained: 8410000
    wait_time_ms: 59.241
  iterations_since_restore: 1682
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14774.961059808731
  time_this_iter_s: 9.313390970230103
  time_total_s: 14774.961059808731
  timestamp: 1594863335
  timesteps_since_restore: 8410000
  timesteps_this_iter: 5000
  timesteps_total: 8410000
  training_iteration: 1682
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14774 s, 1682 iter, 8410000 ts, 53.5 rew

agent-1: 36.5999999993195
agent-2: 39.59999999931949
agent-3: 41.599999999319486
agent-4: 34.599999999319486
agent-5: 36.5999999993195
Extrinsic Rewards:
3
6
8
1
3
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.3238095238095238
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 51.447483579240036
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1682
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.509
    dispatch_time_ms: 33.846
    learner:
      cur_lr: 0.0007998939836397767
      grad_gnorm: 40.0
      policy_entropy: 33.41437530517578
      policy_loss: 40.36989212036133
      var_gnorm: 23.280742645263672
      vf_explained_var: 0.0
      vf_loss: 42.10091781616211
    num_steps_sampled: 8415000
    num_steps_trained: 8415000
    wait_time_ms: 59.795
  iterations_since_restore: 1683
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14783.999674797058
  time_this_iter_s: 9.038614988327026
  time_total_s: 14783.999674797058
  timestamp: 1594863344
  timesteps_since_restore: 8415000
  timesteps_this_iter: 5000
  timesteps_total: 8415000
  training_iteration: 1683
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14783 s, 1683 iter, 8415000 ts, 51.4 rew

agent-1: 36.999999999239414
agent-2: 34.999999999239414
agent-3: 33.999999999239414
agent-4: 37.99999999923942
agent-5: 35.99999999923942
Extrinsic Rewards:
5
3
2
6
4
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.2
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-35-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 49.55748358362783
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1683
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.634
    dispatch_time_ms: 26.344
    learner:
      cur_lr: 0.0007995609776116908
      grad_gnorm: 8.515990257263184
      policy_entropy: 34.4730339050293
      policy_loss: -2.847057819366455
      var_gnorm: 23.28081703186035
      vf_explained_var: 0.0
      vf_loss: 0.04982011020183563
    num_steps_sampled: 8420000
    num_steps_trained: 8420000
    wait_time_ms: 64.758
  iterations_since_restore: 1684
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14793.074312925339
  time_this_iter_s: 9.07463812828064
  time_total_s: 14793.074312925339
  timestamp: 1594863353
  timesteps_since_restore: 8420000
  timesteps_this_iter: 5000
  timesteps_total: 8420000
  training_iteration: 1684
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14793 s, 1684 iter, 8420000 ts, 49.6 rew

agent-1: 34.3999999989679
agent-2: 32.39999999896792
agent-3: 35.3999999989679
agent-4: 31.3999999989679
agent-5: 37.39999999896791
Extrinsic Rewards:
4
2
5
1
7
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.3157894736842105
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 51.2674835835762
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1684
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.067
    dispatch_time_ms: 19.479
    learner:
      cur_lr: 0.0007992279715836048
      grad_gnorm: 40.0
      policy_entropy: 34.65482711791992
      policy_loss: 61.43849563598633
      var_gnorm: 23.280813217163086
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 114.05191040039062
    num_steps_sampled: 8425000
    num_steps_trained: 8425000
    wait_time_ms: 64.919
  iterations_since_restore: 1685
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14802.31995844841
  time_this_iter_s: 9.245645523071289
  time_total_s: 14802.31995844841
  timestamp: 1594863362
  timesteps_since_restore: 8425000
  timesteps_this_iter: 5000
  timesteps_total: 8425000
  training_iteration: 1685
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14802 s, 1685 iter, 8425000 ts, 51.3 rew

agent-1: 26.999999999600952
agent-2: 28.999999999600952
agent-3: 25.999999999600952
agent-4: 25.999999999600952
agent-5: 26.999999999600952
Extrinsic Rewards:
3
5
2
2
3
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.18666666666666668
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 52.61748358355625
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1685
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.883
    dispatch_time_ms: 25.877
    learner:
      cur_lr: 0.0007988950237631798
      grad_gnorm: 15.348803520202637
      policy_entropy: 25.235748291015625
      policy_loss: -3.6643848419189453
      var_gnorm: 23.28167152404785
      vf_explained_var: 0.0
      vf_loss: 0.18068866431713104
    num_steps_sampled: 8430000
    num_steps_trained: 8430000
    wait_time_ms: 65.941
  iterations_since_restore: 1686
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14811.527766227722
  time_this_iter_s: 9.207807779312134
  time_total_s: 14811.527766227722
  timestamp: 1594863372
  timesteps_since_restore: 8430000
  timesteps_this_iter: 5000
  timesteps_total: 8430000
  training_iteration: 1686
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14811 s, 1686 iter, 8430000 ts, 52.6 rew

agent-1: 48.59999998198041
agent-2: 46.599999981980396
agent-3: 45.5999999819804
agent-4: 45.5999999819804
agent-5: 47.599999981980396
Extrinsic Rewards:
7
5
4
4
6
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 4
Max Reward: 7
Gini Coefficient: 0.12307692307692308
20:20 Ratio: 1.75
Max-min Ratio: 1.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 54.95748358265528
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1686
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.962
    dispatch_time_ms: 33.676
    learner:
      cur_lr: 0.0007985620177350938
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.545793533325195
      policy_loss: 9.10855770111084
      var_gnorm: 23.281558990478516
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 5.420231342315674
    num_steps_sampled: 8435000
    num_steps_trained: 8435000
    wait_time_ms: 49.829
  iterations_since_restore: 1687
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14820.574928998947
  time_this_iter_s: 9.047162771224976
  time_total_s: 14820.574928998947
  timestamp: 1594863381
  timesteps_since_restore: 8435000
  timesteps_this_iter: 5000
  timesteps_total: 8435000
  training_iteration: 1687
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14820 s, 1687 iter, 8435000 ts, 55 rew

agent-1: 36.59999999899884
agent-2: 44.59999999899884
agent-3: 35.59999999899883
agent-4: 33.59999999899882
agent-5: 38.599999998998854
Extrinsic Rewards:
3
11
2
0
5
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.47619047619047616
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 56.84748358260522
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1687
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.95
    dispatch_time_ms: 34.175
    learner:
      cur_lr: 0.0007982290117070079
      grad_gnorm: 40.000003814697266
      policy_entropy: 34.258750915527344
      policy_loss: 14.7750825881958
      var_gnorm: 23.296035766601562
      vf_explained_var: 0.0
      vf_loss: 3.375868558883667
    num_steps_sampled: 8440000
    num_steps_trained: 8440000
    wait_time_ms: 52.316
  iterations_since_restore: 1688
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14829.335896015167
  time_this_iter_s: 8.760967016220093
  time_total_s: 14829.335896015167
  timestamp: 1594863390
  timesteps_since_restore: 8440000
  timesteps_this_iter: 5000
  timesteps_total: 8440000
  training_iteration: 1688
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14829 s, 1688 iter, 8440000 ts, 56.8 rew

agent-1: 139.1968435902265
agent-2: 136.19684359022648
agent-3: 124.1968435902267
agent-4: 116.1968435902267
agent-5: 132.19684359022645
Extrinsic Rewards:
24
21
9
1
17
Sum Reward: 72
Avg Reward: 14.4
Min Reward: 1
Max Reward: 24
Gini Coefficient: 0.32222222222222224
20:20 Ratio: 24.0
Max-min Ratio: 24.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 63.32732576211655
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1688
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.046
    dispatch_time_ms: 27.585
    learner:
      cur_lr: 0.0007978960056789219
      grad_gnorm: 39.999996185302734
      policy_entropy: 4.6009745597839355
      policy_loss: -4.355238914489746
      var_gnorm: 23.29205894470215
      vf_explained_var: 0.0
      vf_loss: 2.4169504642486572
    num_steps_sampled: 8445000
    num_steps_trained: 8445000
    wait_time_ms: 62.142
  iterations_since_restore: 1689
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14838.518977165222
  time_this_iter_s: 9.183081150054932
  time_total_s: 14838.518977165222
  timestamp: 1594863399
  timesteps_since_restore: 8445000
  timesteps_this_iter: 5000
  timesteps_total: 8445000
  training_iteration: 1689
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14838 s, 1689 iter, 8445000 ts, 63.3 rew

agent-1: 85.39995318571151
agent-2: 88.39995318571151
agent-3: 88.39995318571151
agent-4: 89.39995318571151
agent-5: 89.39995318571152
Extrinsic Rewards:
7
10
10
11
11
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 7
Max Reward: 11
Gini Coefficient: 0.07346938775510205
20:20 Ratio: 1.5714285714285714
Max-min Ratio: 1.5714285714285714
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 665.9999282687205
  episode_reward_mean: 67.73732342140217
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1689
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 8.093
    learner:
      cur_lr: 0.000797562999650836
      grad_gnorm: 40.0
      policy_entropy: 19.65305519104004
      policy_loss: 33.01271438598633
      var_gnorm: 23.302881240844727
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 80.35739135742188
    num_steps_sampled: 8450000
    num_steps_trained: 8450000
    wait_time_ms: 75.045
  iterations_since_restore: 1690
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14847.098840475082
  time_this_iter_s: 8.57986330986023
  time_total_s: 14847.098840475082
  timestamp: 1594863407
  timesteps_since_restore: 8450000
  timesteps_this_iter: 5000
  timesteps_total: 8450000
  training_iteration: 1690
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14847 s, 1690 iter, 8450000 ts, 67.7 rew

agent-1: 158.5237093053761
agent-2: 163.52370930537603
agent-3: 169.52370930537597
agent-4: 168.52370930537606
agent-5: 164.52370930537603
Extrinsic Rewards:
12
17
23
22
18
Sum Reward: 92
Avg Reward: 18.4
Min Reward: 12
Max Reward: 23
Gini Coefficient: 0.11739130434782609
20:20 Ratio: 1.9166666666666667
Max-min Ratio: 1.9166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-36-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 75.98350888667098
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1690
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.083
    dispatch_time_ms: 9.575
    learner:
      cur_lr: 0.00079722999362275
      grad_gnorm: 40.0
      policy_entropy: 15.22877311706543
      policy_loss: -11.241198539733887
      var_gnorm: 23.317407608032227
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 9.732895851135254
    num_steps_sampled: 8455000
    num_steps_trained: 8455000
    wait_time_ms: 74.978
  iterations_since_restore: 1691
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14855.699596643448
  time_this_iter_s: 8.600756168365479
  time_total_s: 14855.699596643448
  timestamp: 1594863416
  timesteps_since_restore: 8455000
  timesteps_this_iter: 5000
  timesteps_total: 8455000
  training_iteration: 1691
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14855 s, 1691 iter, 8455000 ts, 76 rew

agent-1: 124.59981687449695
agent-2: 125.59981687449692
agent-3: 136.59981687449698
agent-4: 123.59981687449698
agent-5: 128.59981687449707
Extrinsic Rewards:
11
12
23
10
15
Sum Reward: 71
Avg Reward: 14.2
Min Reward: 10
Max Reward: 23
Gini Coefficient: 0.16901408450704225
20:20 Ratio: 2.3
Max-min Ratio: 2.3
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 82.37349973039585
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1691
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.947
    dispatch_time_ms: 7.894
    learner:
      cur_lr: 0.0007968969875946641
      grad_gnorm: 40.000003814697266
      policy_entropy: 31.541942596435547
      policy_loss: -11.270750045776367
      var_gnorm: 23.29874610900879
      vf_explained_var: 0.0
      vf_loss: 4.889278411865234
    num_steps_sampled: 8460000
    num_steps_trained: 8460000
    wait_time_ms: 74.165
  iterations_since_restore: 1692
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14864.382157325745
  time_this_iter_s: 8.682560682296753
  time_total_s: 14864.382157325745
  timestamp: 1594863425
  timesteps_since_restore: 8460000
  timesteps_this_iter: 5000
  timesteps_total: 8460000
  training_iteration: 1692
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14864 s, 1692 iter, 8460000 ts, 82.4 rew

agent-1: 31.39999999940682
agent-2: 30.399999999406823
agent-3: 34.39999999940658
agent-4: 38.399999999406575
agent-5: 36.399999999406575
Extrinsic Rewards:
1
0
4
8
6
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.4421052631578947
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 84.0834997303662
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1692
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.958
    dispatch_time_ms: 8.951
    learner:
      cur_lr: 0.0007965639815665781
      grad_gnorm: 40.0
      policy_entropy: 31.811180114746094
      policy_loss: 28.339344024658203
      var_gnorm: 23.282470703125
      vf_explained_var: 0.0
      vf_loss: 31.09003448486328
    num_steps_sampled: 8465000
    num_steps_trained: 8465000
    wait_time_ms: 74.04
  iterations_since_restore: 1693
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14873.07940864563
  time_this_iter_s: 8.697251319885254
  time_total_s: 14873.07940864563
  timestamp: 1594863433
  timesteps_since_restore: 8465000
  timesteps_this_iter: 5000
  timesteps_total: 8465000
  training_iteration: 1693
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14873 s, 1693 iter, 8465000 ts, 84.1 rew

agent-1: 71.1999999290258
agent-2: 72.1999999290258
agent-3: 70.19999992902581
agent-4: 89.19999992902571
agent-5: 75.19999992902576
Extrinsic Rewards:
4
5
3
22
8
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 3
Max Reward: 22
Gini Coefficient: 0.4
20:20 Ratio: 7.333333333333333
Max-min Ratio: 7.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 87.86349972681752
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1693
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.676
    dispatch_time_ms: 7.809
    learner:
      cur_lr: 0.0007962309755384922
      grad_gnorm: 19.314340591430664
      policy_entropy: 34.08684158325195
      policy_loss: -3.79308819770813
      var_gnorm: 23.282550811767578
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.28469550609588623
    num_steps_sampled: 8470000
    num_steps_trained: 8470000
    wait_time_ms: 74.302
  iterations_since_restore: 1694
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14881.716696977615
  time_this_iter_s: 8.637288331985474
  time_total_s: 14881.716696977615
  timestamp: 1594863442
  timesteps_since_restore: 8470000
  timesteps_this_iter: 5000
  timesteps_total: 8470000
  training_iteration: 1694
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14881 s, 1694 iter, 8470000 ts, 87.9 rew

agent-1: 41.39999999881243
agent-2: 46.39999999881243
agent-3: 44.39999999881243
agent-4: 40.399999998812426
agent-5: 43.39999999881243
Extrinsic Rewards:
3
8
6
2
5
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.25
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 90.02349972675815
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1694
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.371
    dispatch_time_ms: 9.635
    learner:
      cur_lr: 0.0007958980277180672
      grad_gnorm: 4.888352870941162
      policy_entropy: 27.30308723449707
      policy_loss: -0.24618422985076904
      var_gnorm: 23.28207015991211
      vf_explained_var: 0.0
      vf_loss: 0.018464699387550354
    num_steps_sampled: 8475000
    num_steps_trained: 8475000
    wait_time_ms: 73.744
  iterations_since_restore: 1695
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14890.335299491882
  time_this_iter_s: 8.618602514266968
  time_total_s: 14890.335299491882
  timestamp: 1594863451
  timesteps_since_restore: 8475000
  timesteps_this_iter: 5000
  timesteps_total: 8475000
  training_iteration: 1695
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14890 s, 1695 iter, 8475000 ts, 90 rew

agent-1: 60.19999999325541
agent-2: 53.199999993255396
agent-3: 60.19999999325541
agent-4: 58.19999999325541
agent-5: 56.19999999325541
Extrinsic Rewards:
9
2
9
7
5
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.225
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 92.90349972642088
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1695
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.83
    dispatch_time_ms: 6.233
    learner:
      cur_lr: 0.0007955650216899812
      grad_gnorm: 11.925191879272461
      policy_entropy: 34.115474700927734
      policy_loss: -2.0396053791046143
      var_gnorm: 23.282150268554688
      vf_explained_var: 0.0
      vf_loss: 0.10816624760627747
    num_steps_sampled: 8480000
    num_steps_trained: 8480000
    wait_time_ms: 79.608
  iterations_since_restore: 1696
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14899.078495264053
  time_this_iter_s: 8.74319577217102
  time_total_s: 14899.078495264053
  timestamp: 1594863460
  timesteps_since_restore: 8480000
  timesteps_this_iter: 5000
  timesteps_total: 8480000
  training_iteration: 1696
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14899 s, 1696 iter, 8480000 ts, 92.9 rew

agent-1: 53.59999998800633
agent-2: 53.599999988006324
agent-3: 65.59999998800643
agent-4: 53.59999998800633
agent-5: 52.59999998800633
Extrinsic Rewards:
4
4
16
4
3
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 3
Max Reward: 16
Gini Coefficient: 0.33548387096774196
20:20 Ratio: 5.333333333333333
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 95.69349972582114
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1696
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.704
    dispatch_time_ms: 8.433
    learner:
      cur_lr: 0.0007952320156618953
      grad_gnorm: 40.00000762939453
      policy_entropy: 34.423091888427734
      policy_loss: 20.455455780029297
      var_gnorm: 23.28206443786621
      vf_explained_var: 0.0
      vf_loss: 11.640917778015137
    num_steps_sampled: 8485000
    num_steps_trained: 8485000
    wait_time_ms: 74.869
  iterations_since_restore: 1697
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14907.716391563416
  time_this_iter_s: 8.637896299362183
  time_total_s: 14907.716391563416
  timestamp: 1594863468
  timesteps_since_restore: 8485000
  timesteps_this_iter: 5000
  timesteps_total: 8485000
  training_iteration: 1697
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14907 s, 1697 iter, 8485000 ts, 95.7 rew

agent-1: 25.99999999964453
agent-2: 26.99999999964453
agent-3: 27.999999999644537
agent-4: 24.999999999644537
agent-5: 28.999999999644537
Extrinsic Rewards:
2
3
4
1
5
Sum Reward: 15
Avg Reward: 3.0
Min Reward: 1
Max Reward: 5
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-37-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 97.04349972580336
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1697
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.629
    dispatch_time_ms: 8.318
    learner:
      cur_lr: 0.0007948990096338093
      grad_gnorm: 13.291203498840332
      policy_entropy: 25.594619750976562
      policy_loss: -1.7974618673324585
      var_gnorm: 23.282609939575195
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.1367795467376709
    num_steps_sampled: 8490000
    num_steps_trained: 8490000
    wait_time_ms: 74.486
  iterations_since_restore: 1698
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14916.345576286316
  time_this_iter_s: 8.62918472290039
  time_total_s: 14916.345576286316
  timestamp: 1594863477
  timesteps_since_restore: 8490000
  timesteps_this_iter: 5000
  timesteps_total: 8490000
  training_iteration: 1698
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14916 s, 1698 iter, 8490000 ts, 97 rew

agent-1: 39.99999999919049
agent-2: 34.99999999919051
agent-3: 36.99999999919049
agent-4: 31.99999999919043
agent-5: 35.9999999991905
Extrinsic Rewards:
8
3
5
0
4
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.36
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 98.84349972576291
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1698
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.375
    dispatch_time_ms: 8.17
    learner:
      cur_lr: 0.0007945660036057234
      grad_gnorm: 4.542963981628418
      policy_entropy: 19.796857833862305
      policy_loss: -0.4288264214992523
      var_gnorm: 23.28270149230957
      vf_explained_var: 0.0
      vf_loss: 0.01595689170062542
    num_steps_sampled: 8495000
    num_steps_trained: 8495000
    wait_time_ms: 75.033
  iterations_since_restore: 1699
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14925.029314756393
  time_this_iter_s: 8.683738470077515
  time_total_s: 14925.029314756393
  timestamp: 1594863486
  timesteps_since_restore: 8495000
  timesteps_this_iter: 5000
  timesteps_total: 8495000
  training_iteration: 1699
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14925 s, 1699 iter, 8495000 ts, 98.8 rew

agent-1: 49.19999999749084
agent-2: 46.199999997490856
agent-3: 49.19999999749086
agent-4: 50.19999999749084
agent-5: 48.199999997490856
Extrinsic Rewards:
6
3
6
7
5
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.13333333333333333
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 101.27349972563744
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1699
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.605
    dispatch_time_ms: 8.553
    learner:
      cur_lr: 0.0007942329975776374
      grad_gnorm: 40.0
      policy_entropy: 22.32318115234375
      policy_loss: -4.11441707611084
      var_gnorm: 23.288759231567383
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 1.6178933382034302
    num_steps_sampled: 8500000
    num_steps_trained: 8500000
    wait_time_ms: 76.007
  iterations_since_restore: 1700
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14933.592390298843
  time_this_iter_s: 8.563075542449951
  time_total_s: 14933.592390298843
  timestamp: 1594863494
  timesteps_since_restore: 8500000
  timesteps_this_iter: 5000
  timesteps_total: 8500000
  training_iteration: 1700
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14933 s, 1700 iter, 8500000 ts, 101 rew

agent-1: 115.79999464993409
agent-2: 113.79999464993412
agent-3: 116.79999464993409
agent-4: 110.79999464993409
agent-5: 109.79999464993409
Extrinsic Rewards:
15
13
16
10
9
Sum Reward: 63
Avg Reward: 12.6
Min Reward: 9
Max Reward: 16
Gini Coefficient: 0.12063492063492064
20:20 Ratio: 1.7777777777777777
Max-min Ratio: 1.7777777777777777
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 106.94349945813416
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1700
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 10.861
    learner:
      cur_lr: 0.0007938999915495515
      grad_gnorm: 6.143779277801514
      policy_entropy: 20.635498046875
      policy_loss: -0.6349995732307434
      var_gnorm: 23.282962799072266
      vf_explained_var: 0.0
      vf_loss: 0.029200775548815727
    num_steps_sampled: 8505000
    num_steps_trained: 8505000
    wait_time_ms: 73.122
  iterations_since_restore: 1701
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14942.363600254059
  time_this_iter_s: 8.771209955215454
  time_total_s: 14942.363600254059
  timestamp: 1594863503
  timesteps_since_restore: 8505000
  timesteps_this_iter: 5000
  timesteps_total: 8505000
  training_iteration: 1701
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14942 s, 1701 iter, 8505000 ts, 107 rew

agent-1: 62.799999968392655
agent-2: 57.79999996839264
agent-3: 63.799999968392655
agent-4: 59.79999996839267
agent-5: 52.79999996839264
Extrinsic Rewards:
10
5
11
7
0
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.32727272727272727
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 109.9134994565538
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1701
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.622
    dispatch_time_ms: 6.362
    learner:
      cur_lr: 0.0007935669855214655
      grad_gnorm: 22.11078643798828
      policy_entropy: 31.67270278930664
      policy_loss: -3.589829444885254
      var_gnorm: 23.283674240112305
      vf_explained_var: 0.0
      vf_loss: 0.3751116991043091
    num_steps_sampled: 8510000
    num_steps_trained: 8510000
    wait_time_ms: 78.346
  iterations_since_restore: 1702
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14951.013590574265
  time_this_iter_s: 8.649990320205688
  time_total_s: 14951.013590574265
  timestamp: 1594863512
  timesteps_since_restore: 8510000
  timesteps_this_iter: 5000
  timesteps_total: 8510000
  training_iteration: 1702
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14951 s, 1702 iter, 8510000 ts, 110 rew

agent-1: 62.599999939266645
agent-2: 64.59999993926684
agent-3: 65.59999993926687
agent-4: 71.59999993926682
agent-5: 59.59999993926664
Extrinsic Rewards:
5
7
8
14
2
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.3
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 113.15349945351714
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1702
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.698
    dispatch_time_ms: 10.772
    learner:
      cur_lr: 0.0007932339794933796
      grad_gnorm: 4.1096014976501465
      policy_entropy: 32.072994232177734
      policy_loss: -0.5383338928222656
      var_gnorm: 23.283021926879883
      vf_explained_var: 0.0
      vf_loss: 0.012288529425859451
    num_steps_sampled: 8515000
    num_steps_trained: 8515000
    wait_time_ms: 72.472
  iterations_since_restore: 1703
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14959.62151169777
  time_this_iter_s: 8.607921123504639
  time_total_s: 14959.62151169777
  timestamp: 1594863520
  timesteps_since_restore: 8515000
  timesteps_this_iter: 5000
  timesteps_total: 8515000
  training_iteration: 1703
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14959 s, 1703 iter, 8515000 ts, 113 rew

agent-1: 46.199999997418125
agent-2: 47.19999999741811
agent-3: 47.19999999741811
agent-4: 47.19999999741811
agent-5: 55.19999999741814
Extrinsic Rewards:
3
4
4
4
12
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 115.58349945338803
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1703
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.499
    dispatch_time_ms: 5.741
    learner:
      cur_lr: 0.0007929009734652936
      grad_gnorm: 24.296310424804688
      policy_entropy: 20.427391052246094
      policy_loss: -3.006089925765991
      var_gnorm: 23.284812927246094
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.45495229959487915
    num_steps_sampled: 8520000
    num_steps_trained: 8520000
    wait_time_ms: 76.696
  iterations_since_restore: 1704
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14968.195101737976
  time_this_iter_s: 8.57359004020691
  time_total_s: 14968.195101737976
  timestamp: 1594863529
  timesteps_since_restore: 8520000
  timesteps_this_iter: 5000
  timesteps_total: 8520000
  training_iteration: 1704
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14968 s, 1704 iter, 8520000 ts, 116 rew

agent-1: 56.399999994540266
agent-2: 58.39999999454027
agent-3: 69.3999999945403
agent-4: 57.39999999454028
agent-5: 64.39999999454034
Extrinsic Rewards:
2
4
15
3
10
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.38823529411764707
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-38-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 118.6434994531151
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1704
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.037
    dispatch_time_ms: 7.26
    learner:
      cur_lr: 0.0007925680256448686
      grad_gnorm: 4.263362884521484
      policy_entropy: 25.042057037353516
      policy_loss: -0.3940124213695526
      var_gnorm: 23.283201217651367
      vf_explained_var: 0.0
      vf_loss: 0.01320335827767849
    num_steps_sampled: 8525000
    num_steps_trained: 8525000
    wait_time_ms: 77.853
  iterations_since_restore: 1705
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14976.878035783768
  time_this_iter_s: 8.682934045791626
  time_total_s: 14976.878035783768
  timestamp: 1594863538
  timesteps_since_restore: 8525000
  timesteps_this_iter: 5000
  timesteps_total: 8525000
  training_iteration: 1705
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14976 s, 1705 iter, 8525000 ts, 119 rew

agent-1: 82.7999999603961
agent-2: 90.79999996039611
agent-3: 86.79999996039611
agent-4: 92.79999996039612
agent-5: 78.79999996039612
Extrinsic Rewards:
6
14
10
16
2
Sum Reward: 48
Avg Reward: 9.6
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.3
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 122.96349945113494
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1705
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.696
    dispatch_time_ms: 6.074
    learner:
      cur_lr: 0.0007922350196167827
      grad_gnorm: 31.1903133392334
      policy_entropy: 31.854434967041016
      policy_loss: -5.129409313201904
      var_gnorm: 23.285659790039062
      vf_explained_var: 0.0
      vf_loss: 0.747991144657135
    num_steps_sampled: 8530000
    num_steps_trained: 8530000
    wait_time_ms: 77.382
  iterations_since_restore: 1706
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14987.245340824127
  time_this_iter_s: 10.367305040359497
  time_total_s: 14987.245340824127
  timestamp: 1594863548
  timesteps_since_restore: 8530000
  timesteps_this_iter: 5000
  timesteps_total: 8530000
  training_iteration: 1706
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14987 s, 1706 iter, 8530000 ts, 123 rew

agent-1: 112.19999612929549
agent-2: 110.19999612929546
agent-3: 112.19999612929547
agent-4: 111.19999612929547
agent-5: 112.19999612929546
Extrinsic Rewards:
13
11
13
12
13
Sum Reward: 62
Avg Reward: 12.4
Min Reward: 11
Max Reward: 13
Gini Coefficient: 0.03225806451612903
20:20 Ratio: 1.1818181818181819
Max-min Ratio: 1.1818181818181819
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-17
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 128.54349925759968
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1706
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.889
    dispatch_time_ms: 9.312
    learner:
      cur_lr: 0.0007919020135886967
      grad_gnorm: 40.000003814697266
      policy_entropy: 33.98911666870117
      policy_loss: 59.33619689941406
      var_gnorm: 23.2833309173584
      vf_explained_var: 0.0
      vf_loss: 82.28373718261719
    num_steps_sampled: 8535000
    num_steps_trained: 8535000
    wait_time_ms: 74.61
  iterations_since_restore: 1707
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 14995.909742116928
  time_this_iter_s: 8.664401292800903
  time_total_s: 14995.909742116928
  timestamp: 1594863557
  timesteps_since_restore: 8535000
  timesteps_this_iter: 5000
  timesteps_total: 8535000
  training_iteration: 1707
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 14995 s, 1707 iter, 8535000 ts, 129 rew

agent-1: 37.19999999908153
agent-2: 37.19999999908152
agent-3: 41.199999999081506
agent-4: 42.199999999081506
agent-5: 40.19999999908152
Extrinsic Rewards:
2
2
6
7
5
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 130.52349925755374
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1707
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 7.709
    learner:
      cur_lr: 0.0007915690075606108
      grad_gnorm: 25.765666961669922
      policy_entropy: 34.220279693603516
      policy_loss: -4.257063388824463
      var_gnorm: 23.28440284729004
      vf_explained_var: 0.0
      vf_loss: 0.5054646730422974
    num_steps_sampled: 8540000
    num_steps_trained: 8540000
    wait_time_ms: 75.201
  iterations_since_restore: 1708
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15004.386781930923
  time_this_iter_s: 8.477039813995361
  time_total_s: 15004.386781930923
  timestamp: 1594863565
  timesteps_since_restore: 8540000
  timesteps_this_iter: 5000
  timesteps_total: 8540000
  training_iteration: 1708
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15004 s, 1708 iter, 8540000 ts, 131 rew

agent-1: 78.59999997828753
agent-2: 80.5999999782875
agent-3: 72.5999999782875
agent-4: 68.5999999782875
agent-5: 68.5999999782875
Extrinsic Rewards:
13
15
7
3
3
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 3
Max Reward: 15
Gini Coefficient: 0.33170731707317075
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 134.21349925646814
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1708
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.531
    dispatch_time_ms: 8.076
    learner:
      cur_lr: 0.0007912360015325248
      grad_gnorm: 40.0
      policy_entropy: 34.65936279296875
      policy_loss: 53.123409271240234
      var_gnorm: 23.28367042541504
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 78.29057312011719
    num_steps_sampled: 8545000
    num_steps_trained: 8545000
    wait_time_ms: 72.641
  iterations_since_restore: 1709
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15012.817084312439
  time_this_iter_s: 8.430302381515503
  time_total_s: 15012.817084312439
  timestamp: 1594863574
  timesteps_since_restore: 8545000
  timesteps_this_iter: 5000
  timesteps_total: 8545000
  training_iteration: 1709
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15012 s, 1709 iter, 8545000 ts, 134 rew

agent-1: 45.79999998375758
agent-2: 60.79999998375756
agent-3: 47.79999998375759
agent-4: 47.79999998375758
agent-5: 49.79999998375758
Extrinsic Rewards:
1
16
3
3
5
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 16
Gini Coefficient: 0.45714285714285713
20:20 Ratio: 16.0
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 136.73349925565603
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1709
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.229
    dispatch_time_ms: 8.523
    learner:
      cur_lr: 0.0007909029955044389
      grad_gnorm: 32.35243606567383
      policy_entropy: 34.64352798461914
      policy_loss: -5.427678108215332
      var_gnorm: 23.28517723083496
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.7645681500434875
    num_steps_sampled: 8550000
    num_steps_trained: 8550000
    wait_time_ms: 72.53
  iterations_since_restore: 1710
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15021.347953557968
  time_this_iter_s: 8.530869245529175
  time_total_s: 15021.347953557968
  timestamp: 1594863582
  timesteps_since_restore: 8550000
  timesteps_this_iter: 5000
  timesteps_total: 8550000
  training_iteration: 1710
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15021 s, 1710 iter, 8550000 ts, 137 rew

agent-1: 101.99999901104454
agent-2: 105.99999901104454
agent-3: 111.99999901104454
agent-4: 111.99999901104454
agent-5: 107.99999901104454
Extrinsic Rewards:
6
10
16
16
12
Sum Reward: 60
Avg Reward: 12.0
Min Reward: 6
Max Reward: 16
Gini Coefficient: 0.17333333333333334
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 142.13349920620823
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1710
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.535
    dispatch_time_ms: 8.728
    learner:
      cur_lr: 0.0007905699894763529
      grad_gnorm: 6.060626029968262
      policy_entropy: 13.265132904052734
      policy_loss: 0.3512583374977112
      var_gnorm: 23.284841537475586
      vf_explained_var: 0.0
      vf_loss: 0.029371343553066254
    num_steps_sampled: 8555000
    num_steps_trained: 8555000
    wait_time_ms: 69.589
  iterations_since_restore: 1711
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15029.620638132095
  time_this_iter_s: 8.272684574127197
  time_total_s: 15029.620638132095
  timestamp: 1594863591
  timesteps_since_restore: 8555000
  timesteps_this_iter: 5000
  timesteps_total: 8555000
  training_iteration: 1711
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15029 s, 1711 iter, 8555000 ts, 142 rew

agent-1: 46.99999999860143
agent-2: 43.99999999860143
agent-3: 41.99999999860144
agent-4: 44.99999999860144
agent-5: 46.99999999860144
Extrinsic Rewards:
7
4
2
5
7
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.208
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-39-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 144.3834992061383
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1711
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.476
    dispatch_time_ms: 7.449
    learner:
      cur_lr: 0.000790236983448267
      grad_gnorm: 40.0
      policy_entropy: 33.25404739379883
      policy_loss: 18.678421020507812
      var_gnorm: 23.291929244995117
      vf_explained_var: 0.0
      vf_loss: 8.382145881652832
    num_steps_sampled: 8560000
    num_steps_trained: 8560000
    wait_time_ms: 71.55
  iterations_since_restore: 1712
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15037.690867424011
  time_this_iter_s: 8.070229291915894
  time_total_s: 15037.690867424011
  timestamp: 1594863599
  timesteps_since_restore: 8560000
  timesteps_this_iter: 5000
  timesteps_total: 8560000
  training_iteration: 1712
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15037 s, 1712 iter, 8560000 ts, 144 rew

agent-1: 153.0695237766331
agent-2: 140.06952377663316
agent-3: 139.0695237766332
agent-4: 153.06952377663313
agent-5: 141.06952377663313
Extrinsic Rewards:
24
11
10
24
12
Sum Reward: 81
Avg Reward: 16.2
Min Reward: 10
Max Reward: 24
Gini Coefficient: 0.20246913580246914
20:20 Ratio: 2.4
Max-min Ratio: 2.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 151.64697539496996
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1712
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.38
    dispatch_time_ms: 6.355
    learner:
      cur_lr: 0.000789903977420181
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.954097747802734
      policy_loss: -11.198246955871582
      var_gnorm: 23.29752540588379
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.438419818878174
    num_steps_sampled: 8565000
    num_steps_trained: 8565000
    wait_time_ms: 78.82
  iterations_since_restore: 1713
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15046.10042142868
  time_this_iter_s: 8.40955400466919
  time_total_s: 15046.10042142868
  timestamp: 1594863607
  timesteps_since_restore: 8565000
  timesteps_this_iter: 5000
  timesteps_total: 8565000
  training_iteration: 1713
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15046 s, 1713 iter, 8565000 ts, 152 rew

agent-1: 92.5999820579335
agent-2: 96.59998205793345
agent-3: 92.59998205793347
agent-4: 86.59998205793347
agent-5: 90.59998205793347
Extrinsic Rewards:
11
15
11
5
9
Sum Reward: 51
Avg Reward: 10.2
Min Reward: 5
Max Reward: 15
Gini Coefficient: 0.17254901960784313
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 156.23697449786664
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1713
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.466
    dispatch_time_ms: 8.235
    learner:
      cur_lr: 0.0007895709713920951
      grad_gnorm: 40.0
      policy_entropy: 34.2894287109375
      policy_loss: -8.783215522766113
      var_gnorm: 23.289962768554688
      vf_explained_var: 0.0
      vf_loss: 2.062614917755127
    num_steps_sampled: 8570000
    num_steps_trained: 8570000
    wait_time_ms: 75.602
  iterations_since_restore: 1714
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15054.54786491394
  time_this_iter_s: 8.44744348526001
  time_total_s: 15054.54786491394
  timestamp: 1594863616
  timesteps_since_restore: 8570000
  timesteps_this_iter: 5000
  timesteps_total: 8570000
  training_iteration: 1714
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15054 s, 1714 iter, 8570000 ts, 156 rew

agent-1: 74.99999998646949
agent-2: 71.99999998646949
agent-3: 76.99999998646952
agent-4: 68.99999998646953
agent-5: 66.99999998646949
Extrinsic Rewards:
11
8
13
5
3
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.26
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 159.83697449719014
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1714
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.626
    dispatch_time_ms: 5.29
    learner:
      cur_lr: 0.0007892380235716701
      grad_gnorm: 4.369527816772461
      policy_entropy: 9.316696166992188
      policy_loss: -0.4529040455818176
      var_gnorm: 23.286226272583008
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.014208302833139896
    num_steps_sampled: 8575000
    num_steps_trained: 8575000
    wait_time_ms: 76.174
  iterations_since_restore: 1715
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15062.943006753922
  time_this_iter_s: 8.395141839981079
  time_total_s: 15062.943006753922
  timestamp: 1594863624
  timesteps_since_restore: 8575000
  timesteps_this_iter: 5000
  timesteps_total: 8575000
  training_iteration: 1715
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15062 s, 1715 iter, 8575000 ts, 160 rew

agent-1: 33.399999999107926
agent-2: 31.39999999910782
agent-3: 35.39999999910794
agent-4: 34.39999999910792
agent-5: 36.39999999910794
Extrinsic Rewards:
3
1
5
4
6
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.25263157894736843
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 161.54697449714553
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1715
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.882
    dispatch_time_ms: 7.356
    learner:
      cur_lr: 0.0007889050175435841
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.864501953125
      policy_loss: 23.88239860534668
      var_gnorm: 23.29171371459961
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 15.591704368591309
    num_steps_sampled: 8580000
    num_steps_trained: 8580000
    wait_time_ms: 69.936
  iterations_since_restore: 1716
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15071.1795835495
  time_this_iter_s: 8.236576795578003
  time_total_s: 15071.1795835495
  timestamp: 1594863632
  timesteps_since_restore: 8580000
  timesteps_this_iter: 5000
  timesteps_total: 8580000
  training_iteration: 1716
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15071 s, 1716 iter, 8580000 ts, 162 rew

agent-1: 95.99830792867208
agent-2: 102.99830792867212
agent-3: 104.99830792867209
agent-4: 94.99830792867209
agent-5: 95.99830792867209
Extrinsic Rewards:
8
15
17
7
8
Sum Reward: 55
Avg Reward: 11.0
Min Reward: 7
Max Reward: 17
Gini Coefficient: 0.19636363636363635
20:20 Ratio: 2.4285714285714284
Max-min Ratio: 2.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 166.4968898935791
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1716
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.746
    dispatch_time_ms: 6.553
    learner:
      cur_lr: 0.0007885720115154982
      grad_gnorm: 40.0
      policy_entropy: 34.35806655883789
      policy_loss: -9.165106773376465
      var_gnorm: 23.290721893310547
      vf_explained_var: 0.0
      vf_loss: 2.3089232444763184
    num_steps_sampled: 8585000
    num_steps_trained: 8585000
    wait_time_ms: 80.262
  iterations_since_restore: 1717
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15079.789657115936
  time_this_iter_s: 8.610073566436768
  time_total_s: 15079.789657115936
  timestamp: 1594863641
  timesteps_since_restore: 8585000
  timesteps_this_iter: 5000
  timesteps_total: 8585000
  training_iteration: 1717
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15079 s, 1717 iter, 8585000 ts, 166 rew

agent-1: 124.59977905173596
agent-2: 127.59977905173596
agent-3: 133.59977905173574
agent-4: 126.59977905173594
agent-5: 126.599779051736
Extrinsic Rewards:
11
14
20
13
13
Sum Reward: 71
Avg Reward: 14.2
Min Reward: 11
Max Reward: 20
Gini Coefficient: 0.10704225352112676
20:20 Ratio: 1.8181818181818181
Max-min Ratio: 1.8181818181818181
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 172.8868788461659
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1717
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.423
    dispatch_time_ms: 8.574
    learner:
      cur_lr: 0.0007882390054874122
      grad_gnorm: 24.718820571899414
      policy_entropy: 26.925527572631836
      policy_loss: -3.3815698623657227
      var_gnorm: 23.286867141723633
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.4729181230068207
    num_steps_sampled: 8590000
    num_steps_trained: 8590000
    wait_time_ms: 73.868
  iterations_since_restore: 1718
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15088.42429614067
  time_this_iter_s: 8.634639024734497
  time_total_s: 15088.42429614067
  timestamp: 1594863650
  timesteps_since_restore: 8590000
  timesteps_this_iter: 5000
  timesteps_total: 8590000
  training_iteration: 1718
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15088 s, 1718 iter, 8590000 ts, 173 rew

agent-1: 27.199999999374455
agent-2: 27.199999999374455
agent-3: 30.199999999374448
agent-4: 35.19999999937436
agent-5: 33.19999999937435
Extrinsic Rewards:
0
0
3
8
6
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.5176470588235295
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-40-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 174.4168788461346
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1718
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.647
    dispatch_time_ms: 5.899
    learner:
      cur_lr: 0.0007879059994593263
      grad_gnorm: 5.13812255859375
      policy_entropy: 32.36894607543945
      policy_loss: -0.693960964679718
      var_gnorm: 23.287569046020508
      vf_explained_var: 0.0
      vf_loss: 0.02028375118970871
    num_steps_sampled: 8595000
    num_steps_trained: 8595000
    wait_time_ms: 78.17
  iterations_since_restore: 1719
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15096.945958852768
  time_this_iter_s: 8.521662712097168
  time_total_s: 15096.945958852768
  timestamp: 1594863658
  timesteps_since_restore: 8595000
  timesteps_this_iter: 5000
  timesteps_total: 8595000
  training_iteration: 1719
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15096 s, 1719 iter, 8595000 ts, 174 rew

agent-1: 44.99999999822186
agent-2: 44.99999999822185
agent-3: 44.99999999822186
agent-4: 43.99999999822187
agent-5: 45.99999999822186
Extrinsic Rewards:
5
5
5
4
6
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 4
Max Reward: 6
Gini Coefficient: 0.064
20:20 Ratio: 1.5
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 176.6668788460457
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1719
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.656
    dispatch_time_ms: 6.659
    learner:
      cur_lr: 0.0007875729934312403
      grad_gnorm: 16.668020248413086
      policy_entropy: 34.33184814453125
      policy_loss: -2.765852451324463
      var_gnorm: 23.286924362182617
      vf_explained_var: 0.0
      vf_loss: 0.21132196485996246
    num_steps_sampled: 8600000
    num_steps_trained: 8600000
    wait_time_ms: 78.427
  iterations_since_restore: 1720
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15105.530457735062
  time_this_iter_s: 8.584498882293701
  time_total_s: 15105.530457735062
  timestamp: 1594863667
  timesteps_since_restore: 8600000
  timesteps_this_iter: 5000
  timesteps_total: 8600000
  training_iteration: 1720
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15105 s, 1720 iter, 8600000 ts, 177 rew

agent-1: 67.39999999297706
agent-2: 57.399999992977094
agent-3: 60.399999992977094
agent-4: 54.399999992977094
agent-5: 66.39999999297707
Extrinsic Rewards:
13
3
6
0
12
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.4117647058823529
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 179.72687884569456
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1720
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.821
    dispatch_time_ms: 8.698
    learner:
      cur_lr: 0.0007872399874031544
      grad_gnorm: 3.902444362640381
      policy_entropy: 34.658958435058594
      policy_loss: -0.3810999095439911
      var_gnorm: 23.28837776184082
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.011759631335735321
    num_steps_sampled: 8605000
    num_steps_trained: 8605000
    wait_time_ms: 72.867
  iterations_since_restore: 1721
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15114.139657020569
  time_this_iter_s: 8.609199285507202
  time_total_s: 15114.139657020569
  timestamp: 1594863676
  timesteps_since_restore: 8605000
  timesteps_this_iter: 5000
  timesteps_total: 8605000
  training_iteration: 1721
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15114 s, 1721 iter, 8605000 ts, 180 rew

agent-1: 37.59999999749644
agent-2: 37.59999999749644
agent-3: 42.599999997496454
agent-4: 33.59999999749645
agent-5: 37.59999999749644
Extrinsic Rewards:
4
4
9
0
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.34285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 181.61687884556935
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1721
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.038
    dispatch_time_ms: 8.06
    learner:
      cur_lr: 0.0007869069813750684
      grad_gnorm: 32.389060974121094
      policy_entropy: 30.808731079101562
      policy_loss: -4.991147994995117
      var_gnorm: 23.287628173828125
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.8122192621231079
    num_steps_sampled: 8610000
    num_steps_trained: 8610000
    wait_time_ms: 75.244
  iterations_since_restore: 1722
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15122.772661685944
  time_this_iter_s: 8.633004665374756
  time_total_s: 15122.772661685944
  timestamp: 1594863684
  timesteps_since_restore: 8610000
  timesteps_this_iter: 5000
  timesteps_total: 8610000
  training_iteration: 1722
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15122 s, 1722 iter, 8610000 ts, 182 rew

agent-1: 48.799999987914354
agent-2: 58.79999998791436
agent-3: 47.799999987914354
agent-4: 48.799999987914354
agent-5: 47.79999998791436
Extrinsic Rewards:
4
14
3
4
3
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.32857142857142857
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 184.13687884496505
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1722
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.403
    dispatch_time_ms: 11.532
    learner:
      cur_lr: 0.0007865739753469825
      grad_gnorm: 40.0
      policy_entropy: 31.664384841918945
      policy_loss: 73.29640197753906
      var_gnorm: 23.288427352905273
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 131.20143127441406
    num_steps_sampled: 8615000
    num_steps_trained: 8615000
    wait_time_ms: 70.393
  iterations_since_restore: 1723
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15131.30422949791
  time_this_iter_s: 8.531567811965942
  time_total_s: 15131.30422949791
  timestamp: 1594863693
  timesteps_since_restore: 8615000
  timesteps_this_iter: 5000
  timesteps_total: 8615000
  training_iteration: 1723
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15131 s, 1723 iter, 8615000 ts, 184 rew

agent-1: 102.19999985679745
agent-2: 97.19999985679748
agent-3: 108.19999985679745
agent-4: 110.19999985679745
agent-5: 95.19999985679745
Extrinsic Rewards:
11
6
17
19
4
Sum Reward: 57
Avg Reward: 11.4
Min Reward: 4
Max Reward: 19
Gini Coefficient: 0.28771929824561404
20:20 Ratio: 4.75
Max-min Ratio: 4.75
W0715 21:41:41.977483 26841 client_connection.cc:255] [worker]ProcessMessage with type 19 took 1810 ms.
W0715 21:41:41.996801 26841 node_manager.cc:250] Last heartbeat was sent 1864 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 189.2668788378049
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1723
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.967
    dispatch_time_ms: 13.225
    learner:
      cur_lr: 0.0007862410275265574
      grad_gnorm: 20.435903549194336
      policy_entropy: 25.80934715270996
      policy_loss: -3.2945406436920166
      var_gnorm: 23.288450241088867
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2815771996974945
    num_steps_sampled: 8620000
    num_steps_trained: 8620000
    wait_time_ms: 48.728
  iterations_since_restore: 1724
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15141.03007054329
  time_this_iter_s: 9.725841045379639
  time_total_s: 15141.03007054329
  timestamp: 1594863703
  timesteps_since_restore: 8620000
  timesteps_this_iter: 5000
  timesteps_total: 8620000
  training_iteration: 1724
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15141 s, 1724 iter, 8620000 ts, 189 rew

agent-1: 48.99999998930864
agent-2: 41.99999998930861
agent-3: 45.99999998930863
agent-4: 43.99999998930863
agent-5: 43.99999998930863
Extrinsic Rewards:
9
2
6
4
4
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.256
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-41-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 191.51687883727035
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1724
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.766
    dispatch_time_ms: 5.831
    learner:
      cur_lr: 0.0007859080214984715
      grad_gnorm: 40.00000762939453
      policy_entropy: 18.781936645507812
      policy_loss: 36.705204010009766
      var_gnorm: 23.29048728942871
      vf_explained_var: 0.0
      vf_loss: 35.1855354309082
    num_steps_sampled: 8625000
    num_steps_trained: 8625000
    wait_time_ms: 80.575
  iterations_since_restore: 1725
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15149.70179605484
  time_this_iter_s: 8.671725511550903
  time_total_s: 15149.70179605484
  timestamp: 1594863711
  timesteps_since_restore: 8625000
  timesteps_this_iter: 5000
  timesteps_total: 8625000
  training_iteration: 1725
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15149 s, 1725 iter, 8625000 ts, 192 rew

agent-1: 32.399999999231696
agent-2: 34.39999999923174
agent-3: 33.39999999923173
agent-4: 35.39999999923176
agent-5: 35.39999999923175
Extrinsic Rewards:
2
4
3
5
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.16842105263157894
20:20 Ratio: 2.5
Max-min Ratio: 2.5
W0715 21:41:57.317096 26841 client_connection.cc:255] [worker]ProcessMessage with type 19 took 1763 ms.
W0715 21:41:57.317389 26841 node_manager.cc:250] Last heartbeat was sent 1767 ms ago 
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 193.22687883723194
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1725
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.893
    dispatch_time_ms: 21.751
    learner:
      cur_lr: 0.0007855750154703856
      grad_gnorm: 40.0
      policy_entropy: 24.93916893005371
      policy_loss: 5.657162666320801
      var_gnorm: 23.288841247558594
      vf_explained_var: 0.0
      vf_loss: 2.143033981323242
    num_steps_sampled: 8630000
    num_steps_trained: 8630000
    wait_time_ms: 58.031
  iterations_since_restore: 1726
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15159.533485412598
  time_this_iter_s: 9.831689357757568
  time_total_s: 15159.533485412598
  timestamp: 1594863721
  timesteps_since_restore: 8630000
  timesteps_this_iter: 5000
  timesteps_total: 8630000
  training_iteration: 1726
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15159 s, 1726 iter, 8630000 ts, 193 rew

agent-1: 35.39999999928985
agent-2: 32.39999999928983
agent-3: 34.39999999928983
agent-4: 33.39999999928982
agent-5: 35.39999999928985
Extrinsic Rewards:
5
2
4
3
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.16842105263157894
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 194.93687883719642
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1726
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.835
    dispatch_time_ms: 24.634
    learner:
      cur_lr: 0.0007852420094422996
      grad_gnorm: 40.0
      policy_entropy: 29.79846954345703
      policy_loss: 48.008575439453125
      var_gnorm: 23.265552520751953
      vf_explained_var: 0.0
      vf_loss: 98.79576110839844
    num_steps_sampled: 8635000
    num_steps_trained: 8635000
    wait_time_ms: 66.93
  iterations_since_restore: 1727
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15168.735333681107
  time_this_iter_s: 9.201848268508911
  time_total_s: 15168.735333681107
  timestamp: 1594863730
  timesteps_since_restore: 8635000
  timesteps_this_iter: 5000
  timesteps_total: 8635000
  training_iteration: 1727
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15168 s, 1727 iter, 8635000 ts, 195 rew

agent-1: 115.99999889186913
agent-2: 111.99999889186913
agent-3: 115.99999889186913
agent-4: 115.99999889186914
agent-5: 124.99999889186917
Extrinsic Rewards:
12
8
12
12
21
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 8
Max Reward: 21
Gini Coefficient: 0.16
20:20 Ratio: 2.625
Max-min Ratio: 2.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 200.78687878178988
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1727
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.251
    dispatch_time_ms: 28.986
    learner:
      cur_lr: 0.0007849090034142137
      grad_gnorm: 12.377159118652344
      policy_entropy: 34.228248596191406
      policy_loss: -4.341642379760742
      var_gnorm: 23.26569938659668
      vf_explained_var: 0.0
      vf_loss: 0.11862003803253174
    num_steps_sampled: 8640000
    num_steps_trained: 8640000
    wait_time_ms: 59.11
  iterations_since_restore: 1728
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15177.857479095459
  time_this_iter_s: 9.122145414352417
  time_total_s: 15177.857479095459
  timestamp: 1594863739
  timesteps_since_restore: 8640000
  timesteps_this_iter: 5000
  timesteps_total: 8640000
  training_iteration: 1728
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15177 s, 1728 iter, 8640000 ts, 201 rew

agent-1: 41.999999998043755
agent-2: 44.999999998043755
agent-3: 43.99999999804375
agent-4: 49.999999998043755
agent-5: 43.999999998043755
Extrinsic Rewards:
2
5
4
10
4
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.272
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 203.03687878169202
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1728
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.866
    dispatch_time_ms: 33.369
    learner:
      cur_lr: 0.0007845759973861277
      grad_gnorm: 40.0
      policy_entropy: 31.89495849609375
      policy_loss: 28.855712890625
      var_gnorm: 23.265581130981445
      vf_explained_var: 0.0
      vf_loss: 25.983076095581055
    num_steps_sampled: 8645000
    num_steps_trained: 8645000
    wait_time_ms: 54.658
  iterations_since_restore: 1729
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15187.033050775528
  time_this_iter_s: 9.17557168006897
  time_total_s: 15187.033050775528
  timestamp: 1594863749
  timesteps_since_restore: 8645000
  timesteps_this_iter: 5000
  timesteps_total: 8645000
  training_iteration: 1729
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15187 s, 1729 iter, 8645000 ts, 203 rew

agent-1: 31.799999999117404
agent-2: 33.79999999911744
agent-3: 32.79999999911743
agent-4: 32.79999999911743
agent-5: 30.799999999117404
Extrinsic Rewards:
3
5
4
4
2
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.15555555555555556
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 204.6568787816479
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1729
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.65
    dispatch_time_ms: 28.967
    learner:
      cur_lr: 0.0007842429913580418
      grad_gnorm: 35.490726470947266
      policy_entropy: 32.62323760986328
      policy_loss: -6.507770538330078
      var_gnorm: 23.273149490356445
      vf_explained_var: 0.0
      vf_loss: 0.9636662602424622
    num_steps_sampled: 8650000
    num_steps_trained: 8650000
    wait_time_ms: 64.781
  iterations_since_restore: 1730
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15196.10686969757
  time_this_iter_s: 9.073818922042847
  time_total_s: 15196.10686969757
  timestamp: 1594863758
  timesteps_since_restore: 8650000
  timesteps_this_iter: 5000
  timesteps_total: 8650000
  training_iteration: 1730
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15196 s, 1730 iter, 8650000 ts, 205 rew

agent-1: 80.39998584077095
agent-2: 80.39998584077094
agent-3: 80.39998584077097
agent-4: 70.39998584077101
agent-5: 84.39998584077095
Extrinsic Rewards:
10
10
10
0
14
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.2545454545454545
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 208.6168780736864
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1730
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.437
    dispatch_time_ms: 23.395
    learner:
      cur_lr: 0.0007839099853299558
      grad_gnorm: 40.0
      policy_entropy: 13.796873092651367
      policy_loss: 8.482444763183594
      var_gnorm: 23.266937255859375
      vf_explained_var: 0.0
      vf_loss: 13.964564323425293
    num_steps_sampled: 8655000
    num_steps_trained: 8655000
    wait_time_ms: 64.426
  iterations_since_restore: 1731
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15205.243654489517
  time_this_iter_s: 9.136784791946411
  time_total_s: 15205.243654489517
  timestamp: 1594863767
  timesteps_since_restore: 8655000
  timesteps_this_iter: 5000
  timesteps_total: 8655000
  training_iteration: 1731
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15205 s, 1731 iter, 8655000 ts, 209 rew

agent-1: 55.19999998243473
agent-2: 60.19999998243475
agent-3: 62.19999998243475
agent-4: 56.19999998243475
agent-5: 54.19999998243475
Extrinsic Rewards:
4
9
11
5
3
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.2625
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-42-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 211.49687807280822
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1731
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.782
    dispatch_time_ms: 33.11
    learner:
      cur_lr: 0.0007835769793018699
      grad_gnorm: 40.0
      policy_entropy: 17.942319869995117
      policy_loss: 7.536117076873779
      var_gnorm: 23.268901824951172
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 19.480066299438477
    num_steps_sampled: 8660000
    num_steps_trained: 8660000
    wait_time_ms: 61.828
  iterations_since_restore: 1732
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15214.527639389038
  time_this_iter_s: 9.283984899520874
  time_total_s: 15214.527639389038
  timestamp: 1594863776
  timesteps_since_restore: 8660000
  timesteps_this_iter: 5000
  timesteps_total: 8660000
  training_iteration: 1732
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15214 s, 1732 iter, 8660000 ts, 211 rew

agent-1: 32.199999999527655
agent-2: 31.19999999952763
agent-3: 29.19999999952763
agent-4: 32.199999999527655
agent-5: 28.19999999952763
Extrinsic Rewards:
5
4
2
5
1
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 5
Gini Coefficient: 0.25882352941176473
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 213.02687807278457
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1732
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.913
    dispatch_time_ms: 32.413
    learner:
      cur_lr: 0.0007832439732737839
      grad_gnorm: 40.0
      policy_entropy: 11.868901252746582
      policy_loss: 24.70462417602539
      var_gnorm: 23.267131805419922
      vf_explained_var: 0.0
      vf_loss: 49.3329963684082
    num_steps_sampled: 8665000
    num_steps_trained: 8665000
    wait_time_ms: 56.137
  iterations_since_restore: 1733
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15223.73349905014
  time_this_iter_s: 9.205859661102295
  time_total_s: 15223.73349905014
  timestamp: 1594863786
  timesteps_since_restore: 8665000
  timesteps_this_iter: 5000
  timesteps_total: 8665000
  training_iteration: 1733
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15223 s, 1733 iter, 8665000 ts, 213 rew

agent-1: 113.99999662054564
agent-2: 110.99999662054559
agent-3: 115.99999662054562
agent-4: 122.99999662054567
agent-5: 120.99999662054567
Extrinsic Rewards:
10
7
12
19
17
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 7
Max Reward: 19
Gini Coefficient: 0.19076923076923077
20:20 Ratio: 2.7142857142857144
Max-min Ratio: 2.7142857142857144
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 218.87687790381187
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1733
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.871
    dispatch_time_ms: 32.799
    learner:
      cur_lr: 0.0007829110254533589
      grad_gnorm: 8.644230842590332
      policy_entropy: 34.654449462890625
      policy_loss: -3.982387065887451
      var_gnorm: 23.26717758178711
      vf_explained_var: 0.0
      vf_loss: 0.13180091977119446
    num_steps_sampled: 8670000
    num_steps_trained: 8670000
    wait_time_ms: 1103.282
  iterations_since_restore: 1734
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15243.366642475128
  time_this_iter_s: 19.633143424987793
  time_total_s: 15243.366642475128
  timestamp: 1594863805
  timesteps_since_restore: 8670000
  timesteps_this_iter: 5000
  timesteps_total: 8670000
  training_iteration: 1734
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15243 s, 1734 iter, 8670000 ts, 219 rew

agent-1: 46.79999997971858
agent-2: 52.79999997971859
agent-3: 50.799999979718585
agent-4: 50.799999979718585
agent-5: 50.79999997971857
Extrinsic Rewards:
2
8
6
6
6
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.17142857142857143
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 221.39687790279774
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1734
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 9.517
    learner:
      cur_lr: 0.0007825780194252729
      grad_gnorm: 1.9067323207855225
      policy_entropy: 4.204239845275879
      policy_loss: -0.007843852043151855
      var_gnorm: 23.268775939941406
      vf_explained_var: 0.0
      vf_loss: 0.0028053962159901857
    num_steps_sampled: 8675000
    num_steps_trained: 8675000
    wait_time_ms: 70.824
  iterations_since_restore: 1735
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15251.148166656494
  time_this_iter_s: 7.781524181365967
  time_total_s: 15251.148166656494
  timestamp: 1594863813
  timesteps_since_restore: 8675000
  timesteps_this_iter: 5000
  timesteps_total: 8675000
  training_iteration: 1735
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15251 s, 1735 iter, 8675000 ts, 221 rew

agent-1: 41.399999996946235
agent-2: 38.399999996946235
agent-3: 49.39999999694622
agent-4: 40.39999999694622
agent-5: 46.39999999694623
Extrinsic Rewards:
3
0
11
2
8
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.4666666666666667
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 223.5568779026451
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1735
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.907
    dispatch_time_ms: 6.259
    learner:
      cur_lr: 0.000782245013397187
      grad_gnorm: 40.000003814697266
      policy_entropy: 21.785058975219727
      policy_loss: 34.69667053222656
      var_gnorm: 23.270893096923828
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 38.291099548339844
    num_steps_sampled: 8680000
    num_steps_trained: 8680000
    wait_time_ms: 74.355
  iterations_since_restore: 1736
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15259.356043338776
  time_this_iter_s: 8.207876682281494
  time_total_s: 15259.356043338776
  timestamp: 1594863821
  timesteps_since_restore: 8680000
  timesteps_this_iter: 5000
  timesteps_total: 8680000
  training_iteration: 1736
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15259 s, 1736 iter, 8680000 ts, 224 rew

agent-1: 68.19810546711058
agent-2: 70.19810546711057
agent-3: 72.19810546711057
agent-4: 59.19810546711062
agent-5: 63.19810546711062
Extrinsic Rewards:
9
11
13
0
4
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.3567567567567568
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 226.88678317600062
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1736
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.578
    dispatch_time_ms: 6.685
    learner:
      cur_lr: 0.000781912007369101
      grad_gnorm: 31.893293380737305
      policy_entropy: 28.403596878051758
      policy_loss: -5.017557144165039
      var_gnorm: 23.269344329833984
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.7641915678977966
    num_steps_sampled: 8685000
    num_steps_trained: 8685000
    wait_time_ms: 71.77
  iterations_since_restore: 1737
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15267.84727859497
  time_this_iter_s: 8.491235256195068
  time_total_s: 15267.84727859497
  timestamp: 1594863830
  timesteps_since_restore: 8685000
  timesteps_this_iter: 5000
  timesteps_total: 8685000
  training_iteration: 1737
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15267 s, 1737 iter, 8685000 ts, 227 rew

agent-1: 72.1999496837187
agent-2: 63.199949683718835
agent-3: 59.199949683718835
agent-4: 71.19994968371874
agent-5: 67.19994968371874
Extrinsic Rewards:
13
4
0
12
8
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.3675675675675676
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-43-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 824.6185465268809
  episode_reward_mean: 230.21678066018652
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1737
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.991
    dispatch_time_ms: 8.638
    learner:
      cur_lr: 0.0007815790013410151
      grad_gnorm: 40.0
      policy_entropy: 32.38396453857422
      policy_loss: -9.953075408935547
      var_gnorm: 23.275968551635742
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.688239574432373
    num_steps_sampled: 8690000
    num_steps_trained: 8690000
    wait_time_ms: 72.764
  iterations_since_restore: 1738
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15276.29489159584
  time_this_iter_s: 8.447613000869751
  time_total_s: 15276.29489159584
  timestamp: 1594863838
  timesteps_since_restore: 8690000
  timesteps_this_iter: 5000
  timesteps_total: 8690000
  training_iteration: 1738
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15276 s, 1738 iter, 8690000 ts, 230 rew

agent-1: 197.78301882153153
agent-2: 181.78301882153153
agent-3: 184.78301882153153
agent-4: 188.78301882153153
agent-5: 190.7830188215314
Extrinsic Rewards:
30
14
17
21
23
Sum Reward: 105
Avg Reward: 21.0
Min Reward: 14
Max Reward: 30
Gini Coefficient: 0.14476190476190476
20:20 Ratio: 2.142857142857143
Max-min Ratio: 2.142857142857143
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 239.65593160126306
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1738
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.942
    dispatch_time_ms: 6.486
    learner:
      cur_lr: 0.0007812459953129292
      grad_gnorm: 40.0
      policy_entropy: 21.46274185180664
      policy_loss: 46.92906951904297
      var_gnorm: 23.272348403930664
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 110.6990737915039
    num_steps_sampled: 8695000
    num_steps_trained: 8695000
    wait_time_ms: 76.82
  iterations_since_restore: 1739
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15284.892920732498
  time_this_iter_s: 8.598029136657715
  time_total_s: 15284.892920732498
  timestamp: 1594863847
  timesteps_since_restore: 8695000
  timesteps_this_iter: 5000
  timesteps_total: 8695000
  training_iteration: 1739
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15284 s, 1739 iter, 8695000 ts, 240 rew

agent-1: 37.59999999818227
agent-2: 38.59999999818227
agent-3: 35.599999998182284
agent-4: 41.59999999818228
agent-5: 35.599999998182284
Extrinsic Rewards:
4
5
2
8
2
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2857142857142857
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 241.54593160117219
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1739
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.692
    dispatch_time_ms: 9.924
    learner:
      cur_lr: 0.0007809129892848432
      grad_gnorm: 38.60747146606445
      policy_entropy: 21.621273040771484
      policy_loss: -3.0967979431152344
      var_gnorm: 23.277257919311523
      vf_explained_var: 0.0
      vf_loss: 1.1049058437347412
    num_steps_sampled: 8700000
    num_steps_trained: 8700000
    wait_time_ms: 75.584
  iterations_since_restore: 1740
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15293.57491850853
  time_this_iter_s: 8.681997776031494
  time_total_s: 15293.57491850853
  timestamp: 1594863856
  timesteps_since_restore: 8700000
  timesteps_this_iter: 5000
  timesteps_total: 8700000
  training_iteration: 1740
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15293 s, 1740 iter, 8700000 ts, 242 rew

agent-1: 78.79999995940186
agent-2: 71.79999995940187
agent-3: 75.79999995940187
agent-4: 77.79999995940186
agent-5: 82.79999995940186
Extrinsic Rewards:
10
3
7
9
14
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.23255813953488372
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 245.4159315991423
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1740
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.579
    dispatch_time_ms: 6.197
    learner:
      cur_lr: 0.0007805799832567573
      grad_gnorm: 40.000003814697266
      policy_entropy: 26.846538543701172
      policy_loss: 60.26809310913086
      var_gnorm: 23.267663955688477
      vf_explained_var: 0.0
      vf_loss: 153.01849365234375
    num_steps_sampled: 8705000
    num_steps_trained: 8705000
    wait_time_ms: 76.392
  iterations_since_restore: 1741
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15302.179040431976
  time_this_iter_s: 8.604121923446655
  time_total_s: 15302.179040431976
  timestamp: 1594863864
  timesteps_since_restore: 8705000
  timesteps_this_iter: 5000
  timesteps_total: 8705000
  training_iteration: 1741
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15302 s, 1741 iter, 8705000 ts, 245 rew

agent-1: 103.59999967323306
agent-2: 109.59999967323307
agent-3: 113.59999967323307
agent-4: 113.59999967323307
agent-5: 108.59999967323307
Extrinsic Rewards:
6
12
16
16
11
Sum Reward: 61
Avg Reward: 12.2
Min Reward: 6
Max Reward: 16
Gini Coefficient: 0.16393442622950818
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 250.90593158280402
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1741
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.55
    dispatch_time_ms: 7.756
    learner:
      cur_lr: 0.0007802469772286713
      grad_gnorm: 20.099994659423828
      policy_entropy: 16.415264129638672
      policy_loss: -2.7426955699920654
      var_gnorm: 23.24739646911621
      vf_explained_var: 0.0
      vf_loss: 0.29097887873649597
    num_steps_sampled: 8710000
    num_steps_trained: 8710000
    wait_time_ms: 74.499
  iterations_since_restore: 1742
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15310.80992269516
  time_this_iter_s: 8.630882263183594
  time_total_s: 15310.80992269516
  timestamp: 1594863873
  timesteps_since_restore: 8710000
  timesteps_this_iter: 5000
  timesteps_total: 8710000
  training_iteration: 1742
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15310 s, 1742 iter, 8710000 ts, 251 rew

agent-1: 90.19999997704977
agent-2: 107.19999997704974
agent-3: 93.19999997704974
agent-4: 90.19999997704974
agent-5: 87.19999997704974
Extrinsic Rewards:
7
24
10
7
4
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 4
Max Reward: 24
Gini Coefficient: 0.33076923076923076
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 255.58593158165644
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1742
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.658
    dispatch_time_ms: 8.807
    learner:
      cur_lr: 0.0007799139712005854
      grad_gnorm: 3.5825560092926025
      policy_entropy: 17.423255920410156
      policy_loss: -0.3099045157432556
      var_gnorm: 23.245630264282227
      vf_explained_var: 0.0
      vf_loss: 0.009934517554938793
    num_steps_sampled: 8715000
    num_steps_trained: 8715000
    wait_time_ms: 73.628
  iterations_since_restore: 1743
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15319.491106748581
  time_this_iter_s: 8.68118405342102
  time_total_s: 15319.491106748581
  timestamp: 1594863882
  timesteps_since_restore: 8715000
  timesteps_this_iter: 5000
  timesteps_total: 8715000
  training_iteration: 1743
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15319 s, 1743 iter, 8715000 ts, 256 rew

agent-1: 46.599999998407625
agent-2: 50.59999999840762
agent-3: 45.599999998407625
agent-4: 47.59999999840762
agent-5: 43.599999998407625
Extrinsic Rewards:
5
9
4
6
2
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.24615384615384617
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 257.92593158157683
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1743
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.697
    dispatch_time_ms: 8.113
    learner:
      cur_lr: 0.0007795810233801603
      grad_gnorm: 36.39052200317383
      policy_entropy: 26.246868133544922
      policy_loss: -4.899072170257568
      var_gnorm: 23.249223709106445
      vf_explained_var: 0.0
      vf_loss: 1.0239077806472778
    num_steps_sampled: 8720000
    num_steps_trained: 8720000
    wait_time_ms: 75.309
  iterations_since_restore: 1744
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15328.13221859932
  time_this_iter_s: 8.641111850738525
  time_total_s: 15328.13221859932
  timestamp: 1594863890
  timesteps_since_restore: 8720000
  timesteps_this_iter: 5000
  timesteps_total: 8720000
  training_iteration: 1744
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15328 s, 1744 iter, 8720000 ts, 258 rew

agent-1: 127.39999637552016
agent-2: 111.39999637552022
agent-3: 125.39999637552019
agent-4: 127.39999637552016
agent-5: 129.3999963755204
Extrinsic Rewards:
17
1
15
17
19
Sum Reward: 69
Avg Reward: 13.8
Min Reward: 1
Max Reward: 19
Gini Coefficient: 0.22028985507246376
20:20 Ratio: 19.0
Max-min Ratio: 19.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-44-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 264.13593140035283
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1744
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.806
    dispatch_time_ms: 9.433
    learner:
      cur_lr: 0.0007792480173520744
      grad_gnorm: 5.2728729248046875
      policy_entropy: 29.4429988861084
      policy_loss: -0.6854478716850281
      var_gnorm: 23.245105743408203
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.02087034285068512
    num_steps_sampled: 8725000
    num_steps_trained: 8725000
    wait_time_ms: 73.993
  iterations_since_restore: 1745
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15336.748294591904
  time_this_iter_s: 8.616075992584229
  time_total_s: 15336.748294591904
  timestamp: 1594863899
  timesteps_since_restore: 8725000
  timesteps_this_iter: 5000
  timesteps_total: 8725000
  training_iteration: 1745
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15336 s, 1745 iter, 8725000 ts, 264 rew

agent-1: 36.1999999983603
agent-2: 39.19999999836032
agent-3: 41.19999999836031
agent-4: 41.19999999836031
agent-5: 40.199999998360305
Extrinsic Rewards:
1
4
6
6
5
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 6
Gini Coefficient: 0.21818181818181817
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-08
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 266.11593140027094
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1745
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.794
    dispatch_time_ms: 8.196
    learner:
      cur_lr: 0.0007789150113239884
      grad_gnorm: 15.04480266571045
      policy_entropy: 30.65631866455078
      policy_loss: -2.7119550704956055
      var_gnorm: 23.245641708374023
      vf_explained_var: 0.0
      vf_loss: 0.15670862793922424
    num_steps_sampled: 8730000
    num_steps_trained: 8730000
    wait_time_ms: 77.109
  iterations_since_restore: 1746
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15345.449295520782
  time_this_iter_s: 8.701000928878784
  time_total_s: 15345.449295520782
  timestamp: 1594863908
  timesteps_since_restore: 8730000
  timesteps_this_iter: 5000
  timesteps_total: 8730000
  training_iteration: 1746
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15345 s, 1746 iter, 8730000 ts, 266 rew

agent-1: 34.39999999911894
agent-2: 33.39999999911895
agent-3: 37.39999999911894
agent-4: 31.399999999119025
agent-5: 34.39999999911895
Extrinsic Rewards:
4
3
7
1
4
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.2736842105263158
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 267.82593140022686
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1746
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.666
    dispatch_time_ms: 6.82
    learner:
      cur_lr: 0.0007785820052959025
      grad_gnorm: 40.00000762939453
      policy_entropy: 24.81808853149414
      policy_loss: 58.75994110107422
      var_gnorm: 23.24522590637207
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 129.1627197265625
    num_steps_sampled: 8735000
    num_steps_trained: 8735000
    wait_time_ms: 74.69
  iterations_since_restore: 1747
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15354.124548435211
  time_this_iter_s: 8.675252914428711
  time_total_s: 15354.124548435211
  timestamp: 1594863916
  timesteps_since_restore: 8735000
  timesteps_this_iter: 5000
  timesteps_total: 8735000
  training_iteration: 1747
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15354 s, 1747 iter, 8735000 ts, 268 rew

agent-1: 56.19999999675158
agent-2: 50.199999996751586
agent-3: 43.19999999675158
agent-4: 49.19999999675158
agent-5: 44.19999999675158
Extrinsic Rewards:
13
7
0
6
1
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.4740740740740741
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 270.2559314000644
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1747
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.738
    dispatch_time_ms: 32.294
    learner:
      cur_lr: 0.0007782489992678165
      grad_gnorm: 14.089676856994629
      policy_entropy: 26.29325294494629
      policy_loss: -3.1177690029144287
      var_gnorm: 23.24833869934082
      vf_explained_var: 0.0
      vf_loss: 0.2216162085533142
    num_steps_sampled: 8740000
    num_steps_trained: 8740000
    wait_time_ms: 64.666
  iterations_since_restore: 1748
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15363.25351190567
  time_this_iter_s: 9.128963470458984
  time_total_s: 15363.25351190567
  timestamp: 1594863926
  timesteps_since_restore: 8740000
  timesteps_this_iter: 5000
  timesteps_total: 8740000
  training_iteration: 1748
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15363 s, 1748 iter, 8740000 ts, 270 rew

agent-1: 67.9999999834187
agent-2: 60.999999983418675
agent-3: 58.99999998341867
agent-4: 65.99999998341868
agent-5: 60.999999983418675
Extrinsic Rewards:
12
5
3
10
5
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.26285714285714284
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 273.4059313992353
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1748
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.571
    dispatch_time_ms: 39.554
    learner:
      cur_lr: 0.0007779159932397306
      grad_gnorm: 40.0
      policy_entropy: 14.66727066040039
      policy_loss: 6.462195873260498
      var_gnorm: 23.2459659576416
      vf_explained_var: 0.0
      vf_loss: 70.64302825927734
    num_steps_sampled: 8745000
    num_steps_trained: 8745000
    wait_time_ms: 49.741
  iterations_since_restore: 1749
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15372.38098859787
  time_this_iter_s: 9.127476692199707
  time_total_s: 15372.38098859787
  timestamp: 1594863935
  timesteps_since_restore: 8745000
  timesteps_this_iter: 5000
  timesteps_total: 8745000
  training_iteration: 1749
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15372 s, 1749 iter, 8745000 ts, 273 rew

agent-1: 90.39999987062802
agent-2: 96.399999870628
agent-3: 101.39999987062802
agent-4: 99.39999987062802
agent-5: 98.399999870628
Extrinsic Rewards:
4
10
15
13
12
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 4
Max Reward: 15
Gini Coefficient: 0.18518518518518517
20:20 Ratio: 3.75
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 278.26593139276673
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1749
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.689
    dispatch_time_ms: 40.684
    learner:
      cur_lr: 0.0007775829872116446
      grad_gnorm: 36.8089599609375
      policy_entropy: 17.371381759643555
      policy_loss: -6.006844997406006
      var_gnorm: 23.253864288330078
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.2260922193527222
    num_steps_sampled: 8750000
    num_steps_trained: 8750000
    wait_time_ms: 51.867
  iterations_since_restore: 1750
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15381.516229391098
  time_this_iter_s: 9.13524079322815
  time_total_s: 15381.516229391098
  timestamp: 1594863944
  timesteps_since_restore: 8750000
  timesteps_this_iter: 5000
  timesteps_total: 8750000
  training_iteration: 1750
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15381 s, 1750 iter, 8750000 ts, 278 rew

agent-1: 154.5999855741394
agent-2: 154.59998557413934
agent-3: 152.59998557413934
agent-4: 156.59998557413934
agent-5: 155.5999855741394
Extrinsic Rewards:
17
17
15
19
18
Sum Reward: 86
Avg Reward: 17.2
Min Reward: 15
Max Reward: 19
Gini Coefficient: 0.04186046511627907
20:20 Ratio: 1.2666666666666666
Max-min Ratio: 1.2666666666666666
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-45-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 286.0059306714736
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1750
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.989
    dispatch_time_ms: 21.117
    learner:
      cur_lr: 0.0007772499811835587
      grad_gnorm: 40.0
      policy_entropy: 31.396080017089844
      policy_loss: 60.76227569580078
      var_gnorm: 23.245269775390625
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 95.9128189086914
    num_steps_sampled: 8755000
    num_steps_trained: 8755000
    wait_time_ms: 64.577
  iterations_since_restore: 1751
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15390.659901857376
  time_this_iter_s: 9.143672466278076
  time_total_s: 15390.659901857376
  timestamp: 1594863953
  timesteps_since_restore: 8755000
  timesteps_this_iter: 5000
  timesteps_total: 8755000
  training_iteration: 1751
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15390 s, 1751 iter, 8755000 ts, 286 rew

agent-1: 74.99999998625619
agent-2: 68.99999998625617
agent-3: 73.99999998625619
agent-4: 72.99999998625617
agent-5: 68.99999998625617
Extrinsic Rewards:
11
5
10
9
5
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 5
Max Reward: 11
Gini Coefficient: 0.17
20:20 Ratio: 2.2
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 289.60593067078645
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1751
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.568
    dispatch_time_ms: 27.118
    learner:
      cur_lr: 0.0007769169751554728
      grad_gnorm: 16.818994522094727
      policy_entropy: 30.17348289489746
      policy_loss: -2.902913808822632
      var_gnorm: 23.245874404907227
      vf_explained_var: 0.0
      vf_loss: 0.20173956453800201
    num_steps_sampled: 8760000
    num_steps_trained: 8760000
    wait_time_ms: 57.572
  iterations_since_restore: 1752
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15399.860621929169
  time_this_iter_s: 9.200720071792603
  time_total_s: 15399.860621929169
  timestamp: 1594863962
  timesteps_since_restore: 8760000
  timesteps_this_iter: 5000
  timesteps_total: 8760000
  training_iteration: 1752
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15399 s, 1752 iter, 8760000 ts, 290 rew

agent-1: 48.79999999862579
agent-2: 36.7999999986258
agent-3: 36.7999999986258
agent-4: 42.7999999986258
agent-5: 41.79999999862581
Extrinsic Rewards:
12
0
0
6
5
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.5217391304347826
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 291.6759306707177
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1752
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.181
    dispatch_time_ms: 26.07
    learner:
      cur_lr: 0.0007765840273350477
      grad_gnorm: 40.0
      policy_entropy: 33.54005432128906
      policy_loss: 28.47615623474121
      var_gnorm: 23.24493408203125
      vf_explained_var: 0.0
      vf_loss: 26.072460174560547
    num_steps_sampled: 8765000
    num_steps_trained: 8765000
    wait_time_ms: 73.985
  iterations_since_restore: 1753
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15409.043166160583
  time_this_iter_s: 9.182544231414795
  time_total_s: 15409.043166160583
  timestamp: 1594863972
  timesteps_since_restore: 8765000
  timesteps_this_iter: 5000
  timesteps_total: 8765000
  training_iteration: 1753
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15409 s, 1753 iter, 8765000 ts, 292 rew

agent-1: 57.199999998099145
agent-2: 61.19999999809913
agent-3: 55.199999998099145
agent-4: 62.19999999809914
agent-5: 52.199999998099145
Extrinsic Rewards:
6
10
4
11
1
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.325
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 294.5559306706227
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1753
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.721
    dispatch_time_ms: 35.52
    learner:
      cur_lr: 0.0007762510213069618
      grad_gnorm: 25.323680877685547
      policy_entropy: 24.92613410949707
      policy_loss: -2.7001307010650635
      var_gnorm: 23.24718475341797
      vf_explained_var: 0.0
      vf_loss: 0.4759005606174469
    num_steps_sampled: 8770000
    num_steps_trained: 8770000
    wait_time_ms: 55.596
  iterations_since_restore: 1754
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15418.00156879425
  time_this_iter_s: 8.958402633666992
  time_total_s: 15418.00156879425
  timestamp: 1594863981
  timesteps_since_restore: 8770000
  timesteps_this_iter: 5000
  timesteps_total: 8770000
  training_iteration: 1754
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15418 s, 1754 iter, 8770000 ts, 295 rew

agent-1: 76.39999989985365
agent-2: 67.39999989985367
agent-3: 69.39999989985368
agent-4: 69.39999989985368
agent-5: 68.39999989985368
Extrinsic Rewards:
14
5
7
7
6
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 5
Max Reward: 14
Gini Coefficient: 0.19487179487179487
20:20 Ratio: 2.8
Max-min Ratio: 2.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 298.0659306656153
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1754
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.481
    dispatch_time_ms: 10.184
    learner:
      cur_lr: 0.0007759180152788758
      grad_gnorm: 3.360384702682495
      policy_entropy: 15.125458717346191
      policy_loss: -0.003437136532738805
      var_gnorm: 23.245847702026367
      vf_explained_var: 0.0
      vf_loss: 0.008737422525882721
    num_steps_sampled: 8775000
    num_steps_trained: 8775000
    wait_time_ms: 69.877
  iterations_since_restore: 1755
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15426.734857559204
  time_this_iter_s: 8.733288764953613
  time_total_s: 15426.734857559204
  timestamp: 1594863989
  timesteps_since_restore: 8775000
  timesteps_this_iter: 5000
  timesteps_total: 8775000
  training_iteration: 1755
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15426 s, 1755 iter, 8775000 ts, 298 rew

agent-1: 44.3999999960063
agent-2: 43.3999999960063
agent-3: 38.3999999960063
agent-4: 49.3999999960063
agent-5: 40.3999999960063
Extrinsic Rewards:
6
5
0
11
2
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.43333333333333335
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 300.22593066541566
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1755
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.643
    dispatch_time_ms: 8.992
    learner:
      cur_lr: 0.0007755850092507899
      grad_gnorm: 18.487239837646484
      policy_entropy: 21.111783981323242
      policy_loss: -1.4409968852996826
      var_gnorm: 23.248046875
      vf_explained_var: 0.0
      vf_loss: 0.25373589992523193
    num_steps_sampled: 8780000
    num_steps_trained: 8780000
    wait_time_ms: 74.384
  iterations_since_restore: 1756
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15435.323209285736
  time_this_iter_s: 8.588351726531982
  time_total_s: 15435.323209285736
  timestamp: 1594863998
  timesteps_since_restore: 8780000
  timesteps_this_iter: 5000
  timesteps_total: 8780000
  training_iteration: 1756
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15435 s, 1756 iter, 8780000 ts, 300 rew

agent-1: 41.59999999849268
agent-2: 38.5999999984927
agent-3: 38.5999999984927
agent-4: 36.599999998492706
agent-5: 33.599999998492734
Extrinsic Rewards:
8
5
5
3
0
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.34285714285714286
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 302.11593066534033
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1756
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.087
    dispatch_time_ms: 8.508
    learner:
      cur_lr: 0.0007752520032227039
      grad_gnorm: 3.7672250270843506
      policy_entropy: 27.39370346069336
      policy_loss: -0.47506189346313477
      var_gnorm: 23.24517822265625
      vf_explained_var: 0.0
      vf_loss: 0.010990552604198456
    num_steps_sampled: 8785000
    num_steps_trained: 8785000
    wait_time_ms: 77.979
  iterations_since_restore: 1757
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15444.021425485611
  time_this_iter_s: 8.698216199874878
  time_total_s: 15444.021425485611
  timestamp: 1594864007
  timesteps_since_restore: 8785000
  timesteps_this_iter: 5000
  timesteps_total: 8785000
  training_iteration: 1757
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15444 s, 1757 iter, 8785000 ts, 302 rew

agent-1: 64.79999980447293
agent-2: 69.79999980447296
agent-3: 71.79999980447298
agent-4: 68.79999980447296
agent-5: 66.79999980447295
Extrinsic Rewards:
4
9
11
8
6
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 4
Max Reward: 11
Gini Coefficient: 0.17894736842105263
20:20 Ratio: 2.75
Max-min Ratio: 2.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-46-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 305.53593065556396
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1757
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.888
    dispatch_time_ms: 7.193
    learner:
      cur_lr: 0.000774918997194618
      grad_gnorm: 9.103562355041504
      policy_entropy: 24.997634887695312
      policy_loss: -1.3394800424575806
      var_gnorm: 23.245508193969727
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.06153290346264839
    num_steps_sampled: 8790000
    num_steps_trained: 8790000
    wait_time_ms: 74.755
  iterations_since_restore: 1758
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15452.698558330536
  time_this_iter_s: 8.677132844924927
  time_total_s: 15452.698558330536
  timestamp: 1594864015
  timesteps_since_restore: 8790000
  timesteps_this_iter: 5000
  timesteps_total: 8790000
  training_iteration: 1758
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15452 s, 1758 iter, 8790000 ts, 306 rew

agent-1: 31.199999999544495
agent-2: 29.199999999544488
agent-3: 35.199999999544424
agent-4: 28.199999999544495
agent-5: 29.199999999544488
Extrinsic Rewards:
4
2
8
1
2
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.3764705882352941
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 307.06593065554114
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1758
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.931
    dispatch_time_ms: 7.718
    learner:
      cur_lr: 0.000774585991166532
      grad_gnorm: 2.9091744422912598
      policy_entropy: 23.980344772338867
      policy_loss: 0.001953727565705776
      var_gnorm: 23.245302200317383
      vf_explained_var: 0.0
      vf_loss: 0.006306462921202183
    num_steps_sampled: 8795000
    num_steps_trained: 8795000
    wait_time_ms: 77.835
  iterations_since_restore: 1759
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15461.355943202972
  time_this_iter_s: 8.657384872436523
  time_total_s: 15461.355943202972
  timestamp: 1594864024
  timesteps_since_restore: 8795000
  timesteps_this_iter: 5000
  timesteps_total: 8795000
  training_iteration: 1759
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15461 s, 1759 iter, 8795000 ts, 307 rew

agent-1: 36.79999999912263
agent-2: 45.79999999912263
agent-3: 41.799999999122626
agent-4: 39.79999999912263
agent-5: 42.799999999122626
Extrinsic Rewards:
0
9
5
3
6
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.3652173913043478
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 309.1359306554973
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1759
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.965
    dispatch_time_ms: 8.59
    learner:
      cur_lr: 0.0007742529851384461
      grad_gnorm: 8.96437931060791
      policy_entropy: 30.97216033935547
      policy_loss: -1.5326869487762451
      var_gnorm: 23.245281219482422
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0613214448094368
    num_steps_sampled: 8800000
    num_steps_trained: 8800000
    wait_time_ms: 73.717
  iterations_since_restore: 1760
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15469.997789382935
  time_this_iter_s: 8.641846179962158
  time_total_s: 15469.997789382935
  timestamp: 1594864033
  timesteps_since_restore: 8800000
  timesteps_this_iter: 5000
  timesteps_total: 8800000
  training_iteration: 1760
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15469 s, 1760 iter, 8800000 ts, 309 rew

agent-1: 25.599999999374507
agent-2: 28.599999999374514
agent-3: 27.599999999374514
agent-4: 28.599999999374514
agent-5: 33.59999999937452
Extrinsic Rewards:
0
3
2
3
8
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.425
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 310.575930655466
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1760
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.142
    dispatch_time_ms: 7.912
    learner:
      cur_lr: 0.0007739199791103601
      grad_gnorm: 40.0
      policy_entropy: 31.1995792388916
      policy_loss: 56.059329986572266
      var_gnorm: 23.245019912719727
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 103.92489624023438
    num_steps_sampled: 8805000
    num_steps_trained: 8805000
    wait_time_ms: 75.446
  iterations_since_restore: 1761
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15478.530101060867
  time_this_iter_s: 8.53231167793274
  time_total_s: 15478.530101060867
  timestamp: 1594864041
  timesteps_since_restore: 8805000
  timesteps_this_iter: 5000
  timesteps_total: 8805000
  training_iteration: 1761
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15478 s, 1761 iter, 8805000 ts, 311 rew

agent-1: 37.59999999924047
agent-2: 35.59999999924046
agent-3: 38.59999999924047
agent-4: 39.599999999240474
agent-5: 37.59999999924047
Extrinsic Rewards:
4
2
5
6
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.17142857142857143
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 312.465930655428
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1761
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.151
    dispatch_time_ms: 8.114
    learner:
      cur_lr: 0.0007735869730822742
      grad_gnorm: 11.128068923950195
      policy_entropy: 34.622398376464844
      policy_loss: -2.0363447666168213
      var_gnorm: 23.24528694152832
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.08819591253995895
    num_steps_sampled: 8810000
    num_steps_trained: 8810000
    wait_time_ms: 72.051
  iterations_since_restore: 1762
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15487.00958275795
  time_this_iter_s: 8.47948169708252
  time_total_s: 15487.00958275795
  timestamp: 1594864050
  timesteps_since_restore: 8810000
  timesteps_this_iter: 5000
  timesteps_total: 8810000
  training_iteration: 1762
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15487 s, 1762 iter, 8810000 ts, 312 rew

agent-1: 46.399999998237604
agent-2: 40.3999999982376
agent-3: 41.399999998237604
agent-4: 44.3999999982376
agent-5: 43.39999999823759
Extrinsic Rewards:
8
2
3
6
5
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.25
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 314.6259306553399
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1762
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.735
    dispatch_time_ms: 7.235
    learner:
      cur_lr: 0.0007732540252618492
      grad_gnorm: 3.2803194522857666
      policy_entropy: 34.578853607177734
      policy_loss: -0.15631850063800812
      var_gnorm: 23.244937896728516
      vf_explained_var: 0.0
      vf_loss: 0.007980133406817913
    num_steps_sampled: 8815000
    num_steps_trained: 8815000
    wait_time_ms: 76.693
  iterations_since_restore: 1763
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15495.7248005867
  time_this_iter_s: 8.71521782875061
  time_total_s: 15495.7248005867
  timestamp: 1594864059
  timesteps_since_restore: 8815000
  timesteps_this_iter: 5000
  timesteps_total: 8815000
  training_iteration: 1763
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15495 s, 1763 iter, 8815000 ts, 315 rew

agent-1: 45.99999999881928
agent-2: 41.99999999881927
agent-3: 47.99999999881928
agent-4: 43.99999999881927
agent-5: 44.99999999881927
Extrinsic Rewards:
6
2
8
4
5
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.224
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 316.8759306552809
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1763
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.628
    dispatch_time_ms: 7.914
    learner:
      cur_lr: 0.0007729210192337632
      grad_gnorm: 14.682193756103516
      policy_entropy: 34.64241409301758
      policy_loss: -2.6249325275421143
      var_gnorm: 23.245542526245117
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.1464426964521408
    num_steps_sampled: 8820000
    num_steps_trained: 8820000
    wait_time_ms: 71.429
  iterations_since_restore: 1764
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15504.20087313652
  time_this_iter_s: 8.476072549819946
  time_total_s: 15504.20087313652
  timestamp: 1594864067
  timesteps_since_restore: 8820000
  timesteps_this_iter: 5000
  timesteps_total: 8820000
  training_iteration: 1764
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15504 s, 1764 iter, 8820000 ts, 317 rew

agent-1: 39.99999999668116
agent-2: 44.99999999668115
agent-3: 41.99999999668116
agent-4: 50.99999999668113
agent-5: 46.99999999668115
Extrinsic Rewards:
0
5
2
11
7
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.432
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-47-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 319.1259306551149
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1764
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.008
    dispatch_time_ms: 8.736
    learner:
      cur_lr: 0.0007725880132056773
      grad_gnorm: 40.0
      policy_entropy: 33.64653015136719
      policy_loss: 65.69113159179688
      var_gnorm: 23.244964599609375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 135.58470153808594
    num_steps_sampled: 8825000
    num_steps_trained: 8825000
    wait_time_ms: 74.188
  iterations_since_restore: 1765
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15512.621979951859
  time_this_iter_s: 8.421106815338135
  time_total_s: 15512.621979951859
  timestamp: 1594864076
  timesteps_since_restore: 8825000
  timesteps_this_iter: 5000
  timesteps_total: 8825000
  training_iteration: 1765
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15512 s, 1765 iter, 8825000 ts, 319 rew

agent-1: 46.799999997629804
agent-2: 51.79999999762979
agent-3: 47.799999997629804
agent-4: 57.79999999762979
agent-5: 47.799999997629804
Extrinsic Rewards:
2
7
3
13
3
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 13
Gini Coefficient: 0.37142857142857144
20:20 Ratio: 6.5
Max-min Ratio: 6.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 321.6459306549964
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1765
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.779
    dispatch_time_ms: 5.714
    learner:
      cur_lr: 0.0007722550071775913
      grad_gnorm: 10.839690208435059
      policy_entropy: 31.61684226989746
      policy_loss: -2.18994140625
      var_gnorm: 23.245399475097656
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.08799690008163452
    num_steps_sampled: 8830000
    num_steps_trained: 8830000
    wait_time_ms: 74.144
  iterations_since_restore: 1766
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15521.175198793411
  time_this_iter_s: 8.553218841552734
  time_total_s: 15521.175198793411
  timestamp: 1594864084
  timesteps_since_restore: 8830000
  timesteps_this_iter: 5000
  timesteps_total: 8830000
  training_iteration: 1766
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15521 s, 1766 iter, 8830000 ts, 322 rew

agent-1: 39.1999999991719
agent-2: 37.19999999917189
agent-3: 37.19999999917189
agent-4: 42.1999999991719
agent-5: 42.1999999991719
Extrinsic Rewards:
4
2
2
7
7
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.2727272727272727
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 323.625930654955
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1766
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.203
    dispatch_time_ms: 7.884
    learner:
      cur_lr: 0.0007719220011495054
      grad_gnorm: 2.233365535736084
      policy_entropy: 32.70932388305664
      policy_loss: -0.10018368065357208
      var_gnorm: 23.244991302490234
      vf_explained_var: 0.0
      vf_loss: 0.0032700439915060997
    num_steps_sampled: 8835000
    num_steps_trained: 8835000
    wait_time_ms: 73.988
  iterations_since_restore: 1767
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15529.620567560196
  time_this_iter_s: 8.445368766784668
  time_total_s: 15529.620567560196
  timestamp: 1594864093
  timesteps_since_restore: 8835000
  timesteps_this_iter: 5000
  timesteps_total: 8835000
  training_iteration: 1767
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15529 s, 1767 iter, 8835000 ts, 324 rew

agent-1: 49.59999999823432
agent-2: 45.5999999982343
agent-3: 47.59999999823431
agent-4: 42.5999999982343
agent-5: 48.59999999823432
Extrinsic Rewards:
8
4
6
1
7
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.26153846153846155
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 325.9659306548667
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1767
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.095
    dispatch_time_ms: 9.295
    learner:
      cur_lr: 0.0007715889951214194
      grad_gnorm: 21.791004180908203
      policy_entropy: 16.979280471801758
      policy_loss: -2.5847225189208984
      var_gnorm: 23.247407913208008
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.3568688929080963
    num_steps_sampled: 8840000
    num_steps_trained: 8840000
    wait_time_ms: 74.419
  iterations_since_restore: 1768
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15538.211992502213
  time_this_iter_s: 8.591424942016602
  time_total_s: 15538.211992502213
  timestamp: 1594864101
  timesteps_since_restore: 8840000
  timesteps_this_iter: 5000
  timesteps_total: 8840000
  training_iteration: 1768
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15538 s, 1768 iter, 8840000 ts, 326 rew

agent-1: 33.999999999006626
agent-2: 41.99999999900664
agent-3: 31.999999999006572
agent-4: 33.999999999006626
agent-5: 37.99999999900665
Extrinsic Rewards:
2
10
0
2
6
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.48
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 327.76593065481705
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1768
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.582
    dispatch_time_ms: 7.9
    learner:
      cur_lr: 0.0007712559890933335
      grad_gnorm: 40.000003814697266
      policy_entropy: 18.347013473510742
      policy_loss: 17.34067726135254
      var_gnorm: 23.245643615722656
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 43.23152160644531
    num_steps_sampled: 8845000
    num_steps_trained: 8845000
    wait_time_ms: 72.972
  iterations_since_restore: 1769
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15546.736520051956
  time_this_iter_s: 8.524527549743652
  time_total_s: 15546.736520051956
  timestamp: 1594864110
  timesteps_since_restore: 8845000
  timesteps_this_iter: 5000
  timesteps_total: 8845000
  training_iteration: 1769
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15546 s, 1769 iter, 8845000 ts, 328 rew

agent-1: 93.99999996243028
agent-2: 84.9999999624303
agent-3: 90.99999996243027
agent-4: 91.99999996243027
agent-5: 87.9999999624303
Extrinsic Rewards:
14
5
11
12
8
Sum Reward: 50
Avg Reward: 10.0
Min Reward: 5
Max Reward: 14
Gini Coefficient: 0.176
20:20 Ratio: 2.8
Max-min Ratio: 2.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 332.2659306529387
  episode_reward_min: 0.0
  episodes_this_iter: 1
  episodes_total: 1769
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.053
    dispatch_time_ms: 6.752
    learner:
      cur_lr: 0.0007709229830652475
      grad_gnorm: 16.458288192749023
      policy_entropy: 27.522192001342773
      policy_loss: 2.6603610515594482
      var_gnorm: 23.261125564575195
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 0.2158259153366089
    num_steps_sampled: 8850000
    num_steps_trained: 8850000
    wait_time_ms: 79.427
  iterations_since_restore: 1770
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15555.315640926361
  time_this_iter_s: 8.579120874404907
  time_total_s: 15555.315640926361
  timestamp: 1594864118
  timesteps_since_restore: 8850000
  timesteps_this_iter: 5000
  timesteps_total: 8850000
  training_iteration: 1770
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15555 s, 1770 iter, 8850000 ts, 332 rew

agent-1: 110.99999772560528
agent-2: 126.99999772560525
agent-3: 113.99999772560531
agent-4: 119.99999772560528
agent-5: 112.99999772560528
Extrinsic Rewards:
7
23
10
16
9
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 7
Max Reward: 23
Gini Coefficient: 0.24
20:20 Ratio: 3.2857142857142856
Max-min Ratio: 3.2857142857142856
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 338.1159305392189
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1770
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.592
    dispatch_time_ms: 7.859
    learner:
      cur_lr: 0.0007705899770371616
      grad_gnorm: 40.0
      policy_entropy: 34.07839584350586
      policy_loss: 31.270084381103516
      var_gnorm: 23.245380401611328
      vf_explained_var: 0.0
      vf_loss: 29.46896743774414
    num_steps_sampled: 8855000
    num_steps_trained: 8855000
    wait_time_ms: 77.43
  iterations_since_restore: 1771
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15563.990188360214
  time_this_iter_s: 8.67454743385315
  time_total_s: 15563.990188360214
  timestamp: 1594864127
  timesteps_since_restore: 8855000
  timesteps_this_iter: 5000
  timesteps_total: 8855000
  training_iteration: 1771
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15563 s, 1771 iter, 8855000 ts, 338 rew

agent-1: 113.1999979344103
agent-2: 107.19999793441025
agent-3: 108.19999793441028
agent-4: 113.1999979344103
agent-5: 116.19999793441028
Extrinsic Rewards:
14
8
9
14
17
Sum Reward: 62
Avg Reward: 12.4
Min Reward: 8
Max Reward: 17
Gini Coefficient: 0.14838709677419354
20:20 Ratio: 2.125
Max-min Ratio: 2.125
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-48-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 341.5681942917113
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1771
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.182
    dispatch_time_ms: 9.752
    learner:
      cur_lr: 0.0007702569710090756
      grad_gnorm: 12.831575393676758
      policy_entropy: 32.79762649536133
      policy_loss: -2.1781911849975586
      var_gnorm: 23.245521545410156
      vf_explained_var: 0.0
      vf_loss: 0.11481394618749619
    num_steps_sampled: 8860000
    num_steps_trained: 8860000
    wait_time_ms: 72.437
  iterations_since_restore: 1772
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15572.576699733734
  time_this_iter_s: 8.586511373519897
  time_total_s: 15572.576699733734
  timestamp: 1594864136
  timesteps_since_restore: 8860000
  timesteps_this_iter: 5000
  timesteps_total: 8860000
  training_iteration: 1772
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15572 s, 1772 iter, 8860000 ts, 342 rew

agent-1: 34.19999999949946
agent-2: 29.199999999499383
agent-3: 34.19999999949946
agent-4: 27.199999999499383
agent-5: 28.199999999499386
Extrinsic Rewards:
7
2
7
0
1
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.47058823529411764
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 340.5781943019717
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1772
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.747
    dispatch_time_ms: 7.805
    learner:
      cur_lr: 0.0007699240231886506
      grad_gnorm: 40.0
      policy_entropy: 32.91669845581055
      policy_loss: 35.70216369628906
      var_gnorm: 23.245037078857422
      vf_explained_var: 0.0
      vf_loss: 52.01845169067383
    num_steps_sampled: 8865000
    num_steps_trained: 8865000
    wait_time_ms: 72.613
  iterations_since_restore: 1773
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15581.228226184845
  time_this_iter_s: 8.65152645111084
  time_total_s: 15581.228226184845
  timestamp: 1594864144
  timesteps_since_restore: 8865000
  timesteps_this_iter: 5000
  timesteps_total: 8865000
  training_iteration: 1773
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15581 s, 1773 iter, 8865000 ts, 341 rew

agent-1: 51.999999997812836
agent-2: 55.99999999781283
agent-3: 49.999999997812836
agent-4: 49.99999999781283
agent-5: 61.999999997812814
Extrinsic Rewards:
4
8
2
2
14
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.4
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 337.1584387965376
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1773
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.134
    dispatch_time_ms: 8.529
    learner:
      cur_lr: 0.0007695910171605647
      grad_gnorm: 12.949082374572754
      policy_entropy: 29.82192039489746
      policy_loss: -1.9374117851257324
      var_gnorm: 23.245668411254883
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.12642768025398254
    num_steps_sampled: 8870000
    num_steps_trained: 8870000
    wait_time_ms: 74.589
  iterations_since_restore: 1774
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15589.864326000214
  time_this_iter_s: 8.636099815368652
  time_total_s: 15589.864326000214
  timestamp: 1594864153
  timesteps_since_restore: 8870000
  timesteps_this_iter: 5000
  timesteps_total: 8870000
  training_iteration: 1774
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15589 s, 1774 iter, 8870000 ts, 337 rew

agent-1: 38.799999998571046
agent-2: 46.799999998571046
agent-3: 40.79999999857104
agent-4: 38.799999998571046
agent-5: 41.799999998571046
Extrinsic Rewards:
2
10
4
2
5
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.33043478260869563
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 332.5684395137789
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1774
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.62
    dispatch_time_ms: 5.894
    learner:
      cur_lr: 0.0007692580111324787
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.540077209472656
      policy_loss: 49.535091400146484
      var_gnorm: 23.24506378173828
      vf_explained_var: 0.0
      vf_loss: 83.47464752197266
    num_steps_sampled: 8875000
    num_steps_trained: 8875000
    wait_time_ms: 77.231
  iterations_since_restore: 1775
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15598.43210554123
  time_this_iter_s: 8.567779541015625
  time_total_s: 15598.43210554123
  timestamp: 1594864162
  timesteps_since_restore: 8875000
  timesteps_this_iter: 5000
  timesteps_total: 8875000
  training_iteration: 1775
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15598 s, 1775 iter, 8875000 ts, 333 rew

agent-1: 50.599999997354296
agent-2: 44.59999999735431
agent-3: 46.59999999735431
agent-4: 45.59999999735431
agent-5: 46.59999999735431
Extrinsic Rewards:
9
3
5
4
5
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.2
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 330.76843952197646
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1775
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.256
    dispatch_time_ms: 8.165
    learner:
      cur_lr: 0.0007689250051043928
      grad_gnorm: 9.465676307678223
      policy_entropy: 12.900781631469727
      policy_loss: -0.4550476372241974
      var_gnorm: 23.246427536010742
      vf_explained_var: 0.0
      vf_loss: 0.06898002326488495
    num_steps_sampled: 8880000
    num_steps_trained: 8880000
    wait_time_ms: 77.829
  iterations_since_restore: 1776
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15607.114954710007
  time_this_iter_s: 8.682849168777466
  time_total_s: 15607.114954710007
  timestamp: 1594864170
  timesteps_since_restore: 8880000
  timesteps_this_iter: 5000
  timesteps_total: 8880000
  training_iteration: 1776
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15607 s, 1776 iter, 8880000 ts, 331 rew

agent-1: 48.999999996458975
agent-2: 46.99999999645897
agent-3: 40.99999999645894
agent-4: 43.99999999645897
agent-5: 43.99999999645896
Extrinsic Rewards:
9
7
1
4
4
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.304
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 329.9584395225556
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1776
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.619
    dispatch_time_ms: 9.147
    learner:
      cur_lr: 0.0007685919990763068
      grad_gnorm: 2.870413303375244
      policy_entropy: 19.20330810546875
      policy_loss: -0.14872513711452484
      var_gnorm: 23.245651245117188
      vf_explained_var: 0.0
      vf_loss: 0.006377038080245256
    num_steps_sampled: 8885000
    num_steps_trained: 8885000
    wait_time_ms: 74.218
  iterations_since_restore: 1777
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15615.747032165527
  time_this_iter_s: 8.63207745552063
  time_total_s: 15615.747032165527
  timestamp: 1594864179
  timesteps_since_restore: 8885000
  timesteps_this_iter: 5000
  timesteps_total: 8885000
  training_iteration: 1777
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15615 s, 1777 iter, 8885000 ts, 330 rew

agent-1: 26.599999999564915
agent-2: 27.599999999564915
agent-3: 27.599999999564908
agent-4: 27.599999999564908
agent-5: 34.59999999956485
Extrinsic Rewards:
1
2
2
2
9
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 328.8784395226446
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1777
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.584
    dispatch_time_ms: 6.317
    learner:
      cur_lr: 0.0007682589930482209
      grad_gnorm: 21.79627227783203
      policy_entropy: 20.01544189453125
      policy_loss: -2.1678290367126465
      var_gnorm: 23.248445510864258
      vf_explained_var: 0.0
      vf_loss: 0.36428210139274597
    num_steps_sampled: 8890000
    num_steps_trained: 8890000
    wait_time_ms: 78.576
  iterations_since_restore: 1778
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15624.452058076859
  time_this_iter_s: 8.705025911331177
  time_total_s: 15624.452058076859
  timestamp: 1594864188
  timesteps_since_restore: 8890000
  timesteps_this_iter: 5000
  timesteps_total: 8890000
  training_iteration: 1778
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15624 s, 1778 iter, 8890000 ts, 329 rew

agent-1: 31.399999998825777
agent-2: 34.399999998825734
agent-3: 40.39999999882571
agent-4: 31.399999998825773
agent-5: 33.39999999882573
Extrinsic Rewards:
1
4
10
1
3
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.4421052631578947
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-49-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 324.73844570112277
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1778
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.114
    dispatch_time_ms: 7.867
    learner:
      cur_lr: 0.0007679259870201349
      grad_gnorm: 3.305683135986328
      policy_entropy: 16.50657844543457
      policy_loss: -0.08868278563022614
      var_gnorm: 23.245851516723633
      vf_explained_var: 0.0
      vf_loss: 0.008459120988845825
    num_steps_sampled: 8895000
    num_steps_trained: 8895000
    wait_time_ms: 74.441
  iterations_since_restore: 1779
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15633.147948741913
  time_this_iter_s: 8.695890665054321
  time_total_s: 15633.147948741913
  timestamp: 1594864197
  timesteps_since_restore: 8895000
  timesteps_this_iter: 5000
  timesteps_total: 8895000
  training_iteration: 1779
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15633 s, 1779 iter, 8895000 ts, 325 rew

agent-1: 89.19999979976647
agent-2: 84.19999979976649
agent-3: 84.19999979976649
agent-4: 83.19999979976649
agent-5: 82.19999979976654
Extrinsic Rewards:
14
9
9
8
7
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 7
Max Reward: 14
Gini Coefficient: 0.1276595744680851
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 324.738445756334
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1779
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.783
    dispatch_time_ms: 7.236
    learner:
      cur_lr: 0.000767592980992049
      grad_gnorm: 19.48884391784668
      policy_entropy: 31.699962615966797
      policy_loss: -3.373466968536377
      var_gnorm: 23.246337890625
      vf_explained_var: 0.0
      vf_loss: 0.2938455641269684
    num_steps_sampled: 8900000
    num_steps_trained: 8900000
    wait_time_ms: 77.3
  iterations_since_restore: 1780
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15641.764159440994
  time_this_iter_s: 8.616210699081421
  time_total_s: 15641.764159440994
  timestamp: 1594864205
  timesteps_since_restore: 8900000
  timesteps_this_iter: 5000
  timesteps_total: 8900000
  training_iteration: 1780
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15641 s, 1780 iter, 8900000 ts, 325 rew

agent-1: 38.7999999786737
agent-2: 42.799999978673696
agent-3: 38.7999999786737
agent-4: 46.79999997867372
agent-5: 39.799999978673696
Extrinsic Rewards:
2
6
2
10
3
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.34782608695652173
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 321.31844683990164
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1780
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.568
    dispatch_time_ms: 5.836
    learner:
      cur_lr: 0.000767259974963963
      grad_gnorm: 3.027872085571289
      policy_entropy: 28.64739418029785
      policy_loss: -0.26526352763175964
      var_gnorm: 23.24524688720703
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.007099930662661791
    num_steps_sampled: 8905000
    num_steps_trained: 8905000
    wait_time_ms: 80.665
  iterations_since_restore: 1781
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15650.446798801422
  time_this_iter_s: 8.682639360427856
  time_total_s: 15650.446798801422
  timestamp: 1594864214
  timesteps_since_restore: 8905000
  timesteps_this_iter: 5000
  timesteps_total: 8905000
  training_iteration: 1781
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15650 s, 1781 iter, 8905000 ts, 321 rew

agent-1: 53.39999999524049
agent-2: 49.399999995240506
agent-3: 50.3999999952405
agent-4: 56.39999999524052
agent-5: 51.399999995240506
Extrinsic Rewards:
7
3
4
10
5
Sum Reward: 29
Avg Reward: 5.8
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.23448275862068965
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 320.77844684032783
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1781
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 8.88
    learner:
      cur_lr: 0.000766927027143538
      grad_gnorm: 24.16912269592285
      policy_entropy: 26.54414176940918
      policy_loss: 3.561727285385132
      var_gnorm: 23.248308181762695
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.46467024087905884
    num_steps_sampled: 8910000
    num_steps_trained: 8910000
    wait_time_ms: 74.545
  iterations_since_restore: 1782
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15659.000942707062
  time_this_iter_s: 8.554143905639648
  time_total_s: 15659.000942707062
  timestamp: 1594864223
  timesteps_since_restore: 8910000
  timesteps_this_iter: 5000
  timesteps_total: 8910000
  training_iteration: 1782
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15659 s, 1782 iter, 8910000 ts, 321 rew

agent-1: 30.199999999332093
agent-2: 27.199999999332093
agent-3: 36.19999999933212
agent-4: 29.199999999332093
agent-5: 30.19999999933209
Extrinsic Rewards:
3
0
9
2
3
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.4470588235294118
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 320.41844684032844
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1782
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 8.311
    learner:
      cur_lr: 0.000766594021115452
      grad_gnorm: 40.0
      policy_entropy: 34.55119705200195
      policy_loss: 52.239933013916016
      var_gnorm: 23.24509048461914
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 73.0089340209961
    num_steps_sampled: 8915000
    num_steps_trained: 8915000
    wait_time_ms: 73.433
  iterations_since_restore: 1783
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15667.648519515991
  time_this_iter_s: 8.647576808929443
  time_total_s: 15667.648519515991
  timestamp: 1594864231
  timesteps_since_restore: 8915000
  timesteps_this_iter: 5000
  timesteps_total: 8915000
  training_iteration: 1783
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15667 s, 1783 iter, 8915000 ts, 320 rew

agent-1: 99.19999900480025
agent-2: 101.19999900480022
agent-3: 109.19999900480022
agent-4: 101.19999900480025
agent-5: 102.19999900480025
Extrinsic Rewards:
8
10
18
10
11
Sum Reward: 57
Avg Reward: 11.4
Min Reward: 8
Max Reward: 18
Gini Coefficient: 0.14736842105263157
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 323.7484467906065
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1783
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.057
    dispatch_time_ms: 9.393
    learner:
      cur_lr: 0.0007662610150873661
      grad_gnorm: 19.492746353149414
      policy_entropy: 34.604278564453125
      policy_loss: -3.789543867111206
      var_gnorm: 23.246379852294922
      vf_explained_var: 0.0
      vf_loss: 0.2925082743167877
    num_steps_sampled: 8920000
    num_steps_trained: 8920000
    wait_time_ms: 74.742
  iterations_since_restore: 1784
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15676.252367258072
  time_this_iter_s: 8.603847742080688
  time_total_s: 15676.252367258072
  timestamp: 1594864240
  timesteps_since_restore: 8920000
  timesteps_this_iter: 5000
  timesteps_total: 8920000
  training_iteration: 1784
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15676 s, 1784 iter, 8920000 ts, 324 rew

agent-1: 32.399999999416195
agent-2: 37.39999999941619
agent-3: 32.3999999994162
agent-4: 31.399999999416302
agent-5: 37.39999999941619
Extrinsic Rewards:
2
7
2
1
7
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.35789473684210527
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 323.748446790629
  episode_reward_min: 134.9999999980043
  episodes_this_iter: 1
  episodes_total: 1784
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.753
    dispatch_time_ms: 6.272
    learner:
      cur_lr: 0.0007659280090592802
      grad_gnorm: 3.106640577316284
      policy_entropy: 30.691843032836914
      policy_loss: 0.1408001333475113
      var_gnorm: 23.24521255493164
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.006926910486072302
    num_steps_sampled: 8925000
    num_steps_trained: 8925000
    wait_time_ms: 78.622
  iterations_since_restore: 1785
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15684.891748905182
  time_this_iter_s: 8.639381647109985
  time_total_s: 15684.891748905182
  timestamp: 1594864249
  timesteps_since_restore: 8925000
  timesteps_this_iter: 5000
  timesteps_total: 8925000
  training_iteration: 1785
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15684 s, 1785 iter, 8925000 ts, 324 rew

agent-1: 57.79999997875111
agent-2: 54.79999997875111
agent-3: 68.79999997875103
agent-4: 57.79999997875112
agent-5: 57.79999997875112
Extrinsic Rewards:
5
2
16
5
5
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.3393939393939394
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-50-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 325.36844678958647
  episode_reward_min: 134.999999998222
  episodes_this_iter: 1
  episodes_total: 1785
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.644
    dispatch_time_ms: 9.086
    learner:
      cur_lr: 0.0007655950030311942
      grad_gnorm: 20.195083618164062
      policy_entropy: 19.096363067626953
      policy_loss: -2.3565735816955566
      var_gnorm: 23.246992111206055
      vf_explained_var: 0.0
      vf_loss: 0.31233134865760803
    num_steps_sampled: 8930000
    num_steps_trained: 8930000
    wait_time_ms: 75.507
  iterations_since_restore: 1786
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15693.575590610504
  time_this_iter_s: 8.683841705322266
  time_total_s: 15693.575590610504
  timestamp: 1594864257
  timesteps_since_restore: 8930000
  timesteps_this_iter: 5000
  timesteps_total: 8930000
  training_iteration: 1786
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15693 s, 1786 iter, 8930000 ts, 325 rew

agent-1: 39.59999999933973
agent-2: 37.59999999933974
agent-3: 40.59999999933972
agent-4: 33.599999999339715
agent-5: 37.59999999933973
Extrinsic Rewards:
6
4
7
0
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.3047619047619048
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 324.9184467904544
  episode_reward_min: 134.999999998222
  episodes_this_iter: 1
  episodes_total: 1786
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.524
    dispatch_time_ms: 9.694
    learner:
      cur_lr: 0.0007652619970031083
      grad_gnorm: 3.2744009494781494
      policy_entropy: 18.323904037475586
      policy_loss: -0.3621333837509155
      var_gnorm: 23.245803833007812
      vf_explained_var: 0.0
      vf_loss: 0.00823573675006628
    num_steps_sampled: 8935000
    num_steps_trained: 8935000
    wait_time_ms: 73.923
  iterations_since_restore: 1787
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15702.186841487885
  time_this_iter_s: 8.611250877380371
  time_total_s: 15702.186841487885
  timestamp: 1594864266
  timesteps_since_restore: 8935000
  timesteps_this_iter: 5000
  timesteps_total: 8935000
  training_iteration: 1787
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15702 s, 1787 iter, 8935000 ts, 325 rew

agent-1: 67.59999998130391
agent-2: 70.59999998130392
agent-3: 78.59999998130388
agent-4: 81.59999998130388
agent-5: 70.59999998130394
Extrinsic Rewards:
2
5
13
16
5
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.35121951219512193
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 326.71844678956967
  episode_reward_min: 134.999999998222
  episodes_this_iter: 1
  episodes_total: 1787
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.912
    dispatch_time_ms: 10.021
    learner:
      cur_lr: 0.0007649289909750223
      grad_gnorm: 13.829279899597168
      policy_entropy: 20.520984649658203
      policy_loss: -1.3035050630569458
      var_gnorm: 23.246273040771484
      vf_explained_var: 0.0
      vf_loss: 0.14577756822109222
    num_steps_sampled: 8940000
    num_steps_trained: 8940000
    wait_time_ms: 72.087
  iterations_since_restore: 1788
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15710.821318387985
  time_this_iter_s: 8.634476900100708
  time_total_s: 15710.821318387985
  timestamp: 1594864275
  timesteps_since_restore: 8940000
  timesteps_this_iter: 5000
  timesteps_total: 8940000
  training_iteration: 1788
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15710 s, 1788 iter, 8940000 ts, 327 rew

agent-1: 41.79999999691737
agent-2: 39.79999999691738
agent-3: 36.79999999691738
agent-4: 41.79999999691738
agent-5: 46.79999999691739
Extrinsic Rewards:
5
3
0
5
10
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.3826086956521739
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 322.3086046099042
  episode_reward_min: 134.999999998222
  episodes_this_iter: 1
  episodes_total: 1788
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.9
    dispatch_time_ms: 8.852
    learner:
      cur_lr: 0.0007645959849469364
      grad_gnorm: 39.999996185302734
      policy_entropy: 18.917415618896484
      policy_loss: 41.43697738647461
      var_gnorm: 23.24578285217285
      vf_explained_var: 0.0
      vf_loss: 124.64964294433594
    num_steps_sampled: 8945000
    num_steps_trained: 8945000
    wait_time_ms: 74.798
  iterations_since_restore: 1789
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15719.599036216736
  time_this_iter_s: 8.77771782875061
  time_total_s: 15719.599036216736
  timestamp: 1594864283
  timesteps_since_restore: 8945000
  timesteps_this_iter: 5000
  timesteps_total: 8945000
  training_iteration: 1789
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15719 s, 1789 iter, 8945000 ts, 322 rew

agent-1: 43.59999999777023
agent-2: 49.59999999777023
agent-3: 48.59999999777023
agent-4: 49.59999999777024
agent-5: 42.59999999777023
Extrinsic Rewards:
2
8
7
8
1
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.3076923076923077
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 320.23860695050706
  episode_reward_min: 134.999999998222
  episodes_this_iter: 1
  episodes_total: 1789
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.304
    dispatch_time_ms: 6.012
    learner:
      cur_lr: 0.0007642629789188504
      grad_gnorm: 25.056556701660156
      policy_entropy: 25.35384178161621
      policy_loss: -3.1580300331115723
      var_gnorm: 23.247377395629883
      vf_explained_var: 0.0
      vf_loss: 0.4831019639968872
    num_steps_sampled: 8950000
    num_steps_trained: 8950000
    wait_time_ms: 81.782
  iterations_since_restore: 1790
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15728.20642542839
  time_this_iter_s: 8.607389211654663
  time_total_s: 15728.20642542839
  timestamp: 1594864292
  timesteps_since_restore: 8950000
  timesteps_this_iter: 5000
  timesteps_total: 8950000
  training_iteration: 1790
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15728 s, 1790 iter, 8950000 ts, 320 rew

agent-1: 48.999999997928384
agent-2: 39.99999999792841
agent-3: 47.999999997928384
agent-4: 43.9999999979284
agent-5: 43.9999999979284
Extrinsic Rewards:
9
0
8
4
4
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.352
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-51-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 314.2424214851347
  episode_reward_min: 134.999999998222
  episodes_this_iter: 1
  episodes_total: 1790
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.618
    dispatch_time_ms: 52.408
    learner:
      cur_lr: 0.0007639299728907645
      grad_gnorm: 19.553741455078125
      policy_entropy: 30.151037216186523
      policy_loss: 0.6871496438980103
      var_gnorm: 23.245351791381836
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.23693016171455383
    num_steps_sampled: 8955000
    num_steps_trained: 8955000
    wait_time_ms: 29.561
  iterations_since_restore: 1791
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15748.206522226334
  time_this_iter_s: 20.000096797943115
  time_total_s: 15748.206522226334
  timestamp: 1594864312
  timesteps_since_restore: 8955000
  timesteps_this_iter: 5000
  timesteps_total: 8955000
  training_iteration: 1791
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15748 s, 1791 iter, 8955000 ts, 314 rew

agent-1: 68.99999996044747
agent-2: 73.99999996044748
agent-3: 68.99999996044748
agent-4: 73.9999999604475
agent-5: 73.9999999604475
Extrinsic Rewards:
5
10
5
10
10
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 5
Max Reward: 10
Gini Coefficient: 0.15
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 311.4524306394322
  episode_reward_min: 134.999999998222
  episodes_this_iter: 1
  episodes_total: 1791
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.894
    dispatch_time_ms: 25.506
    learner:
      cur_lr: 0.0007635970250703394
      grad_gnorm: 25.90983009338379
      policy_entropy: 18.096097946166992
      policy_loss: -3.619114398956299
      var_gnorm: 23.247787475585938
      vf_explained_var: 0.0
      vf_loss: 0.5117312669754028
    num_steps_sampled: 8960000
    num_steps_trained: 8960000
    wait_time_ms: 60.891
  iterations_since_restore: 1792
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15757.36437344551
  time_this_iter_s: 9.157851219177246
  time_total_s: 15757.36437344551
  timestamp: 1594864321
  timesteps_since_restore: 8960000
  timesteps_this_iter: 5000
  timesteps_total: 8960000
  training_iteration: 1792
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15757 s, 1792 iter, 8960000 ts, 311 rew

agent-1: 60.39999998606536
agent-2: 60.39999998606536
agent-3: 70.3999999860652
agent-4: 56.39999998606536
agent-5: 58.39999998606536
Extrinsic Rewards:
6
6
16
2
4
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.35294117647058826
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 312.8024306387651
  episode_reward_min: 134.999999998222
  episodes_this_iter: 1
  episodes_total: 1792
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.221
    dispatch_time_ms: 43.797
    learner:
      cur_lr: 0.0007632640190422535
      grad_gnorm: 2.291703224182129
      policy_entropy: 5.847146511077881
      policy_loss: -0.19796261191368103
      var_gnorm: 23.247474670410156
      vf_explained_var: 0.0
      vf_loss: 0.012416591867804527
    num_steps_sampled: 8965000
    num_steps_trained: 8965000
    wait_time_ms: 27.872
  iterations_since_restore: 1793
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15766.276966571808
  time_this_iter_s: 8.912593126296997
  time_total_s: 15766.276966571808
  timestamp: 1594864330
  timesteps_since_restore: 8965000
  timesteps_this_iter: 5000
  timesteps_total: 8965000
  training_iteration: 1793
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15766 s, 1793 iter, 8965000 ts, 313 rew

agent-1: 73.19999998696923
agent-2: 62.19999998696899
agent-3: 69.19999998696917
agent-4: 65.19999998696922
agent-5: 63.19999998696899
Extrinsic Rewards:
14
3
10
6
4
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.3027027027027027
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 312.35243064166224
  episode_reward_min: 134.999999998222
  episodes_this_iter: 1
  episodes_total: 1793
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.263
    dispatch_time_ms: 24.872
    learner:
      cur_lr: 0.0007629310130141675
      grad_gnorm: 4.752660274505615
      policy_entropy: 23.745738983154297
      policy_loss: 0.3653419613838196
      var_gnorm: 23.26070785522461
      vf_explained_var: 0.0
      vf_loss: 0.013083851896226406
    num_steps_sampled: 8970000
    num_steps_trained: 8970000
    wait_time_ms: 80.471
  iterations_since_restore: 1794
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15775.318188905716
  time_this_iter_s: 9.041222333908081
  time_total_s: 15775.318188905716
  timestamp: 1594864339
  timesteps_since_restore: 8970000
  timesteps_this_iter: 5000
  timesteps_total: 8970000
  training_iteration: 1794
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15775 s, 1794 iter, 8970000 ts, 312 rew

agent-1: 114.99661147712725
agent-2: 128.99661147712712
agent-3: 130.9966114771271
agent-4: 125.99661147712729
agent-5: 128.99661147712715
Extrinsic Rewards:
3
17
19
14
17
Sum Reward: 70
Avg Reward: 14.0
Min Reward: 3
Max Reward: 19
Gini Coefficient: 0.2
20:20 Ratio: 6.333333333333333
Max-min Ratio: 6.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 316.492261215578
  episode_reward_min: 134.999999998222
  episodes_this_iter: 1
  episodes_total: 1794
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.84
    dispatch_time_ms: 6.114
    learner:
      cur_lr: 0.0007625980069860816
      grad_gnorm: 40.0
      policy_entropy: 14.75623607635498
      policy_loss: 33.53630447387695
      var_gnorm: 23.248916625976562
      vf_explained_var: 0.0
      vf_loss: 31.65519142150879
    num_steps_sampled: 8975000
    num_steps_trained: 8975000
    wait_time_ms: 74.197
  iterations_since_restore: 1795
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15783.684893608093
  time_this_iter_s: 8.36670470237732
  time_total_s: 15783.684893608093
  timestamp: 1594864348
  timesteps_since_restore: 8975000
  timesteps_this_iter: 5000
  timesteps_total: 8975000
  training_iteration: 1795
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15783 s, 1795 iter, 8975000 ts, 316 rew

agent-1: 70.19999905611337
agent-2: 71.19999905611338
agent-3: 82.19999905611336
agent-4: 73.19999905611336
agent-5: 81.19999905611333
Extrinsic Rewards:
3
4
15
6
14
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 3
Max Reward: 15
Gini Coefficient: 0.3238095238095238
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 317.39226116872095
  episode_reward_min: 134.999999998222
  episodes_this_iter: 1
  episodes_total: 1795
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.786
    dispatch_time_ms: 7.675
    learner:
      cur_lr: 0.0007622650009579957
      grad_gnorm: 40.0
      policy_entropy: 24.39188003540039
      policy_loss: -6.013895034790039
      var_gnorm: 23.25383949279785
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.5550463199615479
    num_steps_sampled: 8980000
    num_steps_trained: 8980000
    wait_time_ms: 77.776
  iterations_since_restore: 1796
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15792.168205022812
  time_this_iter_s: 8.483311414718628
  time_total_s: 15792.168205022812
  timestamp: 1594864356
  timesteps_since_restore: 8980000
  timesteps_this_iter: 5000
  timesteps_total: 8980000
  training_iteration: 1796
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15792 s, 1796 iter, 8980000 ts, 317 rew

agent-1: 93.19999170331357
agent-2: 92.19999170331356
agent-3: 89.19999170331361
agent-4: 102.19999170331356
agent-5: 91.19999170331357
Extrinsic Rewards:
10
9
6
19
8
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 6
Max Reward: 19
Gini Coefficient: 0.2153846153846154
20:20 Ratio: 3.1666666666666665
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 319.2822607544863
  episode_reward_min: 134.999999998222
  episodes_this_iter: 1
  episodes_total: 1796
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.74
    dispatch_time_ms: 8.288
    learner:
      cur_lr: 0.0007619319949299097
      grad_gnorm: 40.0
      policy_entropy: 22.954936981201172
      policy_loss: 32.20442199707031
      var_gnorm: 23.24574089050293
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 57.80040740966797
    num_steps_sampled: 8985000
    num_steps_trained: 8985000
    wait_time_ms: 71.032
  iterations_since_restore: 1797
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15800.675257921219
  time_this_iter_s: 8.507052898406982
  time_total_s: 15800.675257921219
  timestamp: 1594864365
  timesteps_since_restore: 8985000
  timesteps_this_iter: 5000
  timesteps_total: 8985000
  training_iteration: 1797
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15800 s, 1797 iter, 8985000 ts, 319 rew

agent-1: 28.79999999811306
agent-2: 38.79999999811306
agent-3: 33.799999998113044
agent-4: 28.79999999811306
agent-5: 31.799999998113062
Extrinsic Rewards:
0
10
5
0
3
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.5555555555555556
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-52-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 319.55226075440976
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1797
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.89
    dispatch_time_ms: 6.836
    learner:
      cur_lr: 0.0007615989889018238
      grad_gnorm: 40.0
      policy_entropy: 33.44485855102539
      policy_loss: -7.274850368499756
      var_gnorm: 23.2510929107666
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 1.4418476819992065
    num_steps_sampled: 8990000
    num_steps_trained: 8990000
    wait_time_ms: 75.85
  iterations_since_restore: 1798
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15809.188093185425
  time_this_iter_s: 8.512835264205933
  time_total_s: 15809.188093185425
  timestamp: 1594864373
  timesteps_since_restore: 8990000
  timesteps_this_iter: 5000
  timesteps_total: 8990000
  training_iteration: 1798
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15809 s, 1798 iter, 8990000 ts, 320 rew

agent-1: 90.59999729664828
agent-2: 101.59999729664827
agent-3: 82.59999729664823
agent-4: 98.59999729664828
agent-5: 85.59999729664823
Extrinsic Rewards:
9
20
1
17
4
Sum Reward: 51
Avg Reward: 10.2
Min Reward: 1
Max Reward: 20
Gini Coefficient: 0.4
20:20 Ratio: 20.0
Max-min Ratio: 20.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 322.3422606192826
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1798
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.51
    dispatch_time_ms: 7.748
    learner:
      cur_lr: 0.0007612659828737378
      grad_gnorm: 40.0
      policy_entropy: 32.81425476074219
      policy_loss: 60.44284439086914
      var_gnorm: 23.245466232299805
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 104.08290100097656
    num_steps_sampled: 8995000
    num_steps_trained: 8995000
    wait_time_ms: 74.967
  iterations_since_restore: 1799
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15817.660105705261
  time_this_iter_s: 8.472012519836426
  time_total_s: 15817.660105705261
  timestamp: 1594864382
  timesteps_since_restore: 8995000
  timesteps_this_iter: 5000
  timesteps_total: 8995000
  training_iteration: 1799
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15817 s, 1799 iter, 8995000 ts, 322 rew

agent-1: 66.99999998324967
agent-2: 58.999999983249566
agent-3: 62.99999998324958
agent-4: 65.99999998324967
agent-5: 59.999999983249566
Extrinsic Rewards:
11
3
7
10
4
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.25142857142857145
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 323.0622606185705
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1799
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.987
    dispatch_time_ms: 6.51
    learner:
      cur_lr: 0.0007609329768456519
      grad_gnorm: 24.043212890625
      policy_entropy: 30.784936904907227
      policy_loss: -4.186244964599609
      var_gnorm: 23.24700927734375
      vf_explained_var: 0.0
      vf_loss: 0.3998538851737976
    num_steps_sampled: 9000000
    num_steps_trained: 9000000
    wait_time_ms: 78.898
  iterations_since_restore: 1800
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15826.239946842194
  time_this_iter_s: 8.579841136932373
  time_total_s: 15826.239946842194
  timestamp: 1594864391
  timesteps_since_restore: 9000000
  timesteps_this_iter: 5000
  timesteps_total: 9000000
  training_iteration: 1800
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15826 s, 1800 iter, 9000000 ts, 323 rew

agent-1: 56.199999941901254
agent-2: 63.199999941901254
agent-3: 58.199999941901254
agent-4: 59.199999941901254
agent-5: 51.19999994190127
Extrinsic Rewards:
5
12
7
8
0
Sum Reward: 32
Avg Reward: 6.4
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.3375
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 320.2722608831688
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1800
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.749
    dispatch_time_ms: 6.071
    learner:
      cur_lr: 0.0007606000290252268
      grad_gnorm: 4.534444808959961
      policy_entropy: 29.405916213989258
      policy_loss: -0.3758179843425751
      var_gnorm: 23.24555206298828
      vf_explained_var: 0.0
      vf_loss: 0.015872925519943237
    num_steps_sampled: 9005000
    num_steps_trained: 9005000
    wait_time_ms: 79.145
  iterations_since_restore: 1801
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15834.885015964508
  time_this_iter_s: 8.645069122314453
  time_total_s: 15834.885015964508
  timestamp: 1594864399
  timesteps_since_restore: 9005000
  timesteps_this_iter: 5000
  timesteps_total: 9005000
  training_iteration: 1801
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15834 s, 1801 iter, 9005000 ts, 320 rew

agent-1: 37.599999997058305
agent-2: 39.599999997058305
agent-3: 40.59999999705831
agent-4: 35.59999999705829
agent-5: 35.59999999705829
Extrinsic Rewards:
4
6
7
2
2
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-28
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 319.1922608846021
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1801
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.789
    dispatch_time_ms: 7.154
    learner:
      cur_lr: 0.0007602670229971409
      grad_gnorm: 15.195914268493652
      policy_entropy: 34.193782806396484
      policy_loss: 2.268711805343628
      var_gnorm: 23.247394561767578
      vf_explained_var: 0.0
      vf_loss: 0.15978921949863434
    num_steps_sampled: 9010000
    num_steps_trained: 9010000
    wait_time_ms: 76.901
  iterations_since_restore: 1802
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15843.479252815247
  time_this_iter_s: 8.594236850738525
  time_total_s: 15843.479252815247
  timestamp: 1594864408
  timesteps_since_restore: 9010000
  timesteps_this_iter: 5000
  timesteps_total: 9010000
  training_iteration: 1802
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15843 s, 1802 iter, 9010000 ts, 319 rew

agent-1: 36.39999999923516
agent-2: 31.39999999923507
agent-3: 41.39999999923515
agent-4: 30.399999999235074
agent-5: 31.39999999923507
Extrinsic Rewards:
6
1
11
0
1
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.5684210526315789
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 317.66226088760055
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1802
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.477
    dispatch_time_ms: 7.437
    learner:
      cur_lr: 0.0007599340169690549
      grad_gnorm: 39.999996185302734
      policy_entropy: 21.04239845275879
      policy_loss: 21.885848999023438
      var_gnorm: 23.246036529541016
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 38.59907150268555
    num_steps_sampled: 9015000
    num_steps_trained: 9015000
    wait_time_ms: 75.343
  iterations_since_restore: 1803
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15852.217604398727
  time_this_iter_s: 8.738351583480835
  time_total_s: 15852.217604398727
  timestamp: 1594864417
  timesteps_since_restore: 9015000
  timesteps_this_iter: 5000
  timesteps_total: 9015000
  training_iteration: 1803
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.2/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15852 s, 1803 iter, 9015000 ts, 318 rew

agent-1: 87.59999956379606
agent-2: 79.59999956379606
agent-3: 85.59999956379606
agent-4: 79.59999956379603
agent-5: 81.59999956379606
Extrinsic Rewards:
14
6
12
6
8
Sum Reward: 46
Avg Reward: 9.2
Min Reward: 6
Max Reward: 14
Gini Coefficient: 0.19130434782608696
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-45
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 319.37226086591943
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1803
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.24
    dispatch_time_ms: 10.036
    learner:
      cur_lr: 0.000759601010940969
      grad_gnorm: 14.58950424194336
      policy_entropy: 30.906021118164062
      policy_loss: -2.318551778793335
      var_gnorm: 23.246150970458984
      vf_explained_var: 0.0
      vf_loss: 0.16468408703804016
    num_steps_sampled: 9020000
    num_steps_trained: 9020000
    wait_time_ms: 75.97
  iterations_since_restore: 1804
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15860.868921041489
  time_this_iter_s: 8.65131664276123
  time_total_s: 15860.868921041489
  timestamp: 1594864425
  timesteps_since_restore: 9020000
  timesteps_this_iter: 5000
  timesteps_total: 9020000
  training_iteration: 1804
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15860 s, 1804 iter, 9020000 ts, 319 rew

agent-1: 61.39999999218133
agent-2: 60.39999999218132
agent-3: 60.39999999218131
agent-4: 62.39999999218131
agent-5: 61.39999999218132
Extrinsic Rewards:
7
6
6
8
7
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 6
Max Reward: 8
Gini Coefficient: 0.058823529411764705
20:20 Ratio: 1.3333333333333333
Max-min Ratio: 1.3333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-53-54
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 319.3722608658015
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1804
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.68
    dispatch_time_ms: 10.13
    learner:
      cur_lr: 0.000759268004912883
      grad_gnorm: 39.999996185302734
      policy_entropy: 30.116579055786133
      policy_loss: 94.4063720703125
      var_gnorm: 23.2456111907959
      vf_explained_var: 0.0
      vf_loss: 333.6310729980469
    num_steps_sampled: 9025000
    num_steps_trained: 9025000
    wait_time_ms: 74.712
  iterations_since_restore: 1805
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15869.481008768082
  time_this_iter_s: 8.612087726593018
  time_total_s: 15869.481008768082
  timestamp: 1594864434
  timesteps_since_restore: 9025000
  timesteps_this_iter: 5000
  timesteps_total: 9025000
  training_iteration: 1805
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15869 s, 1805 iter, 9025000 ts, 319 rew

agent-1: 37.19999999883351
agent-2: 43.19999999883354
agent-3: 39.19999999883351
agent-4: 38.19999999883351
agent-5: 40.199999998833526
Extrinsic Rewards:
2
8
4
3
5
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2545454545454545
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 317.0322608677233
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1805
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.016
    dispatch_time_ms: 8.323
    learner:
      cur_lr: 0.0007589349988847971
      grad_gnorm: 33.2462158203125
      policy_entropy: 33.7305908203125
      policy_loss: -5.936768054962158
      var_gnorm: 23.248746871948242
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.8550043702125549
    num_steps_sampled: 9030000
    num_steps_trained: 9030000
    wait_time_ms: 76.444
  iterations_since_restore: 1806
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15878.173080205917
  time_this_iter_s: 8.692071437835693
  time_total_s: 15878.173080205917
  timestamp: 1594864443
  timesteps_since_restore: 9030000
  timesteps_this_iter: 5000
  timesteps_total: 9030000
  training_iteration: 1806
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15878 s, 1806 iter, 9030000 ts, 317 rew

agent-1: 126.19999817686477
agent-2: 121.19999817686474
agent-3: 117.19999817686477
agent-4: 125.19999817686474
agent-5: 113.19999817686475
Extrinsic Rewards:
19
14
10
18
6
Sum Reward: 67
Avg Reward: 13.4
Min Reward: 6
Max Reward: 19
Gini Coefficient: 0.20298507462686566
20:20 Ratio: 3.1666666666666665
Max-min Ratio: 3.1666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-11
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 317.4822609701018
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1806
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.874
    dispatch_time_ms: 7.031
    learner:
      cur_lr: 0.0007586019928567111
      grad_gnorm: 40.0
      policy_entropy: 26.78437042236328
      policy_loss: 17.19672393798828
      var_gnorm: 23.24587059020996
      vf_explained_var: 0.0
      vf_loss: 14.228293418884277
    num_steps_sampled: 9035000
    num_steps_trained: 9035000
    wait_time_ms: 77.745
  iterations_since_restore: 1807
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15886.84914803505
  time_this_iter_s: 8.67606782913208
  time_total_s: 15886.84914803505
  timestamp: 1594864451
  timesteps_since_restore: 9035000
  timesteps_this_iter: 5000
  timesteps_total: 9035000
  training_iteration: 1807
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15886 s, 1807 iter, 9035000 ts, 317 rew

agent-1: 41.99999999852425
agent-2: 47.99999999852428
agent-3: 45.99999999852426
agent-4: 43.99999999852426
agent-5: 44.99999999852427
Extrinsic Rewards:
2
8
6
4
5
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.224
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-20
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 317.75226097007385
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1807
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.569
    dispatch_time_ms: 7.064
    learner:
      cur_lr: 0.0007582689868286252
      grad_gnorm: 16.794105529785156
      policy_entropy: 25.21281623840332
      policy_loss: -2.022185802459717
      var_gnorm: 23.246768951416016
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.215033620595932
    num_steps_sampled: 9040000
    num_steps_trained: 9040000
    wait_time_ms: 79.776
  iterations_since_restore: 1808
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15895.502181053162
  time_this_iter_s: 8.653033018112183
  time_total_s: 15895.502181053162
  timestamp: 1594864460
  timesteps_since_restore: 9040000
  timesteps_this_iter: 5000
  timesteps_total: 9040000
  training_iteration: 1808
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15895 s, 1808 iter, 9040000 ts, 318 rew

agent-1: 32.79999999940591
agent-2: 34.799999999405905
agent-3: 35.79999999940593
agent-4: 28.799999999405998
agent-5: 29.799999999405998
Extrinsic Rewards:
4
6
7
0
1
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.4222222222222222
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 315.6822609711297
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1808
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.925
    dispatch_time_ms: 7.485
    learner:
      cur_lr: 0.0007579359808005393
      grad_gnorm: 4.687689304351807
      policy_entropy: 24.506746292114258
      policy_loss: -0.4777940511703491
      var_gnorm: 23.245988845825195
      vf_explained_var: 0.0
      vf_loss: 0.016928086057305336
    num_steps_sampled: 9045000
    num_steps_trained: 9045000
    wait_time_ms: 75.815
  iterations_since_restore: 1809
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15904.181148767471
  time_this_iter_s: 8.678967714309692
  time_total_s: 15904.181148767471
  timestamp: 1594864469
  timesteps_since_restore: 9045000
  timesteps_this_iter: 5000
  timesteps_total: 9045000
  training_iteration: 1809
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15904 s, 1809 iter, 9045000 ts, 316 rew

agent-1: 64.7999999912817
agent-2: 58.79999999128181
agent-3: 59.79999999128181
agent-4: 55.79999999128182
agent-5: 57.79999999128181
Extrinsic Rewards:
12
6
7
3
5
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.24242424242424243
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 316.13226097150596
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1809
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.732
    dispatch_time_ms: 11.865
    learner:
      cur_lr: 0.0007576029747724533
      grad_gnorm: 17.03562355041504
      policy_entropy: 34.13981628417969
      policy_loss: -2.844472646713257
      var_gnorm: 23.248197555541992
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.21201083064079285
    num_steps_sampled: 9050000
    num_steps_trained: 9050000
    wait_time_ms: 71.041
  iterations_since_restore: 1810
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15912.798041343689
  time_this_iter_s: 8.616892576217651
  time_total_s: 15912.798041343689
  timestamp: 1594864477
  timesteps_since_restore: 9050000
  timesteps_this_iter: 5000
  timesteps_total: 9050000
  training_iteration: 1810
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15912 s, 1810 iter, 9050000 ts, 316 rew

agent-1: 50.599999995849586
agent-2: 52.59999999584959
agent-3: 51.59999999584959
agent-4: 59.59999999584958
agent-5: 64.59999999584974
Extrinsic Rewards:
1
3
2
10
15
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 1
Max Reward: 15
Gini Coefficient: 0.4645161290322581
20:20 Ratio: 15.0
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 313.5222610207462
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1810
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.678
    dispatch_time_ms: 26.631
    learner:
      cur_lr: 0.0007572700269520283
      grad_gnorm: 40.0
      policy_entropy: 34.500221252441406
      policy_loss: 56.30287551879883
      var_gnorm: 23.2457218170166
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 82.42252349853516
    num_steps_sampled: 9055000
    num_steps_trained: 9055000
    wait_time_ms: 49.783
  iterations_since_restore: 1811
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15921.597135782242
  time_this_iter_s: 8.799094438552856
  time_total_s: 15921.597135782242
  timestamp: 1594864486
  timesteps_since_restore: 9055000
  timesteps_this_iter: 5000
  timesteps_total: 9055000
  training_iteration: 1811
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15921 s, 1811 iter, 9055000 ts, 314 rew

agent-1: 68.199999854075
agent-2: 67.199999854075
agent-3: 71.19999985407502
agent-4: 62.199999854074974
agent-5: 64.19999985407503
Extrinsic Rewards:
9
8
12
3
5
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.23783783783783785
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-54-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 314.6022610135199
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1811
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.819
    dispatch_time_ms: 26.799
    learner:
      cur_lr: 0.0007569370209239423
      grad_gnorm: 27.926010131835938
      policy_entropy: 33.021263122558594
      policy_loss: -4.980195045471191
      var_gnorm: 23.247859954833984
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.6039703488349915
    num_steps_sampled: 9060000
    num_steps_trained: 9060000
    wait_time_ms: 55.456
  iterations_since_restore: 1812
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15930.68558216095
  time_this_iter_s: 9.088446378707886
  time_total_s: 15930.68558216095
  timestamp: 1594864495
  timesteps_since_restore: 9060000
  timesteps_this_iter: 5000
  timesteps_total: 9060000
  training_iteration: 1812
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15930 s, 1812 iter, 9060000 ts, 315 rew

agent-1: 38.799999998470405
agent-2: 42.79999999847042
agent-3: 38.799999998470405
agent-4: 46.7999999984704
agent-5: 39.799999998470405
Extrinsic Rewards:
2
6
2
10
3
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.34782608695652173
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 309.40878482461176
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1812
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.601
    dispatch_time_ms: 28.691
    learner:
      cur_lr: 0.0007566040148958564
      grad_gnorm: 39.999996185302734
      policy_entropy: 32.86561584472656
      policy_loss: 34.338626861572266
      var_gnorm: 23.245849609375
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 33.35496520996094
    num_steps_sampled: 9065000
    num_steps_trained: 9065000
    wait_time_ms: 66.412
  iterations_since_restore: 1813
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15939.9565346241
  time_this_iter_s: 9.270952463150024
  time_total_s: 15939.9565346241
  timestamp: 1594864505
  timesteps_since_restore: 9065000
  timesteps_this_iter: 5000
  timesteps_total: 9065000
  training_iteration: 1813
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15939 s, 1813 iter, 9065000 ts, 309 rew

agent-1: 100.39999976115853
agent-2: 110.39999976115855
agent-3: 106.39999976115855
agent-4: 104.39999976115858
agent-5: 109.39999976115858
Extrinsic Rewards:
6
16
12
10
15
Sum Reward: 59
Avg Reward: 11.8
Min Reward: 6
Max Reward: 16
Gini Coefficient: 0.1694915254237288
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 310.128785709773
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1813
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.027
    dispatch_time_ms: 34.256
    learner:
      cur_lr: 0.0007562710088677704
      grad_gnorm: 10.878183364868164
      policy_entropy: 34.570213317871094
      policy_loss: -2.315617322921753
      var_gnorm: 23.245933532714844
      vf_explained_var: 0.0
      vf_loss: 0.07740291208028793
    num_steps_sampled: 9070000
    num_steps_trained: 9070000
    wait_time_ms: 57.411
  iterations_since_restore: 1814
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15949.14849114418
  time_this_iter_s: 9.191956520080566
  time_total_s: 15949.14849114418
  timestamp: 1594864514
  timesteps_since_restore: 9070000
  timesteps_this_iter: 5000
  timesteps_total: 9070000
  training_iteration: 1814
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15949 s, 1814 iter, 9070000 ts, 310 rew

agent-1: 33.79999999937696
agent-2: 32.79999999937695
agent-3: 31.79999999937688
agent-4: 32.79999999937694
agent-5: 30.79999999937688
Extrinsic Rewards:
5
4
3
4
2
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 2
Max Reward: 5
Gini Coefficient: 0.15555555555555556
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-23
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 308.1487857104183
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1814
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.881
    dispatch_time_ms: 29.93
    learner:
      cur_lr: 0.0007559380028396845
      grad_gnorm: 15.168305397033691
      policy_entropy: 33.832462310791016
      policy_loss: -0.5465506911277771
      var_gnorm: 23.245813369750977
      vf_explained_var: 0.0
      vf_loss: 0.14167152345180511
    num_steps_sampled: 9075000
    num_steps_trained: 9075000
    wait_time_ms: 54.968
  iterations_since_restore: 1815
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15958.036623001099
  time_this_iter_s: 8.888131856918335
  time_total_s: 15958.036623001099
  timestamp: 1594864523
  timesteps_since_restore: 9075000
  timesteps_this_iter: 5000
  timesteps_total: 9075000
  training_iteration: 1815
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15958 s, 1815 iter, 9075000 ts, 308 rew

agent-1: 48.999999998884896
agent-2: 40.999999998884896
agent-3: 43.999999998884896
agent-4: 48.999999998884896
agent-5: 41.9999999988849
Extrinsic Rewards:
9
1
4
9
2
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.368
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-32
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 308.68878571040716
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1815
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.108
    dispatch_time_ms: 28.895
    learner:
      cur_lr: 0.0007556049968115985
      grad_gnorm: 39.38652038574219
      policy_entropy: 33.24273681640625
      policy_loss: -8.350010871887207
      var_gnorm: 23.25092315673828
      vf_explained_var: 0.0
      vf_loss: 1.1149054765701294
    num_steps_sampled: 9080000
    num_steps_trained: 9080000
    wait_time_ms: 55.191
  iterations_since_restore: 1816
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15966.869665145874
  time_this_iter_s: 8.83304214477539
  time_total_s: 15966.869665145874
  timestamp: 1594864532
  timesteps_since_restore: 9080000
  timesteps_this_iter: 5000
  timesteps_total: 9080000
  training_iteration: 1816
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15966 s, 1816 iter, 9080000 ts, 309 rew

agent-1: 115.59999603834811
agent-2: 111.59999603834808
agent-3: 125.59999603834811
agent-4: 123.59999603834807
agent-5: 117.5999960383481
Extrinsic Rewards:
10
6
20
18
12
Sum Reward: 66
Avg Reward: 13.2
Min Reward: 6
Max Reward: 20
Gini Coefficient: 0.21818181818181817
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 309.678870115891
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1816
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.7
    dispatch_time_ms: 24.467
    learner:
      cur_lr: 0.0007552719907835126
      grad_gnorm: 40.0
      policy_entropy: 6.105132102966309
      policy_loss: 13.285115242004395
      var_gnorm: 23.2484188079834
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 27.443899154663086
    num_steps_sampled: 9085000
    num_steps_trained: 9085000
    wait_time_ms: 65.38
  iterations_since_restore: 1817
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15976.04671907425
  time_this_iter_s: 9.177053928375244
  time_total_s: 15976.04671907425
  timestamp: 1594864541
  timesteps_since_restore: 9085000
  timesteps_this_iter: 5000
  timesteps_total: 9085000
  training_iteration: 1817
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15976 s, 1817 iter, 9085000 ts, 310 rew

agent-1: 63.199999993894814
agent-2: 72.19999999389458
agent-3: 74.19999999389461
agent-4: 64.1999999938946
agent-5: 59.199999993894814
Extrinsic Rewards:
4
13
15
5
0
Sum Reward: 37
Avg Reward: 7.4
Min Reward: 0
Max Reward: 15
Gini Coefficient: 0.42162162162162165
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-55-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 306.6188811629989
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1817
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.006
    dispatch_time_ms: 24.597
    learner:
      cur_lr: 0.0007549389847554266
      grad_gnorm: 40.0
      policy_entropy: 17.843578338623047
      policy_loss: 31.70907974243164
      var_gnorm: 23.263599395751953
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 36.94130325317383
    num_steps_sampled: 9090000
    num_steps_trained: 9090000
    wait_time_ms: 67.759
  iterations_since_restore: 1818
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15984.920462846756
  time_this_iter_s: 8.873743772506714
  time_total_s: 15984.920462846756
  timestamp: 1594864550
  timesteps_since_restore: 9090000
  timesteps_this_iter: 5000
  timesteps_total: 9090000
  training_iteration: 1818
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15984 s, 1818 iter, 9090000 ts, 307 rew

agent-1: 175.79960605634065
agent-2: 174.79960605634065
agent-3: 169.7996060563406
agent-4: 157.7996060563406
agent-5: 158.79960605634062
Extrinsic Rewards:
27
26
21
9
10
Sum Reward: 93
Avg Reward: 18.6
Min Reward: 9
Max Reward: 27
Gini Coefficient: 0.22365591397849463
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 313.4588614658471
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1818
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 5.548
    dispatch_time_ms: 11.229
    learner:
      cur_lr: 0.0007546059787273407
      grad_gnorm: 34.92470932006836
      policy_entropy: 20.963844299316406
      policy_loss: -5.030348300933838
      var_gnorm: 23.266843795776367
      vf_explained_var: 0.0
      vf_loss: 1.530470848083496
    num_steps_sampled: 9095000
    num_steps_trained: 9095000
    wait_time_ms: 22.682
  iterations_since_restore: 1819
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 15998.66727757454
  time_this_iter_s: 13.746814727783203
  time_total_s: 15998.66727757454
  timestamp: 1594864564
  timesteps_since_restore: 9095000
  timesteps_this_iter: 5000
  timesteps_total: 9095000
  training_iteration: 1819
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 15998 s, 1819 iter, 9095000 ts, 313 rew

agent-1: 173.19291852823176
agent-2: 165.19291852823173
agent-3: 168.19291852823176
agent-4: 160.19291852823167
agent-5: 161.19291852823164
Extrinsic Rewards:
26
18
21
13
14
Sum Reward: 92
Avg Reward: 18.4
Min Reward: 13
Max Reward: 26
Gini Coefficient: 0.14347826086956522
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 319.4885073923477
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1819
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 9.673
    learner:
      cur_lr: 0.0007542729726992548
      grad_gnorm: 40.0
      policy_entropy: 33.45827102661133
      policy_loss: -11.83117961883545
      var_gnorm: 23.26236343383789
      vf_explained_var: 0.0
      vf_loss: 4.394559860229492
    num_steps_sampled: 9100000
    num_steps_trained: 9100000
    wait_time_ms: 74.855
  iterations_since_restore: 1820
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16007.07801914215
  time_this_iter_s: 8.410741567611694
  time_total_s: 16007.07801914215
  timestamp: 1594864572
  timesteps_since_restore: 9100000
  timesteps_this_iter: 5000
  timesteps_total: 9100000
  training_iteration: 1820
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16007 s, 1820 iter, 9100000 ts, 319 rew

agent-1: 84.19999987816767
agent-2: 83.19999987816765
agent-3: 97.19999987816767
agent-4: 75.19999987816765
agent-5: 83.19999987816767
Extrinsic Rewards:
9
8
22
0
8
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 0
Max Reward: 22
Gini Coefficient: 0.3829787234042553
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 320.6585073866072
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1820
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.752
    dispatch_time_ms: 6.941
    learner:
      cur_lr: 0.0007539400248788297
      grad_gnorm: 40.0
      policy_entropy: 27.036283493041992
      policy_loss: 54.54652404785156
      var_gnorm: 23.247495651245117
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 151.70396423339844
    num_steps_sampled: 9105000
    num_steps_trained: 9105000
    wait_time_ms: 74.654
  iterations_since_restore: 1821
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16015.413976430893
  time_this_iter_s: 8.335957288742065
  time_total_s: 16015.413976430893
  timestamp: 1594864581
  timesteps_since_restore: 9105000
  timesteps_this_iter: 5000
  timesteps_total: 9105000
  training_iteration: 1821
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16015 s, 1821 iter, 9105000 ts, 321 rew

agent-1: 43.99999999787167
agent-2: 49.99999999787167
agent-3: 45.999999997871655
agent-4: 39.999999997871676
agent-5: 44.99999999787167
Extrinsic Rewards:
4
10
6
0
5
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 0
Max Reward: 10
Gini Coefficient: 0.352
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 321.018507386626
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1821
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.412
    dispatch_time_ms: 7.681
    learner:
      cur_lr: 0.0007536070188507438
      grad_gnorm: 29.279184341430664
      policy_entropy: 34.56741714477539
      policy_loss: -5.785253524780273
      var_gnorm: 23.248695373535156
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.65678870677948
    num_steps_sampled: 9110000
    num_steps_trained: 9110000
    wait_time_ms: 71.471
  iterations_since_restore: 1822
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16024.452487707138
  time_this_iter_s: 9.038511276245117
  time_total_s: 16024.452487707138
  timestamp: 1594864590
  timesteps_since_restore: 9110000
  timesteps_this_iter: 5000
  timesteps_total: 9110000
  training_iteration: 1822
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16024 s, 1822 iter, 9110000 ts, 321 rew

agent-1: 37.79999999837305
agent-2: 44.799999998373046
agent-3: 38.79999999837306
agent-4: 41.79999999837306
agent-5: 43.799999998373046
Extrinsic Rewards:
1
8
2
5
7
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.33043478260869563
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 320.56850738714894
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1822
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.614
    dispatch_time_ms: 6.987
    learner:
      cur_lr: 0.0007532740128226578
      grad_gnorm: 2.924471855163574
      policy_entropy: 33.76810073852539
      policy_loss: -0.48924529552459717
      var_gnorm: 23.24666404724121
      vf_explained_var: 2.384185791015625e-07
      vf_loss: 0.00609486922621727
    num_steps_sampled: 9115000
    num_steps_trained: 9115000
    wait_time_ms: 75.221
  iterations_since_restore: 1823
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16033.079313516617
  time_this_iter_s: 8.62682580947876
  time_total_s: 16033.079313516617
  timestamp: 1594864598
  timesteps_since_restore: 9115000
  timesteps_this_iter: 5000
  timesteps_total: 9115000
  training_iteration: 1823
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16033 s, 1823 iter, 9115000 ts, 321 rew

agent-1: 75.39999982409564
agent-2: 80.39999982409563
agent-3: 76.39999982409563
agent-4: 77.39999982409563
agent-5: 86.39999982409564
Extrinsic Rewards:
5
10
6
7
16
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 5
Max Reward: 16
Gini Coefficient: 0.23636363636363636
20:20 Ratio: 3.2
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 319.3985073855139
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1823
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.76
    dispatch_time_ms: 7.707
    learner:
      cur_lr: 0.0007529410067945719
      grad_gnorm: 20.041112899780273
      policy_entropy: 34.408538818359375
      policy_loss: -3.460249662399292
      var_gnorm: 23.247608184814453
      vf_explained_var: 0.0
      vf_loss: 0.3030518889427185
    num_steps_sampled: 9120000
    num_steps_trained: 9120000
    wait_time_ms: 75.911
  iterations_since_restore: 1824
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16041.735486507416
  time_this_iter_s: 8.65617299079895
  time_total_s: 16041.735486507416
  timestamp: 1594864607
  timesteps_since_restore: 9120000
  timesteps_this_iter: 5000
  timesteps_total: 9120000
  training_iteration: 1824
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.8/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16041 s, 1824 iter, 9120000 ts, 319 rew

agent-1: 73.3999999604794
agent-2: 65.39999996047939
agent-3: 65.39999996047939
agent-4: 76.39999996047942
agent-5: 70.3999999604794
Extrinsic Rewards:
11
3
3
14
8
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 3
Max Reward: 14
Gini Coefficient: 0.3076923076923077
20:20 Ratio: 4.666666666666667
Max-min Ratio: 4.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-56-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 320.6585073840725
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1824
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.843
    dispatch_time_ms: 6.234
    learner:
      cur_lr: 0.0007526080007664859
      grad_gnorm: 40.0
      policy_entropy: 33.194068908691406
      policy_loss: 74.38614654541016
      var_gnorm: 23.246868133544922
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 193.52023315429688
    num_steps_sampled: 9125000
    num_steps_trained: 9125000
    wait_time_ms: 80.285
  iterations_since_restore: 1825
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16050.346210956573
  time_this_iter_s: 8.610724449157715
  time_total_s: 16050.346210956573
  timestamp: 1594864616
  timesteps_since_restore: 9125000
  timesteps_this_iter: 5000
  timesteps_total: 9125000
  training_iteration: 1825
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16050 s, 1825 iter, 9125000 ts, 321 rew

agent-1: 41.19999999814975
agent-2: 38.19999999814974
agent-3: 42.19999999814976
agent-4: 41.19999999814975
agent-5: 35.19999999814975
Extrinsic Rewards:
6
3
7
6
0
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.3090909090909091
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 320.92850738401836
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1825
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.811
    dispatch_time_ms: 6.255
    learner:
      cur_lr: 0.0007522749947384
      grad_gnorm: 19.64641571044922
      policy_entropy: 21.94161033630371
      policy_loss: -2.650163173675537
      var_gnorm: 23.248172760009766
      vf_explained_var: 0.0
      vf_loss: 0.2948802411556244
    num_steps_sampled: 9130000
    num_steps_trained: 9130000
    wait_time_ms: 75.79
  iterations_since_restore: 1826
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16058.945182800293
  time_this_iter_s: 8.598971843719482
  time_total_s: 16058.945182800293
  timestamp: 1594864624
  timesteps_since_restore: 9130000
  timesteps_this_iter: 5000
  timesteps_total: 9130000
  training_iteration: 1826
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16058 s, 1826 iter, 9130000 ts, 321 rew

agent-1: 75.9999999476332
agent-2: 80.9999999476332
agent-3: 77.9999999476332
agent-4: 86.99999994763323
agent-5: 82.9999999476332
Extrinsic Rewards:
4
9
6
15
11
Sum Reward: 45
Avg Reward: 9.0
Min Reward: 4
Max Reward: 15
Gini Coefficient: 0.24
20:20 Ratio: 3.75
Max-min Ratio: 3.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 323.26850738143554
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1826
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.224
    dispatch_time_ms: 8.644
    learner:
      cur_lr: 0.000751941988710314
      grad_gnorm: 40.0
      policy_entropy: 19.80820655822754
      policy_loss: 44.04598617553711
      var_gnorm: 23.247417449951172
      vf_explained_var: 0.0
      vf_loss: 80.37591552734375
    num_steps_sampled: 9135000
    num_steps_trained: 9135000
    wait_time_ms: 76.198
  iterations_since_restore: 1827
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16067.737457036972
  time_this_iter_s: 8.792274236679077
  time_total_s: 16067.737457036972
  timestamp: 1594864633
  timesteps_since_restore: 9135000
  timesteps_this_iter: 5000
  timesteps_total: 9135000
  training_iteration: 1827
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16067 s, 1827 iter, 9135000 ts, 323 rew

agent-1: 33.999999999102805
agent-2: 40.999999999102776
agent-3: 33.99999999910281
agent-4: 33.999999999102805
agent-5: 36.99999999910278
Extrinsic Rewards:
2
9
2
2
5
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.34
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 319.21850743679727
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1827
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.69
    dispatch_time_ms: 7.906
    learner:
      cur_lr: 0.0007516089826822281
      grad_gnorm: 29.398603439331055
      policy_entropy: 22.70580291748047
      policy_loss: -3.941906452178955
      var_gnorm: 23.24959373474121
      vf_explained_var: 0.0
      vf_loss: 0.6631461977958679
    num_steps_sampled: 9140000
    num_steps_trained: 9140000
    wait_time_ms: 75.291
  iterations_since_restore: 1828
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16076.321651220322
  time_this_iter_s: 8.58419418334961
  time_total_s: 16076.321651220322
  timestamp: 1594864642
  timesteps_since_restore: 9140000
  timesteps_this_iter: 5000
  timesteps_total: 9140000
  training_iteration: 1828
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16076 s, 1828 iter, 9140000 ts, 319 rew

agent-1: 91.39999998023676
agent-2: 86.39999998023671
agent-3: 90.39999998023674
agent-4: 87.39999998023673
agent-5: 85.39999998023673
Extrinsic Rewards:
13
8
12
9
7
Sum Reward: 49
Avg Reward: 9.8
Min Reward: 7
Max Reward: 13
Gini Coefficient: 0.1306122448979592
20:20 Ratio: 1.8571428571428572
Max-min Ratio: 1.8571428571428572
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 321.3785074359069
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1828
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.839
    dispatch_time_ms: 9.935
    learner:
      cur_lr: 0.0007512759766541421
      grad_gnorm: 2.026710271835327
      policy_entropy: 21.028934478759766
      policy_loss: -0.2901872396469116
      var_gnorm: 23.247468948364258
      vf_explained_var: 0.0
      vf_loss: 0.003088266123086214
    num_steps_sampled: 9145000
    num_steps_trained: 9145000
    wait_time_ms: 76.504
  iterations_since_restore: 1829
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16084.971436023712
  time_this_iter_s: 8.649784803390503
  time_total_s: 16084.971436023712
  timestamp: 1594864650
  timesteps_since_restore: 9145000
  timesteps_this_iter: 5000
  timesteps_total: 9145000
  training_iteration: 1829
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16084 s, 1829 iter, 9145000 ts, 321 rew

agent-1: 70.39999993629237
agent-2: 84.3999999362924
agent-3: 83.39999993629239
agent-4: 75.39999993629239
agent-5: 82.39999993629239
Extrinsic Rewards:
0
14
13
5
12
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 0
Max Reward: 14
Gini Coefficient: 0.32727272727272727
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 323.7185074327656
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1829
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.613
    dispatch_time_ms: 10.269
    learner:
      cur_lr: 0.0007509430288337171
      grad_gnorm: 19.261234283447266
      policy_entropy: 11.337023735046387
      policy_loss: -1.0447832345962524
      var_gnorm: 23.24911880493164
      vf_explained_var: 0.0
      vf_loss: 0.2871358096599579
    num_steps_sampled: 9150000
    num_steps_trained: 9150000
    wait_time_ms: 73.992
  iterations_since_restore: 1830
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16093.57184934616
  time_this_iter_s: 8.60041332244873
  time_total_s: 16093.57184934616
  timestamp: 1594864659
  timesteps_since_restore: 9150000
  timesteps_this_iter: 5000
  timesteps_total: 9150000
  training_iteration: 1830
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16093 s, 1830 iter, 9150000 ts, 324 rew

agent-1: 48.999999990156795
agent-2: 55.999999990156795
agent-3: 53.999999990156795
agent-4: 51.99999999015681
agent-5: 58.999999990156795
Extrinsic Rewards:
1
8
6
4
11
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.32
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-48
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 322.4585081402349
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1830
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.817
    dispatch_time_ms: 7.784
    learner:
      cur_lr: 0.0007506100228056312
      grad_gnorm: 1.146513819694519
      policy_entropy: 13.642066955566406
      policy_loss: -0.026121189817786217
      var_gnorm: 23.247947692871094
      vf_explained_var: 0.0
      vf_loss: 0.0009198630577884614
    num_steps_sampled: 9155000
    num_steps_trained: 9155000
    wait_time_ms: 75.651
  iterations_since_restore: 1831
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16102.268923997879
  time_this_iter_s: 8.69707465171814
  time_total_s: 16102.268923997879
  timestamp: 1594864668
  timesteps_since_restore: 9155000
  timesteps_this_iter: 5000
  timesteps_total: 9155000
  training_iteration: 1831
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16102 s, 1831 iter, 9155000 ts, 322 rew

agent-1: 44.59999999044175
agent-2: 54.59999999044175
agent-3: 41.59999999044175
agent-4: 44.59999999044175
agent-5: 48.59999999044175
Extrinsic Rewards:
3
13
0
3
7
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 0
Max Reward: 13
Gini Coefficient: 0.46153846153846156
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-57-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 321.91850814063514
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1831
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.109
    dispatch_time_ms: 7.992
    learner:
      cur_lr: 0.0007502770167775452
      grad_gnorm: 20.11549949645996
      policy_entropy: 22.784696578979492
      policy_loss: -1.9030110836029053
      var_gnorm: 23.25063705444336
      vf_explained_var: 0.0
      vf_loss: 0.30308225750923157
    num_steps_sampled: 9160000
    num_steps_trained: 9160000
    wait_time_ms: 76.644
  iterations_since_restore: 1832
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16110.893990278244
  time_this_iter_s: 8.62506628036499
  time_total_s: 16110.893990278244
  timestamp: 1594864676
  timesteps_since_restore: 9160000
  timesteps_this_iter: 5000
  timesteps_total: 9160000
  training_iteration: 1832
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16110 s, 1832 iter, 9160000 ts, 322 rew

agent-1: 104.99999731939685
agent-2: 112.99999731939685
agent-3: 110.99999731939685
agent-4: 102.99999731939687
agent-5: 107.99999731939683
Extrinsic Rewards:
9
17
15
7
12
Sum Reward: 60
Avg Reward: 12.0
Min Reward: 7
Max Reward: 17
Gini Coefficient: 0.17333333333333334
20:20 Ratio: 2.4285714285714284
Max-min Ratio: 2.4285714285714284
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 325.7885080066286
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1832
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.257
    dispatch_time_ms: 8.684
    learner:
      cur_lr: 0.0007499440107494593
      grad_gnorm: 2.782721757888794
      policy_entropy: 20.560911178588867
      policy_loss: -0.32500261068344116
      var_gnorm: 23.247774124145508
      vf_explained_var: 0.0
      vf_loss: 0.0059654489159584045
    num_steps_sampled: 9165000
    num_steps_trained: 9165000
    wait_time_ms: 73.837
  iterations_since_restore: 1833
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16119.58888053894
  time_this_iter_s: 8.694890260696411
  time_total_s: 16119.58888053894
  timestamp: 1594864685
  timesteps_since_restore: 9165000
  timesteps_this_iter: 5000
  timesteps_total: 9165000
  training_iteration: 1833
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16119 s, 1833 iter, 9165000 ts, 326 rew

agent-1: 34.39999999918805
agent-2: 36.39999999918807
agent-3: 37.39999999918806
agent-4: 30.399999999188037
agent-5: 32.39999999918804
Extrinsic Rewards:
4
6
7
0
2
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.37894736842105264
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-14
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 321.6485081755607
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1833
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 7.613
    learner:
      cur_lr: 0.0007496110047213733
      grad_gnorm: 20.88248634338379
      policy_entropy: 34.608245849609375
      policy_loss: -3.7943878173828125
      var_gnorm: 23.248254776000977
      vf_explained_var: 0.0
      vf_loss: 0.32619574666023254
    num_steps_sampled: 9170000
    num_steps_trained: 9170000
    wait_time_ms: 76.614
  iterations_since_restore: 1834
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16128.156497716904
  time_this_iter_s: 8.567617177963257
  time_total_s: 16128.156497716904
  timestamp: 1594864694
  timesteps_since_restore: 9170000
  timesteps_this_iter: 5000
  timesteps_total: 9170000
  training_iteration: 1834
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16128 s, 1834 iter, 9170000 ts, 322 rew

agent-1: 105.19999985737613
agent-2: 100.1999998573761
agent-3: 116.19999985737613
agent-4: 97.19999985737607
agent-5: 94.19999985737607
Extrinsic Rewards:
14
9
25
6
3
Sum Reward: 57
Avg Reward: 11.4
Min Reward: 3
Max Reward: 25
Gini Coefficient: 0.3649122807017544
20:20 Ratio: 8.333333333333334
Max-min Ratio: 8.333333333333334
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 324.2585081694436
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1834
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.906
    dispatch_time_ms: 8.428
    learner:
      cur_lr: 0.0007492779986932874
      grad_gnorm: 1.1995102167129517
      policy_entropy: 33.926483154296875
      policy_loss: -0.20664827525615692
      var_gnorm: 23.247699737548828
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.0010802325559780002
    num_steps_sampled: 9175000
    num_steps_trained: 9175000
    wait_time_ms: 74.896
  iterations_since_restore: 1835
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16136.75604391098
  time_this_iter_s: 8.599546194076538
  time_total_s: 16136.75604391098
  timestamp: 1594864702
  timesteps_since_restore: 9175000
  timesteps_this_iter: 5000
  timesteps_total: 9175000
  training_iteration: 1835
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16136 s, 1835 iter, 9175000 ts, 324 rew

agent-1: 30.599999999663737
agent-2: 25.599999999663734
agent-3: 31.599999999663734
agent-4: 29.599999999663734
agent-5: 26.59999999966373
Extrinsic Rewards:
5
0
6
4
1
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 323.53850816957953
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1835
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.137
    dispatch_time_ms: 8.245
    learner:
      cur_lr: 0.0007489449926652014
      grad_gnorm: 24.60863494873047
      policy_entropy: 22.158279418945312
      policy_loss: -1.7956273555755615
      var_gnorm: 23.252492904663086
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.4253360331058502
    num_steps_sampled: 9180000
    num_steps_trained: 9180000
    wait_time_ms: 75.677
  iterations_since_restore: 1836
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16145.365039110184
  time_this_iter_s: 8.608995199203491
  time_total_s: 16145.365039110184
  timestamp: 1594864711
  timesteps_since_restore: 9180000
  timesteps_this_iter: 5000
  timesteps_total: 9180000
  training_iteration: 1836
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16145 s, 1836 iter, 9180000 ts, 324 rew

agent-1: 45.19999997109014
agent-2: 52.19999997109014
agent-3: 47.19999997109014
agent-4: 46.19999997109015
agent-5: 52.19999997109015
Extrinsic Rewards:
2
9
4
3
9
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 2
Max Reward: 9
Gini Coefficient: 0.2962962962962963
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 322.6386028947785
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1836
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.805
    dispatch_time_ms: 8.686
    learner:
      cur_lr: 0.0007486119866371155
      grad_gnorm: 40.000003814697266
      policy_entropy: 25.045438766479492
      policy_loss: 35.58063888549805
      var_gnorm: 23.24801254272461
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 88.97108459472656
    num_steps_sampled: 9185000
    num_steps_trained: 9185000
    wait_time_ms: 73.649
  iterations_since_restore: 1837
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16153.990028619766
  time_this_iter_s: 8.62498950958252
  time_total_s: 16153.990028619766
  timestamp: 1594864720
  timesteps_since_restore: 9185000
  timesteps_this_iter: 5000
  timesteps_total: 9185000
  training_iteration: 1837
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16153 s, 1837 iter, 9185000 ts, 323 rew

agent-1: 80.59999902988251
agent-2: 76.59999902988255
agent-3: 68.59999902988254
agent-4: 73.59999902988253
agent-5: 69.59999902988254
Extrinsic Rewards:
15
11
3
8
4
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 3
Max Reward: 15
Gini Coefficient: 0.3024390243902439
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 943.9150941076548
  episode_reward_mean: 322.9986053620867
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1837
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.688
    dispatch_time_ms: 7.809
    learner:
      cur_lr: 0.0007482789806090295
      grad_gnorm: 14.29944896697998
      policy_entropy: 30.13336181640625
      policy_loss: -2.329723358154297
      var_gnorm: 23.248231887817383
      vf_explained_var: 0.0
      vf_loss: 0.15728969871997833
    num_steps_sampled: 9190000
    num_steps_trained: 9190000
    wait_time_ms: 76.621
  iterations_since_restore: 1838
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16162.740736722946
  time_this_iter_s: 8.750708103179932
  time_total_s: 16162.740736722946
  timestamp: 1594864729
  timesteps_since_restore: 9190000
  timesteps_this_iter: 5000
  timesteps_total: 9190000
  training_iteration: 1838
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16162 s, 1838 iter, 9190000 ts, 323 rew

agent-1: 46.59999999749909
agent-2: 43.599999997499076
agent-3: 44.599999997499076
agent-4: 47.599999997499076
agent-5: 51.59999999749906
Extrinsic Rewards:
5
2
3
6
10
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 2
Max Reward: 10
Gini Coefficient: 0.2923076923076923
20:20 Ratio: 5.0
Max-min Ratio: 5.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-58-57
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 315.89945442088515
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1838
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.584
    dispatch_time_ms: 14.662
    learner:
      cur_lr: 0.0007479459745809436
      grad_gnorm: 1.1425892114639282
      policy_entropy: 34.567901611328125
      policy_loss: -0.08399621397256851
      var_gnorm: 23.24816131591797
      vf_explained_var: 0.0
      vf_loss: 0.0010021886555477977
    num_steps_sampled: 9195000
    num_steps_trained: 9195000
    wait_time_ms: 75.196
  iterations_since_restore: 1839
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16171.440888166428
  time_this_iter_s: 8.700151443481445
  time_total_s: 16171.440888166428
  timestamp: 1594864737
  timesteps_since_restore: 9195000
  timesteps_this_iter: 5000
  timesteps_total: 9195000
  training_iteration: 1839
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16171 s, 1839 iter, 9195000 ts, 316 rew

agent-1: 53.99999999707352
agent-2: 54.99999999707352
agent-3: 59.99999999707354
agent-4: 50.99999999707354
agent-5: 49.99999999707354
Extrinsic Rewards:
6
7
12
3
2
Sum Reward: 30
Avg Reward: 6.0
Min Reward: 2
Max Reward: 12
Gini Coefficient: 0.32
20:20 Ratio: 6.0
Max-min Ratio: 6.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-06
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 316.70945442082973
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1839
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.116
    dispatch_time_ms: 17.434
    learner:
      cur_lr: 0.0007476130267605186
      grad_gnorm: 18.235815048217773
      policy_entropy: 31.312604904174805
      policy_loss: -3.9092273712158203
      var_gnorm: 23.248422622680664
      vf_explained_var: 0.0
      vf_loss: 0.16463516652584076
    num_steps_sampled: 9200000
    num_steps_trained: 9200000
    wait_time_ms: 67.713
  iterations_since_restore: 1840
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16180.118105888367
  time_this_iter_s: 8.677217721939087
  time_total_s: 16180.118105888367
  timestamp: 1594864746
  timesteps_since_restore: 9200000
  timesteps_this_iter: 5000
  timesteps_total: 9200000
  training_iteration: 1840
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16180 s, 1840 iter, 9200000 ts, 317 rew

agent-1: 42.999999998115015
agent-2: 49.999999998115015
agent-3: 44.99999999811502
agent-4: 42.999999998115015
agent-5: 43.99999999811502
Extrinsic Rewards:
3
10
5
3
4
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.256
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-15
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 315.08945442276536
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1840
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 31.168
    learner:
      cur_lr: 0.0007472800207324326
      grad_gnorm: 1.3618254661560059
      policy_entropy: 27.563810348510742
      policy_loss: -0.2143547087907791
      var_gnorm: 23.249038696289062
      vf_explained_var: 0.0
      vf_loss: 0.0014109188923612237
    num_steps_sampled: 9205000
    num_steps_trained: 9205000
    wait_time_ms: 58.003
  iterations_since_restore: 1841
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16189.329605102539
  time_this_iter_s: 9.211499214172363
  time_total_s: 16189.329605102539
  timestamp: 1594864755
  timesteps_since_restore: 9205000
  timesteps_this_iter: 5000
  timesteps_total: 9205000
  training_iteration: 1841
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16189 s, 1841 iter, 9205000 ts, 315 rew

agent-1: 61.599999995658834
agent-2: 57.599999995658806
agent-3: 53.599999995658806
agent-4: 50.599999995658806
agent-5: 55.59999999565882
Extrinsic Rewards:
12
8
4
1
6
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.33548387096774196
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 312.38945443888656
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1841
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.174
    dispatch_time_ms: 30.678
    learner:
      cur_lr: 0.0007469470147043467
      grad_gnorm: 20.663347244262695
      policy_entropy: 30.03548240661621
      policy_loss: -5.5342512130737305
      var_gnorm: 23.24919319152832
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.230667844414711
    num_steps_sampled: 9210000
    num_steps_trained: 9210000
    wait_time_ms: 63.906
  iterations_since_restore: 1842
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16198.53601193428
  time_this_iter_s: 9.206406831741333
  time_total_s: 16198.53601193428
  timestamp: 1594864765
  timesteps_since_restore: 9210000
  timesteps_this_iter: 5000
  timesteps_total: 9210000
  training_iteration: 1842
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16198 s, 1842 iter, 9210000 ts, 312 rew

agent-1: 75.5999999602054
agent-2: 67.5999999602054
agent-3: 74.5999999602054
agent-4: 74.59999996020541
agent-5: 76.5999999602054
Extrinsic Rewards:
10
2
9
9
11
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.18536585365853658
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 311.39945443804436
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1842
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.031
    dispatch_time_ms: 28.2
    learner:
      cur_lr: 0.0007466140086762607
      grad_gnorm: 1.5019468069076538
      policy_entropy: 33.09857940673828
      policy_loss: 0.4284542500972748
      var_gnorm: 23.24952507019043
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.001741975313052535
    num_steps_sampled: 9215000
    num_steps_trained: 9215000
    wait_time_ms: 62.912
  iterations_since_restore: 1843
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16207.66933465004
  time_this_iter_s: 9.133322715759277
  time_total_s: 16207.66933465004
  timestamp: 1594864774
  timesteps_since_restore: 9215000
  timesteps_this_iter: 5000
  timesteps_total: 9215000
  training_iteration: 1843
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16207 s, 1843 iter, 9215000 ts, 311 rew

agent-1: 31.19999999960883
agent-2: 31.19999999960883
agent-3: 34.19999999960893
agent-4: 27.199999999608824
agent-5: 29.19999999960883
Extrinsic Rewards:
4
4
7
0
2
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.3764705882352941
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 310.58945443810444
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1843
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.326
    dispatch_time_ms: 26.477
    learner:
      cur_lr: 0.0007462810026481748
      grad_gnorm: 13.334823608398438
      policy_entropy: 22.89210319519043
      policy_loss: -4.424962043762207
      var_gnorm: 23.24993896484375
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.16477343440055847
    num_steps_sampled: 9220000
    num_steps_trained: 9220000
    wait_time_ms: 67.254
  iterations_since_restore: 1844
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16216.895915746689
  time_this_iter_s: 9.22658109664917
  time_total_s: 16216.895915746689
  timestamp: 1594864783
  timesteps_since_restore: 9220000
  timesteps_this_iter: 5000
  timesteps_total: 9220000
  training_iteration: 1844
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16216 s, 1844 iter, 9220000 ts, 311 rew

agent-1: 66.59999996229537
agent-2: 61.59999996229546
agent-3: 61.59999996229546
agent-4: 69.59999996229531
agent-5: 64.59999996229537
Extrinsic Rewards:
9
4
4
12
7
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.23333333333333334
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_21-59-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 307.6194546174432
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1844
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.943
    dispatch_time_ms: 27.351
    learner:
      cur_lr: 0.0007459479966200888
      grad_gnorm: 2.0958385467529297
      policy_entropy: 16.824644088745117
      policy_loss: -0.06956303119659424
      var_gnorm: 23.250593185424805
      vf_explained_var: 0.0
      vf_loss: 0.003401820082217455
    num_steps_sampled: 9225000
    num_steps_trained: 9225000
    wait_time_ms: 60.997
  iterations_since_restore: 1845
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16226.037070512772
  time_this_iter_s: 9.141154766082764
  time_total_s: 16226.037070512772
  timestamp: 1594864792
  timesteps_since_restore: 9225000
  timesteps_this_iter: 5000
  timesteps_total: 9225000
  training_iteration: 1845
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16226 s, 1845 iter, 9225000 ts, 308 rew

agent-1: 40.39999999860187
agent-2: 41.39999999860187
agent-3: 40.39999999860187
agent-4: 40.39999999860187
agent-5: 53.399999998601864
Extrinsic Rewards:
2
3
2
2
15
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.45
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 307.79945461745524
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1845
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.61
    dispatch_time_ms: 29.117
    learner:
      cur_lr: 0.0007456149905920029
      grad_gnorm: 40.0
      policy_entropy: 21.143566131591797
      policy_loss: -3.099355459213257
      var_gnorm: 23.263080596923828
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.3933939933776855
    num_steps_sampled: 9230000
    num_steps_trained: 9230000
    wait_time_ms: 63.494
  iterations_since_restore: 1846
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16235.187463283539
  time_this_iter_s: 9.150392770767212
  time_total_s: 16235.187463283539
  timestamp: 1594864801
  timesteps_since_restore: 9230000
  timesteps_this_iter: 5000
  timesteps_total: 9230000
  training_iteration: 1846
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16235 s, 1846 iter, 9230000 ts, 308 rew

agent-1: 133.99997078189656
agent-2: 139.99997078189645
agent-3: 136.99997078189648
agent-4: 125.99997078189664
agent-5: 137.99997078189648
Extrinsic Rewards:
14
20
17
6
18
Sum Reward: 75
Avg Reward: 15.0
Min Reward: 6
Max Reward: 20
Gini Coefficient: 0.17066666666666666
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 312.8394531565941
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1846
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.466
    dispatch_time_ms: 40.076
    learner:
      cur_lr: 0.0007452819845639169
      grad_gnorm: 18.64415168762207
      policy_entropy: 3.7912583351135254
      policy_loss: -0.7891599535942078
      var_gnorm: 23.255098342895508
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2688673436641693
    num_steps_sampled: 9235000
    num_steps_trained: 9235000
    wait_time_ms: 45.127
  iterations_since_restore: 1847
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16244.327412366867
  time_this_iter_s: 9.139949083328247
  time_total_s: 16244.327412366867
  timestamp: 1594864810
  timesteps_since_restore: 9235000
  timesteps_this_iter: 5000
  timesteps_total: 9235000
  training_iteration: 1847
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16244 s, 1847 iter, 9235000 ts, 313 rew

agent-1: 103.3999993587447
agent-2: 102.39999935874468
agent-3: 108.39999935874468
agent-4: 114.3999993587447
agent-5: 102.3999993587447
Extrinsic Rewards:
9
8
14
20
8
Sum Reward: 59
Avg Reward: 11.8
Min Reward: 8
Max Reward: 20
Gini Coefficient: 0.2033898305084746
20:20 Ratio: 2.5
Max-min Ratio: 2.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-24
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 315.7194531246937
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1847
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.751
    dispatch_time_ms: 7.295
    learner:
      cur_lr: 0.000744948978535831
      grad_gnorm: 40.0
      policy_entropy: 18.784259796142578
      policy_loss: 16.90753746032715
      var_gnorm: 23.255069732666016
      vf_explained_var: 0.0
      vf_loss: 12.974510192871094
    num_steps_sampled: 9240000
    num_steps_trained: 9240000
    wait_time_ms: 73.954
  iterations_since_restore: 1848
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16258.055290699005
  time_this_iter_s: 13.727878332138062
  time_total_s: 16258.055290699005
  timestamp: 1594864824
  timesteps_since_restore: 9240000
  timesteps_this_iter: 5000
  timesteps_total: 9240000
  training_iteration: 1848
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16258 s, 1848 iter, 9240000 ts, 316 rew

agent-1: 77.3957905329972
agent-2: 63.395790532997275
agent-3: 64.39579053299718
agent-4: 69.39579053299715
agent-5: 76.3957905329972
Extrinsic Rewards:
15
1
2
7
14
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 1
Max Reward: 15
Gini Coefficient: 0.41025641025641024
20:20 Ratio: 15.0
Max-min Ratio: 15.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 316.0792426521726
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1848
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.451
    dispatch_time_ms: 8.67
    learner:
      cur_lr: 0.000744615972507745
      grad_gnorm: 40.0
      policy_entropy: 34.431575775146484
      policy_loss: 31.210124969482422
      var_gnorm: 23.26280975341797
      vf_explained_var: 0.0
      vf_loss: 36.046844482421875
    num_steps_sampled: 9245000
    num_steps_trained: 9245000
    wait_time_ms: 72.463
  iterations_since_restore: 1849
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16266.48969078064
  time_this_iter_s: 8.434400081634521
  time_total_s: 16266.48969078064
  timestamp: 1594864833
  timesteps_since_restore: 9245000
  timesteps_this_iter: 5000
  timesteps_total: 9245000
  training_iteration: 1849
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16266 s, 1849 iter, 9245000 ts, 316 rew

agent-1: 103.54065870114319
agent-2: 115.54065870114314
agent-3: 114.54065870114313
agent-4: 110.54065870114313
agent-5: 113.54065870114319
Extrinsic Rewards:
5
17
16
12
15
Sum Reward: 65
Avg Reward: 13.0
Min Reward: 5
Max Reward: 17
Gini Coefficient: 0.1723076923076923
20:20 Ratio: 3.4
Max-min Ratio: 3.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-41
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 316.7962755936984
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1849
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.719
    dispatch_time_ms: 11.023
    learner:
      cur_lr: 0.00074428302468732
      grad_gnorm: 40.0
      policy_entropy: 27.89527130126953
      policy_loss: -7.073329925537109
      var_gnorm: 23.264272689819336
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 4.284034252166748
    num_steps_sampled: 9250000
    num_steps_trained: 9250000
    wait_time_ms: 72.832
  iterations_since_restore: 1850
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16275.099861860275
  time_this_iter_s: 8.61017107963562
  time_total_s: 16275.099861860275
  timestamp: 1594864841
  timesteps_since_restore: 9250000
  timesteps_this_iter: 5000
  timesteps_total: 9250000
  training_iteration: 1850
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16275 s, 1850 iter, 9250000 ts, 317 rew

agent-1: 48.79999999404008
agent-2: 49.799999994040085
agent-3: 53.79999999404007
agent-4: 45.79999999404008
agent-5: 53.79999999404008
Extrinsic Rewards:
4
5
9
1
9
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.3
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-50
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 311.57627631469336
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1850
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.566
    dispatch_time_ms: 8.556
    learner:
      cur_lr: 0.000743950018659234
      grad_gnorm: 40.0
      policy_entropy: 34.44271469116211
      policy_loss: 74.93069458007812
      var_gnorm: 23.254648208618164
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 156.04946899414062
    num_steps_sampled: 9255000
    num_steps_trained: 9255000
    wait_time_ms: 74.814
  iterations_since_restore: 1851
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16283.777776002884
  time_this_iter_s: 8.677914142608643
  time_total_s: 16283.777776002884
  timestamp: 1594864850
  timesteps_since_restore: 9255000
  timesteps_this_iter: 5000
  timesteps_total: 9255000
  training_iteration: 1851
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16283 s, 1851 iter, 9255000 ts, 312 rew

agent-1: 71.59999997713028
agent-2: 82.59999997713027
agent-3: 72.59999997713028
agent-4: 72.59999997713028
agent-5: 69.59999997713027
Extrinsic Rewards:
6
17
7
7
4
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 4
Max Reward: 17
Gini Coefficient: 0.2634146341463415
20:20 Ratio: 4.25
Max-min Ratio: 4.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-00-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 311.66627631423705
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1851
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.739
    dispatch_time_ms: 7.324
    learner:
      cur_lr: 0.0007436170126311481
      grad_gnorm: 21.694499969482422
      policy_entropy: 31.30733871459961
      policy_loss: -3.321207284927368
      var_gnorm: 23.25431251525879
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.3516215980052948
    num_steps_sampled: 9260000
    num_steps_trained: 9260000
    wait_time_ms: 73.981
  iterations_since_restore: 1852
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16292.364080429077
  time_this_iter_s: 8.586304426193237
  time_total_s: 16292.364080429077
  timestamp: 1594864859
  timesteps_since_restore: 9260000
  timesteps_this_iter: 5000
  timesteps_total: 9260000
  training_iteration: 1852
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16292 s, 1852 iter, 9260000 ts, 312 rew

agent-1: 81.19999998536308
agent-2: 73.19999998536304
agent-3: 72.19999998536302
agent-4: 73.19999998536302
agent-5: 78.19999998536306
Extrinsic Rewards:
14
6
5
6
11
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 5
Max Reward: 14
Gini Coefficient: 0.21904761904761905
20:20 Ratio: 2.8
Max-min Ratio: 2.8
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 313.37627631357395
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1852
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.991
    dispatch_time_ms: 11.287
    learner:
      cur_lr: 0.0007432840066030622
      grad_gnorm: 2.5566961765289307
      policy_entropy: 30.173301696777344
      policy_loss: -0.2768542468547821
      var_gnorm: 23.256380081176758
      vf_explained_var: 0.0
      vf_loss: 0.004998301155865192
    num_steps_sampled: 9265000
    num_steps_trained: 9265000
    wait_time_ms: 71.096
  iterations_since_restore: 1853
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16301.01368188858
  time_this_iter_s: 8.649601459503174
  time_total_s: 16301.01368188858
  timestamp: 1594864867
  timesteps_since_restore: 9265000
  timesteps_this_iter: 5000
  timesteps_total: 9265000
  training_iteration: 1853
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16301 s, 1853 iter, 9265000 ts, 313 rew

agent-1: 37.19999999635353
agent-2: 44.19999999635351
agent-3: 41.19999999635352
agent-4: 35.19999999635353
agent-5: 40.19999999635352
Extrinsic Rewards:
2
9
6
0
5
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.4
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-16
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 312.4762763134866
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1853
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.132
    dispatch_time_ms: 8.255
    learner:
      cur_lr: 0.0007429510005749762
      grad_gnorm: 10.967094421386719
      policy_entropy: 33.422218322753906
      policy_loss: -2.1065680980682373
      var_gnorm: 23.25525665283203
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.09263736009597778
    num_steps_sampled: 9270000
    num_steps_trained: 9270000
    wait_time_ms: 75.419
  iterations_since_restore: 1854
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16309.609334945679
  time_this_iter_s: 8.595653057098389
  time_total_s: 16309.609334945679
  timestamp: 1594864876
  timesteps_since_restore: 9270000
  timesteps_this_iter: 5000
  timesteps_total: 9270000
  training_iteration: 1854
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16309 s, 1854 iter, 9270000 ts, 312 rew

agent-1: 50.19999999759353
agent-2: 54.19999999759353
agent-3: 43.199999997593494
agent-4: 47.199999997593515
agent-5: 48.19999999759352
Extrinsic Rewards:
7
11
0
4
5
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.37037037037037035
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 311.3962763183736
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1854
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.086
    dispatch_time_ms: 8.255
    learner:
      cur_lr: 0.0007426179945468903
      grad_gnorm: 1.8013654947280884
      policy_entropy: 33.74934387207031
      policy_loss: 0.06627301126718521
      var_gnorm: 23.257305145263672
      vf_explained_var: 0.0
      vf_loss: 0.002423659898340702
    num_steps_sampled: 9275000
    num_steps_trained: 9275000
    wait_time_ms: 75.163
  iterations_since_restore: 1855
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16318.283496141434
  time_this_iter_s: 8.674161195755005
  time_total_s: 16318.283496141434
  timestamp: 1594864885
  timesteps_since_restore: 9275000
  timesteps_this_iter: 5000
  timesteps_total: 9275000
  training_iteration: 1855
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16318 s, 1855 iter, 9275000 ts, 311 rew

agent-1: 38.99999999916436
agent-2: 34.99999999916436
agent-3: 34.99999999916436
agent-4: 35.99999999916434
agent-5: 34.99999999916436
Extrinsic Rewards:
7
3
3
4
3
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 3
Max Reward: 7
Gini Coefficient: 0.18
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-33
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 311.0362763185315
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1855
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.0
    dispatch_time_ms: 9.542
    learner:
      cur_lr: 0.0007422849885188043
      grad_gnorm: 14.547113418579102
      policy_entropy: 34.65729522705078
      policy_loss: -3.145501136779785
      var_gnorm: 23.255542755126953
      vf_explained_var: 0.0
      vf_loss: 0.16065937280654907
    num_steps_sampled: 9280000
    num_steps_trained: 9280000
    wait_time_ms: 73.529
  iterations_since_restore: 1856
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16326.86640882492
  time_this_iter_s: 8.582912683486938
  time_total_s: 16326.86640882492
  timestamp: 1594864893
  timesteps_since_restore: 9280000
  timesteps_this_iter: 5000
  timesteps_total: 9280000
  training_iteration: 1856
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16326 s, 1856 iter, 9280000 ts, 311 rew

agent-1: 34.79999999949239
agent-2: 31.79999999949238
agent-3: 28.79999999949237
agent-4: 31.79999999949238
agent-5: 34.79999999949239
Extrinsic Rewards:
6
3
0
3
6
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.3333333333333333
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-42
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 310.7662763185815
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1856
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.02
    dispatch_time_ms: 8.958
    learner:
      cur_lr: 0.0007419519824907184
      grad_gnorm: 1.8587749004364014
      policy_entropy: 34.35871887207031
      policy_loss: -0.1882537454366684
      var_gnorm: 23.258502960205078
      vf_explained_var: 0.0
      vf_loss: 0.0025900807231664658
    num_steps_sampled: 9285000
    num_steps_trained: 9285000
    wait_time_ms: 72.581
  iterations_since_restore: 1857
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16335.4531686306
  time_this_iter_s: 8.586759805679321
  time_total_s: 16335.4531686306
  timestamp: 1594864902
  timesteps_since_restore: 9285000
  timesteps_this_iter: 5000
  timesteps_total: 9285000
  training_iteration: 1857
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16335 s, 1857 iter, 9285000 ts, 311 rew

agent-1: 56.99999999160203
agent-2: 62.99999999160203
agent-3: 64.99999999160205
agent-4: 59.99999999160203
agent-5: 69.99999999160214
Extrinsic Rewards:
1
7
9
4
14
Sum Reward: 35
Avg Reward: 7.0
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.35428571428571426
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-51
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 310.496276327938
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1857
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.728
    dispatch_time_ms: 6.214
    learner:
      cur_lr: 0.0007416189764626324
      grad_gnorm: 23.679351806640625
      policy_entropy: 34.65427780151367
      policy_loss: -4.060535430908203
      var_gnorm: 23.254758834838867
      vf_explained_var: 0.0
      vf_loss: 0.43354296684265137
    num_steps_sampled: 9290000
    num_steps_trained: 9290000
    wait_time_ms: 78.695
  iterations_since_restore: 1858
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16344.169756412506
  time_this_iter_s: 8.716587781906128
  time_total_s: 16344.169756412506
  timestamp: 1594864911
  timesteps_since_restore: 9290000
  timesteps_this_iter: 5000
  timesteps_total: 9290000
  training_iteration: 1858
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16344 s, 1858 iter, 9290000 ts, 310 rew

agent-1: 67.39999995902046
agent-2: 70.39999995902046
agent-3: 71.39999995902045
agent-4: 68.39999995902045
agent-5: 73.39999995902049
Extrinsic Rewards:
5
8
9
6
11
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 5
Max Reward: 11
Gini Coefficient: 0.15384615384615385
20:20 Ratio: 2.2
Max-min Ratio: 2.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-01-59
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 312.47627632591184
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1858
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.769
    dispatch_time_ms: 47.579
    learner:
      cur_lr: 0.0007412860286422074
      grad_gnorm: 40.000003814697266
      policy_entropy: 29.371471405029297
      policy_loss: 20.469589233398438
      var_gnorm: 23.258220672607422
      vf_explained_var: 1.7881393432617188e-07
      vf_loss: 17.40484619140625
    num_steps_sampled: 9295000
    num_steps_trained: 9295000
    wait_time_ms: 32.377
  iterations_since_restore: 1859
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16352.78615474701
  time_this_iter_s: 8.616398334503174
  time_total_s: 16352.78615474701
  timestamp: 1594864919
  timesteps_since_restore: 9295000
  timesteps_this_iter: 5000
  timesteps_total: 9295000
  training_iteration: 1859
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 39.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16352 s, 1859 iter, 9295000 ts, 312 rew

agent-1: 50.79999999245481
agent-2: 45.79999999245481
agent-3: 51.79999999245481
agent-4: 51.79999999245481
agent-5: 51.799999992454794
Extrinsic Rewards:
6
1
7
7
7
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.18571428571428572
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 836.9980302817013
  episode_reward_mean: 312.9262763255784
  episode_reward_min: 143.99999999687262
  episodes_this_iter: 1
  episodes_total: 1859
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.659
    dispatch_time_ms: 36.491
    learner:
      cur_lr: 0.0007409530226141214
      grad_gnorm: 40.0
      policy_entropy: 29.61174201965332
      policy_loss: -4.49370002746582
      var_gnorm: 23.252824783325195
      vf_explained_var: 0.0
      vf_loss: 1.2606490850448608
    num_steps_sampled: 9300000
    num_steps_trained: 9300000
    wait_time_ms: 49.355
  iterations_since_restore: 1860
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16361.906888246536
  time_this_iter_s: 9.120733499526978
  time_total_s: 16361.906888246536
  timestamp: 1594864929
  timesteps_since_restore: 9300000
  timesteps_this_iter: 5000
  timesteps_total: 9300000
  training_iteration: 1860
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16361 s, 1860 iter, 9300000 ts, 313 rew

agent-1: 196.5177106042061
agent-2: 179.51771060420623
agent-3: 184.5177106042061
agent-4: 184.51771060420614
agent-5: 197.5177106042061
Extrinsic Rewards:
30
13
18
18
31
Sum Reward: 110
Avg Reward: 22.0
Min Reward: 13
Max Reward: 31
Gini Coefficient: 0.17454545454545456
20:20 Ratio: 2.3846153846153846
Max-min Ratio: 2.3846153846153846
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 320.91216185582005
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1860
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.036
    dispatch_time_ms: 34.153
    learner:
      cur_lr: 0.0007406200165860355
      grad_gnorm: 38.5121955871582
      policy_entropy: 33.67646026611328
      policy_loss: -6.842417240142822
      var_gnorm: 23.25271224975586
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.1293699741363525
    num_steps_sampled: 9305000
    num_steps_trained: 9305000
    wait_time_ms: 60.233
  iterations_since_restore: 1861
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16370.987674236298
  time_this_iter_s: 9.080785989761353
  time_total_s: 16370.987674236298
  timestamp: 1594864938
  timesteps_since_restore: 9305000
  timesteps_this_iter: 5000
  timesteps_total: 9305000
  training_iteration: 1861
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16370 s, 1861 iter, 9305000 ts, 321 rew

agent-1: 55.799999993787026
agent-2: 51.799999993787026
agent-3: 50.79999999378702
agent-4: 45.79999999378702
agent-5: 47.79999999378702
Extrinsic Rewards:
11
7
6
1
3
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.34285714285714286
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 321.54216185554736
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1861
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.673
    dispatch_time_ms: 46.121
    learner:
      cur_lr: 0.0007402870105579495
      grad_gnorm: 19.084428787231445
      policy_entropy: 10.232377052307129
      policy_loss: -1.4244881868362427
      var_gnorm: 23.25403594970703
      vf_explained_var: 0.0
      vf_loss: 0.2819176912307739
    num_steps_sampled: 9310000
    num_steps_trained: 9310000
    wait_time_ms: 45.825
  iterations_since_restore: 1862
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16380.07104587555
  time_this_iter_s: 9.083371639251709
  time_total_s: 16380.07104587555
  timestamp: 1594864947
  timesteps_since_restore: 9310000
  timesteps_this_iter: 5000
  timesteps_total: 9310000
  training_iteration: 1862
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16380 s, 1862 iter, 9310000 ts, 322 rew

agent-1: 36.99999999933402
agent-2: 36.99999999933402
agent-3: 37.99999999933402
agent-4: 31.99999999933393
agent-5: 35.999999999334015
Extrinsic Rewards:
5
5
6
0
4
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 0
Max Reward: 6
Gini Coefficient: 0.26
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 321.1821618556022
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1862
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.795
    dispatch_time_ms: 44.211
    learner:
      cur_lr: 0.0007399540045298636
      grad_gnorm: 27.920297622680664
      policy_entropy: 8.140790939331055
      policy_loss: 1.8294686079025269
      var_gnorm: 23.256383895874023
      vf_explained_var: 0.0
      vf_loss: 0.5990228056907654
    num_steps_sampled: 9315000
    num_steps_trained: 9315000
    wait_time_ms: 44.673
  iterations_since_restore: 1863
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16389.046919107437
  time_this_iter_s: 8.975873231887817
  time_total_s: 16389.046919107437
  timestamp: 1594864956
  timesteps_since_restore: 9315000
  timesteps_this_iter: 5000
  timesteps_total: 9315000
  training_iteration: 1863
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16389 s, 1863 iter, 9315000 ts, 321 rew

agent-1: 38.199999998963634
agent-2: 45.19999999896365
agent-3: 42.19999999896364
agent-4: 36.199999998963634
agent-5: 36.19999999896363
Extrinsic Rewards:
3
10
7
1
1
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 1
Max Reward: 10
Gini Coefficient: 0.43636363636363634
20:20 Ratio: 10.0
Max-min Ratio: 10.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 320.91216185560944
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1863
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.028
    dispatch_time_ms: 8.445
    learner:
      cur_lr: 0.0007396209985017776
      grad_gnorm: 40.0
      policy_entropy: 28.752159118652344
      policy_loss: 12.712656021118164
      var_gnorm: 23.257770538330078
      vf_explained_var: 0.0
      vf_loss: 7.823737621307373
    num_steps_sampled: 9320000
    num_steps_trained: 9320000
    wait_time_ms: 70.113
  iterations_since_restore: 1864
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16397.465803861618
  time_this_iter_s: 8.418884754180908
  time_total_s: 16397.465803861618
  timestamp: 1594864964
  timesteps_since_restore: 9320000
  timesteps_this_iter: 5000
  timesteps_total: 9320000
  training_iteration: 1864
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.7/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16397 s, 1864 iter, 9320000 ts, 321 rew

agent-1: 86.19968816026181
agent-2: 87.19968816026181
agent-3: 86.19968816026181
agent-4: 83.19968816026179
agent-5: 80.19968816026179
Extrinsic Rewards:
11
12
11
8
5
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 5
Max Reward: 12
Gini Coefficient: 0.14468085106382977
20:20 Ratio: 2.4
Max-min Ratio: 2.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-02-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 322.89214626378845
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1864
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.771
    dispatch_time_ms: 10.699
    learner:
      cur_lr: 0.0007392879924736917
      grad_gnorm: 39.999996185302734
      policy_entropy: 31.916152954101562
      policy_loss: 38.594417572021484
      var_gnorm: 23.25632667541504
      vf_explained_var: 0.0
      vf_loss: 56.51664352416992
    num_steps_sampled: 9325000
    num_steps_trained: 9325000
    wait_time_ms: 72.14
  iterations_since_restore: 1865
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16406.064606189728
  time_this_iter_s: 8.598802328109741
  time_total_s: 16406.064606189728
  timestamp: 1594864973
  timesteps_since_restore: 9325000
  timesteps_this_iter: 5000
  timesteps_total: 9325000
  training_iteration: 1865
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16406 s, 1865 iter, 9325000 ts, 323 rew

agent-1: 131.19878142441107
agent-2: 128.19878142441112
agent-3: 132.19878142441107
agent-4: 126.19878142441121
agent-5: 130.19878142441112
Extrinsic Rewards:
16
13
17
11
15
Sum Reward: 72
Avg Reward: 14.4
Min Reward: 11
Max Reward: 17
Gini Coefficient: 0.08333333333333333
20:20 Ratio: 1.5454545454545454
Max-min Ratio: 1.5454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 326.8520853351276
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1865
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.578
    dispatch_time_ms: 5.962
    learner:
      cur_lr: 0.0007389549864456058
      grad_gnorm: 39.57694625854492
      policy_entropy: 23.45612907409668
      policy_loss: -3.8787424564361572
      var_gnorm: 23.25420379638672
      vf_explained_var: 0.0
      vf_loss: 1.172814965248108
    num_steps_sampled: 9330000
    num_steps_trained: 9330000
    wait_time_ms: 82.696
  iterations_since_restore: 1866
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16414.732347249985
  time_this_iter_s: 8.667741060256958
  time_total_s: 16414.732347249985
  timestamp: 1594864982
  timesteps_since_restore: 9330000
  timesteps_this_iter: 5000
  timesteps_total: 9330000
  training_iteration: 1866
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16414 s, 1866 iter, 9330000 ts, 327 rew

agent-1: 58.79999999792643
agent-2: 46.79999999792644
agent-3: 48.79999999792644
agent-4: 45.79999999792644
agent-5: 51.799999997926435
Extrinsic Rewards:
14
2
4
1
7
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 1
Max Reward: 14
Gini Coefficient: 0.44285714285714284
20:20 Ratio: 14.0
Max-min Ratio: 14.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 327.3920853350653
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1866
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.475
    dispatch_time_ms: 8.317
    learner:
      cur_lr: 0.0007386219804175198
      grad_gnorm: 40.0
      policy_entropy: 27.212886810302734
      policy_loss: 47.40960693359375
      var_gnorm: 23.25934410095215
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 92.61978912353516
    num_steps_sampled: 9335000
    num_steps_trained: 9335000
    wait_time_ms: 70.918
  iterations_since_restore: 1867
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16423.39532852173
  time_this_iter_s: 8.662981271743774
  time_total_s: 16423.39532852173
  timestamp: 1594864990
  timesteps_since_restore: 9335000
  timesteps_this_iter: 5000
  timesteps_total: 9335000
  training_iteration: 1867
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16423 s, 1867 iter, 9335000 ts, 327 rew

agent-1: 46.199999993630954
agent-2: 49.19999999363096
agent-3: 48.19999999363096
agent-4: 52.19999999363096
agent-5: 47.199999993630954
Extrinsic Rewards:
3
6
5
9
4
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.2074074074074074
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 327.4820853348351
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1867
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.239
    dispatch_time_ms: 8.913
    learner:
      cur_lr: 0.0007382889743894339
      grad_gnorm: 30.1348934173584
      policy_entropy: 15.9885835647583
      policy_loss: -2.849876642227173
      var_gnorm: 23.2546443939209
      vf_explained_var: 0.0
      vf_loss: 0.6968039274215698
    num_steps_sampled: 9340000
    num_steps_trained: 9340000
    wait_time_ms: 74.127
  iterations_since_restore: 1868
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16431.96737909317
  time_this_iter_s: 8.57205057144165
  time_total_s: 16431.96737909317
  timestamp: 1594864999
  timesteps_since_restore: 9340000
  timesteps_this_iter: 5000
  timesteps_total: 9340000
  training_iteration: 1868
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16431 s, 1868 iter, 9340000 ts, 327 rew

agent-1: 71.3999999565167
agent-2: 72.39999995651671
agent-3: 62.39999995651686
agent-4: 74.39999995651672
agent-5: 70.3999999565167
Extrinsic Rewards:
9
10
0
12
8
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 0
Max Reward: 12
Gini Coefficient: 0.26666666666666666
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 329.1920853327106
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1868
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.586
    dispatch_time_ms: 8.294
    learner:
      cur_lr: 0.0007379560265690088
      grad_gnorm: 5.167010307312012
      policy_entropy: 12.480154037475586
      policy_loss: -0.1487063318490982
      var_gnorm: 23.25706672668457
      vf_explained_var: 0.0
      vf_loss: 0.02023088000714779
    num_steps_sampled: 9345000
    num_steps_trained: 9345000
    wait_time_ms: 73.077
  iterations_since_restore: 1869
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16440.47942352295
  time_this_iter_s: 8.512044429779053
  time_total_s: 16440.47942352295
  timestamp: 1594865007
  timesteps_since_restore: 9345000
  timesteps_this_iter: 5000
  timesteps_total: 9345000
  training_iteration: 1869
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16440 s, 1869 iter, 9345000 ts, 329 rew

agent-1: 70.79999980635618
agent-2: 72.7999998063562
agent-3: 83.7999998063562
agent-4: 78.79999980635618
agent-5: 80.79999980635618
Extrinsic Rewards:
2
4
15
10
12
Sum Reward: 43
Avg Reward: 8.6
Min Reward: 2
Max Reward: 15
Gini Coefficient: 0.31627906976744186
20:20 Ratio: 7.5
Max-min Ratio: 7.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 328.5620853249069
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1869
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.893
    dispatch_time_ms: 8.019
    learner:
      cur_lr: 0.0007376230205409229
      grad_gnorm: 23.698957443237305
      policy_entropy: 17.903289794921875
      policy_loss: -2.1119728088378906
      var_gnorm: 23.254209518432617
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.4343755543231964
    num_steps_sampled: 9350000
    num_steps_trained: 9350000
    wait_time_ms: 75.68
  iterations_since_restore: 1870
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16448.87985110283
  time_this_iter_s: 8.40042757987976
  time_total_s: 16448.87985110283
  timestamp: 1594865016
  timesteps_since_restore: 9350000
  timesteps_this_iter: 5000
  timesteps_total: 9350000
  training_iteration: 1870
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16448 s, 1870 iter, 9350000 ts, 329 rew

agent-1: 46.999999994208984
agent-2: 41.99999999420898
agent-3: 45.99999999420896
agent-4: 44.99999999420896
agent-5: 44.99999999420897
Extrinsic Rewards:
7
2
6
5
5
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.176
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 324.96208543833706
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1870
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 9.883
    learner:
      cur_lr: 0.0007372900145128369
      grad_gnorm: 39.99999237060547
      policy_entropy: 14.349865913391113
      policy_loss: 29.21812629699707
      var_gnorm: 23.258684158325195
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 212.92330932617188
    num_steps_sampled: 9355000
    num_steps_trained: 9355000
    wait_time_ms: 70.918
  iterations_since_restore: 1871
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16457.382224798203
  time_this_iter_s: 8.502373695373535
  time_total_s: 16457.382224798203
  timestamp: 1594865024
  timesteps_since_restore: 9355000
  timesteps_this_iter: 5000
  timesteps_total: 9355000
  training_iteration: 1871
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16457 s, 1871 iter, 9355000 ts, 325 rew

agent-1: 60.39999997781002
agent-2: 70.39999997780997
agent-3: 60.39999997781002
agent-4: 59.399999977810026
agent-5: 55.399999977810005
Extrinsic Rewards:
6
16
6
5
1
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 1
Max Reward: 16
Gini Coefficient: 0.36470588235294116
20:20 Ratio: 16.0
Max-min Ratio: 16.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-03-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 322.4420855405071
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1871
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.831
    dispatch_time_ms: 7.116
    learner:
      cur_lr: 0.000736957008484751
      grad_gnorm: 29.71551513671875
      policy_entropy: 24.33045196533203
      policy_loss: -2.4886221885681152
      var_gnorm: 23.254554748535156
      vf_explained_var: 0.0
      vf_loss: 0.6218001842498779
    num_steps_sampled: 9360000
    num_steps_trained: 9360000
    wait_time_ms: 75.003
  iterations_since_restore: 1872
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16465.825510025024
  time_this_iter_s: 8.4432852268219
  time_total_s: 16465.825510025024
  timestamp: 1594865033
  timesteps_since_restore: 9360000
  timesteps_this_iter: 5000
  timesteps_total: 9360000
  training_iteration: 1872
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16465 s, 1872 iter, 9360000 ts, 322 rew

agent-1: 135.99999134736964
agent-2: 132.9999913473697
agent-3: 133.9999913473696
agent-4: 138.9999913473697
agent-5: 132.99999134736967
Extrinsic Rewards:
16
13
14
19
13
Sum Reward: 75
Avg Reward: 15.0
Min Reward: 13
Max Reward: 19
Gini Coefficient: 0.08
20:20 Ratio: 1.4615384615384615
Max-min Ratio: 1.4615384615384615
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 327.66208510790057
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1872
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.218
    dispatch_time_ms: 8.81
    learner:
      cur_lr: 0.000736624002456665
      grad_gnorm: 7.213718891143799
      policy_entropy: 14.280691146850586
      policy_loss: -0.5513975620269775
      var_gnorm: 23.256376266479492
      vf_explained_var: 0.0
      vf_loss: 0.04028787836432457
    num_steps_sampled: 9365000
    num_steps_trained: 9365000
    wait_time_ms: 73.415
  iterations_since_restore: 1873
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16474.43501973152
  time_this_iter_s: 8.609509706497192
  time_total_s: 16474.43501973152
  timestamp: 1594865042
  timesteps_since_restore: 9365000
  timesteps_this_iter: 5000
  timesteps_total: 9365000
  training_iteration: 1873
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16474 s, 1873 iter, 9365000 ts, 328 rew

agent-1: 70.39999995927202
agent-2: 79.39999995927204
agent-3: 82.39999995927205
agent-4: 72.39999995927201
agent-5: 91.39999995927207
Extrinsic Rewards:
0
9
12
2
21
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 0
Max Reward: 21
Gini Coefficient: 0.4727272727272727
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 328.9220851059735
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1873
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.304
    dispatch_time_ms: 7.415
    learner:
      cur_lr: 0.0007362909964285791
      grad_gnorm: 40.0
      policy_entropy: 21.34966468811035
      policy_loss: -2.8641157150268555
      var_gnorm: 23.252750396728516
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 1.4154378175735474
    num_steps_sampled: 9370000
    num_steps_trained: 9370000
    wait_time_ms: 74.568
  iterations_since_restore: 1874
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16482.812938451767
  time_this_iter_s: 8.377918720245361
  time_total_s: 16482.812938451767
  timestamp: 1594865050
  timesteps_since_restore: 9370000
  timesteps_this_iter: 5000
  timesteps_total: 9370000
  training_iteration: 1874
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16482 s, 1874 iter, 9370000 ts, 329 rew

agent-1: 55.79999992919438
agent-2: 65.79999992919414
agent-3: 60.799999929194385
agent-4: 58.79999992919438
agent-5: 55.79999992919438
Extrinsic Rewards:
3
13
8
6
3
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 3
Max Reward: 13
Gini Coefficient: 0.30303030303030304
20:20 Ratio: 4.333333333333333
Max-min Ratio: 4.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 329.82208510250473
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1874
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.671
    dispatch_time_ms: 6.846
    learner:
      cur_lr: 0.0007359579904004931
      grad_gnorm: 7.40439510345459
      policy_entropy: 23.335216522216797
      policy_loss: -0.7330248355865479
      var_gnorm: 23.258075714111328
      vf_explained_var: 0.0
      vf_loss: 0.042011458426713943
    num_steps_sampled: 9375000
    num_steps_trained: 9375000
    wait_time_ms: 76.947
  iterations_since_restore: 1875
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16491.39658522606
  time_this_iter_s: 8.583646774291992
  time_total_s: 16491.39658522606
  timestamp: 1594865059
  timesteps_since_restore: 9375000
  timesteps_this_iter: 5000
  timesteps_total: 9375000
  training_iteration: 1875
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16491 s, 1875 iter, 9375000 ts, 330 rew

agent-1: 124.7999981879585
agent-2: 117.7999981879585
agent-3: 126.7999981879585
agent-4: 122.79999818795851
agent-5: 119.79999818795852
Extrinsic Rewards:
16
9
18
14
11
Sum Reward: 68
Avg Reward: 13.6
Min Reward: 9
Max Reward: 18
Gini Coefficient: 0.13529411764705881
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-37
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 333.6020850120351
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1875
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.911
    dispatch_time_ms: 8.224
    learner:
      cur_lr: 0.0007356249843724072
      grad_gnorm: 12.25362777709961
      policy_entropy: 34.650856018066406
      policy_loss: -2.0930075645446777
      var_gnorm: 23.25459098815918
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.11543948203325272
    num_steps_sampled: 9380000
    num_steps_trained: 9380000
    wait_time_ms: 80.474
  iterations_since_restore: 1876
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16510.0351228714
  time_this_iter_s: 18.638537645339966
  time_total_s: 16510.0351228714
  timestamp: 1594865077
  timesteps_since_restore: 9380000
  timesteps_this_iter: 5000
  timesteps_total: 9380000
  training_iteration: 1876
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16510 s, 1876 iter, 9380000 ts, 334 rew

agent-1: 63.79999999632219
agent-2: 59.79999999632218
agent-3: 61.79999999632219
agent-4: 57.79999999632219
agent-5: 53.79999999632219
Extrinsic Rewards:
11
7
9
5
1
Sum Reward: 33
Avg Reward: 6.6
Min Reward: 1
Max Reward: 11
Gini Coefficient: 0.2909090909090909
20:20 Ratio: 11.0
Max-min Ratio: 11.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-46
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 334.3220850120282
  episode_reward_min: 143.99999999782278
  episodes_this_iter: 1
  episodes_total: 1876
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.462
    dispatch_time_ms: 11.633
    learner:
      cur_lr: 0.0007352919783443213
      grad_gnorm: 39.999996185302734
      policy_entropy: 34.623470306396484
      policy_loss: 75.34052276611328
      var_gnorm: 23.26345443725586
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 159.57298278808594
    num_steps_sampled: 9385000
    num_steps_trained: 9385000
    wait_time_ms: 71.0
  iterations_since_restore: 1877
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16518.637776374817
  time_this_iter_s: 8.602653503417969
  time_total_s: 16518.637776374817
  timestamp: 1594865086
  timesteps_since_restore: 9385000
  timesteps_this_iter: 5000
  timesteps_total: 9385000
  training_iteration: 1877
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16518 s, 1877 iter, 9385000 ts, 334 rew

agent-1: 35.19999999928067
agent-2: 37.19999999928066
agent-3: 43.19999999928064
agent-4: 42.19999999928066
agent-5: 40.19999999928066
Extrinsic Rewards:
0
2
8
7
5
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 0
Max Reward: 8
Gini Coefficient: 0.38181818181818183
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-04-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 334.862085012014
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1877
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.364
    dispatch_time_ms: 7.992
    learner:
      cur_lr: 0.0007349589723162353
      grad_gnorm: 19.185657501220703
      policy_entropy: 22.40142822265625
      policy_loss: -2.127847909927368
      var_gnorm: 23.250091552734375
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2836430072784424
    num_steps_sampled: 9390000
    num_steps_trained: 9390000
    wait_time_ms: 74.888
  iterations_since_restore: 1878
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16527.253159999847
  time_this_iter_s: 8.615383625030518
  time_total_s: 16527.253159999847
  timestamp: 1594865095
  timesteps_since_restore: 9390000
  timesteps_this_iter: 5000
  timesteps_total: 9390000
  training_iteration: 1878
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16527 s, 1878 iter, 9390000 ts, 335 rew

agent-1: 64.3999999902999
agent-2: 74.39999999030005
agent-3: 62.39999999029979
agent-4: 79.39999999030003
agent-5: 70.39999999029999
Extrinsic Rewards:
2
12
0
17
8
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 0
Max Reward: 17
Gini Coefficient: 0.4512820512820513
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-03
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 336.6620850115877
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1878
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.948
    dispatch_time_ms: 8.047
    learner:
      cur_lr: 0.0007346260244958103
      grad_gnorm: 2.388458251953125
      policy_entropy: 16.81572723388672
      policy_loss: -0.31371986865997314
      var_gnorm: 23.2552490234375
      vf_explained_var: 0.0
      vf_loss: 0.004172812215983868
    num_steps_sampled: 9395000
    num_steps_trained: 9395000
    wait_time_ms: 74.159
  iterations_since_restore: 1879
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16535.914481639862
  time_this_iter_s: 8.661321640014648
  time_total_s: 16535.914481639862
  timestamp: 1594865103
  timesteps_since_restore: 9395000
  timesteps_this_iter: 5000
  timesteps_total: 9395000
  training_iteration: 1879
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16535 s, 1879 iter, 9395000 ts, 337 rew

agent-1: 59.399999992631535
agent-2: 62.399999992631535
agent-3: 61.399999992631535
agent-4: 60.399999992631535
agent-5: 62.39999999263154
Extrinsic Rewards:
5
8
7
6
8
Sum Reward: 34
Avg Reward: 6.8
Min Reward: 5
Max Reward: 8
Gini Coefficient: 0.09411764705882353
20:20 Ratio: 1.6
Max-min Ratio: 1.6
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-12
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 335.49208502123093
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1879
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.961
    dispatch_time_ms: 8.276
    learner:
      cur_lr: 0.0007342930184677243
      grad_gnorm: 39.53557586669922
      policy_entropy: 15.956158638000488
      policy_loss: -3.6678171157836914
      var_gnorm: 23.253681182861328
      vf_explained_var: 0.0
      vf_loss: 1.19015371799469
    num_steps_sampled: 9400000
    num_steps_trained: 9400000
    wait_time_ms: 75.034
  iterations_since_restore: 1880
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16544.59221792221
  time_this_iter_s: 8.677736282348633
  time_total_s: 16544.59221792221
  timestamp: 1594865112
  timesteps_since_restore: 9400000
  timesteps_this_iter: 5000
  timesteps_total: 9400000
  training_iteration: 1880
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16544 s, 1880 iter, 9400000 ts, 335 rew

agent-1: 141.39999336631516
agent-2: 140.39999336631513
agent-3: 127.3999933663151
agent-4: 128.39999336631516
agent-5: 128.39999336631513
Extrinsic Rewards:
23
22
9
10
10
Sum Reward: 74
Avg Reward: 14.8
Min Reward: 9
Max Reward: 23
Gini Coefficient: 0.21621621621621623
20:20 Ratio: 2.5555555555555554
Max-min Ratio: 2.5555555555555554
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 340.0820846906131
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1880
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.86
    dispatch_time_ms: 6.14
    learner:
      cur_lr: 0.0007339600124396384
      grad_gnorm: 11.30488109588623
      policy_entropy: 12.786032676696777
      policy_loss: -0.8034534454345703
      var_gnorm: 23.24951934814453
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.09877084195613861
    num_steps_sampled: 9405000
    num_steps_trained: 9405000
    wait_time_ms: 81.776
  iterations_since_restore: 1881
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16553.276216506958
  time_this_iter_s: 8.683998584747314
  time_total_s: 16553.276216506958
  timestamp: 1594865121
  timesteps_since_restore: 9405000
  timesteps_this_iter: 5000
  timesteps_total: 9405000
  training_iteration: 1881
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16553 s, 1881 iter, 9405000 ts, 340 rew

agent-1: 119.79999948641937
agent-2: 112.79999948641932
agent-3: 115.79999948641935
agent-4: 113.79999948641932
agent-5: 104.79999948641931
Extrinsic Rewards:
19
12
15
13
4
Sum Reward: 63
Avg Reward: 12.6
Min Reward: 4
Max Reward: 19
Gini Coefficient: 0.20952380952380953
20:20 Ratio: 4.75
Max-min Ratio: 4.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-29
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 343.1420846651719
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1881
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.455
    dispatch_time_ms: 5.806
    learner:
      cur_lr: 0.0007336270064115524
      grad_gnorm: 40.000003814697266
      policy_entropy: 18.350421905517578
      policy_loss: -5.3217692375183105
      var_gnorm: 23.24984359741211
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 2.214503765106201
    num_steps_sampled: 9410000
    num_steps_trained: 9410000
    wait_time_ms: 80.53
  iterations_since_restore: 1882
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16561.84026479721
  time_this_iter_s: 8.564048290252686
  time_total_s: 16561.84026479721
  timestamp: 1594865129
  timesteps_since_restore: 9410000
  timesteps_this_iter: 5000
  timesteps_total: 9410000
  training_iteration: 1882
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16561 s, 1882 iter, 9410000 ts, 343 rew

agent-1: 95.19999956804911
agent-2: 93.19999956804908
agent-3: 92.19999956804908
agent-4: 88.19999956804905
agent-5: 99.19999956804911
Extrinsic Rewards:
12
10
9
5
16
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 5
Max Reward: 16
Gini Coefficient: 0.19230769230769232
20:20 Ratio: 3.2
Max-min Ratio: 3.2
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-38
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 346.2920846436077
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1882
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.684
    dispatch_time_ms: 7.474
    learner:
      cur_lr: 0.0007332940003834665
      grad_gnorm: 23.66213607788086
      policy_entropy: 10.579023361206055
      policy_loss: -1.644066333770752
      var_gnorm: 23.249834060668945
      vf_explained_var: 0.0
      vf_loss: 0.43190598487854004
    num_steps_sampled: 9415000
    num_steps_trained: 9415000
    wait_time_ms: 76.052
  iterations_since_restore: 1883
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16570.544979333878
  time_this_iter_s: 8.70471453666687
  time_total_s: 16570.544979333878
  timestamp: 1594865138
  timesteps_since_restore: 9415000
  timesteps_this_iter: 5000
  timesteps_total: 9415000
  training_iteration: 1883
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16570 s, 1883 iter, 9415000 ts, 346 rew

agent-1: 167.39985843489177
agent-2: 170.3998584348918
agent-3: 177.39985843489177
agent-4: 169.3998584348918
agent-5: 161.39985843489177
Extrinsic Rewards:
17
20
27
19
11
Sum Reward: 94
Avg Reward: 18.8
Min Reward: 11
Max Reward: 27
Gini Coefficient: 0.14893617021276595
20:20 Ratio: 2.4545454545454546
Max-min Ratio: 2.4545454545454546
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 349.62207761511223
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1883
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.156
    dispatch_time_ms: 8.03
    learner:
      cur_lr: 0.0007329609943553805
      grad_gnorm: 40.000003814697266
      policy_entropy: 29.113826751708984
      policy_loss: 42.273780822753906
      var_gnorm: 23.253482818603516
      vf_explained_var: 0.0
      vf_loss: 84.48555755615234
    num_steps_sampled: 9420000
    num_steps_trained: 9420000
    wait_time_ms: 74.774
  iterations_since_restore: 1884
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16579.09357523918
  time_this_iter_s: 8.548595905303955
  time_total_s: 16579.09357523918
  timestamp: 1594865147
  timesteps_since_restore: 9420000
  timesteps_this_iter: 5000
  timesteps_total: 9420000
  training_iteration: 1884
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16579 s, 1884 iter, 9420000 ts, 350 rew

agent-1: 97.1999973388723
agent-2: 93.19999733887232
agent-3: 90.19999733887231
agent-4: 92.19999733887232
agent-5: 95.19999733887232
Extrinsic Rewards:
14
10
7
9
12
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 7
Max Reward: 14
Gini Coefficient: 0.13076923076923078
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-05-55
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 352.592077482085
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1884
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.812
    dispatch_time_ms: 8.68
    learner:
      cur_lr: 0.0007326279883272946
      grad_gnorm: 25.353429794311523
      policy_entropy: 14.001641273498535
      policy_loss: -1.7598044872283936
      var_gnorm: 23.253841400146484
      vf_explained_var: 0.0
      vf_loss: 0.4977961778640747
    num_steps_sampled: 9425000
    num_steps_trained: 9425000
    wait_time_ms: 73.763
  iterations_since_restore: 1885
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16587.727775335312
  time_this_iter_s: 8.634200096130371
  time_total_s: 16587.727775335312
  timestamp: 1594865155
  timesteps_since_restore: 9425000
  timesteps_this_iter: 5000
  timesteps_total: 9425000
  training_iteration: 1885
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16587 s, 1885 iter, 9425000 ts, 353 rew

agent-1: 135.79998772685315
agent-2: 128.7999877268531
agent-3: 124.7999877268531
agent-4: 129.79998772685298
agent-5: 137.79998772685315
Extrinsic Rewards:
19
12
8
13
21
Sum Reward: 73
Avg Reward: 14.6
Min Reward: 8
Max Reward: 21
Gini Coefficient: 0.18082191780821918
20:20 Ratio: 2.625
Max-min Ratio: 2.625
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-04
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 356.19207686949017
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1885
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.758
    dispatch_time_ms: 6.947
    learner:
      cur_lr: 0.0007322949822992086
      grad_gnorm: 0.7864744067192078
      policy_entropy: 24.552993774414062
      policy_loss: -0.15190082788467407
      var_gnorm: 23.250444412231445
      vf_explained_var: 0.0
      vf_loss: 0.0014193103415891528
    num_steps_sampled: 9430000
    num_steps_trained: 9430000
    wait_time_ms: 81.148
  iterations_since_restore: 1886
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16596.332961797714
  time_this_iter_s: 8.605186462402344
  time_total_s: 16596.332961797714
  timestamp: 1594865164
  timesteps_since_restore: 9430000
  timesteps_this_iter: 5000
  timesteps_total: 9430000
  training_iteration: 1886
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16596 s, 1886 iter, 9430000 ts, 356 rew

agent-1: 60.599999967412096
agent-2: 64.59999996741209
agent-3: 66.599999967412
agent-4: 67.59999996741206
agent-5: 64.5999999674121
Extrinsic Rewards:
3
7
9
10
7
Sum Reward: 36
Avg Reward: 7.2
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.17777777777777778
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 357.5420768678938
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1886
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.878
    dispatch_time_ms: 8.653
    learner:
      cur_lr: 0.0007319619762711227
      grad_gnorm: 11.128320693969727
      policy_entropy: 33.70118713378906
      policy_loss: -1.7463635206222534
      var_gnorm: 23.265703201293945
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.09589595347642899
    num_steps_sampled: 9435000
    num_steps_trained: 9435000
    wait_time_ms: 79.778
  iterations_since_restore: 1887
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16605.010633945465
  time_this_iter_s: 8.677672147750854
  time_total_s: 16605.010633945465
  timestamp: 1594865173
  timesteps_since_restore: 9435000
  timesteps_this_iter: 5000
  timesteps_total: 9435000
  training_iteration: 1887
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16605 s, 1887 iter, 9435000 ts, 358 rew

agent-1: 80.19999884842811
agent-2: 96.19999884842812
agent-3: 89.19999884842817
agent-4: 77.1999988484281
agent-5: 80.19999884842811
Extrinsic Rewards:
5
21
14
2
5
Sum Reward: 47
Avg Reward: 9.4
Min Reward: 2
Max Reward: 21
Gini Coefficient: 0.4
20:20 Ratio: 10.5
Max-min Ratio: 10.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-21
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 358.08207681125003
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1887
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.698
    dispatch_time_ms: 7.329
    learner:
      cur_lr: 0.0007316290284506977
      grad_gnorm: 13.77578353881836
      policy_entropy: 34.638790130615234
      policy_loss: -2.4878878593444824
      var_gnorm: 23.25627899169922
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.13814634084701538
    num_steps_sampled: 9440000
    num_steps_trained: 9440000
    wait_time_ms: 75.61
  iterations_since_restore: 1888
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16613.63787341118
  time_this_iter_s: 8.627239465713501
  time_total_s: 16613.63787341118
  timestamp: 1594865181
  timesteps_since_restore: 9440000
  timesteps_this_iter: 5000
  timesteps_total: 9440000
  training_iteration: 1888
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16613 s, 1888 iter, 9440000 ts, 358 rew

agent-1: 43.39999999914744
agent-2: 38.399999999147454
agent-3: 39.399999999147454
agent-4: 41.39999999914744
agent-5: 53.399999999147454
Extrinsic Rewards:
5
0
1
3
15
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 0
Max Reward: 15
Gini Coefficient: 0.5666666666666667
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-30
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 358.17207681136153
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1888
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.596
    dispatch_time_ms: 8.218
    learner:
      cur_lr: 0.0007312960224226117
      grad_gnorm: 3.033111572265625
      policy_entropy: 34.46917724609375
      policy_loss: -0.389651358127594
      var_gnorm: 23.277700424194336
      vf_explained_var: 0.0
      vf_loss: 0.007109952624887228
    num_steps_sampled: 9445000
    num_steps_trained: 9445000
    wait_time_ms: 74.711
  iterations_since_restore: 1889
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16622.291340827942
  time_this_iter_s: 8.653467416763306
  time_total_s: 16622.291340827942
  timestamp: 1594865190
  timesteps_since_restore: 9445000
  timesteps_this_iter: 5000
  timesteps_total: 9445000
  training_iteration: 1889
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16622 s, 1889 iter, 9445000 ts, 358 rew

agent-1: 49.99999999852411
agent-2: 42.9999999985241
agent-3: 42.999999998524096
agent-4: 45.99999999852411
agent-5: 42.999999998524096
Extrinsic Rewards:
10
3
3
6
3
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 3
Max Reward: 10
Gini Coefficient: 0.272
20:20 Ratio: 3.3333333333333335
Max-min Ratio: 3.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-39
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 358.0820768113992
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1889
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.944
    dispatch_time_ms: 8.963
    learner:
      cur_lr: 0.0007309630163945258
      grad_gnorm: 12.132146835327148
      policy_entropy: 33.2220344543457
      policy_loss: 2.108844041824341
      var_gnorm: 23.248023986816406
      vf_explained_var: 0.0
      vf_loss: 0.10372089594602585
    num_steps_sampled: 9450000
    num_steps_trained: 9450000
    wait_time_ms: 74.365
  iterations_since_restore: 1890
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16630.866521835327
  time_this_iter_s: 8.575181007385254
  time_total_s: 16630.866521835327
  timestamp: 1594865199
  timesteps_since_restore: 9450000
  timesteps_this_iter: 5000
  timesteps_total: 9450000
  training_iteration: 1890
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16630 s, 1890 iter, 9450000 ts, 358 rew

agent-1: 32.399999999362684
agent-2: 32.399999999362684
agent-3: 34.399999999362684
agent-4: 37.3999999993627
agent-5: 34.399999999362684
Extrinsic Rewards:
2
2
4
7
4
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.25263157894736843
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-47
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 357.54207681147096
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1890
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.651
    dispatch_time_ms: 7.447
    learner:
      cur_lr: 0.0007306300103664398
      grad_gnorm: 6.176761627197266
      policy_entropy: 22.79305076599121
      policy_loss: -0.5608264207839966
      var_gnorm: 23.254093170166016
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.028765127062797546
    num_steps_sampled: 9455000
    num_steps_trained: 9455000
    wait_time_ms: 73.587
  iterations_since_restore: 1891
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16639.438411474228
  time_this_iter_s: 8.571889638900757
  time_total_s: 16639.438411474228
  timestamp: 1594865207
  timesteps_since_restore: 9455000
  timesteps_this_iter: 5000
  timesteps_total: 9455000
  training_iteration: 1891
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16639 s, 1891 iter, 9455000 ts, 358 rew

agent-1: 96.39999931661049
agent-2: 93.39999931661048
agent-3: 99.39999931661048
agent-4: 96.39999931661049
agent-5: 100.39999931661049
Extrinsic Rewards:
10
7
13
10
14
Sum Reward: 54
Avg Reward: 10.8
Min Reward: 7
Max Reward: 14
Gini Coefficient: 0.1259259259259259
20:20 Ratio: 2.0
Max-min Ratio: 2.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-06-56
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 358.80207677927916
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1891
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.924
    dispatch_time_ms: 7.122
    learner:
      cur_lr: 0.0007302970043383539
      grad_gnorm: 27.194284439086914
      policy_entropy: 16.16640853881836
      policy_loss: -2.5265891551971436
      var_gnorm: 23.248781204223633
      vf_explained_var: 0.0
      vf_loss: 0.571959912776947
    num_steps_sampled: 9460000
    num_steps_trained: 9460000
    wait_time_ms: 76.171
  iterations_since_restore: 1892
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16648.077231884003
  time_this_iter_s: 8.63882040977478
  time_total_s: 16648.077231884003
  timestamp: 1594865216
  timesteps_since_restore: 9460000
  timesteps_this_iter: 5000
  timesteps_total: 9460000
  training_iteration: 1892
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16648 s, 1892 iter, 9460000 ts, 359 rew

agent-1: 70.99999997993517
agent-2: 69.99999997993515
agent-3: 79.9999999799352
agent-4: 65.99999997993517
agent-5: 72.99999997993515
Extrinsic Rewards:
7
6
16
2
9
Sum Reward: 40
Avg Reward: 8.0
Min Reward: 2
Max Reward: 16
Gini Coefficient: 0.31
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-05
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 359.3420767789726
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1892
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.847
    dispatch_time_ms: 10.822
    learner:
      cur_lr: 0.0007299639983102679
      grad_gnorm: 40.0
      policy_entropy: 29.547359466552734
      policy_loss: 38.391361236572266
      var_gnorm: 23.253520965576172
      vf_explained_var: 0.0
      vf_loss: 42.06260299682617
    num_steps_sampled: 9465000
    num_steps_trained: 9465000
    wait_time_ms: 73.425
  iterations_since_restore: 1893
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16656.80760383606
  time_this_iter_s: 8.730371952056885
  time_total_s: 16656.80760383606
  timestamp: 1594865225
  timesteps_since_restore: 9465000
  timesteps_this_iter: 5000
  timesteps_total: 9465000
  training_iteration: 1893
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16656 s, 1893 iter, 9465000 ts, 359 rew

agent-1: 77.5999999775615
agent-2: 75.5999999775615
agent-3: 68.59999997756147
agent-4: 67.59999997756144
agent-5: 79.59999997756148
Extrinsic Rewards:
12
10
3
2
14
Sum Reward: 41
Avg Reward: 8.2
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.32195121951219513
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 359.7020767785023
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1893
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.482
    dispatch_time_ms: 7.141
    learner:
      cur_lr: 0.000729630992282182
      grad_gnorm: 22.528823852539062
      policy_entropy: 26.1273193359375
      policy_loss: -3.759355306625366
      var_gnorm: 23.245508193969727
      vf_explained_var: 0.0
      vf_loss: 0.3607558012008667
    num_steps_sampled: 9470000
    num_steps_trained: 9470000
    wait_time_ms: 77.224
  iterations_since_restore: 1894
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16665.411717891693
  time_this_iter_s: 8.604114055633545
  time_total_s: 16665.411717891693
  timestamp: 1594865233
  timesteps_since_restore: 9470000
  timesteps_this_iter: 5000
  timesteps_total: 9470000
  training_iteration: 1894
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16665 s, 1894 iter, 9470000 ts, 360 rew

agent-1: 93.99999992562542
agent-2: 89.99999992562542
agent-3: 85.99999992562539
agent-4: 89.9999999256254
agent-5: 89.99999992562542
Extrinsic Rewards:
14
10
6
10
10
Sum Reward: 50
Avg Reward: 10.0
Min Reward: 6
Max Reward: 14
Gini Coefficient: 0.128
20:20 Ratio: 2.3333333333333335
Max-min Ratio: 2.3333333333333335
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-22
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 357.9022462009273
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1894
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.71
    dispatch_time_ms: 7.922
    learner:
      cur_lr: 0.000729297986254096
      grad_gnorm: 3.905569314956665
      policy_entropy: 22.71711540222168
      policy_loss: -0.2674373388290405
      var_gnorm: 23.250404357910156
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.011119290255010128
    num_steps_sampled: 9475000
    num_steps_trained: 9475000
    wait_time_ms: 76.341
  iterations_since_restore: 1895
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16674.100465774536
  time_this_iter_s: 8.688747882843018
  time_total_s: 16674.100465774536
  timestamp: 1594865242
  timesteps_since_restore: 9475000
  timesteps_this_iter: 5000
  timesteps_total: 9475000
  training_iteration: 1895
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16674 s, 1895 iter, 9475000 ts, 358 rew

agent-1: 47.19999999781846
agent-2: 55.19999999781845
agent-3: 46.19999999781846
agent-4: 48.199999997818445
agent-5: 46.19999999781845
Extrinsic Rewards:
4
12
3
5
3
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 12
Gini Coefficient: 0.2962962962962963
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-31
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 356.5522462480125
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1895
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.733
    dispatch_time_ms: 39.1
    learner:
      cur_lr: 0.0007289649802260101
      grad_gnorm: 16.66115951538086
      policy_entropy: 15.781742095947266
      policy_loss: -1.3473727703094482
      var_gnorm: 23.24700927734375
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.2126721441745758
    num_steps_sampled: 9480000
    num_steps_trained: 9480000
    wait_time_ms: 39.649
  iterations_since_restore: 1896
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16683.070341587067
  time_this_iter_s: 8.969875812530518
  time_total_s: 16683.070341587067
  timestamp: 1594865251
  timesteps_since_restore: 9480000
  timesteps_this_iter: 5000
  timesteps_total: 9480000
  training_iteration: 1896
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16683 s, 1896 iter, 9480000 ts, 357 rew

agent-1: 72.1999999865141
agent-2: 72.1999999865141
agent-3: 86.19999998651416
agent-4: 69.1999999865141
agent-5: 78.19999998651413
Extrinsic Rewards:
5
5
19
2
11
Sum Reward: 42
Avg Reward: 8.4
Min Reward: 2
Max Reward: 19
Gini Coefficient: 0.38095238095238093
20:20 Ratio: 9.5
Max-min Ratio: 9.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-40
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 355.65224666217256
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1896
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.937
    dispatch_time_ms: 37.03
    learner:
      cur_lr: 0.0007286319741979241
      grad_gnorm: 40.0
      policy_entropy: 24.207124710083008
      policy_loss: 43.84298324584961
      var_gnorm: 23.252534866333008
      vf_explained_var: 0.0
      vf_loss: 105.28864288330078
    num_steps_sampled: 9485000
    num_steps_trained: 9485000
    wait_time_ms: 57.359
  iterations_since_restore: 1897
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16692.280165672302
  time_this_iter_s: 9.209824085235596
  time_total_s: 16692.280165672302
  timestamp: 1594865260
  timesteps_since_restore: 9485000
  timesteps_this_iter: 5000
  timesteps_total: 9485000
  training_iteration: 1897
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16692 s, 1897 iter, 9485000 ts, 356 rew

agent-1: 34.399999999084585
agent-2: 37.399999999084585
agent-3: 30.39999999908457
agent-4: 35.399999999084585
agent-5: 33.399999999084585
Extrinsic Rewards:
4
7
0
5
3
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 7
Gini Coefficient: 0.3368421052631579
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-49
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 355.742246662221
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1897
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.824
    dispatch_time_ms: 11.76
    learner:
      cur_lr: 0.0007282990263774991
      grad_gnorm: 12.789510726928711
      policy_entropy: 22.519838333129883
      policy_loss: -2.034482955932617
      var_gnorm: 23.246488571166992
      vf_explained_var: 0.0
      vf_loss: 0.11167959123849869
    num_steps_sampled: 9490000
    num_steps_trained: 9490000
    wait_time_ms: 72.156
  iterations_since_restore: 1898
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16701.132884025574
  time_this_iter_s: 8.852718353271484
  time_total_s: 16701.132884025574
  timestamp: 1594865269
  timesteps_since_restore: 9490000
  timesteps_this_iter: 5000
  timesteps_total: 9490000
  training_iteration: 1898
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16701 s, 1898 iter, 9490000 ts, 356 rew

agent-1: 33.99999999905365
agent-2: 39.999999999053614
agent-3: 35.999999999053614
agent-4: 33.99999999905365
agent-5: 35.999999999053614
Extrinsic Rewards:
2
8
4
2
4
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.28
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-07-58
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 352.95224679734133
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1898
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.827
    dispatch_time_ms: 7.493
    learner:
      cur_lr: 0.0007279660203494132
      grad_gnorm: 40.0
      policy_entropy: 20.59097671508789
      policy_loss: 32.75893020629883
      var_gnorm: 23.2502498626709
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 94.9752197265625
    num_steps_sampled: 9495000
    num_steps_trained: 9495000
    wait_time_ms: 76.583
  iterations_since_restore: 1899
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16709.824941158295
  time_this_iter_s: 8.692057132720947
  time_total_s: 16709.824941158295
  timestamp: 1594865278
  timesteps_since_restore: 9495000
  timesteps_this_iter: 5000
  timesteps_total: 9495000
  training_iteration: 1899
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16709 s, 1899 iter, 9495000 ts, 353 rew

agent-1: 53.59999999827362
agent-2: 45.599999998273624
agent-3: 43.59999999827363
agent-4: 42.59999999827363
agent-5: 48.59999999827362
Extrinsic Rewards:
12
4
2
1
7
Sum Reward: 26
Avg Reward: 5.2
Min Reward: 1
Max Reward: 12
Gini Coefficient: 0.4153846153846154
20:20 Ratio: 12.0
Max-min Ratio: 12.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-07
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 352.14224679809263
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1899
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.663
    dispatch_time_ms: 28.198
    learner:
      cur_lr: 0.0007276330143213272
      grad_gnorm: 14.389381408691406
      policy_entropy: 14.28485107421875
      policy_loss: -0.9646424651145935
      var_gnorm: 23.24573516845703
      vf_explained_var: 0.0
      vf_loss: 0.15793077647686005
    num_steps_sampled: 9500000
    num_steps_trained: 9500000
    wait_time_ms: 65.177
  iterations_since_restore: 1900
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16719.107840538025
  time_this_iter_s: 9.282899379730225
  time_total_s: 16719.107840538025
  timestamp: 1594865287
  timesteps_since_restore: 9500000
  timesteps_this_iter: 5000
  timesteps_total: 9500000
  training_iteration: 1900
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16719 s, 1900 iter, 9500000 ts, 352 rew

W0715 22:08:17.331333 26841 node_manager.cc:250] Last heartbeat was sent 740 ms ago 
agent-1: 40.59999999908397
agent-2: 39.599999999083984
agent-3: 36.59999999908399
agent-4: 34.599999999083984
agent-5: 37.59999999908399
Extrinsic Rewards:
7
6
3
1
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.2857142857142857
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-25
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 351.1522468009518
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1900
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.84
    dispatch_time_ms: 34.121
    learner:
      cur_lr: 0.0007273000082932413
      grad_gnorm: 40.0
      policy_entropy: 10.213459014892578
      policy_loss: 4.92060661315918
      var_gnorm: 23.251201629638672
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 14.796475410461426
    num_steps_sampled: 9505000
    num_steps_trained: 9505000
    wait_time_ms: 53.242
  iterations_since_restore: 1901
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16727.558613538742
  time_this_iter_s: 8.450773000717163
  time_total_s: 16727.558613538742
  timestamp: 1594865305
  timesteps_since_restore: 9505000
  timesteps_this_iter: 5000
  timesteps_total: 9505000
  training_iteration: 1901
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16727 s, 1901 iter, 9505000 ts, 351 rew

agent-1: 44.39999999536186
agent-2: 43.39999999536186
agent-3: 42.39999999536185
agent-4: 42.39999999536185
agent-5: 43.39999999536186
Extrinsic Rewards:
6
5
4
4
5
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 4
Max Reward: 6
Gini Coefficient: 0.08333333333333333
20:20 Ratio: 1.5
Max-min Ratio: 1.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-34
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 351.4222468008669
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1901
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.455
    dispatch_time_ms: 33.026
    learner:
      cur_lr: 0.0007269670022651553
      grad_gnorm: 30.97817039489746
      policy_entropy: 20.11791229248047
      policy_loss: -0.7187824845314026
      var_gnorm: 23.2517032623291
      vf_explained_var: 0.0
      vf_loss: 0.7085071206092834
    num_steps_sampled: 9510000
    num_steps_trained: 9510000
    wait_time_ms: 56.954
  iterations_since_restore: 1902
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16736.32725906372
  time_this_iter_s: 8.768645524978638
  time_total_s: 16736.32725906372
  timestamp: 1594865314
  timesteps_since_restore: 9510000
  timesteps_this_iter: 5000
  timesteps_total: 9510000
  training_iteration: 1902
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16736 s, 1902 iter, 9510000 ts, 351 rew

agent-1: 167.5986029278132
agent-2: 181.59860292781323
agent-3: 179.59860292781323
agent-4: 164.59860292781335
agent-5: 170.5986029278133
Extrinsic Rewards:
14
28
26
11
17
Sum Reward: 96
Avg Reward: 19.2
Min Reward: 11
Max Reward: 28
Gini Coefficient: 0.19166666666666668
20:20 Ratio: 2.5454545454545454
Max-min Ratio: 2.5454545454545454
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 358.3521769472959
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1902
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.798
    dispatch_time_ms: 32.655
    learner:
      cur_lr: 0.0007266339962370694
      grad_gnorm: 32.43511199951172
      policy_entropy: 4.257870674133301
      policy_loss: -0.22940872609615326
      var_gnorm: 23.249988555908203
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.8094292283058167
    num_steps_sampled: 9515000
    num_steps_trained: 9515000
    wait_time_ms: 58.787
  iterations_since_restore: 1903
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16745.202151298523
  time_this_iter_s: 8.874892234802246
  time_total_s: 16745.202151298523
  timestamp: 1594865323
  timesteps_since_restore: 9515000
  timesteps_this_iter: 5000
  timesteps_total: 9515000
  training_iteration: 1903
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16745 s, 1903 iter, 9515000 ts, 358 rew

agent-1: 103.19999896609542
agent-2: 117.1999989660954
agent-3: 110.19999896609536
agent-4: 117.19999896609536
agent-5: 110.1999989660954
Extrinsic Rewards:
4
18
11
18
11
Sum Reward: 62
Avg Reward: 12.4
Min Reward: 4
Max Reward: 18
Gini Coefficient: 0.22580645161290322
20:20 Ratio: 4.5
Max-min Ratio: 4.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-08-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 359.7921769174107
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1903
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.765
    dispatch_time_ms: 5.708
    learner:
      cur_lr: 0.0007263009902089834
      grad_gnorm: 40.0
      policy_entropy: 20.023269653320312
      policy_loss: 26.212688446044922
      var_gnorm: 23.24439811706543
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 54.24823760986328
    num_steps_sampled: 9520000
    num_steps_trained: 9520000
    wait_time_ms: 73.304
  iterations_since_restore: 1904
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16753.84241294861
  time_this_iter_s: 8.64026165008545
  time_total_s: 16753.84241294861
  timestamp: 1594865332
  timesteps_since_restore: 9520000
  timesteps_this_iter: 5000
  timesteps_total: 9520000
  training_iteration: 1904
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16753 s, 1904 iter, 9520000 ts, 360 rew

agent-1: 147.91236700950896
agent-2: 128.91236700950898
agent-3: 143.91236700950893
agent-4: 141.91236700950893
agent-5: 129.91236700950898
Extrinsic Rewards:
25
6
21
19
7
Sum Reward: 78
Avg Reward: 15.6
Min Reward: 6
Max Reward: 25
Gini Coefficient: 0.26666666666666666
20:20 Ratio: 4.166666666666667
Max-min Ratio: 4.166666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-00
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 363.65779526827697
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1904
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.933
    dispatch_time_ms: 9.68
    learner:
      cur_lr: 0.0007259679841808975
      grad_gnorm: 40.0
      policy_entropy: 31.044937133789062
      policy_loss: 71.01707458496094
      var_gnorm: 23.257877349853516
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 222.91397094726562
    num_steps_sampled: 9525000
    num_steps_trained: 9525000
    wait_time_ms: 72.874
  iterations_since_restore: 1905
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16762.340260982513
  time_this_iter_s: 8.49784803390503
  time_total_s: 16762.340260982513
  timestamp: 1594865340
  timesteps_since_restore: 9525000
  timesteps_this_iter: 5000
  timesteps_total: 9525000
  training_iteration: 1905
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16762 s, 1905 iter, 9525000 ts, 364 rew

agent-1: 117.47426100374982
agent-2: 133.47426100374986
agent-3: 132.47426100374975
agent-4: 136.4742610037499
agent-5: 118.47426100374979
Extrinsic Rewards:
4
20
19
23
5
Sum Reward: 71
Avg Reward: 14.2
Min Reward: 4
Max Reward: 23
Gini Coefficient: 0.29859154929577464
20:20 Ratio: 5.75
Max-min Ratio: 5.75
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 368.0615083185229
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1905
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.051
    dispatch_time_ms: 7.827
    learner:
      cur_lr: 0.0007256349781528115
      grad_gnorm: 40.000003814697266
      policy_entropy: 30.807449340820312
      policy_loss: -13.869080543518066
      var_gnorm: 23.2502384185791
      vf_explained_var: 0.0
      vf_loss: 5.433249473571777
    num_steps_sampled: 9530000
    num_steps_trained: 9530000
    wait_time_ms: 77.034
  iterations_since_restore: 1906
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16771.00088596344
  time_this_iter_s: 8.660624980926514
  time_total_s: 16771.00088596344
  timestamp: 1594865349
  timesteps_since_restore: 9530000
  timesteps_this_iter: 5000
  timesteps_total: 9530000
  training_iteration: 1906
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16771 s, 1906 iter, 9530000 ts, 368 rew

agent-1: 82.3999999734374
agent-2: 75.39999997343739
agent-3: 79.39999997343742
agent-4: 80.39999997343742
agent-5: 78.3999999734374
Extrinsic Rewards:
12
5
9
10
8
Sum Reward: 44
Avg Reward: 8.8
Min Reward: 5
Max Reward: 12
Gini Coefficient: 0.14545454545454545
20:20 Ratio: 2.4
Max-min Ratio: 2.4
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 365.99150840835154
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1906
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.503
    dispatch_time_ms: 7.106
    learner:
      cur_lr: 0.0007253019721247256
      grad_gnorm: 21.463069915771484
      policy_entropy: 27.9346981048584
      policy_loss: -3.242431879043579
      var_gnorm: 23.24607276916504
      vf_explained_var: 0.0
      vf_loss: 0.3498063385486603
    num_steps_sampled: 9535000
    num_steps_trained: 9535000
    wait_time_ms: 78.145
  iterations_since_restore: 1907
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16779.72653079033
  time_this_iter_s: 8.725644826889038
  time_total_s: 16779.72653079033
  timestamp: 1594865358
  timesteps_since_restore: 9535000
  timesteps_this_iter: 5000
  timesteps_total: 9535000
  training_iteration: 1907
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16779 s, 1907 iter, 9535000 ts, 366 rew

agent-1: 51.19999999881464
agent-2: 46.199999998814626
agent-3: 48.199999998814626
agent-4: 47.199999998814626
agent-5: 50.199999998814626
Extrinsic Rewards:
8
3
5
4
7
Sum Reward: 27
Avg Reward: 5.4
Min Reward: 3
Max Reward: 8
Gini Coefficient: 0.1925925925925926
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-26
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 366.171508408366
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1907
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.919
    dispatch_time_ms: 7.343
    learner:
      cur_lr: 0.0007249690243043005
      grad_gnorm: 26.737533569335938
      policy_entropy: 32.81307601928711
      policy_loss: -4.567050933837891
      var_gnorm: 23.24336051940918
      vf_explained_var: 0.0
      vf_loss: 0.49899056553840637
    num_steps_sampled: 9540000
    num_steps_trained: 9540000
    wait_time_ms: 74.152
  iterations_since_restore: 1908
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16788.327590227127
  time_this_iter_s: 8.601059436798096
  time_total_s: 16788.327590227127
  timestamp: 1594865366
  timesteps_since_restore: 9540000
  timesteps_this_iter: 5000
  timesteps_total: 9540000
  training_iteration: 1908
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16788 s, 1908 iter, 9540000 ts, 366 rew

agent-1: 46.79999999728178
agent-2: 58.799999997281795
agent-3: 47.799999997281795
agent-4: 49.79999999728181
agent-5: 48.799999997281795
Extrinsic Rewards:
2
14
3
5
4
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 14
Gini Coefficient: 0.37142857142857144
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-35
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 367.0715084082598
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1908
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.892
    dispatch_time_ms: 11.413
    learner:
      cur_lr: 0.0007246360182762146
      grad_gnorm: 40.0
      policy_entropy: 33.3940315246582
      policy_loss: 74.64862060546875
      var_gnorm: 23.2643985748291
      vf_explained_var: 0.0
      vf_loss: 151.85438537597656
    num_steps_sampled: 9545000
    num_steps_trained: 9545000
    wait_time_ms: 74.598
  iterations_since_restore: 1909
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16796.976319789886
  time_this_iter_s: 8.6487295627594
  time_total_s: 16796.976319789886
  timestamp: 1594865375
  timesteps_since_restore: 9545000
  timesteps_this_iter: 5000
  timesteps_total: 9545000
  training_iteration: 1909
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16796 s, 1909 iter, 9545000 ts, 367 rew

agent-1: 66.3999999831381
agent-2: 70.39999998313804
agent-3: 71.39999998313806
agent-4: 71.39999998313806
agent-5: 71.39999998313804
Extrinsic Rewards:
4
8
9
9
9
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 4
Max Reward: 9
Gini Coefficient: 0.11282051282051282
20:20 Ratio: 2.25
Max-min Ratio: 2.25
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-43
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 367.6115084078527
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1909
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.447
    dispatch_time_ms: 6.609
    learner:
      cur_lr: 0.0007243030122481287
      grad_gnorm: 11.57274055480957
      policy_entropy: 33.77012634277344
      policy_loss: -1.9554728269577026
      var_gnorm: 23.243635177612305
      vf_explained_var: 0.0
      vf_loss: 0.10341846197843552
    num_steps_sampled: 9550000
    num_steps_trained: 9550000
    wait_time_ms: 78.13
  iterations_since_restore: 1910
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16805.556026935577
  time_this_iter_s: 8.579707145690918
  time_total_s: 16805.556026935577
  timestamp: 1594865383
  timesteps_since_restore: 9550000
  timesteps_this_iter: 5000
  timesteps_total: 9550000
  training_iteration: 1910
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16805 s, 1910 iter, 9550000 ts, 368 rew

agent-1: 37.599999997600705
agent-2: 40.59999999760072
agent-3: 34.599999997600705
agent-4: 38.59999999760072
agent-5: 37.599999997600705
Extrinsic Rewards:
4
7
1
5
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.24761904761904763
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-09-52
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 366.7115084079403
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1910
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.057
    dispatch_time_ms: 7.05
    learner:
      cur_lr: 0.0007239700062200427
      grad_gnorm: 40.0
      policy_entropy: 34.59871292114258
      policy_loss: 34.99134826660156
      var_gnorm: 23.251054763793945
      vf_explained_var: 0.0
      vf_loss: 32.87117385864258
    num_steps_sampled: 9555000
    num_steps_trained: 9555000
    wait_time_ms: 77.456
  iterations_since_restore: 1911
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16814.12657403946
  time_this_iter_s: 8.570547103881836
  time_total_s: 16814.12657403946
  timestamp: 1594865392
  timesteps_since_restore: 9555000
  timesteps_this_iter: 5000
  timesteps_total: 9555000
  training_iteration: 1911
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16814 s, 1911 iter, 9555000 ts, 367 rew

agent-1: 35.39999999924689
agent-2: 30.399999999246837
agent-3: 34.39999999924691
agent-4: 35.39999999924689
agent-5: 35.39999999924689
Extrinsic Rewards:
5
0
4
5
5
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 0
Max Reward: 5
Gini Coefficient: 0.23157894736842105
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-01
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 365.0915084151989
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1911
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.598
    dispatch_time_ms: 8.709
    learner:
      cur_lr: 0.0007236370001919568
      grad_gnorm: 13.9818696975708
      policy_entropy: 34.441253662109375
      policy_loss: -2.31256103515625
      var_gnorm: 23.24102210998535
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.11861202120780945
    num_steps_sampled: 9560000
    num_steps_trained: 9560000
    wait_time_ms: 75.936
  iterations_since_restore: 1912
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16822.77491044998
  time_this_iter_s: 8.648336410522461
  time_total_s: 16822.77491044998
  timestamp: 1594865401
  timesteps_since_restore: 9560000
  timesteps_this_iter: 5000
  timesteps_total: 9560000
  training_iteration: 1912
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16822 s, 1912 iter, 9560000 ts, 365 rew

agent-1: 51.79999999480654
agent-2: 50.799999994806534
agent-3: 47.799999994806505
agent-4: 53.799999994806534
agent-5: 47.79999999480651
Extrinsic Rewards:
7
6
3
9
3
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 3
Max Reward: 9
Gini Coefficient: 0.22857142857142856
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-09
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 365.5415084150157
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1912
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.435
    dispatch_time_ms: 9.305
    learner:
      cur_lr: 0.0007233039941638708
      grad_gnorm: 40.0
      policy_entropy: 34.63313293457031
      policy_loss: 69.03262329101562
      var_gnorm: 23.249439239501953
      vf_explained_var: 0.0
      vf_loss: 128.63592529296875
    num_steps_sampled: 9565000
    num_steps_trained: 9565000
    wait_time_ms: 71.274
  iterations_since_restore: 1913
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16831.310836791992
  time_this_iter_s: 8.535926342010498
  time_total_s: 16831.310836791992
  timestamp: 1594865409
  timesteps_since_restore: 9565000
  timesteps_this_iter: 5000
  timesteps_total: 9565000
  training_iteration: 1913
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16831 s, 1913 iter, 9565000 ts, 366 rew

agent-1: 36.599999999181705
agent-2: 34.599999999181705
agent-3: 36.599999999181705
agent-4: 42.59999999918171
agent-5: 38.599999999181705
Extrinsic Rewards:
3
1
3
9
5
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 9
Gini Coefficient: 0.34285714285714286
20:20 Ratio: 9.0
Max-min Ratio: 9.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-18
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 362.12150842691693
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1913
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.455
    dispatch_time_ms: 5.985
    learner:
      cur_lr: 0.0007229709881357849
      grad_gnorm: 16.20568084716797
      policy_entropy: 26.446744918823242
      policy_loss: -1.4358354806900024
      var_gnorm: 23.238752365112305
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.1817619651556015
    num_steps_sampled: 9570000
    num_steps_trained: 9570000
    wait_time_ms: 82.64
  iterations_since_restore: 1914
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16839.98113012314
  time_this_iter_s: 8.67029333114624
  time_total_s: 16839.98113012314
  timestamp: 1594865418
  timesteps_since_restore: 9570000
  timesteps_this_iter: 5000
  timesteps_total: 9570000
  training_iteration: 1914
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16839 s, 1914 iter, 9570000 ts, 362 rew

agent-1: 67.39999999354983
agent-2: 65.39999999354984
agent-3: 66.39999999354986
agent-4: 72.39999999354986
agent-5: 79.39999999354986
Extrinsic Rewards:
5
3
4
10
17
Sum Reward: 39
Avg Reward: 7.8
Min Reward: 3
Max Reward: 17
Gini Coefficient: 0.3487179487179487
20:20 Ratio: 5.666666666666667
Max-min Ratio: 5.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 364.0115084266256
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1914
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.969
    dispatch_time_ms: 6.278
    learner:
      cur_lr: 0.0007226379821076989
      grad_gnorm: 40.0
      policy_entropy: 33.45398712158203
      policy_loss: 35.587039947509766
      var_gnorm: 23.243717193603516
      vf_explained_var: 0.0
      vf_loss: 33.26469039916992
    num_steps_sampled: 9575000
    num_steps_trained: 9575000
    wait_time_ms: 78.452
  iterations_since_restore: 1915
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16848.698187351227
  time_this_iter_s: 8.717057228088379
  time_total_s: 16848.698187351227
  timestamp: 1594865427
  timesteps_since_restore: 9575000
  timesteps_this_iter: 5000
  timesteps_total: 9575000
  training_iteration: 1915
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16848 s, 1915 iter, 9575000 ts, 364 rew

agent-1: 47.99999999765836
agent-2: 42.99999999765835
agent-3: 42.99999999765834
agent-4: 45.99999999765835
agent-5: 44.99999999765835
Extrinsic Rewards:
8
3
3
6
5
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 3
Max Reward: 8
Gini Coefficient: 0.208
20:20 Ratio: 2.6666666666666665
Max-min Ratio: 2.6666666666666665
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 364.0115084265642
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1915
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.315
    dispatch_time_ms: 10.193
    learner:
      cur_lr: 0.000722304976079613
      grad_gnorm: 10.39995288848877
      policy_entropy: 29.727933883666992
      policy_loss: -1.5504096746444702
      var_gnorm: 23.239273071289062
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.08335984498262405
    num_steps_sampled: 9580000
    num_steps_trained: 9580000
    wait_time_ms: 74.289
  iterations_since_restore: 1916
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16857.375131368637
  time_this_iter_s: 8.676944017410278
  time_total_s: 16857.375131368637
  timestamp: 1594865436
  timesteps_since_restore: 9580000
  timesteps_this_iter: 5000
  timesteps_total: 9580000
  training_iteration: 1916
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16857 s, 1916 iter, 9580000 ts, 364 rew

agent-1: 31.199999999466417
agent-2: 36.19999999946644
agent-3: 28.199999999466417
agent-4: 30.199999999466417
agent-5: 27.19999999946641
Extrinsic Rewards:
4
9
1
3
0
Sum Reward: 17
Avg Reward: 3.4
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.49411764705882355
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 359.6015086246202
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1916
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.891
    dispatch_time_ms: 7.459
    learner:
      cur_lr: 0.0007219720282591879
      grad_gnorm: 40.000003814697266
      policy_entropy: 31.070995330810547
      policy_loss: 62.07430648803711
      var_gnorm: 23.244075775146484
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 141.94659423828125
    num_steps_sampled: 9585000
    num_steps_trained: 9585000
    wait_time_ms: 73.815
  iterations_since_restore: 1917
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16865.917506456375
  time_this_iter_s: 8.542375087738037
  time_total_s: 16865.917506456375
  timestamp: 1594865444
  timesteps_since_restore: 9585000
  timesteps_this_iter: 5000
  timesteps_total: 9585000
  training_iteration: 1917
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16865 s, 1917 iter, 9585000 ts, 360 rew

agent-1: 33.599999998714516
agent-2: 34.59999999871452
agent-3: 38.599999998714516
agent-4: 44.59999999871451
agent-5: 37.59999999871453
Extrinsic Rewards:
0
1
5
11
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 0
Max Reward: 11
Gini Coefficient: 0.49523809523809526
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-10-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 358.16150862486114
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1917
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.033
    dispatch_time_ms: 12.826
    learner:
      cur_lr: 0.000721639022231102
      grad_gnorm: 18.334596633911133
      policy_entropy: 24.211660385131836
      policy_loss: -2.4199562072753906
      var_gnorm: 23.238101959228516
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2593896985054016
    num_steps_sampled: 9590000
    num_steps_trained: 9590000
    wait_time_ms: 71.545
  iterations_since_restore: 1918
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16874.645688533783
  time_this_iter_s: 8.728182077407837
  time_total_s: 16874.645688533783
  timestamp: 1594865453
  timesteps_since_restore: 9590000
  timesteps_this_iter: 5000
  timesteps_total: 9590000
  training_iteration: 1918
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16874 s, 1918 iter, 9590000 ts, 358 rew

agent-1: 38.19999999915279
agent-2: 43.19999999915277
agent-3: 38.19999999915279
agent-4: 41.19999999915278
agent-5: 37.19999999915279
Extrinsic Rewards:
3
8
3
6
2
Sum Reward: 22
Avg Reward: 4.4
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.2727272727272727
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 351.7715283220018
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1918
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.313
    dispatch_time_ms: 8.966
    learner:
      cur_lr: 0.000721306016203016
      grad_gnorm: 3.310913562774658
      policy_entropy: 26.363075256347656
      policy_loss: -0.4999151825904846
      var_gnorm: 23.244861602783203
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.008224048651754856
    num_steps_sampled: 9595000
    num_steps_trained: 9595000
    wait_time_ms: 74.717
  iterations_since_restore: 1919
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16883.297711372375
  time_this_iter_s: 8.65202283859253
  time_total_s: 16883.297711372375
  timestamp: 1594865462
  timesteps_since_restore: 9595000
  timesteps_this_iter: 5000
  timesteps_total: 9595000
  training_iteration: 1919
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16883 s, 1919 iter, 9595000 ts, 352 rew

agent-1: 44.99999998542901
agent-2: 41.999999985429035
agent-3: 46.99999998542901
agent-4: 45.99999998542901
agent-5: 44.99999998542901
Extrinsic Rewards:
5
2
7
6
5
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 2
Max Reward: 7
Gini Coefficient: 0.176
20:20 Ratio: 3.5
Max-min Ratio: 3.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 345.7418823948616
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1919
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 4.332
    dispatch_time_ms: 9.577
    learner:
      cur_lr: 0.0007209730101749301
      grad_gnorm: 11.72912311553955
      policy_entropy: 23.73790740966797
      policy_loss: -1.815097689628601
      var_gnorm: 23.239307403564453
      vf_explained_var: 0.0
      vf_loss: 0.10569987446069717
    num_steps_sampled: 9600000
    num_steps_trained: 9600000
    wait_time_ms: 73.938
  iterations_since_restore: 1920
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16891.954780578613
  time_this_iter_s: 8.657069206237793
  time_total_s: 16891.954780578613
  timestamp: 1594865470
  timesteps_since_restore: 9600000
  timesteps_this_iter: 5000
  timesteps_total: 9600000
  training_iteration: 1920
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16891 s, 1920 iter, 9600000 ts, 346 rew

agent-1: 40.799999998698624
agent-2: 41.799999998698624
agent-3: 44.799999998698624
agent-4: 37.79999999869861
agent-5: 41.799999998698624
Extrinsic Rewards:
4
5
8
1
5
Sum Reward: 23
Avg Reward: 4.6
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.2608695652173913
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 343.5818824008882
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1920
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.938
    dispatch_time_ms: 9.211
    learner:
      cur_lr: 0.0007206400041468441
      grad_gnorm: 40.00000762939453
      policy_entropy: 24.672321319580078
      policy_loss: 45.561580657958984
      var_gnorm: 23.24563217163086
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 118.22803497314453
    num_steps_sampled: 9605000
    num_steps_trained: 9605000
    wait_time_ms: 72.901
  iterations_since_restore: 1921
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16900.545496225357
  time_this_iter_s: 8.590715646743774
  time_total_s: 16900.545496225357
  timestamp: 1594865479
  timesteps_since_restore: 9605000
  timesteps_this_iter: 5000
  timesteps_total: 9605000
  training_iteration: 1921
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16900 s, 1921 iter, 9605000 ts, 344 rew

agent-1: 43.39999999844227
agent-2: 43.39999999844227
agent-3: 42.39999999844226
agent-4: 40.399999998442254
agent-5: 46.399999998442276
Extrinsic Rewards:
5
5
4
2
8
Sum Reward: 24
Avg Reward: 4.8
Min Reward: 2
Max Reward: 8
Gini Coefficient: 0.21666666666666667
20:20 Ratio: 4.0
Max-min Ratio: 4.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 343.4918824009168
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1921
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.557
    dispatch_time_ms: 8.405
    learner:
      cur_lr: 0.0007203069981187582
      grad_gnorm: 19.063800811767578
      policy_entropy: 21.864608764648438
      policy_loss: -1.5171481370925903
      var_gnorm: 23.236600875854492
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.2640073895454407
    num_steps_sampled: 9610000
    num_steps_trained: 9610000
    wait_time_ms: 74.591
  iterations_since_restore: 1922
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16909.041474103928
  time_this_iter_s: 8.495977878570557
  time_total_s: 16909.041474103928
  timestamp: 1594865487
  timesteps_since_restore: 9610000
  timesteps_this_iter: 5000
  timesteps_total: 9610000
  training_iteration: 1922
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16909 s, 1922 iter, 9610000 ts, 343 rew

agent-1: 50.799999992330434
agent-2: 48.79999999233043
agent-3: 49.799999992330434
agent-4: 55.799999992330434
agent-5: 46.79999999233043
Extrinsic Rewards:
6
4
5
11
2
Sum Reward: 28
Avg Reward: 5.6
Min Reward: 2
Max Reward: 11
Gini Coefficient: 0.2857142857142857
20:20 Ratio: 5.5
Max-min Ratio: 5.5
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 343.9418824006147
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1922
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.875
    dispatch_time_ms: 7.299
    learner:
      cur_lr: 0.0007199739920906723
      grad_gnorm: 3.549586772918701
      policy_entropy: 23.967390060424805
      policy_loss: -0.2177780121564865
      var_gnorm: 23.242172241210938
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.00975786242634058
    num_steps_sampled: 9615000
    num_steps_trained: 9615000
    wait_time_ms: 74.137
  iterations_since_restore: 1923
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16917.528235435486
  time_this_iter_s: 8.486761331558228
  time_total_s: 16917.528235435486
  timestamp: 1594865496
  timesteps_since_restore: 9615000
  timesteps_this_iter: 5000
  timesteps_total: 9615000
  training_iteration: 1923
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16917 s, 1923 iter, 9615000 ts, 344 rew

agent-1: 53.59999999482183
agent-2: 54.59999999482183
agent-3: 61.59999999482184
agent-4: 53.59999999482183
agent-5: 55.59999999482183
Extrinsic Rewards:
4
5
12
4
6
Sum Reward: 31
Avg Reward: 6.2
Min Reward: 4
Max Reward: 12
Gini Coefficient: 0.23225806451612904
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 342.771882409151
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1923
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.914
    dispatch_time_ms: 7.285
    learner:
      cur_lr: 0.0007196409860625863
      grad_gnorm: 25.170040130615234
      policy_entropy: 24.532432556152344
      policy_loss: -2.628465175628662
      var_gnorm: 23.23414421081543
      vf_explained_var: 0.0
      vf_loss: 0.47610101103782654
    num_steps_sampled: 9620000
    num_steps_trained: 9620000
    wait_time_ms: 74.342
  iterations_since_restore: 1924
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16925.990047454834
  time_this_iter_s: 8.461812019348145
  time_total_s: 16925.990047454834
  timestamp: 1594865504
  timesteps_since_restore: 9620000
  timesteps_this_iter: 5000
  timesteps_total: 9620000
  training_iteration: 1924
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16925 s, 1924 iter, 9620000 ts, 343 rew

agent-1: 105.59999962612389
agent-2: 104.59999962612385
agent-3: 99.59999962612383
agent-4: 101.59999962612382
agent-5: 92.59999962612383
Extrinsic Rewards:
16
15
10
12
3
Sum Reward: 56
Avg Reward: 11.2
Min Reward: 3
Max Reward: 16
Gini Coefficient: 0.22142857142857142
20:20 Ratio: 5.333333333333333
Max-min Ratio: 5.333333333333333
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-11-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 344.3018823924332
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1924
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.699
    dispatch_time_ms: 7.57
    learner:
      cur_lr: 0.0007193079800345004
      grad_gnorm: 2.480226993560791
      policy_entropy: 18.144332885742188
      policy_loss: -0.09683532267808914
      var_gnorm: 23.24078369140625
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.004746240098029375
    num_steps_sampled: 9625000
    num_steps_trained: 9625000
    wait_time_ms: 77.411
  iterations_since_restore: 1925
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16934.531464338303
  time_this_iter_s: 8.541416883468628
  time_total_s: 16934.531464338303
  timestamp: 1594865513
  timesteps_since_restore: 9625000
  timesteps_this_iter: 5000
  timesteps_total: 9625000
  training_iteration: 1925
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16934 s, 1925 iter, 9625000 ts, 344 rew

agent-1: 33.39999999918989
agent-2: 32.399999999189845
agent-3: 36.39999999918986
agent-4: 35.39999999918988
agent-5: 33.39999999918989
Extrinsic Rewards:
3
2
6
5
3
Sum Reward: 19
Avg Reward: 3.8
Min Reward: 2
Max Reward: 6
Gini Coefficient: 0.21052631578947367
20:20 Ratio: 3.0
Max-min Ratio: 3.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-02
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 344.0318823924853
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1925
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.915
    dispatch_time_ms: 6.871
    learner:
      cur_lr: 0.0007189749740064144
      grad_gnorm: 28.819049835205078
      policy_entropy: 20.1173095703125
      policy_loss: -2.8816957473754883
      var_gnorm: 23.23517608642578
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.6426677703857422
    num_steps_sampled: 9630000
    num_steps_trained: 9630000
    wait_time_ms: 76.596
  iterations_since_restore: 1926
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16942.997968673706
  time_this_iter_s: 8.466504335403442
  time_total_s: 16942.997968673706
  timestamp: 1594865522
  timesteps_since_restore: 9630000
  timesteps_this_iter: 5000
  timesteps_total: 9630000
  training_iteration: 1926
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.1/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16942 s, 1926 iter, 9630000 ts, 344 rew

agent-1: 40.999999996904535
agent-2: 46.999999996904535
agent-3: 47.99999999690455
agent-4: 41.999999996904535
agent-5: 46.999999996904535
Extrinsic Rewards:
1
7
8
2
7
Sum Reward: 25
Avg Reward: 5.0
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.304
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-10
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 342.23188239494885
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1926
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.924
    dispatch_time_ms: 8.735
    learner:
      cur_lr: 0.0007186420261859894
      grad_gnorm: 4.256716251373291
      policy_entropy: 26.088123321533203
      policy_loss: -0.7027543187141418
      var_gnorm: 23.241641998291016
      vf_explained_var: 5.960464477539063e-08
      vf_loss: 0.011942525394260883
    num_steps_sampled: 9635000
    num_steps_trained: 9635000
    wait_time_ms: 77.054
  iterations_since_restore: 1927
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16951.521181344986
  time_this_iter_s: 8.523212671279907
  time_total_s: 16951.521181344986
  timestamp: 1594865530
  timesteps_since_restore: 9635000
  timesteps_this_iter: 5000
  timesteps_total: 9635000
  training_iteration: 1927
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16951 s, 1927 iter, 9635000 ts, 342 rew

agent-1: 95.1999999186244
agent-2: 86.19999991862441
agent-3: 91.1999999186244
agent-4: 103.19999991862439
agent-5: 92.1999999186244
Extrinsic Rewards:
12
3
8
20
9
Sum Reward: 52
Avg Reward: 10.4
Min Reward: 3
Max Reward: 20
Gini Coefficient: 0.2923076923076923
20:20 Ratio: 6.666666666666667
Max-min Ratio: 6.666666666666667
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-19
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 345.11188239092485
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1927
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.899
    dispatch_time_ms: 5.704
    learner:
      cur_lr: 0.0007183090201579034
      grad_gnorm: 7.63466215133667
      policy_entropy: 28.82474708557129
      policy_loss: -1.1582255363464355
      var_gnorm: 23.23831558227539
      vf_explained_var: 0.0
      vf_loss: 0.0447830855846405
    num_steps_sampled: 9640000
    num_steps_trained: 9640000
    wait_time_ms: 79.057
  iterations_since_restore: 1928
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16960.07638645172
  time_this_iter_s: 8.55520510673523
  time_total_s: 16960.07638645172
  timestamp: 1594865539
  timesteps_since_restore: 9640000
  timesteps_this_iter: 5000
  timesteps_total: 9640000
  training_iteration: 1928
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16960 s, 1928 iter, 9640000 ts, 345 rew

agent-1: 32.79999999950229
agent-2: 37.7999999995023
agent-3: 29.799999999502248
agent-4: 28.799999999502248
agent-5: 32.79999999950228
Extrinsic Rewards:
4
9
1
0
4
Sum Reward: 18
Avg Reward: 3.6
Min Reward: 0
Max Reward: 9
Gini Coefficient: 0.4666666666666667
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-27
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 342.32188239188815
  episode_reward_min: 143.99999999831806
  episodes_this_iter: 1
  episodes_total: 1928
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.729
    dispatch_time_ms: 9.824
    learner:
      cur_lr: 0.0007179760141298175
      grad_gnorm: 40.0
      policy_entropy: 33.32050704956055
      policy_loss: 35.4229736328125
      var_gnorm: 23.242115020751953
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 34.59698486328125
    num_steps_sampled: 9645000
    num_steps_trained: 9645000
    wait_time_ms: 71.62
  iterations_since_restore: 1929
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16968.600066661835
  time_this_iter_s: 8.523680210113525
  time_total_s: 16968.600066661835
  timestamp: 1594865547
  timesteps_since_restore: 9645000
  timesteps_this_iter: 5000
  timesteps_total: 9645000
  training_iteration: 1929
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16968 s, 1929 iter, 9645000 ts, 342 rew

agent-1: 30.599999999554537
agent-2: 30.59999999955453
agent-3: 30.599999999554537
agent-4: 25.599999999554523
agent-5: 26.59999999955453
Extrinsic Rewards:
5
5
5
0
1
Sum Reward: 16
Avg Reward: 3.2
Min Reward: 0
Max Reward: 5
Gini Coefficient: 0.35
20:20 Ratio: Undefined
Max-min Ratio: Undefined
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-36
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 339.8018823950513
  episode_reward_min: 143.9999999977724
  episodes_this_iter: 1
  episodes_total: 1929
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.013
    dispatch_time_ms: 7.646
    learner:
      cur_lr: 0.0007176430081017315
      grad_gnorm: 40.0
      policy_entropy: 31.772228240966797
      policy_loss: -7.0272297859191895
      var_gnorm: 23.230377197265625
      vf_explained_var: 0.0
      vf_loss: 1.6231234073638916
    num_steps_sampled: 9650000
    num_steps_trained: 9650000
    wait_time_ms: 75.092
  iterations_since_restore: 1930
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16977.035240888596
  time_this_iter_s: 8.435174226760864
  time_total_s: 16977.035240888596
  timestamp: 1594865556
  timesteps_since_restore: 9650000
  timesteps_this_iter: 5000
  timesteps_total: 9650000
  training_iteration: 1930
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16977 s, 1930 iter, 9650000 ts, 340 rew

agent-1: 155.99996795873025
agent-2: 149.99996795873025
agent-3: 142.99996795873028
agent-4: 149.99996795873025
agent-5: 165.99996795873028
Extrinsic Rewards:
20
14
7
14
30
Sum Reward: 85
Avg Reward: 17.0
Min Reward: 7
Max Reward: 30
Gini Coefficient: 0.2447058823529412
20:20 Ratio: 4.285714285714286
Max-min Ratio: 4.285714285714286
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-44
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 344.7518807934799
  episode_reward_min: 143.9999999977724
  episodes_this_iter: 1
  episodes_total: 1930
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.165
    dispatch_time_ms: 7.054
    learner:
      cur_lr: 0.0007173100020736456
      grad_gnorm: 40.0
      policy_entropy: 29.614763259887695
      policy_loss: 23.70123863220215
      var_gnorm: 23.23471450805664
      vf_explained_var: -2.384185791015625e-07
      vf_loss: 42.662994384765625
    num_steps_sampled: 9655000
    num_steps_trained: 9655000
    wait_time_ms: 74.947
  iterations_since_restore: 1931
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16985.717915296555
  time_this_iter_s: 8.682674407958984
  time_total_s: 16985.717915296555
  timestamp: 1594865564
  timesteps_since_restore: 9655000
  timesteps_this_iter: 5000
  timesteps_total: 9655000
  training_iteration: 1931
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 41.0/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16985 s, 1931 iter, 9655000 ts, 345 rew

agent-1: 32.99999999875501
agent-2: 32.99999999875501
agent-3: 36.999999998754994
agent-4: 36.999999998754994
agent-5: 39.999999998755
Extrinsic Rewards:
1
1
5
5
8
Sum Reward: 20
Avg Reward: 4.0
Min Reward: 1
Max Reward: 8
Gini Coefficient: 0.36
20:20 Ratio: 8.0
Max-min Ratio: 8.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-12-53
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 344.21188079389555
  episode_reward_min: 143.9999999977724
  episodes_this_iter: 1
  episodes_total: 1931
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 3.115
    dispatch_time_ms: 9.421
    learner:
      cur_lr: 0.0007169769960455596
      grad_gnorm: 20.676780700683594
      policy_entropy: 17.401792526245117
      policy_loss: -3.139450788497925
      var_gnorm: 23.231666564941406
      vf_explained_var: 1.1920928955078125e-07
      vf_loss: 0.28946781158447266
    num_steps_sampled: 9660000
    num_steps_trained: 9660000
    wait_time_ms: 75.244
  iterations_since_restore: 1932
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 16994.42020893097
  time_this_iter_s: 8.702293634414673
  time_total_s: 16994.42020893097
  timestamp: 1594865573
  timesteps_since_restore: 9660000
  timesteps_this_iter: 5000
  timesteps_total: 9660000
  training_iteration: 1932
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 16994 s, 1932 iter, 9660000 ts, 344 rew

agent-1: 36.59999999907414
agent-2: 34.59999999907415
agent-3: 40.599999999074136
agent-4: 39.599999999074136
agent-5: 37.59999999907415
Extrinsic Rewards:
3
1
7
6
4
Sum Reward: 21
Avg Reward: 4.2
Min Reward: 1
Max Reward: 7
Gini Coefficient: 0.2857142857142857
20:20 Ratio: 7.0
Max-min Ratio: 7.0
Result for A3C_harvest_env_0:
  custom_metrics: {}
  date: 2020-07-15_22-13-13
  done: false
  episode_len_mean: 1000.0
  episode_reward_max: 942.588553021036
  episode_reward_mean: 340.7018809278795
  episode_reward_min: 143.9999999977724
  episodes_this_iter: 1
  episodes_total: 1932
  experiment_id: 1fc15ecc34c14fe6a196b7af09cc3531
  hostname: gpu009
  info:
    apply_time_ms: 2.796
    dispatch_time_ms: 35.38
    learner:
      cur_lr: 0.0007166439900174737
      grad_gnorm: 6.692590713500977
      policy_entropy: 13.539861679077148
      policy_loss: 0.12187255918979645
      var_gnorm: 23.238258361816406
      vf_explained_var: -1.1920928955078125e-07
      vf_loss: 0.03445446118712425
    num_steps_sampled: 9665000
    num_steps_trained: 9665000
    wait_time_ms: 52.498
  iterations_since_restore: 1933
  node_ip: 172.17.8.9
  num_metric_batches_dropped: 0
  pid: 26851
  policy_reward_mean: {}
  time_since_restore: 17014.401109695435
  time_this_iter_s: 19.980900764465332
  time_total_s: 17014.401109695435
  timestamp: 1594865593
  timesteps_since_restore: 9665000
  timesteps_this_iter: 5000
  timesteps_total: 9665000
  training_iteration: 1933
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 2.0/2 CPUs, 0/1 GPUs
Memory usage on this node: 40.9/202.5 GB
Result logdir: /h/zhaostep/ray_results/harvest_A3C
RUNNING trials:
 - A3C_harvest_env_0:	RUNNING [pid=26851], 17014 s, 1933 iter, 9665000 ts, 341 rew

agent-1: 63.79999998440469
agent-2: 69.7999999844046
agent-3: 68.79999998440458
agent-4: 67.7999999844046
agent-5: 71.7999999844046
Extrinsic Rewards:
3
9
8
7
11
Sum Reward: 38
Avg Reward: 7.6
Min Reward: 3
Max Reward: 11
Gini Coefficient: 0.18947368421052632
20:20 Ratio: 3.6666666666666665
Max-min Ratio: 3.6666666666666665
